@article{10.1145/3676499,
author = {Jin, Xiaofu and Fan, Mingming},
title = {EarMonitor: Non-clinical Assessment of Ear Health Conditions Using a Low-cost Endoscope Camera on Smartphones},
year = {2024},
issue_date = {September 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {8},
number = {MHCI},
url = {https://doi.org/10.1145/3676499},
doi = {10.1145/3676499},
abstract = {Hearing loss affects 20\% of the global population, a rate that is increasing dramatically as the world's population ages. Early prevention and identification of ear diseases can significantly reduce the risk of becoming disabled with hearing impairment. We proposeEarMonitor, an interactive, vision-based ear health monitoring system that enables users to examine their ear conditions with a low-cost hand-held endoscope.EarMonitor can detect six ear health conditions suitable for self-assessment. It can particularly recognize complications from ear diseases, helping users better understand the results. In the wild, our computer vision algorithm achieves a detection sensitivity of 0.949 for earwax buildup and blockage in 100 external auditory canal photos; our deep learning model achieves an average detection sensitivity of 0.861 for the other five conditions considering complications in 350 tympanic membrane photos. We validatedEarMonitor 's effectiveness through a user study involving 17 participants and two experts, leading to valuable insights regarding the design and interpretation of non-clinical assessment devices.},
journal = {Proc. ACM Hum.-Comput. Interact.},
month = sep,
articleno = {254},
numpages = {20},
keywords = {computer vision, ear health, mobile health}
}

@article{10.1145/3676530,
author = {Nellore, Nidhi and Mishra, Tania and Zimmer, Michael},
title = {Unveiling User Perspectives: Exploring Themes in Femtech Mobile App Reviews for Enhanced Usability and Privacy},
year = {2024},
issue_date = {September 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {8},
number = {MHCI},
url = {https://doi.org/10.1145/3676530},
doi = {10.1145/3676530},
abstract = {Femtech, a growing sector in mobile healthcare technology, caters to women's needs across various life stages with digital solutions like period tracking and pregnancy management apps. Maintaining robust data privacy is crucial due to the sensitive nature of the information involved, such as menstrual cycles and pregnancy status. Our research analyzes user feedback from platforms like the Apple App Store and Google Play Store to understand perceptions of femtech apps, covering accessibility, interface, features, and privacy concerns. Understanding user perspectives helps developers enhance usability and trust, driving further adoption. Prioritizing privacy also fosters industry advancement. This paper stresses the importance of dialogue among developers, users, and policymakers in femtech. Our findings aim to facilitate positive change within the femtech sector, leading to more inclusive, user-centric, and ethically driven advancements, benefiting both the industry and its users.},
journal = {Proc. ACM Hum.-Comput. Interact.},
month = sep,
articleno = {283},
numpages = {21},
keywords = {femtech, mobile applications, mobile health, privacy, user experience, user review analysis}
}

@article{10.1145/3676503,
author = {Sato, Yukina and Amesaka, Takashi and Yamamoto, Takumi and Watanabe, Hiroki and Sugiura, Yuta},
title = {Exploring User-Defined Gestures as Input for Hearables and Recognizing Ear-Level Gestures with IMUs},
year = {2024},
issue_date = {September 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {8},
number = {MHCI},
url = {https://doi.org/10.1145/3676503},
doi = {10.1145/3676503},
abstract = {Hearables are highly functional earphone-type wearables; however, existing input methods using stand-alone hearables are limited in the number of commands, and there is a need to extend device operation through hand gestures. In previous research on hearables for hand input, user understanding and gesture recognition systems have been developed. However, in the realm of user understanding, investigation concerning hand input with hearables remains incomplete, and existing recognition systems have not demonstrated proficiency in discerning user-defined gestures. In this study, we conducted a gesture elicitation study (GES) assuming hand input using hearables under six conditions (three interaction areas x two device shapes). Then, we extracted ear-level gestures that the device's built-in IMU sensor could recognize from the user-defined gestures and investigated the recognition performance. The results of sitting experiments showed that the gesture recognition rate for in-ear devices was 91.0\% and that for ear-hook devices was 74.7\%.},
journal = {Proc. ACM Hum.-Comput. Interact.},
month = sep,
articleno = {258},
numpages = {23},
keywords = {gesture elicitation study, hands gesture recognition, hearables, imu, user-defined gesture}
}

@article{10.1145/3676510,
author = {Gei\ss{}ler, Daniel and Bello, Hymalai and Zahn, Esther and Woop, Emil and Zhou, Bo and Lukowicz, Paul and Karolus, Jakob},
title = {Head 'n Shoulder: Gesture-Driven Biking Through Capacitive Sensing Garments to Innovate Hands-Free Interaction},
year = {2024},
issue_date = {September 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {8},
number = {MHCI},
url = {https://doi.org/10.1145/3676510},
doi = {10.1145/3676510},
abstract = {Distractions caused by digital devices are increasingly causing dangerous situations on the road, particularly for more vulnerable road users like cyclists. While researchers have been exploring ways to enable richer interaction scenarios on the bike, safety concerns are frequently neglected and compromised. In this work, we propose Head 'n Shoulder, a gesture-driven approach to bike interaction without affecting bike control, based on a wearable garment that allows hands- and eyes-free interaction with digital devices through integrated capacitive sensors. It achieves an average accuracy of 97\% in the final iteration, evaluated on 14 participants. Head 'n Shoulder does not rely on direct pressure sensing, allowing users to wear their everyday garments on top or underneath, not affecting recognition accuracy. Our work introduces a promising research direction: easily deployable smart garments with a minimal set of gestures suited for most bike interaction scenarios, sustaining the rider's comfort and safety.},
journal = {Proc. ACM Hum.-Comput. Interact.},
month = sep,
articleno = {265},
numpages = {20},
keywords = {bike interaction, bike safety, capacitive sensing, gesture recognition}
}

@article{10.1145/3676526,
author = {Nasser, Arshad and Hasan, Khalad},
title = {ThermoGrasp: Enabling Localized Thermal Feedback on Fingers for Precision Grasps in Virtual Reality},
year = {2024},
issue_date = {September 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {8},
number = {MHCI},
url = {https://doi.org/10.1145/3676526},
doi = {10.1145/3676526},
abstract = {The increasing interest in thermal haptic feedback devices, particularly for virtual reality (VR) applications, highlights the need for more immersive user experiences. However, replicating precise thermal sensations on the fingers remains challenging due to the complexity of finger joints and movements. In this paper, we introduce ThermoGrasp, a novel thermal display designed to enhance VR experiences by providing realistic thermal feedback during precision object grasping. ThermoGrasp is a modular wearable device that targets controlled thermal feedback on the distal phalanges. The implications of designing its VR application were assessed through two experimental studies. The first study focused on the device's ability to accurately convey thermal sensations across different fingers during various precision grasps. The second study investigated the overall haptic experience in VR, examining the impact of thermal feedback on user immersion and realism during interactions with objects of varying temperatures. Participants' subjective responses were analyzed based on factors such as autotelicity, expressiveness, immersion, realism, and harmony. The findings indicate that precise, localized thermal feedback significantly enhances the VR experience, offering a marked improvement over traditional haptic feedback methods.},
journal = {Proc. ACM Hum.-Comput. Interact.},
month = sep,
articleno = {279},
numpages = {21},
keywords = {thermal haptics, virtual reality, wearable devices}
}

@article{10.1145/3665929,
author = {Bandung, Yoanes and Wicaksono, Mokhamad Arfan and Pribadi, Sean and Langi, Armein Z. R. and Tanjung, Dion},
title = {IoT Video Delivery Optimization through Machine Learning-Based Frame Resolution Adjustment},
year = {2024},
issue_date = {September 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {20},
number = {9},
issn = {1551-6857},
url = {https://doi.org/10.1145/3665929},
doi = {10.1145/3665929},
abstract = {Providing acceptable video quality in the Internet of Things (IoT) implementation poses a significant challenge, mainly when the application is performed on low-cost and low-power devices. This research focuses on developing a frame resolution adjustment system that maintains the frame rate value of video delivery in wireless IoT environments with resource-constrained devices. Consistent frame rates prevent motion lag and data loss, improving user experience. The system works by predicting the upcoming throughput values using machine learning methods to adjust the sensing parameter, which is the resolution of the video frame to be captured by camera nodes. Hence, the proposed system is equipped with a file size estimator to estimate the size of the next video frame and then adjust the resolution in accordance with the throughput prediction. In this research, we conducted extensive experiments to evaluate the accuracy of the file size estimator and the throughput prediction. The experiment generated a dataset to evaluate throughput prediction and file size estimator model. The evaluation results for the file size estimator showed a mean absolute percentage error (MAPE) of 6.73\% in the experiment using 317 frames with video resolutions between 72p and 720p. Experiments were also conducted to compare several machine learning methods for predicting throughput values. Compared to long short-term memory (LSTM) and autoregressive integrated moving average (ARIMA), simple exponential smoothing (SES) outperforms the others with the lowest root mean squared error (RMSE) and mean absolute error (MAE) values. Building upon these findings, we implemented the frame resolution adjustment system using SES as the method for predicting the upcoming throughput values. Finally, we demonstrated that the proposed system can maintain the frame rate according to the threshold set by the system while the resolution is being maximized, thereby addressing the challenges of maintaining video quality in resource-constrained IoT environments.},
journal = {ACM Trans. Multimedia Comput. Commun. Appl.},
month = sep,
articleno = {277},
numpages = {24},
keywords = {Internet of video things, machine learning, time series forecasting, throughput prediction, file size estimator}
}

@inproceedings{10.1145/3677779.3677811,
author = {Dong, Jianmin},
title = {The application of spread spectrum technology in information automatic acquisition systems},
year = {2024},
isbn = {9798400709760},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3677779.3677811},
doi = {10.1145/3677779.3677811},
abstract = {Low voltage power carrier communication requires high requirements, and the current power information collection system has problems such as unstable collection, poor real-time performance, and inability to collect all low-voltage power user information. Therefore, for low-voltage power, a user information automatic collection system is proposed with spread spectrum communication as technical support. Utilize components such as data concentrators, data acquisition terminals, carrier energy meters, meter reader, and main stations to construct the structural framework of the low-voltage power user information automatic collection system. Using the main station section, concentrator control section, terminal carrier section, and concentrator carrier section, based on the corresponding module operating environment, the software part of the automatic acquisition system is formed. Finally, using spread spectrum communication technology, a code division multiple access strategy is designed to maintain the consistency of the spread spectrum code sequence between the sending and receiving ends. The experimental results show that regardless of whether the network condition is good or not, data cannot be transmitted continuously, and there is always a gap in the middle. Therefore, there is a significant difference in values between the uplink and downlink, with a minimum value of 0 dB and a maximum value of 55 dB. The communication performance of the system in this paper is good and can meet the practical application needs of complex power networks with multiple interference factors. Due to the large number of available channels, it can effectively avoid the affected frequency bands, greatly improving the communication completion rate. Channel 20 still maintains communication, indicating that the system in this paper has strong immune performance and reception sensitivity, making effective use of spectrum resources. It has been proven that the established system has significant advantages in acquisition accuracy and efficiency. When applied in complex power practical scenarios, the system can still achieve good communication performance, and has superior immune performance and reception sensitivity.},
booktitle = {Proceedings of the International Conference on Modeling, Natural Language Processing and Machine Learning},
pages = {193–197},
numpages = {5},
location = {Xi'an, China},
series = {CMNM '24}
}

@inproceedings{10.1145/3678299.3678304,
author = {Kantan, Prithvi Ravi and Dahl, Sofia and J\o{}rgensen, Helle Rovsing and Spaich, Erika G.},
title = {Making Movement Sonification Usable in Clinical Gait Rehabilitation: A User-Centered Study},
year = {2024},
isbn = {9798400709685},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3678299.3678304},
doi = {10.1145/3678299.3678304},
abstract = {Sound-assisted movement rehabilitation is one of the most interesting and socially relevant applications of sonic interaction research, and existing research shows the potential of movement sonification to enhance patient motivation and movement re-learning. However, this technology is not routinely adopted in practice due to fragmented evidence of clinical effectiveness, feasibility, and usability. A key but little-explored challenge is that of designing and developing sonification systems that can readily be set up, configured, and applied by physiotherapists in a manner compatible with clinical practices and tailorable to individual patient needs and capacities, as well as training goals. In this work, we carried out an iterative user-centered design process to develop a sonification system for clinical gait rehabilitation of hemiparetic patients. This yielded a fully functional system that integrated wireless wearable inertial sensors with a laptop-based software interface for physiotherapists to configure and adjust the feedback on the fly. The feedback was ecologically based (naturalistic wading sounds) and highly individualizable through patient-specific adjustments. The system was evaluated in a real-life clinical feasibility study involving four physiotherapists and seven hemiparetic patients (4M,3F, mean age 56.14 ± 15.45). Overall, the physiotherapists found the system easy to set up and seamless to use during training, although they expressed a need for more system portability, a set of additional feedback configuration functions, and extra training / practice with using the more advanced feedback adjustment controls. While future work should address these findings and systematically explore clinical effectiveness in terms of motor learning outcomes, we believe that this work can serve to guide the design of clinically usable movement sonification systems targeting a breadth of rehabilitative applications.},
booktitle = {Proceedings of the 19th International Audio Mostly Conference: Explorations in Sonic Cultures},
pages = {43–60},
numpages = {18},
keywords = {Biofeedback, Ecological Feedback, Gait, Movement Sonification, Rehabilitation Technology, User-Centered Design},
location = {Milan, Italy},
series = {AM '24}
}

@inproceedings{10.1145/3678299.3678305,
author = {Kantan, Prithvi Ravi and Dahl, Sofia and Spaich, Erika G.},
title = {Developing Enjoyable Auditory Feedback Paradigms to Alleviate Toe Walking in Children with Cerebral Palsy},
year = {2024},
isbn = {9798400709685},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3678299.3678305},
doi = {10.1145/3678299.3678305},
abstract = {Movement sonification has great potential as an auditory feedback tool to enhance motor learning. A user group that has received relatively little attention is children with cerebral palsy, who commonly exhibit ‘toe walking’, which is characterized by lacking heel contact with the ground during stepping. Sonification designs aiming to alleviate this commonly employ simplistic feedback sounds (e.g. buzzing or clicking), which not only are unsuitable for sustained use with children, but also undershoot the potential of the auditory medium to promote motivation, engagement, and meaningful perception-action coupling during training. To address this, we established an overall feedback design direction based on past literature and discussions with stakeholders. Accordingly, we built a technological framework for lightweight wireless motion sensing, sonification prototyping, and real-time testing. Next, we developed and showcased five novel feedback paradigms to inform on toe walking and reward heel strike through a combination of rich ecological sounds aimed at promoting playfulness and engagement while providing salient and meaningful positive reinforcement. Future work will test the feasibility and motor learning effects of these (and similar) paradigms while also investigating their optimal application in clinical and home environments. We believe that this work can serve as an important step towards countering the long term effects of toe walking in many children with cerebral palsy through sonic interaction.},
booktitle = {Proceedings of the 19th International Audio Mostly Conference: Explorations in Sonic Cultures},
pages = {61–67},
numpages = {7},
keywords = {Cerebral Palsy, Real-time Interaction, Rehabilitation, Sonification},
location = {Milan, Italy},
series = {AM '24}
}

@inproceedings{10.1145/3678299.3678354,
author = {Carson, Tate and Gordon, Carter},
title = {Resonant Landscapes},
year = {2024},
isbn = {9798400709685},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3678299.3678354},
doi = {10.1145/3678299.3678354},
abstract = {Resonant Landscapes is a web application that integrates ambisonics and GPS technology to overlay soundscape recordings from South Dakota state parks onto the campus of Dakota State University (DSU). This project enables users to engage with immersive nature soundscapes in an urban environment, fostering a connection between technology and nature appreciation. By mapping the coordinates of state parks onto physical campus locations, Resonant Landscapes creates a scaled geographical rendering of these parks, allowing users to experience rich acoustic environments through their smartphones and headphones. The application utilizes a body-oriented tracking system, which uses built-in smartphone sensors to dynamically change the listener’s orientation. This paper details the technical implementation of the project, including the recording and post-processing of ambisonic audio, the development of the web-based interface, and the integration of GPS and orientation sensors. We discuss how frugal innovation principles guided our design choices, resulting in an accessible and cost-effective solution. The paper also explores the project’s foundations in soundscape studies, locative media, and ecological awareness. Future developments aim to address current limitations, improve the user experience, and extend the application’s functionality.},
booktitle = {Proceedings of the 19th International Audio Mostly Conference: Explorations in Sonic Cultures},
pages = {525–532},
numpages = {8},
keywords = {Ambisonic Audio, Ecological Awareness, GPS Technology, Head Tracking, Locative Media, Soundscape Studies},
location = {Milan, Italy},
series = {AM '24}
}

@inproceedings{10.1145/3678299.3678313,
author = {Lucena, Raquel and Ramirez, Rafael},
title = {A machine learning approach to gesture detection in violin performance},
year = {2024},
isbn = {9798400709685},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3678299.3678313},
doi = {10.1145/3678299.3678313},
abstract = {Playing a musical instrument is a highly complex activity. It requires mental and sensorimotor skills, which are learned during a long trajectory. Learning to play an instrument typically involves long periods of practice without teacher supervision. Systems providing feedback on the student’s performance during these self-study periods hold significant potential for improving the learning process. We present a machine learning approach to assess the correctness of body gestures in violin performances. We collect images and audio of several violinists performing correct and incorrect postures, extract image and audio descriptors, and apply machine learning algorithms to classify violin gestures. Finally, a real-time feedback system designed for pedagogical use is implemented, in which users receive visual feedback about whether the given gesture is performed properly or not. The system not only has the potential to facilitate the development of sensorimotor skills essential for playing violin, but also can enhance the learning experience for musicians, potentially providing benefits in musical education, performance, and health.},
booktitle = {Proceedings of the 19th International Audio Mostly Conference: Explorations in Sonic Cultures},
pages = {144–151},
numpages = {8},
keywords = {audio features, gesture prediction, machine learning, pose estimation, violin},
location = {Milan, Italy},
series = {AM '24}
}

@article{10.1145/3685695,
author = {Greenlee, Eric and Rothrock, Blaine and Kim, Hyeonwook and Zegura, Ellen and Hester, Josiah},
title = {“The Devil You Know”: Barriers and Opportunities for Co-Designing Microclimate Sensors, A Case Study of Manoomi},
year = {2024},
issue_date = {September 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {2},
number = {3},
url = {https://doi.org/10.1145/3685695},
doi = {10.1145/3685695},
abstract = {Current environmental challenges have profound local consequences and often benefit from the collection of fine-grained microclimate data. Advances in wireless sensor networks and the Internet of Things have led to technologies nominally suited to support remote sensing; however, in practice long-running deployments of in-field environmental sensors are rare. Field conditions are often remote and culturally sensitive, with limited power, Internet, transportation, and human infrastructure; advances in device technology alone will not suffice. We ask how communities, Internet of Things researchers, government, and other interested parties can work together to co-design useful, low burden, sustainability-focused infrastructure. Toward this end, we conducted 11 semi-structured interviews with 13 experts who use or rely on environmental sensing technology. To complement our interview data, we engaged in three months of participant observation while immersed in organizations specifically working toward manoomin (wild rice) conservation. We make two primary contributions. First, we confirm and enrich a five-stage model, the microclimate sensor lifecycle, focusing on desired features and persistent challenges. Second, we outline a space for co-design of microclimate sensors with emphasis on the cost of experience, the generally unaddressed issue of technical usability in the messy field, and the opportunity for community engagement to improve technical design and outcomes. Furthermore, we discuss future design opportunities, recommendations, and challenges in the microclimate sensor design, deployment, and sustainability space.},
journal = {ACM J. Comput. Sustain. Soc.},
month = sep,
articleno = {39},
numpages = {30},
keywords = {Environmental Sensors, Co-design, Community Engagement}
}

@article{10.1145/3685694,
author = {Karmakar, Prasenjit and Pradhan, Swadhin and Chakraborty, Sandip},
title = {Exploring Indoor Air Quality Dynamics in Developing Nations: A Perspective from India},
year = {2024},
issue_date = {September 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {2},
number = {3},
url = {https://doi.org/10.1145/3685694},
doi = {10.1145/3685694},
abstract = {Indoor air pollution is a major issue in developing countries such as India and Bangladesh, exacerbated by factors such as traditional cooking methods, insufficient ventilation, and cramped living conditions, all of which elevate the risk of health issues such as lung infections and cardiovascular diseases. With the World Health Organization associating around 3.2 million annual deaths globally to household air pollution, the gravity of the problem is clear. Yet, extensive empirical studies exploring these unique patterns and indoor pollution’s extent are missing. To fill this gap, we carried out a 6-months long field study involving over 30 households, uncovering the complexity of indoor air pollution in developing countries, such as the longer lingering time of volatile organic compounds (VOCs) in the air or the significant influence of air circulation on the spatiotemporal distribution of pollutants. We introduced an innovative Internet of Things (IoT) air quality sensing platform, the Distributed Air QuaLiTy MONitor (DALTON), explicitly designed to meet the needs of these nations, considering factors such as cost, sensor type, accuracy, network connectivity, power, and usability. As a result of a multi-device deployment, the platform identifies pollution hot spots in low- and middle-income households in developing nations. It identifies best practices to minimize daily indoor pollution exposure. Our extensive qualitative survey estimates an overall system usability score of 2.04, indicating an efficient system for air quality monitoring.},
journal = {ACM J. Comput. Sustain. Soc.},
month = sep,
articleno = {40},
numpages = {40},
keywords = {Indoor pollution, pollution dynamics, best practices}
}

@inproceedings{10.1145/3678726.3678770,
author = {Quinto, Edward Jay Mansarate and Elizaga, Lance Austin Go and Basister, Michel P and Abdon, Ria Grace P and Castillo, John Christopher Dimasaka and Ebreo, Jeanne Elyzza S.},
title = {Outcomes Attainment in Online Learning: An Analysis of Engineering Students' Perceptions},
year = {2024},
isbn = {9798400717611},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3678726.3678770},
doi = {10.1145/3678726.3678770},
abstract = {Apart from COVID-19 striking as a global health crisis, the COVID-19 pandemic has evolved into an educational dilemma, wherein schools and institutions scrambled to buffer through various instructional innovations in the delivery of online or distance learning. Outcome-Based Education (OBE) has been utilized as a framework to ‘organize everything in the [online] educational system around what is essential for all students to be able to do successfully at the end of their learning experience’ [21] in hopes of addressing the everyday challenges to teaching and learning brought by the pandemic. Since OBE has been widely a used framework since its introduction in 1994 and more so during the pandemic, it is imperative to examine the context-specific experiences of students as they navigated through the demands of outcomes attainment in online learning. In this study, we conducted online structured interviews among (n=177) students enrolled in various engineering programs in four (4) Philippine universities that use OBE as their framework for teaching and learning in the online setup. Thematic analysis using MAXQDA Plus 2022 revealed themes and unpacked students’ views about the positive and negative drivers of outcomes attainment in online learning. Particularly, the analysis yielded factors that students perceive to influence their capacity to learn in online contexts, types of support services that students perceive to help them succeed in online learning, factors that influence online learners’ feelings or sense of accomplishment, and strategies that students deploy to ensure success in online learning. The results can help administrators and teachers to develop ways to support students to succeed at demonstrating course outcomes in online learning contexts.},
booktitle = {Proceedings of the 2024 8th International Conference on Education and Multimedia Technology},
pages = {235–241},
numpages = {7},
location = {Tokyo, Japan},
series = {ICEMT '24}
}

@inproceedings{10.1145/3670243.3670263,
author = {Hage, Roger and Kormann-Hainzl, Gerhard and Ruiz-Torrubiano, Ruben},
title = {Facilitating Environmental Monitoring for Sustainable Smart Regions by Enabling Citizen Co-Creation},
year = {2024},
isbn = {9798400717093},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3670243.3670263},
doi = {10.1145/3670243.3670263},
abstract = {In this paper, a conceptual framework designed to transform citizens in sustainable and smart regions from passive users and consumers into active co-creating citizen developers through a Low-Code and No-Code (LCNC) Smart Service Manager is presented. The platform leverages both regional and individual data to underpin the development of smart services on a broad scale. In particular, it advances environmental monitoring and carbon footprint reduction initiatives in accordance with the framework outlined in this paper. By integrating sensor networks and open data sources, the LCNC platform supports the development of personalised smart services, enabling citizens to actively engage in monitoring and visualising their environmental impact. The framework facilitates community collaboration and co-creation, empowering individual citizens and local communities to not only participate in the ideation and development of these services but also to individualise and continuously improve the services by adding new features and contributing data via personal devices such as smart meters and smartphones. The democratisation of technology use is designed to encourage sustainable behavioural changes and to improve the overall quality of life in smart regions. We illustrate the application of this framework through a use case on energy CO2 footprint reduction, demonstrating how co-creative processes can enhance community engagement and accelerate the implementation of sustainability transformations in urban settings.},
booktitle = {Proceedings of the Central and Eastern European EDem and EGov Days 2024},
pages = {70–76},
numpages = {7},
keywords = {Co-creation, Smart services, Sustainability},
location = {Budapest, Hungary},
series = {CEEeGov '24}
}

@inproceedings{10.1145/3670243.3673857,
author = {Alexei, Arina and Platon, Nicolae and Bolun, Ion and Alexei, Anatolie},
title = {Smart and Digital Healthcare. Advanced Technologies and Security Issues},
year = {2024},
isbn = {9798400717093},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3670243.3673857},
doi = {10.1145/3670243.3673857},
abstract = {Smart and Digital healthcare is governed by ICT (Information and Communication Technology) and uses interconnected devices through communication networks to manage medical data, monitor patient status, manage hospitals and interact with government agencies. Multiple types of network architectures are used to be able to implement Digital Healthcare, some of them use the bottom-up approach, while others use the top-down approach. In Smart Healthcare, in addition to the advanced features of ICT, modern technologies such as IoT and sensors, Big Data and Data Mining, Deep Learning, Cloud Computing, Fog Computing and Edge Computing, Artificial Intelligence and Machine Learning are implemented. However, since the digitization process, the security challenges in Healthcare are also growing exponentially, so critical security threats can cause considerable damage, even threatening the lives of patients. The purpose of the scientific article is to create an overview of e-healthcare and s-healthcare practices and the security challenges they face, as well as to review the security technologies to be implemented, to traditional ones such as: encryption, access control, hashing, redundancy etc.; to advanced security technologies such as blockchain, artificial intelligence, cyber-physical system and quantum cryptography.},
booktitle = {Proceedings of the Central and Eastern European EDem and EGov Days 2024},
pages = {288–294},
numpages = {7},
keywords = {Digital, ICT, healthcare, security, smart, technology},
location = {Budapest, Hungary},
series = {CEEeGov '24}
}

@article{10.1145/3672076,
author = {Mamish, John and Alharbi, Rawan and Sen, Sougata and Holla, Shashank and Kamath, Panchami and Sangar, Yaman and Alshurafa, Nabil and Hester, Josiah},
title = {NIR-sighted: A Programmable Streaming Architecture for Low-Energy Human-Centric Vision Applications},
year = {2024},
issue_date = {November 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {23},
number = {6},
issn = {1539-9087},
url = {https://doi.org/10.1145/3672076},
doi = {10.1145/3672076},
abstract = {Human studies often rely on wearable lifelogging cameras that capture videos of individuals and their surroundings to aid in visual confirmation or recollection of daily activities like eating, drinking, and smoking. However, this may include private or sensitive information that may cause some users to refrain from using such monitoring devices. Also, short battery lifetime and large form factors reduce applicability for long-term capture of human activity. Solving this triad of interconnected problems is challenging due to wearable embedded systems’ energy, memory, and computing constraints. Inspired by this critical use case and the unique design problem, we developed NIR-sighted, an architecture for wearable video cameras that navigates this design space via three key ideas: (i)&nbsp;reduce storage and enhance privacy by discarding masked pixels and frames, (ii)&nbsp;enable programmers to generate effective masks with low computational overhead, and (iii)&nbsp;enable the use of small MCUs by moving masking and compression off-chip. Combined together in an end-to-end system, NIR-sighted’s masking capabilities and off-chip compression hardware shrinks systems, stores less data, and enables programmer-defined obfuscation to yield privacy enhancement. The user’s privacy is enhanced significantly as nowhere in the pipeline is any part of the image stored before it is obfuscated. We design a wearable camera called NIR-sightedCam based on this architecture; it is compact and can record IR and grayscale video at 16 and 20+ fps, respectively, for 26 hours nonstop (59 hours with IR disabled) at a fraction of comparable platforms power draw. NIR-sightedCam includes a low-power Field Programmable Gate Array that implements our mJPEG compress/obfuscate hardware, Blindspot. We additionally show the potential for privacy-enhancing function and clinical utility via an in-lab eating study, validated by a nutritionist.},
journal = {ACM Trans. Embed. Comput. Syst.},
month = sep,
articleno = {101},
numpages = {26},
keywords = {Human-Centric Vision Applications}
}

@article{10.1145/3687239,
author = {Basak, Barnali and Dasgupta, Pallab and Pal, Arpan},
title = {Efficient Low-Memory Implementation of Sparse CNNs Using Encoded Partitioned Hybrid Sparse Format},
year = {2024},
issue_date = {November 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {23},
number = {6},
issn = {1539-9087},
url = {https://doi.org/10.1145/3687239},
doi = {10.1145/3687239},
abstract = {Certain data compression techniques like pruning leads to unstructured sparse Convolution Neural Network (CNN) models without directly leveraging sparsity in optimizing both memory consumption and inference latency of a model having low to medium sparsity. State-of-the-art storage techniques either optimize model size at the cost of execution latency or optimize inference latency at the overhead of the memory consumption of the model. This tradeoff is largely due to the absence of storage selection methodology addressing sparsity sensitivity, arising from varied sparsity and positions of nonzero values called sparsity structure across different sparse layers of a model. However, this issue remains unexplored due to the lack of support to handle sparse data in the current deployment standards for edge devices. This article introduces a data compaction strategy for unstructured sparse data that not only compresses nonzero data but also encodes it, leveraging the memory consumption and latency reduction benefits of both data compression and data encoding techniques. We propose a novel storage representation, named Encoded Partitioned Hybrid Sparse (EPaHS) format, which addresses sparsity sensitivity by customizing data storage based on the sparsity structure of the data. Our data compaction technique and storage solution optimizes the tradeoff between the memory consumption and inference latency of a sparse model without altering the network architecture and affecting its accuracy. Our solution easily extends to higher-dimensional data and outperforms standard storage solutions. It proves to be beneficial to all the valid mode orientations of multi-dimensional data. For an important health and wellness application, a single-lead short-time ECG classification model, EPaHS achieves up to  ({tt 16.18\%})  reduction in size and  ({tt 15.16\%}) reduction in latency when compared to its original model of  ({tt 42})  MB size and  ({tt 26.35})  sec latency, having  ({tt approx 59\%})  sparsity. For a ResNet50 model handling higher-dimensional data, it achieves  ({tt 21.33\%})  size reduction and  ({tt 53.9\%})  latency gain against the original model of  ({tt 3265})  KB size and  ({tt 1.7})  sec latency, having  ({tt approx 67\%})  sparsity.},
journal = {ACM Trans. Embed. Comput. Syst.},
month = sep,
articleno = {103},
numpages = {30},
keywords = {Sparsity structure-sensitive data storage, piecewise encoding, data compaction, encoded partitioned hybrid sparse format}
}

@article{10.1145/3678507,
author = {Liu, Runze and Lu, Taiting and Yuan, Shengming and Zhou, Hao and Gowda, Mahanth},
title = {SmartDampener: An Open Source Platform for Sport Analytics in Tennis},
year = {2024},
issue_date = {September 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {8},
number = {3},
url = {https://doi.org/10.1145/3678507},
doi = {10.1145/3678507},
abstract = {In this paper, we introduce SmartDampener, an open-source tennis analytics platform that redefines the traditional understanding of vibration dampeners. Traditional vibration dampeners favored by both amateur and professional tennis players are utilized primarily to diminish vibration transmission and enhance racket stability. However, our platform uniquely merges wireless sensing technologies into a device that resembles a conventional vibration dampener, thereby offering a range of tennis performance metrics including ball speed, impact location, and stroke type. The design of SmartDampener adheres to the familiar form of this accessory, ensuring that (i) it is readily accepted by users and robust under real-play conditions such as ball-hitting, (ii) it has minimal impact on player performance, (iii) it is capable of providing a wide range of analytical insights, and (iv) it is extensible to other sports. Existing computer vision systems for tennis sensing such as Hawk-eye and PlaySight, rely on hardware that costs millions of US dollars to deploy with complex setup procedures and is susceptible to lighting environment. Wearable devices and other tennis sensing accessories, such as Zepp Tennis sensor and TennisEye, using intrusive mounting locations, hinder user experience and impede player performance. In contrast, SmartDampener, a low-cost and compact tennis sensing device, notable for its socially accepted, lightweight and scalable design, seamlessly melds into the form of a vibration dampener. SmartDampener exploits opportunities in SoC and form factor design of conventional dampeners to integrate the sensing units and micro-controllers on a two-layer flexible PCB, that is bent and enclosed inside a dampener case made of 3D printing TPU material, while maintaining the vibration dampening feature and further being enhanced by its extended battery life and the inclusion of wireless communication features. The overall cost is $9.42, with a dimension of 21.4 mm \texttimes{} 27.5 mm \texttimes{} 9.7 mm (W \texttimes{} L \texttimes{} H) and a weight of 6.1 g and 5.8 hours of battery life. In proof of SmartDampener's performance in tennis analytics, we present various tennis analytic applications that exploit the capability of SmartDampener in capturing the correlations across string vibration, and racket motion, including the estimation of ball speed with a median error of 3.59 mph, estimation of ball impact location with accuracy of 3.03 cm, and classification of six tennis strokes with accuracy of 96.75\%. Finally, extensive usability studies with 15 tennis players indicate high levels of social acceptance of form factor design for the SmartDampener dampener in comparison with alternative form factors, as well as its capability of sensing and analyzing tennis stroke in an accurate and robust manner. We believe this platform will enable exciting applications in other sports like badminton, fitness tracking, and injury prevention.},
journal = {Proc. ACM Interact. Mob. Wearable Ubiquitous Technol.},
month = sep,
articleno = {118},
numpages = {30},
keywords = {IoT, Sport Analytics, Wearable Computing, Wireless Sensing}
}

@article{10.1145/3678591,
author = {Fernandes, Glenn J. and Zheng, Jiayi and Pedram, Mahdi and Romano, Christopher and Shahabi, Farzad and Rothrock, Blaine and Cohen, Thomas and Zhu, Helen and Butani, Tanmeet S. and Hester, Josiah and Katsaggelos, Aggelos K. and Alshurafa, Nabil},
title = {HabitSense: A Privacy-Aware, AI-Enhanced Multimodal Wearable Platform for mHealth Applications},
year = {2024},
issue_date = {September 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {8},
number = {3},
url = {https://doi.org/10.1145/3678591},
doi = {10.1145/3678591},
abstract = {Wearable cameras provide an objective method to visually confirm and automate the detection of health-risk behaviors such as smoking and overeating, which is critical for developing and testing adaptive treatment interventions. Despite the potential of wearable camera systems, adoption is hindered by inadequate clinician input in the design, user privacy concerns, and user burden. To address these barriers, we introduced HabitSense, an open-source1, multi-modal neck-worn platform developed with input from focus groups with clinicians (N=36) and user feedback from in-wild studies involving 105 participants over 35 days. Optimized for monitoring health-risk behaviors, the platform utilizes RGB, thermal, and inertial measurement unit sensors to detect eating and smoking events in real time. In a 7-day study involving 15 participants, HabitSense recorded 768 hours of footage, capturing 420.91 minutes of hand-to-mouth gestures associated with eating and smoking data crucial for training machine learning models, achieving a 92\% F1-score in gesture recognition. To address privacy concerns, the platform records only during likely health-risk behavior events using SECURE, a smart activation algorithm. Additionally, HabitSense employs on-device obfuscation algorithms that selectively obfuscate the background during recording, maintaining individual privacy while leaving gestures related to health-risk behaviors unobfuscated. Our implementation of SECURE has resulted in a 48\% reduction in storage needs and a 30\% increase in battery life. This paper highlights the critical roles of clinician feedback, extensive field testing, and privacy-enhancing algorithms in developing an unobtrusive, lightweight, and reproducible wearable system that is both feasible and acceptable for monitoring health-risk behaviors in real-world settings.},
journal = {Proc. ACM Interact. Mob. Wearable Ubiquitous Technol.},
month = sep,
articleno = {101},
numpages = {48},
keywords = {camera, eating, machine learning, multimodal, privacy, smoking, thermal, vision transformers, wearable}
}

@article{10.1145/3678588,
author = {Aljeraisy, Atheer and Rana, Omer and Perera, Charith},
title = {Empowering IoT Developers with Privacy-Preserving End-User Development Tools},
year = {2024},
issue_date = {September 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {8},
number = {3},
url = {https://doi.org/10.1145/3678588},
doi = {10.1145/3678588},
abstract = {Internet of Things applications (IoT) have the potential to derive sensitive user data, necessitating adherence to privacy and data protection laws. However, developers often struggle with privacy issues, resulting in personal data misuse. Despite the proposed Privacy by Design (PbD) approach, criticism arises due to its ambiguity and lack of practical tools for educating software engineers. We introduce Canella, an integrated IoT development ecosystem with privacy-preserving components leveraging End-User Development (EUD) tools Blockly@rduino and Node-RED, to help developers build end-to-end IoT applications that prioritize privacy and comply with regulations. It helps developers integrate privacy during the development process and rapid prototyping phases, offering real-time feedback on privacy concerns. We start by conducting a focus group study to explore the applicability of designing and implementing PbD schemes within different development environments. Based on this, we implemented a proof-of-concept prototype of Canella and evaluated it in controlled lab studies with 18 software developers. The findings reveal that developers using Canella created more privacy-preserving applications, gained a deeper understanding of personal data management, and achieved better privacy compliance. Our results also highlight Canella's role in educating and promoting privacy awareness, enhancing productivity, streamlining privacy implementation, and significantly reducing cognitive load. Overall, developers found Canella and its privacy-preserving components useful, easy to use, and easy to learn, which could potentially improve IoT application privacy. Watch the demo video.},
journal = {Proc. ACM Interact. Mob. Wearable Ubiquitous Technol.},
month = sep,
articleno = {90},
numpages = {47},
keywords = {Internet of Things, Privacy and Data Protection Laws, Privacy by Design, Programming Environments, Software Developers}
}

@inproceedings{10.1145/3665314.3670840,
author = {Alikhani, Hamidreza and Wang, Ziyu and Kanduri, Anil and Liljeberg, Pasi and Rahmani, Amir M. and Dutt, Nikil},
title = {EA^2: Energy Efficient Adaptive Active Learning for Smart Wearables},
year = {2024},
isbn = {9798400706882},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3665314.3670840},
doi = {10.1145/3665314.3670840},
abstract = {Mobile Health (mHealth) applications rely on supervised Machine Learning (ML) algorithms, requiring end-user-labeled data for the training phase. The gold standard for obtaining such labeled data is by sending queries to users and gathering responses for the corresponding label, which was conventionally done through triggering questions sent at random. Active Learning (AL) methods use intelligent query-sending policies by incorporating users' contextual information to maximize the response rate and informativeness of the collected labeled data. However, wearable devices' substantial battery drainage associated with the sensing of physiological signals underscores the need for developing an efficient sensing policy in addition to a query-sending policy. In this work, we present a co-optimization framework for both sensing and querying strategies within wearable devices, leveraging contextual information and ML model's prediction confidence. We designed a Reinforcement Learning (RL) agent to quantify different contextual parameters combined with model confidence to determine sensing and querying decisions. Our evaluation of an exemplar stress monitoring application showed a 76\% reduction in sensing and data transmission energy consumption, with only a 6\% drop in user-labeled data.},
booktitle = {Proceedings of the 29th ACM/IEEE International Symposium on Low Power Electronics and Design},
pages = {1–6},
numpages = {6},
keywords = {efficient machine learning, data efficiency, active learning, context-aware sensing, reinforcement learning},
location = {Newport Beach, CA, USA},
series = {ISLPED '24}
}

@article{10.1145/3678590,
author = {Li, Bofan and Ren, Yili and Wang, Yichao and Yang, Jie},
title = {SpaceBeat: Identity-aware Multi-person Vital Signs Monitoring Using Commodity WiFi},
year = {2024},
issue_date = {September 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {8},
number = {3},
url = {https://doi.org/10.1145/3678590},
doi = {10.1145/3678590},
abstract = {Vital signs monitoring has gained increasing attention due to its ability to indicate various human health and well-being conditions. The development of WiFi sensing technologies has made it possible to monitor vital signs using ubiquitous WiFi signals and devices. However, most existing approaches are dedicated to single-person scenarios. A few WiFi sensing approaches can achieve multi-person vital signs monitoring, whereas they are not identity-aware and sensitive to interferences in the environment. In this paper, we propose SpaceBeat, an identity-aware and interference-robust multi-person vital sign monitoring system using commodity WiFi. In particular, our system separates multiple people and locates each person in the spatial domain by leveraging multiple antennas. We analyze the change of signals at the location of each person to achieve identity-aware vital signs monitoring. We also design a contrastive principal component analysis-contrastive learning framework to mitigate interferences caused by other moving people. We evaluate SpaceBeat in various challenging environments, including interference scenarios, non-line-of-sight scenarios, different distances, etc. Our system achieves an average accuracy of 99.1\% for breathing monitoring and 97.9\% for heartbeat monitoring.},
journal = {Proc. ACM Interact. Mob. Wearable Ubiquitous Technol.},
month = sep,
articleno = {113},
numpages = {23},
keywords = {Deep contrastive learning, Identity-aware, Interference robust, Multi-person, Vital signs monitoring, WiFi sensing}
}

@article{10.1145/3678575,
author = {Lin, Georgianna and Li, Brenna and Li, Jin Yi and Zhao, Chloe and Truong, Khai and Mariakakis, Alexander},
title = {Users' Perspectives on Multimodal Menstrual Tracking Using Consumer Health Devices},
year = {2024},
issue_date = {September 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {8},
number = {3},
url = {https://doi.org/10.1145/3678575},
doi = {10.1145/3678575},
abstract = {Previous menstrual health literature highlights a variety of signals not included in existing menstrual trackers because they are either difficult to gather or are not typically associated with menstrual health. Since it has become increasingly convenient to collect biomarkers through wearables and other consumer-grade devices, our work examines how people incorporate unconventional signals (e.g., blood glucose levels, heart rate) into their understanding of menstrual health. In this paper, we describe a three-month-long study on fifty participants' experiences as they tracked their health using physiological sensors and daily diaries. We analyzed their experiences with both conventional and unconventional menstrual health signals through surveys and interviews conducted throughout the study. We delve into the various aspects of menstrual health that participants sought to affirm using unconventional signals, explore how these signals influenced their daily behaviors, and examine how multimodal menstrual tracking expanded their scope of menstrual health. Finally, we provide design recommendations for future multimodal menstrual trackers.},
journal = {Proc. ACM Interact. Mob. Wearable Ubiquitous Technol.},
month = sep,
articleno = {116},
numpages = {24},
keywords = {health informatics, holistic health, menstrual health, menstrual tracking, sensemaking, wearable devices}
}

@article{10.1145/3678525,
author = {Jing, Xiaoqing and Yu, Chun and Yue, Kun and Lu, Liangyou and Gao, Nan and Shi, Weinan and Zhang, Mingshan and Wang, Ruolin and Shi, Yuanchun},
title = {AngleSizer: Enhancing Spatial Scale Perception for the Visually Impaired with an Interactive Smartphone Assistant},
year = {2024},
issue_date = {September 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {8},
number = {3},
url = {https://doi.org/10.1145/3678525},
doi = {10.1145/3678525},
abstract = {Spatial perception, particularly at small and medium scales, is an essential human sense but poses a significant challenge for the blind and visually impaired (BVI). Traditional learning methods for BVI individuals are often constrained by the limited availability of suitable learning environments and high associated costs. To tackle these barriers, we conducted comprehensive studies to delve into the real-world challenges faced by the BVI community. We have identified several key factors hindering their spatial perception, including the high social cost of seeking assistance, inefficient methods of information intake, cognitive and behavioral disconnects, and a lack of opportunities for hands-on exploration. As a result, we developed AngleSizer, an innovative teaching assistant that leverages smartphone technology. AngleSizer is designed to enable BVI individuals to use natural interaction gestures to try, feel, understand, and learn about sizes and angles effectively. This tool incorporates dual vibration-audio feedback, carefully crafted teaching processes, and specialized learning modules to enhance the learning experience. Extensive user experiments validated its efficacy and applicability with diverse abilities and visual conditions. Ultimately, our research not only expands the understanding of BVI behavioral patterns but also greatly improves their spatial perception capabilities, in a way that is both cost-effective and allows for independent learning.},
journal = {Proc. ACM Interact. Mob. Wearable Ubiquitous Technol.},
month = sep,
articleno = {108},
numpages = {31},
keywords = {Accessibility, Blind and Visually Impaired Users, Spatial Awareness Training, Understanding BVI People}
}

@article{10.1145/3678514,
author = {Song, Yingjian and Pitafi, Zaid Farooq and Dou, Fei and Sun, Jin and Zhang, Xiang and Phillips, Bradley G. and Song, WenZhan},
title = {Self-Supervised Representation Learning and Temporal-Spectral Feature Fusion for Bed Occupancy Detection},
year = {2024},
issue_date = {September 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {8},
number = {3},
url = {https://doi.org/10.1145/3678514},
doi = {10.1145/3678514},
abstract = {In automated sleep monitoring systems, bed occupancy detection is the foundation or the first step before other downstream tasks, such as inferring sleep activities and vital signs. The existing methods do not generalize well to real-world environments due to single environment settings and rely on threshold-based approaches. Manually selecting thresholds requires observing a large amount of data and may not yield optimal results. In contrast, acquiring extensive labeled sensory data poses significant challenges regarding cost and time. Hence, developing models capable of generalizing across diverse environments with limited data is imperative. This paper introduces SeismoDot, which consists of a self-supervised learning module and a spectral-temporal feature fusion module for bed occupancy detection. Unlike conventional methods that require separate pre-training and fine-tuning, our self-supervised learning module is co-optimized with the primary target task, which directs learned representations toward a task-relevant embedding space while expanding the feature space. The proposed feature fusion module enables the simultaneous exploitation of temporal and spectral features, enhancing the diversity of information from both domains. By combining these techniques, SeismoDot expands the diversity of embedding space for both the temporal and spectral domains to enhance its generalizability across different environments. SeismoDot not only achieves high accuracy (98.49\%) and F1 scores (98.08\%) across 13 diverse environments, but it also maintains high performance (97.01\% accuracy and 96.54\% F1 score) even when trained with just 20\% (4 days) of the total data. This demonstrates its exceptional ability to generalize across various environmental settings, even with limited data availability.},
journal = {Proc. ACM Interact. Mob. Wearable Ubiquitous Technol.},
month = sep,
articleno = {124},
numpages = {25},
keywords = {Bed Occupancy, Self-Supervised Learning, Spectrum-temporal feature fusion}
}

@article{10.1145/3678589,
author = {Wang, Zhu and Chen, Zhen and Zhang, Yao and Geng, Chendi and Song, Wenchao and Sun, Zhuo and Guo, Bin and Yu, Zhiwen and Chen, Liming},
title = {GrainSense: A Wireless Grain Moisture Sensing System Based on Wi-Fi Signals},
year = {2024},
issue_date = {September 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {8},
number = {3},
url = {https://doi.org/10.1145/3678589},
doi = {10.1145/3678589},
abstract = {Grain moisture sensing plays a critical role in ensuring grain quality and reducing grain losses. However, existing commercial off-the-shelf (COTS) grain moisture sensing systems are either expensive, inconvenient or inaccurate, which greatly limit their widespread deployment in real-world scenarios. To fill this gap, we develop a system called GrainSense which leverages COTS Wi-Fi devices to detect the grain moisture without the need for dedicated sensors. Specifically, we propose a wireless grain moisture detection model based on the refraction phenomenon of Wi-Fi signals and the Multiple-Input-Multiple-Output (MIMO) technology. On one hand, we correlate the grain moisture with the phase difference between two refracted Wi-Fi signals that propagate along different paths, based on which grain moisture can be deduced accordingly. On the other hand, to reduce the multi-path interference in indoor environments (e.g., the granary), we adopt Wi-Fi beamforming to enhance the refracted signal. In particular, a new signal feature (i.e., the Wi-Fi CSI beamforming ratio) is designed to eliminate the effect of sub-carrier frequency bias and cumulative phase bias. To validate the effectiveness of the developed system, we conduct extensive experiments with different types of grains in both the laboratory and the granary. Results show that the system can accurately estimate the grain moisture with an mean absolute error smaller than 5\%, which meets the requirements for commercial usage. To the best of our knowledge, this is the first model-based work that achieves accurate grain moisture detection based on wireless sensing.},
journal = {Proc. ACM Interact. Mob. Wearable Ubiquitous Technol.},
month = sep,
articleno = {136},
numpages = {25},
keywords = {Grain moisture sensing, Wi-Fi CSI, Wi-Fi beamforming}
}

@article{10.1145/3678505,
author = {Yuan, Kuang and Ibrahim, Mohamed and Song, Yiwen and Deng, Guoxiang and Nerone, Robert A. and Vijayan, Suvendra and Gadre, Akshay and Kumar, Swarun},
title = {ToMoBrush: Exploring Dental Health Sensing Using a Sonic Toothbrush},
year = {2024},
issue_date = {September 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {8},
number = {3},
url = {https://doi.org/10.1145/3678505},
doi = {10.1145/3678505},
abstract = {Early detection of dental disease is crucial to prevent adverse outcomes. Today, dental X-rays are currently the most accurate gold standard for dental disease detection. Unfortunately, regular X-ray exam is still a privilege for billions of people around the world. In this paper, we ask: "Can we develop a low-cost sensing system that enables dental self-examination in the comfort of one's home?"This paper presents ToMoBrush, a dental health sensing system that explores using off-the-shelf sonic toothbrushes for dental condition detection. Our solution leverages the fact that a sonic toothbrush produces rich acoustic signals when in contact with teeth, which contain important information about each tooth's status. ToMoBrush extracts tooth resonance signatures from the acoustic signals to characterize the dental condition of each tooth. We further develop a data-driven signal processing pipeline to detect and discriminate different dental conditions. We evaluate ToMoBrush on 19 participants and dental-standard models for detecting common dental problems including caries, calculus, and food impaction, achieving a detection ROC-AUC of 0.90, 0.83, and 0.88 respectively. Interviews with dental experts further validate ToMoBrush's potential in enhancing at-home dental healthcare.},
journal = {Proc. ACM Interact. Mob. Wearable Ubiquitous Technol.},
month = sep,
articleno = {139},
numpages = {27},
keywords = {Audio Signal Processing, Machine Learning, Mobile Health, User Study}
}

@inproceedings{10.1145/3665314.3670821,
author = {Yang, Cheng-Yun and Ramshankar, Gowri and Eliopoulos, Nicholas and Jajal, Purvish and Nambiar, Sudarshan and Miller, Evan and Zhang, Xun and Tian, Dave (Jing) and Chen, Shuo-Han and Perng, Chiy-Ferng and Lu, Yung-Hsiang},
title = {Securing Deep Neural Networks on Edge from Membership Inference Attacks Using Trusted Execution Environments},
year = {2024},
isbn = {9798400706882},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3665314.3670821},
doi = {10.1145/3665314.3670821},
abstract = {Privacy concerns arise from malicious attacks on Deep Neural Network (DNN) applications during sensitive data inference on edge devices. Membership Inference Attack (MIA) is developed by adversaries to determine whether sensitive data is used to train the DNN applications. Prior work uses Trusted Execution Environments (TEEs) to hide DNN model inference from adversaries on edge devices. Unfortunately, existing methods have two major problems. First, due to the restricted memory of TEEs, prior work cannot secure large-size DNNs from gradient-based MIAs. Second, prior work is ineffective on output-based MIAs. To mitigate the problems, we present a depth-wise layer partitioning method to run large sensitive layers inside TEEs. We further propose a model quantization strategy to improve the defense capability of DNNs against output-based MIAs and accelerate the computation. We also automate the process of securing PyTorch-based DNN models inside TEEs. Experiments on Raspberry Pi 3B+ show that our method can reduce the accuracy of gradient-based MIAs on AlexNet, VGG-16, and ResNet-20 evaluated on the CIFAR-100 dataset by 28.8\%, 11\%, and 35.3\%. The accuracy of output-based MIAs on the three models is also reduced by 18.5\%, 13.4\%, and 29.6\%, respectively.},
booktitle = {Proceedings of the 29th ACM/IEEE International Symposium on Low Power Electronics and Design},
pages = {1–6},
numpages = {6},
keywords = {membership inference attack, ARM TrustZone, trusted execution environment, model partitioning, model quantization},
location = {Newport Beach, CA, USA},
series = {ISLPED '24}
}

@inproceedings{10.1145/3665314.3670810,
author = {Chen, Jeffrey and Jun, Sang-Woo and Mundra, Aditi and Ta, Jonathan},
title = {Xyloni: Very Low Power Neural Network Accelerator for Intermittent Remote Visual Detection of Wildfire and Beyond},
year = {2024},
isbn = {9798400706882},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3665314.3670810},
doi = {10.1145/3665314.3670810},
abstract = {Wildfires are one of the most catastrophic natural disasters, causing increasingly severe ecological and economic damage. Early response is critically important for wildfire management, but also difficult due to the wide geographical area to monitor, often far from utility infrastructures such as stable power and high-bandwidth network. In this work, we present Xyloni, a very low-cost, low-power neural network accelerator for sensor nodes, which improves the cost-effectiveness and scalability of real-time wildfire detection by drastically reducing wireless data transmission and overall power consumption. Xyloni uses low-power flash and FeRAM memories to store a hardware co-optimized Neural Network model for fire and smoke detection, as well as intermediate activations during inference. It also time-shares a Field-Programmable Gate Array across different model layers for power-efficient computation. The detection model prevents benign images from consuming network traffic, allowing the use of low-bandwidth, low-power network fabrics such as a LoRa mesh network with enough range for the necessary geographical coverage. Compared to a wide range of edge and sensor platforms capable of real-time data collection, Xyloni demonstrated an order of magnitude reduction in power consumption for the network transmission reduction task, leading to a corresponding reduction in battery and deployment cost.},
booktitle = {Proceedings of the 29th ACM/IEEE International Symposium on Low Power Electronics and Design},
pages = {1–6},
numpages = {6},
keywords = {edge computing, wildfire detection, CNN, FPGA, NVM, LoRa, mesh},
location = {Newport Beach, CA, USA},
series = {ISLPED '24}
}

@article{10.1145/3678529,
author = {Scott, Danny and Bringle, Matthew and Fahad, Imran and Morales, Gaddiel and Zahid, Azizul and Swaminathan, Sai},
title = {NeuroCamTags: Long-Range, Battery-free, Wireless Sensing with Neuromorphic Cameras},
year = {2024},
issue_date = {September 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {8},
number = {3},
url = {https://doi.org/10.1145/3678529},
doi = {10.1145/3678529},
abstract = {In this research, we introduce NeuroCamTags, a battery-free platform designed to detect a range of rich human interactions and activities in entire rooms and floors without the need for batteries. The NeuroCamTag system comprises low-cost tags that harvest ambient light energy and utilize high-frequency modulation of light-emitting diodes (LEDs) for wireless communication. These visual signals are captured by an available neuromorphic camera, which boasts temporal resolution and frame rates an order of magnitude higher than those of conventional cameras. We present an event processing pipeline that allows simultaneous localization and identification of multiple unique tags. NeuroCamTags offer a wide range of functionalities, providing battery-free wireless sensing for various physical stimuli, including changes in temperature, contact, button presses, key presses, and even sound cues. Our empirical evaluations demonstrate impressive accuracy at long ranges up to 200 feet. In addition to these findings, we consider a range of applications such as battery-free input devices, tracking of human movement, and long-range detection of human activities in various environments such as kitchens, workshops, etc. By reducing reliance on batteries, NeuroCamTags promotes eco-friendliness and opens doors to exciting possibilities in smart environment technology.},
journal = {Proc. ACM Interact. Mob. Wearable Ubiquitous Technol.},
month = sep,
articleno = {122},
numpages = {25},
keywords = {Activity sensing, Battery-free, Context Aware Computing, Wireless sensing}
}

@article{10.1145/3678573,
author = {Corbett, Matthew and David-John, Brendan and Shang, Jiacheng and Ji, Bo},
title = {ShouldAR: Detecting Shoulder Surfing Attacks Using Multimodal Eye Tracking and Augmented Reality},
year = {2024},
issue_date = {September 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {8},
number = {3},
url = {https://doi.org/10.1145/3678573},
doi = {10.1145/3678573},
abstract = {Shoulder surfing attacks (SSAs) are a type of observation attack designed to illicitly gather sensitive data from "over the shoulder" of victims. This attack can be directed at mobile devices, desktop screens, Personal Identification Number (PIN) pads at an Automated Teller Machine (ATM), or written text. Existing solutions are generally focused on authentication techniques (e.g., logins) and are limited to specific attack scenarios (e.g., mobile devices or PIN Pads). We present ShotjldAR, a mobile and usable system to detect SSAs using multimodal eye gaze information (i.e., from both the potential attacker and victim). ShouldAR uses an augmented reality headset as a platform to incorporate user eye gaze tracking, rear-facing image collection and eye gaze analysis, and user notification of potential attacks. In a 24-participant study, we show that the prototype is capable of detecting 87.28\% of SSAs against both physical and digital targets, a two-fold improvement on the baseline solution using a rear-facing mirror, a widely used solution to the SSA problem. The ShouldAR approach provides an AR-based, active SSA defense that applies to both digital and physical information entry in sensitive environments.},
journal = {Proc. ACM Interact. Mob. Wearable Ubiquitous Technol.},
month = sep,
articleno = {97},
numpages = {23},
keywords = {Augmented Reality, Eye Gaze, Privacy, Security}
}

@inproceedings{10.1145/3665314.3670815,
author = {Taji, Hossein and Miranda, Jos\'{e} and Pe\'{o}n-Quir\'{o}s, Miguel and Atienza, David},
title = {Energy-Efficient Frequency Selection Method for Bio-Signal Acquisition in AI/ML Wearables},
year = {2024},
isbn = {9798400706882},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3665314.3670815},
doi = {10.1145/3665314.3670815},
abstract = {In wearable sensors, energy efficiency is crucial, particularly during phases where devices are not processing, but rather acquiring biosignals for subsequent analysis. This study focuses on improving the power consumption of wearables during these acquisition phases, a critical but often overlooked aspect that substantially affects overall device energy consumption, especially in low-duty-cycle applications. Our approach optimizes power consumption by leveraging application-specific requirements (e.g., required signal profile), platform characteristics (e.g., transition-time overhead for the clock generators and power-gating capabilities), and analog biosignal front-end specifications (e.g., ADC buffer sizes). We refine the strategy for switching between low-power idle and active states for the storage of acquired data, introducing a novel method to select optimal frequencies for these states. Based on several case studies on an ultra-low power platform and different biomedical applications, our optimization methodology achieves substantial energy savings. For example, in a 12-lead heartbeat classification task, our method reduces total energy consumption by up to 58\% compared to state-of-the-art methods. This research provides a theoretical basis for frequency optimization and practical insights, including characterizing the platform's power and overheads for optimization purposes. Our findings significantly improve energy efficiency during the acquisition phase of wearable devices, thus extending their operational lifespan.},
booktitle = {Proceedings of the 29th ACM/IEEE International Symposium on Low Power Electronics and Design},
pages = {1–6},
numpages = {6},
keywords = {AI/ML wearables, energy efficiency, bio-signal acquisition, frequency optimization, biomedical signal processing},
location = {Newport Beach, CA, USA},
series = {ISLPED '24}
}

@inproceedings{10.1145/3675669.3675702,
author = {Hammad, Omar and Rahman, Md Rezwanur and Kanugo, Gopala Krishna Vasanth and Clements, Nicholas and Miller, Shelly and Mishra, Shivakant and Sullivan, Esther},
title = {PureConnect: A Localized Social Media System to Increase Awareness and Connectedness in Environmental Justice Communities},
year = {2024},
isbn = {9798400717550},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3675669.3675702},
doi = {10.1145/3675669.3675702},
abstract = {Frequent disruptions like highway constructions are common now-a-days, often impacting environmental justice communities (communities with low socio-economic status with disproportionately high and adverse human health and environmental effects) that live nearby. Based on our interactions via focus groups with the members of four environmental justice communities impacted by a major highway construction, a common concern is a sense of uncertainty about project activities and loss of social connectedness, leading to increased stress, depression, anxiety and diminished wellbeing. This paper addresses this concern by developing a localized social media system called PureConnect with a goal to raise the level of awareness about the project and increase social connectedness among the community members. PureConnect has been designed using active engagement with four environmental justice communities affected by a major highway construction. It has been deployed in the real world among the members of the four environmental justice communities, and a detailed analysis of the data collected from this deployment as well as surveys show that PureConnect is potentially useful in improving community members’ wellbeing and the members appreciate the functionalities it provides.},
booktitle = {Proceedings of the 2024 11th Multidisciplinary International Social Networks Conference},
pages = {1–7},
numpages = {7},
keywords = {Civic Engagement, Environmental Justice Communities, Intervention, Local social media, Mobile app, Planned Disruptions, Smartphone, Well-being},
location = {Bali, Indonesia},
series = {MISNC '24}
}

@article{10.1145/3660340,
author = {Krau\ss{}, Veronika and Saeghe, Pejman and Boden, Alexander and Khamis, Mohamed and McGill, Mark and Gugenheimer, Jan and Nebeling, Michael},
title = {What Makes XR Dark? Examining Emerging Dark Patterns in Augmented and Virtual Reality through Expert Co-Design},
year = {2024},
issue_date = {June 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {31},
number = {3},
issn = {1073-0516},
url = {https://doi.org/10.1145/3660340},
doi = {10.1145/3660340},
abstract = {Dark patterns are deceptive designs that influence a user’s interactions with an interface to benefit someone other than the user. Prior work has identified dark patterns in windows, icons, menus, and pointer (WIMP) interfaces and ubicomp environments, but how dark patterns can manifest in Augmented and Virtual Reality (collectively XR) requires more attention. We therefore conducted 10 co-design workshops with 20 experts in XR and deceptive design. Our participants co-designed 42 scenarios containing dark patterns, based on application archetypes presented in recent HCI/XR literature. In the co-designed scenarios, we identified 10 novel dark patterns in addition to 39 existing ones, as well as 10 examples in which specific characteristics associated with XR potentially amplified the effect dark patterns could have on users. Based on our findings and prior work, we present a classification of XR-specific properties that facilitate dark patterns: perception, spatiality, physical/virtual barriers, and XR device sensing. We also present the experts’ assessments of the likelihood and severity of the co-designed scenarios and highlight key aspects they considered for this evaluation, for example, technological feasibility, ease of upscaling and distributing malicious implementations, and the application’s context of use. Finally, we discuss means to mitigate XR dark patterns and support regulatory bodies to reduce potential harms.},
journal = {ACM Trans. Comput.-Hum. Interact.},
month = aug,
articleno = {32},
numpages = {39},
keywords = {Speculative design workshops, deceptive design, augmented reality, virtual reality, dark patterns}
}

@inproceedings{10.1145/3669754.3669761,
author = {Tomas, John Paul Quilingking and Celeste, Jurich Reuben T. and Reyes, Matthias Andrew S. and Villacruz, Steven Y. and Yabut, Ivanne Cres V.},
title = {Data-Driven Methodology for Bike Route Identification to Enhance Urban Cycling Infrastructure in Metropolitan Manila},
year = {2024},
isbn = {9798400717055},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3669754.3669761},
doi = {10.1145/3669754.3669761},
abstract = {Cycling has emerged as a popular mode of transportation in Metro Manila, particularly in the areas of Norzagaray, Bulacan, and Manila, following the pandemic. This trend has continued even after the pandemic subsided, as many individuals have opted to use cycling as a primary means of transportation. This shift has been attributed to the affordability of cycling and its ability to offer respite from congested roadways. The government has recognized this shift in transportation habits and has already implemented improvements in biking infrastructure throughout the country, including in Metro Manila, Norzagaray, Bulacan, and Manila, including the introduction of dedicated bike lanes and the enactment of relevant legislation aimed at ensuring the safety and efficiency of cyclists amidst other vehicular traffic. Despite these efforts, some critics argue that the infrastructure does not adequately meet the cyclists' needs. One of the primary concerns is the congestion in urban areas due to the increased prominence of cycling. While introducing bike lanes was intended to alleviate traffic congestion, the reality in many urban centres paints a different picture. Cyclists often navigate through crowded streets, facing challenges such as inadequate infrastructure and insufficient enforcement of traffic regulations. Therefore, there is a need for continued investment in biking infrastructure and proactive measures to mitigate urban congestion to fully realize the potential of cycling as a viable mode of transportation. This study aims to delineate key bicycle routes that lack essential infrastructure, hindering cyclists' ability to navigate designated pathways and thus impeding the flow of vehicular traffic. By examining methodologies employed in various nations to develop comprehensive infrastructure conducive to the safety of cyclists and motorists, this research aims to identify effective strategies for implementation. One of the methods that have been identified involves leveraging advanced technologies, such as bike sensors, to pinpoint areas frequented by cyclists and subsequently inform the creation of dedicated bike lanes and supportive infrastructure. This entails the source utilization of data analytics to discern patterns of cyclist movement, thereby facilitating informed decision-making in infrastructure planning. To facilitate this endeavour, a bespoke bike identification model will be devised. This model will be trained using diverse datasets comprising video footage captured by local cyclists across different times of the day. Exposing the model to varying lighting conditions and angles characteristic of bicycling environments will be primed to accurately identify and delineate cyclist pathways. The acquired data will be a foundational resource for local government bodies tasked with infrastructure development. This data-driven approach will enable policymakers to tailor infrastructure initiatives to cyclists' specific needs and safety considerations by providing a comprehensive understanding of cyclist behaviour and preferred routes. This research aims to bridge the gap between existing infrastructure deficiencies and the evolving demands of the cycling community. By integrating advanced technologies and data-driven insights, it seeks to foster the creation of cycling infrastructure that enhances safety and promotes sustainable urban mobility for all road users.},
booktitle = {Proceedings of the 2024 10th International Conference on Computing and Artificial Intelligence},
pages = {38–43},
numpages = {6},
location = {Bali Island, Indonesia},
series = {ICCAI '24}
}

@inproceedings{10.1145/3669828.3669832,
author = {Watthakovit, Annop and Kobchaisawat, Thananop and Tanpowpong, Natthaporn and Chalidabhongse, Thanarat},
title = {Liver Tumor Classification from DCE-MRI images using Discriminative Learning},
year = {2024},
isbn = {9798400710032},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3669828.3669832},
doi = {10.1145/3669828.3669832},
abstract = {Liver cancer remains a significant global health concern, and early-stage differential diagnosis and treatment can dramatically improve patient survival rates. However, current diagnostic methods are challenging and subjective, highlighting the need for accurate diagnostic support tools. This paper introduces a deep learning-based diagnostic framework for detecting liver tumor malignancy using DCE-MRI, particularly in scenarios with limited well-annotated data. To address the overfitting issue, we propose a Siamese convolutional neural network incorporating metric learning concepts, emphasizing discriminative representation learning. The core principle of our framework is to reorganize the embedding space such that similar sample pairs are closer together while dissimilar ones are further apart. Once the embedding space is learned, unseen samples can be classified based on a distance metric to a few seen samples within the embedding space. Comprehensive experiments on a professionally annotated, self-established dataset demonstrate that our framework outperforms fully supervised approaches in data scarcity situations, achieving a sensitivity of 96\%, precision of 82\%, and an F1-score of 88\%.},
booktitle = {Proceedings of the 2024 6th International Conference on Intelligent Medicine and Image Processing},
pages = {22–28},
numpages = {7},
keywords = {HCC, Liver tumor, convolutional neural network, discriminative learning},
location = {Bali, Indonesia},
series = {IMIP '24}
}

@inproceedings{10.1145/3666094.3666104,
author = {Lindstr\"{o}m, Kristina and J\"{o}nsson, Li and Hillgren, Per-Anders},
title = {Reorientations: Practicing Grief and Hope in Post-Carbon Futures},
year = {2024},
isbn = {9798400708084},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3666094.3666104},
doi = {10.1145/3666094.3666104},
abstract = {In response to a modernist optimistic path that has typically colonised narratives of addressing climate change, this paper explores and proposes a prototypical pedagogy that aims to unlearn privileges and restore a sense of commitment and involvement in the unfolding future among the public. In our articulations of this prototypical pedagogy, we trace and reappropriate pedagogies of collective learning within participatory design in combination with contemporary discourses around the affective dimensions of climate change. The prototypical pedagogy is explored through a designerly study circle in future orienteering that was designed to situate the transition to post-carbon futures within specific locations, environments, and lived experiences. To support reorientations and explorations of alternatives to the familiar modernist path, a guiding principle was to foreground objects, values, and imaginaries that are often overlooked in current accounts of climate change and to activate grief and hope as both practical and conceptual orienteering devices.},
booktitle = {Proceedings of the Participatory Design Conference 2024: Full Papers - Volume 1},
pages = {187–196},
numpages = {10},
keywords = {grief, hope, reorientation, study circle, transition},
location = {Sibu, Malaysia},
series = {PDC '24}
}

@article{10.1145/3679050,
author = {Li, Chia-Hao and Jha, Niraj K.},
title = {DOCTOR: A Multi-Disease Detection Continual Learning Framework Based on Wearable Medical Sensors},
year = {2024},
issue_date = {September 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {23},
number = {5},
issn = {1539-9087},
url = {https://doi.org/10.1145/3679050},
doi = {10.1145/3679050},
abstract = {Modern advances in machine learning (ML) and wearable medical sensors (WMSs) in edge devices have enabled ML-driven disease detection for smart healthcare. Conventional ML-driven methods for disease detection rely on customizing individual models for each disease and its corresponding WMS data. However, such methods lack adaptability to distribution shifts and new task classification classes. In addition, they need to be rearchitected and retrained from scratch for each new disease. Moreover, installing multiple ML models in an edge device consumes excessive memory, drains the battery faster, and complicates the detection process. To address these challenges, we propose DOCTOR, a multi-disease detection continual learning (CL) framework based on WMSs. It employs a multi-headed deep neural network (DNN) and a replay-style CL algorithm. The CL algorithm enables the framework to continually learn new missions in which different data distributions, classification classes, and disease detection tasks are introduced sequentially. It counteracts catastrophic forgetting with either a data preservation (DP) method or a synthetic data generation (SDG) module. The DP method preserves the most informative subset of real training data from previous missions for exemplar replay. The SDG module models the probability distribution of the real training data and generates synthetic data for generative replay while retaining data privacy. The multi-headed DNN enables DOCTOR to detect multiple diseases simultaneously based on user WMS data. We demonstrate DOCTOR’s efficacy in maintaining high disease classification accuracy with a single DNN model in various CL experiments. In complex scenarios, DOCTOR achieves 1.43\texttimes{} better average test accuracy, 1.25\texttimes{} better F1-score, and 0.41 higher backward transfer than the na\"{\i}ve fine-tuning framework, with a small model size of less than 350 KB.},
journal = {ACM Trans. Embed. Comput. Syst.},
month = aug,
articleno = {81},
numpages = {33},
keywords = {Catastrophic forgetting, continual learning, disease detection, machine learning, smart healthcare, wearable medical sensors}
}

@inproceedings{10.1145/3674558.3674594,
author = {Namee, Khanista and Srikamta, Nimit and Lelas, Sillawat and Polpinij, Jantima and Kaewsaeng-On, Rudsada and Nimyungdee, Chayapa and Meny, Areej},
title = {Metadata-Driven Innovation in Smart Offices: A Study on the Impact of Standards on Digital Twins and Indoor Positioning Systems},
year = {2024},
isbn = {9798400716386},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3674558.3674594},
doi = {10.1145/3674558.3674594},
abstract = {This study investigates the refinement of metadata from various sources for optimal integration with digital twins, aiming to enhance its applicability in smart office environments through the Internet of Things (IoT) and digital twin technologies. By developing a systematic framework for hypothesis testing, the research evaluates the metadata's performance in real-time operational dynamics, specifically in indoor tracking of wireless devices to assess data transmission accuracy. The analysis, supported by a performance evaluation with five reference sensors, confirms the metadata's effectiveness in ensuring rapid and precise information retrieval. These findings highlight the potential of customized metadata to improve the efficiency and accuracy of digital twin applications in smart offices.},
booktitle = {Proceedings of the 2024 10th International Conference on Computer Technology Applications},
pages = {247–254},
numpages = {8},
keywords = {Digital Twin, Indoor Positioning, Metadata, Smart Offices},
location = {Vienna, Austria},
series = {ICCTA '24}
}

@inproceedings{10.1145/3674558.3674565,
author = {Samonte, Mary Jane C. and Go, Charles Dustinn Lloyd G. and Linco, Mico Ruiz D. and Macabeo, Miles Gabriel E.},
title = {JointCheck: Development of a Mobile Virtual Assessment Tool for Joint Pains in a Telehealth Application for Orthopedic and Rehabilitation Through Range of Motion},
year = {2024},
isbn = {9798400716386},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3674558.3674565},
doi = {10.1145/3674558.3674565},
abstract = {The emergence of mobile technology presents creative approaches to healthcare. This study focuses on people suffering from wrist pain, as there is a lack of applications that cater to people experiencing wrist pain. Therefore, the study aimed to develop a mobile application for orthopedics and rehabilitation in telehealth. It uses built-in accelerometers and gyroscope sensors to make it easier for users to self-assess wrist pain without external equipment. The study's main objective was to provide a comprehensive tool that will allow patients, orthopedic physicians, physical therapists, and administrative personnel to improve assessment, exercise delivery, and communication in hopes of easing the process of wrist rehabilitation. The development process adhered to the Software Development Life Cycle (SDLC) process, incorporating an iterative process from gathering requirements until implementation. The study's respondents measured the effectiveness of the mobile application through the Functionality Testing and User Experience Questionnaire (UEQ). All functionalities were marked as passed after ensuring features worked as expected. The respondents evaluated the Attractiveness, pragmatic, and Hedonic quality, showcasing a positive overall reception. The study is significant as it offers a wide range of benefits. Patients gain autonomy in monitoring wrist health and accessing timely consultations. To conclude, the study created a practical mobile application that offers a platform for personalized, accessible, and efficient wrist rehabilitation solutions, as it exemplifies the idea of combining mobile technology and healthcare.},
booktitle = {Proceedings of the 2024 10th International Conference on Computer Technology Applications},
pages = {37–45},
numpages = {9},
keywords = {Mobile application, accelerometer, gyroscope, telehealth, user experience, wrist rehabilitation},
location = {Vienna, Austria},
series = {ICCTA '24}
}

@inproceedings{10.1145/3637528.3671581,
author = {Qiao, Zhongzheng and Pham, Quang and Cao, Zhen and Le, Hoang H. and Suganthan, P. N. and Jiang, Xudong and Ramasamy, Savitha},
title = {Class-incremental Learning for Time Series: Benchmark and Evaluation},
year = {2024},
isbn = {9798400704901},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3637528.3671581},
doi = {10.1145/3637528.3671581},
abstract = {Real-world environments are inherently non-stationary, frequently introducing new classes over time. This is especially common in time series classification, such as the emergence of new disease classification in healthcare or the addition of new activities in human activity recognition. In such cases, a learning system is required to assimilate novel classes effectively while avoiding catastrophic forgetting of the old ones, which gives rise to the Class-incremental Learning (CIL) problem. However, despite the encouraging progress in the image and language domains, CIL for time series data remains relatively understudied. Existing studies suffer from inconsistent experimental designs, necessitating a comprehensive evaluation and benchmarking of methods across a wide range of datasets. To this end, we first present an overview of the Time Series Class-incremental Learning (TSCIL) problem, highlight its unique challenges, and cover the advanced methodologies. Further, based on standardized settings, we develop a unified experimental framework that supports the rapid development of new algorithms, easy integration of new datasets, and standardization of the evaluation process. Using this framework, we conduct a comprehensive evaluation of various generic and time-series-specific CIL methods in both standard and privacy-sensitive scenarios. Our extensive experiments not only provide a standard baseline to support future research but also shed light on the impact of various design factors such as normalization layers or memory budget thresholds. Codes are available at https://github.com/zqiao11/TSCIL.},
booktitle = {Proceedings of the 30th ACM SIGKDD Conference on Knowledge Discovery and Data Mining},
pages = {5613–5624},
numpages = {12},
keywords = {class-incremental learning, continual learning, time series classification},
location = {Barcelona, Spain},
series = {KDD '24}
}

@inproceedings{10.1145/3637528.3671660,
author = {Guo, Zhuoning and Yao, Duanyi and Yang, Qiang and Liu, Hao},
title = {HiFGL: A Hierarchical Framework for Cross-silo Cross-device Federated Graph Learning},
year = {2024},
isbn = {9798400704901},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3637528.3671660},
doi = {10.1145/3637528.3671660},
abstract = {Federated Graph Learning (FGL) has emerged as a promising way to learn high-quality representations from distributed graph data with privacy preservation. Despite considerable efforts have been made for FGL under either cross-device or cross-silo paradigm, how to effectively capture graph knowledge in a more complicated cross-silo cross-device environment remains an under-explored problem. However, this task is challenging because of the inherent hierarchy and heterogeneity of decentralized clients, diversified privacy constraints in different clients, and the cross-client graph integrity requirement. To this end, in this paper, we propose a Hierarchical Federated Graph Learning (HiFGL) framework for cross-silo cross-device FGL. Specifically, we devise a unified hierarchical architecture to safeguard federated GNN training on heterogeneous clients while ensuring graph integrity. Moreover, we propose a Secret Message Passing (SecMP) scheme to shield unauthorized access to subgraph-level and node-level sensitive information simultaneously. Theoretical analysis proves that HiFGL achieves multi-level privacy preservation with complexity guarantees. Extensive experiments on real-world datasets validate the superiority of the proposed framework against several baselines. Furthermore, HiFGL's versatile nature allows for its application in either solely cross-silo or cross-device settings, further broadening its utility in real-world FGL applications.},
booktitle = {Proceedings of the 30th ACM SIGKDD Conference on Knowledge Discovery and Data Mining},
pages = {968–979},
numpages = {12},
keywords = {federated graph learning, graph neural network, multi-level privacy preservation},
location = {Barcelona, Spain},
series = {KDD '24}
}

@inproceedings{10.1145/3637528.3671737,
author = {Yu, Dazhou and Gong, Xiaoyun and Li, Yun and Qiu, Meikang and Zhao, Liang},
title = {Self-consistent Deep Geometric Learning for Heterogeneous Multi-source Spatial Point Data Prediction},
year = {2024},
isbn = {9798400704901},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3637528.3671737},
doi = {10.1145/3637528.3671737},
abstract = {Multi-source spatial point data prediction is crucial in fields like environmental monitoring and natural resource management, where integrating data from various sensors is the key to achieving a holistic environmental understanding. Existing models in this area often fall short due to their domain-specific nature and lack a strategy for integrating information from various sources in the absence of ground truth labels. Key challenges include evaluating the quality of different data sources and modeling spatial relationships among them effectively. Addressing these issues, we introduce an innovative multi-source spatial point data prediction framework that adeptly aligns information from varied sources without relying on ground truth labels. A unique aspect of our method is the 'fidelity score,' a quantitative measure for evaluating the reliability of each data source. Furthermore, we develop a geo-location-aware graph neural network tailored to accurately depict spatial relationships between data points. Our framework has been rigorously tested on two real-world datasets and one synthetic dataset. The results consistently demonstrate its superior performance over existing state-of-the-art methods.},
booktitle = {Proceedings of the 30th ACM SIGKDD Conference on Knowledge Discovery and Data Mining},
pages = {4001–4011},
numpages = {11},
keywords = {data fusion, graph neural networks, multi-source, point data, spatial data},
location = {Barcelona, Spain},
series = {KDD '24}
}

@inproceedings{10.1145/3637528.3671578,
author = {Li, Zhonghang and Xia, Lianghao and Tang, Jiabin and Xu, Yong and Shi, Lei and Xia, Long and Yin, Dawei and Huang, Chao},
title = {UrbanGPT: Spatio-Temporal Large Language Models},
year = {2024},
isbn = {9798400704901},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3637528.3671578},
doi = {10.1145/3637528.3671578},
abstract = {Spatio-temporal prediction aims to forecast and gain insights into the ever-changing dynamics of urban environments across both time and space. Its purpose is to anticipate future patterns, trends, and events in diverse facets of urban life, including transportation, population movement, and crime rates. Although numerous efforts have been dedicated to developing neural network techniques for accurate predictions on spatio-temporal data, it is important to note that many of these methods heavily depend on having sufficient labeled data to generate precise spatio-temporal representations. Unfortunately, the issue of data scarcity is pervasive in practical urban sensing scenarios. In certain cases, it becomes challenging to collect any labeled data from downstream scenarios, intensifying the problem further. Consequently, it becomes necessary to build a spatio-temporal model that can exhibit strong generalization capabilities across diverse spatio-temporal learning scenarios.Taking inspiration from the remarkable achievements of large language models (LLMs), our objective is to create a spatio-temporal LLM that can exhibit exceptional generalization capabilities across a wide range of downstream urban tasks. To achieve this objective, we present the UrbanGPT, which seamlessly integrates a spatio-temporal dependency encoder with the instruction-tuning paradigm. This integration enables LLMs to comprehend the complex inter-dependencies across time and space, facilitating more comprehensive and accurate predictions under data scarcity. To validate the effectiveness of our approach, we conduct extensive experiments on various public datasets, covering different spatio-temporal prediction tasks. The results consistently demonstrate that our UrbanGPT, with its carefully designed architecture, consistently outperforms state-of-the-art baselines. These findings highlight the potential of building large language models for spatio-temporal learning, particularly in zero-shot scenarios where labeled data is scarce. The code and data are available at: https://github.com/HKUDS/UrbanGPT.},
booktitle = {Proceedings of the 30th ACM SIGKDD Conference on Knowledge Discovery and Data Mining},
pages = {5351–5362},
numpages = {12},
keywords = {generative ai, large language models, smart cities, spatial-temporal data mining, urban computing},
location = {Barcelona, Spain},
series = {KDD '24}
}

@inproceedings{10.1145/3670085.3670090,
author = {Huang, Xinya and Dai, Zheng and Wang, Kesheng and Luo, Xingguang},
title = {Machine Learning-Based Prediction of Binge Drinking among Adults in the United State: Analysis of the 2022 Health Information National Trends Survey},
year = {2024},
isbn = {9798400717284},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3670085.3670090},
doi = {10.1145/3670085.3670090},
abstract = {Little is known about the association of social media and belief in alcohol and cancer with binge drinking. This study aimed to perform feature selection and develop machine learning (ML) tools to predict occurrence of binge drinking among adults in the United State. A total of 5,886 adults including 1,252 who ever experienced with binge drinking were selected from the 2022 Health Information National Trends Survey (HINTS 6). Feature selection of 69 variables was conducted using Boruta and the Least Absolute Shrinkage and Selection Operator (LASSO). Seven machine learning (ML) tools including the Support Vector Machines (SVMs) algorithms, Logistic Regression, Na\"{\i}ve Bayes, Random Forest, K-Nearest Neighbor, Gradient Boosting Machine, and XGBoost were applied to develop ML models to predict binge drinking. The overall prevalence of binge drinking among U.S. adults is 21.3\%. Both Boruta and LASSO selected 28 identical variables. SVM with Radial Basis Function revealed the best model with the highest AUC of 0.949 and sensitivity of 0.958. The top risk factors of binge drinking were tobacco use (e-cigarette use and smoking status), belief in alcohol (alcohol decreases the risk of future health), belief in cancer (prevention is not possible, worry about getting cancer), and social media (social media visits and sharing health information). These findings underscore the need for multiple health behavior interventions to enhance education related to alcohol use and cancer and how to effectively employ social media to improve health outcomes.},
booktitle = {Proceedings of the 2024 9th International Conference on Mathematics and Artificial Intelligence},
pages = {1–10},
numpages = {10},
keywords = {Binger drinking, alcohol, beliefs, cancer, machine learning, social media},
location = {Beijing, China},
series = {ICMAI '24}
}

@inproceedings{10.1145/3674746.3674755,
author = {Wu, Changcheng and Yue, Zeran and Cao, Qingqing and Fang, Ting and Fei, Fei and Song, Aiguo},
title = {Development of a Six-Channel Wearable Electromyography Sensor for hand movement intention recognition},
year = {2024},
isbn = {9798400716782},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3674746.3674755},
doi = {10.1145/3674746.3674755},
abstract = {Surface electromyography (sEMG) signals are biological signals generated during skeletal muscle contraction, which can be captured by electrodes placed on the skin surface. In order to facilitate the acquisition of forearm sEMG signals for hand movement intention recognition, a six-channel wearable EMG sensor is designed and developed in this paper. The architecture of the armband is described in detail. A total of three hand motions from 10 healthy subjects are captured. Firstly we preprocess the original sEMG signals and extract four time-domain features and two frequency-domain features. Secondly, to obtain the optimal recognition results, we sequentially arrange the six features to obtain 43 feature combinations. Finally, the experiment evaluates the dataset with all feature combinations by four models to get the accuracy of hand motion recognition. The experimental results indicate that the average recognition accuracy of the five-feature combination RMS+WL+ZC+MPF+MF is the highest, reaching 93.45\%. Therefore, utilizing the electromyography signals collected by the armband developed in this study can effectively achieve hand motion recognition.},
booktitle = {Proceedings of the 2024 4th International Conference on Robotics and Control Engineering},
pages = {50–56},
numpages = {7},
keywords = {EMG sensor, Feature extraction, Motion recognition, Neural network},
location = {Edinburgh, United Kingdom},
series = {RobCE '24}
}

@inproceedings{10.1145/3674746.3674757,
author = {Miao, Tianyuan and Song, Aiguo and Wang, Shaohu and Ji, Qinjie and Li, Huijun},
title = {Mapping and Human-Robot Interaction of Pipeline Robot in Narrow Environments},
year = {2024},
isbn = {9798400716782},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3674746.3674757},
doi = {10.1145/3674746.3674757},
abstract = {The accumulation of pollutants and rust inside ventilation pipes can lead to respiratory infections and other illnesses. Using robots to inspect the interior of pipes is an effective way to mitigate these risks. To enhance the efficiency of inspections in narrow pipeline environments, we developed a mapping and human-robot interaction system for pipeline robots in complex networks. Employing a compact tracked mobile robot as the motion platform, we proposed a pipeline mapping technique based on multi-sensor fusion. Initially, we utilize error state Kalman filtering (ESKF) to fuse data from the Inertial Measurement Unit (IMU) and wheel encoders for odometer estimation. Next, we perform linear fitting on the point cloud data obtained from the linear array solid-state lidar to calculate the width of the pipeline and the yaw angle of the robot, which are also used to correct the accumulated error of the IMU. Subsequently, combining with the recognition of typical pipeline scenes, we construct the geometric map of the pipeline. Additionally, we propose a pipeline robot-human interaction method based on multimodal fusion, integrating input signals from multiple channels such as voice, gesture, and joystick. By employing multimodal or multi-person collaboration, we effectively reduce motion collisions. Finally, we validate the system functionality in a pipeline experimental environment, demonstrating that the proposed system can rapidly map in the pipeline environment and contribute to improving inspection efficiency.},
booktitle = {Proceedings of the 2024 4th International Conference on Robotics and Control Engineering},
pages = {71–76},
numpages = {6},
keywords = {Pipeline robot, human-machine interaction, inspection and mapping},
location = {Edinburgh, United Kingdom},
series = {RobCE '24}
}

@inproceedings{10.1145/3672406.3672418,
author = {O Fearghail, Colm and Gadipudi, Nivesh and Young, Gareth William},
title = {Back to the Virtual Future: Presence in Cinematic Virtual Reality},
year = {2024},
isbn = {9798400717949},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3672406.3672418},
doi = {10.1145/3672406.3672418},
abstract = {Extended Reality (XR) technologies transform how we experience digital content, offering unparalleled immersion and interaction capabilities. Cinematic Virtual Reality (CVR) stands at the intersection of storytelling and technology, providing a unique medium through which narratives are experienced in an immersive environment. However, the psychological mechanisms through which CVR fosters presence, a key element of immersion, remain under-explored, hindering the potential of CVR to revolutionize storytelling and audience engagement. This study addresses the gap by examining how the sensation of presence differs when a cinematic XR experience is presented on two different platforms: a traditional screen-based monitor and a head-mounted display (HMD). Here, we show that the HMD platform significantly enhances the sense of spatial presence, involvement and overall immersion compared to the monitor. The findings reveal that while both platforms provide engagement with the content, the immersive qualities of the HMD contribute to a stronger sense of being in the virtual environment, thus enhancing the narrative experience. This study advances our understanding of presence in CVR, suggesting that the medium’s ability to envelop the viewer plays a crucial role in storytelling. This research underscores the importance of device choice in designing immersive narrative experiences by situating these results within the broader context of XR applications. It provides a foundation for future work to explore how different aspects of presence influence user engagement and narrative absorption in CVR, offering insights into how technology can enhance the storytelling landscape.},
booktitle = {Proceedings of the 2024 ACM International Conference on Interactive Media Experiences Workshops},
pages = {80–87},
numpages = {8},
keywords = {Cinema, Immersive Experiences, Presence, User Study, Virtual Reality},
location = {Stockholm, Sweden},
series = {IMXw '24}
}

@inproceedings{10.1145/3679409.3679414,
author = {Liu, Chang and Ling, Tianqing and Lu, Wei},
title = {Design study of intelligent voice control system for bionic robots},
year = {2024},
isbn = {9798400709951},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3679409.3679414},
doi = {10.1145/3679409.3679414},
abstract = {A control system for a bionic robot with intelligent voice control function is designed and developed. On the basis of utilizing the sound sensor function, we plan the design scheme of using sound to control the bionic robot, carry out the hardware layout design and software code writing, and carry out comprehensive debugging by combining the hardware and software parameters, so as to make the bionic robot initially equipped with the intelligent sound control function, and verify it through experiments.On the basis of the preliminary theoretical design, this paper firstly plans the overall design scheme of the intelligent voice-controlled bionic robot: adopting Arduino microcontroller as the control core of the robot, adopting 12 high-precision digital servos to drive 12 joints (4\texttimes{}3) of the robot, adopting sound sensors to detect the information in the external environment, and the sensor information is captured and sent to the main control unit Arduino The sensor information is collected and sent to the main control unit Arduino microcontroller, which processes the data and completes the corresponding functions. The software system is programmed by Arduino IDE. In terms of hardware design, this system is composed of Arduino LEONARDO as the control core, plus machine human body and sensors and other peripheral modules. Specifically, it consists of the main controller (Arduino LEONARDO), voice control module, power supply module and so on.},
booktitle = {Proceedings of the 2024 3rd International Symposium on Control Engineering and Robotics},
pages = {23–28},
numpages = {6},
location = {Changsha, China},
series = {ISCER '24}
}

