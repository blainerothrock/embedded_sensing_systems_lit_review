@inproceedings{10.1145/3719027.3765139,
author = {Chhillar, Somiya and Righi, Mary K. and Sutter, Rebecca E. and Kornaropoulos, Evgenios M.},
title = {Exposing Privacy Risks in Anonymizing Clinical Data: Combinatorial Refinement Attacks on k-Anonymity Without Auxiliary Information},
year = {2025},
isbn = {9798400715259},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3719027.3765139},
doi = {10.1145/3719027.3765139},
abstract = {Despite longstanding criticism from the privacy community, k-anonymity remains a widely used standard for data anonymization, mainly due to its simplicity, regulatory alignment, and preservation of data utility. However, non-experts often defend k-anonymity on the grounds that, in the absence of auxiliary information, no known attacks can compromise its protections. In this work, we refute this claim by introducing Combinatorial Refinement Attacks (CRA), a new class of privacy attacks targeting k-anonymized datasets produced using local recoding. This is the first method that does not rely on external auxiliary information or assumptions about the underlying data distribution. CRA leverages the utility-optimizing behavior of local recoding anonymization of ARX, which is a widely used open-source software for anonymizing data in clinical settings, to formulate a linear program that significantly reduces the space of plausible sensitive values. To validate our findings, we partnered with a network of free community health clinics, an environment where (1) auxiliary information is indeed hard to find due to the population they serve and (2) open-source k-anonymity solutions are attractive due to regulatory obligations and limited resources. Our results on real-world clinical microdata reveal that even in the absence of external information, established anonymization frameworks do not deliver the promised level of privacy, raising critical privacy concerns.},
booktitle = {Proceedings of the 2025 ACM SIGSAC Conference on Computer and Communications Security},
pages = {4259–4273},
numpages = {15},
keywords = {anonymization, attack, healthcare data privacy, k-anonymity, local recoding, privacy},
location = {Taipei, Taiwan},
series = {CCS '25}
}

@inproceedings{10.1145/3719027.3765060,
author = {Zhang, Tianfang and Ji, Qiufan and Akanda, Md Mojibur Rahman Redoy and Ye, Zhengkun and Mahdad, Ahmed Tanvir and Shi, Cong and Wang, Yan and Saxena, Nitesh and Chen, Yingying},
title = {Harnessing Vital Sign Vibration Harmonics for Effortless and Inbuilt XR User Authentication},
year = {2025},
isbn = {9798400715259},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3719027.3765060},
doi = {10.1145/3719027.3765060},
abstract = {Extended Reality (XR) headsets are increasingly serving as repositories for substantial volumes of sensitive data and gateways to web applications. This transition highlights the need for convenient and secure user authentication solutions. Traditional password/PIN-based schemes are ill-suited to the XR's gesture- and voice-based interfaces and are prone to shoulder-surfing attacks. Some recent XR systems incorporate two-factor authentication, but it requires additional operations on a second device (e.g., a smartphone or wearable). In this work, we introduce the first effortless and inbuilt XR user authentication system by leveraging the harmonics of vibrations excited by users' vital signs. The system is transparent to users (no efforts during enrollment and authentication) and requires no additional hardware. The key idea is that vital signs (i.e., breathing and heart beating) naturally generate low-frequency mechanical vibrations, causing human skull to vibrate and produces harmonic signals. When the harmonics pass the human head, they carry rich biometrics associated with the wearer's skull structure and soft tissues, which can be captured by the XR motion sensors. Instead of directly utilizing the vibrations, we extract more reliable biometrics from the ratios among different harmonic frequencies, which capture wearers' unique head and facial attenuation properties and are non-volatile when the periodicity and amplitude of vital signs fluctuate. We further design an adaptive filter to mitigate the body motion distortions in common XR interactions. By adopting advanced deep learning models with the attention mechanism, our system realizes effective and robust authentication across XR scenarios. Evaluations across 10 months, with 52 users and two popular XR headsets, show that our system can accurately authenticate users with over 95\% true positive rates and rejects unauthorized users with over 98\% true negative rates under various XR scenarios, with biometrics remaining consistent over long-term periods.},
booktitle = {Proceedings of the 2025 ACM SIGSAC Conference on Computer and Communications Security},
pages = {3520–3534},
numpages = {15},
keywords = {authentication, vital sign harmonics, xr headsets},
location = {Taipei, Taiwan},
series = {CCS '25}
}

@inproceedings{10.1145/3768801.3768932,
author = {Lu, Qinghua},
title = {Research on the Construction of an Artificial Intelligence Ethics Education System in Universities},
year = {2025},
isbn = {9798400715853},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3768801.3768932},
doi = {10.1145/3768801.3768932},
abstract = {Universities, serving as pivotal hubs for knowledge innovation and talent nurturing, have integrated artificial intelligence (AI) ethics education into their curriculum frameworks. This integration is designed to instill ethical consciousness in students from the onset, empowering them to master cutting-edge technology while deeply comprehending and adhering to ethical norms, ultimately facilitating responsible decision-making. Through a comprehensive ethics education program, students not only acquire the skills to identify and address ethical dilemmas arising in AI applications but also develop a proactive mindset to foresee technological consequences and a keen ability to foster consensus amidst diverse cultural and value systems. Consequently, AI ethics education in universities transcends being merely a supplementary aspect of technical training; it stands as a cornerstone for nurturing future scientific and technological talents endowed with a profound sense of social responsibility and a broad global perspective. Such education holds immense significance in advancing the healthy evolution of AI technology and enhancing societal well-being. This paper endeavors to delve into the construction of an AI ethics education system within universities, offering robust scientific rationale and practical directives for the evolution of AI ethics education paradigms in academia.},
booktitle = {Proceedings of the 2025 2nd International Conference on Big Data and Digital Management},
pages = {803–808},
numpages = {6},
keywords = {artificial intelligence, ethics education, system construction in education},
location = {
},
series = {ICBDDM '25}
}

@inproceedings{10.1145/3719027.3765227,
author = {Zhang, Yan and Liu, Zihao and Zhu, Yi and Miao, Chenglin},
title = {Towards Real-Time Defense against Object-Based LiDAR Attacks in Autonomous Driving},
year = {2025},
isbn = {9798400715259},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3719027.3765227},
doi = {10.1145/3719027.3765227},
abstract = {LiDAR (Light Detection and Ranging)-based object detection is a cornerstone of autonomous vehicle perception systems. Modern LiDAR perception relies heavily on deep neural networks (DNNs), which enable accurate object detection by learning geometric features from 3D point clouds. However, recent studies have shown that these systems are vulnerable to object-based adversarial attacks, where physical adversarial objects are strategically placed in the environment to manipulate LiDAR point clouds and mislead detection models. These attacks are practical, stealthy, and require no specialized hardware, posing a serious threat to the safety and reliability of AVs. Despite these risks, existing defense methods suffer from significant limitations, including high computational overhead, limited generalizability and effectiveness, and the inability to operate in real time. In this paper, we propose the first real-time defense mechanism against object-based LiDAR attacks in autonomous driving. Our solution is both detection model-agnostic and attack-agnostic, requiring no prior knowledge of the number, shape, size, or placement of adversarial objects. Positioned between the sensing and perception modules of the AV pipeline, the defense processes LiDAR point clouds in real time and employs a novel generative model that enables efficient and effective identification and removal of adversarial points from suspicious regions. Extensive experiments in both simulated and real-world environments demonstrate that our approach achieves high attack detection rates with minimal latency. This work offers a practical and robust defense solution to a growing security threat in autonomous driving.},
booktitle = {Proceedings of the 2025 ACM SIGSAC Conference on Computer and Communications Security},
pages = {3825–3839},
numpages = {15},
keywords = {adversarial attacks, autonomous driving, defense, lidar perception},
location = {Taipei, Taiwan},
series = {CCS '25}
}

@inproceedings{10.1145/3768801.3768868,
author = {Wang, Yu and Jia, Yanrui and Xu, Jiawei},
title = {A Study on the Impact of Dynamic Pricing Strategies Based on Deep Reinforcement Learning on Customer Loyalty},
year = {2025},
isbn = {9798400715853},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3768801.3768868},
doi = {10.1145/3768801.3768868},
abstract = {Against the backdrop of the rapid development of big data technology, the phenomenon of price discrimination, colloquially known as "big data-enabled price gouging," has sparked widespread social concern and a crisis of consumer trust. To investigate this issue and seek solutions, this study combines traditional empirical analysis with cutting-edge machine learning simulation. First, through questionnaire surveys and regression analysis, and based on equity theory and price sensitivity theory, we verify the direct negative impact of big data-driven price discrimination on customer loyalty, revealing the mediating role of perceived unfairness and the moderating role of price sensitivity. Second, based on these empirical results, we construct a high-fidelity market simulation environment and employ the Deep Q-Network (DQN) algorithm from Deep Reinforcement Learning (DRL) to train a dynamic pricing agent. The agent's objective is to maximize long-term profit while maintaining customer loyalty. The simulation results show that the trained reinforcement learning strategy significantly outperforms both myopic greedy pricing and fixed-price strategies in terms of total revenue and customer retention. The final policy learned by the agent confirms that to maintain long-term customer relationships, it is necessary to offer discounts to price-sensitive, low-loyalty users while adopting moderate pricing for high-loyalty users, thereby effectively validating our initial theoretical hypotheses. This study not only reveals the internal mechanism through which price discrimination affects customer loyalty but also provides a scientific basis and practical path for enterprises to optimize pricing and achieve sustainable development using advanced algorithms.},
booktitle = {Proceedings of the 2025 2nd International Conference on Big Data and Digital Management},
pages = {412–417},
numpages = {6},
keywords = {Customer Loyalty, Deep Q-Network (DQN), Deep Reinforcement Learning, Dynamic Pricing, Perceived Unfairness, Price Sensitivity},
location = {
},
series = {ICBDDM '25}
}

@inproceedings{10.1145/3719027.3765105,
author = {Kang, Yujin and Kim, Eunsun and Cho, Yoon-Sik},
title = {Can Personal Health Information Be Secured in LLM? Privacy Attack and Defense in the Medical Domain},
year = {2025},
isbn = {9798400715259},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3719027.3765105},
doi = {10.1145/3719027.3765105},
abstract = {Recent advancements have shown that Large Language Models (LLMs) possess significant versatility, making them suitable for applications in many areas. Several studies have shown how general-purpose LLMs can be adapted to domain-specific tasks. However, these domain-adapted LLMs can be exposed to greater privacy risks, which are especially exacerbated in the medical field. In this paper, we present the study investigating the susceptibility of LLMs to leaking sensitive health information. We conduct prompt-based attacks on LLMs trained with medical datasets, showing that medical LLMs can inadvertently disclose confidential patient data. To contribute towards mitigating privacy risks in the medical domain, we implement red teaming defense strategies to make LLMs robust against malicious attacks. For this medical red teaming approach, we develop and publicly release MediRed, a dataset of 1,000 red team attacks. By leveraging this dataset to enhance our defense mechanisms, we achieve up to 56\% improvement in privacy protection compared to base models. Our code and dataset are available at https://github.com/yujinKang32/Private_Med_LLM.git},
booktitle = {Proceedings of the 2025 ACM SIGSAC Conference on Computer and Communications Security},
pages = {4199–4213},
numpages = {15},
keywords = {defense, medical llm, personal health information (phi), privacy attack},
location = {Taipei, Taiwan},
series = {CCS '25}
}

@inproceedings{10.1145/3768801.3768931,
author = {Li, Jianing},
title = {Equilibrium price point identification between timber harvest revenue and carbon credits sales revenue based on publicly available Chinese Certified Emission Reduction project},
year = {2025},
isbn = {9798400715853},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3768801.3768931},
doi = {10.1145/3768801.3768931},
abstract = {The Chinese Certified Emission Reduction (CCER) market serves as a pivotal mechanism for addressing climate change while offering forest enterprises a sustainable revenue alternative. This study quantifies the trade-off equilibrium between timber harvest income and carbon credit revenue through integrated application of net present value (NPV) analysis and forest carbon sink accounting frameworks. Focusing on a representative afforestation project in Inner Mongolia, the model incorporates key variables including timber yield, carbon sequestration rates, and market discount rates. Analytical results reveal a break-even carbon price of 69 CNY/ton below the current CCER trading average–demonstrating carbon credit sales' economic viability as a forest management strategy. Sensitivity analysis further indicates that extending rotation periods could enhance carbon pricing competitiveness. These findings substantiate that optimized carbon-inclusive forestry models could generate higher compound returns compared to conventional timber-focused operations, simultaneously advancing China's dual carbon goals and ecological civilization construction. Policy recommendations emphasize refining carbon pricing mechanisms and developing species-specific sequestration coefficients to incentivize low-carbon silviculture practices.},
booktitle = {Proceedings of the 2025 2nd International Conference on Big Data and Digital Management},
pages = {798–802},
numpages = {5},
keywords = {CCER market, carbon accounting, forestry management},
location = {
},
series = {ICBDDM '25}
}

@inproceedings{10.1145/3719027.3765038,
author = {P\"{o}llmann, Daniel and Tang, Tianxin},
title = {Differentially Private Access in Encrypted Search: Achieving Privacy at a Small Cost?},
year = {2025},
isbn = {9798400715259},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3719027.3765038},
doi = {10.1145/3719027.3765038},
abstract = {Encrypted search focuses on protecting sensitive data in outsourced environments while enabling private queries. Although standard encrypted search algorithms are efficient, they often leak some information about the queries and data. One such leakage is the access pattern on the outsourced storage. Recent leakage-abuse attacks have exploited this seemingly harmless leakage to successfully recover both queries and data, shifting research priorities towards finding the right balance between privacy and performance. While some proposals leverage oblivious RAM or other oblivious data structures to hide the access pattern, they typically incur significant bandwidth costs. In response, researchers have developed new schemes that ensure access leakage satisfies differential privacy (DP). Yet the security implications of these new guarantees remain unclear. Especially, compared with conventional differential privacy, the application and threat model are significantly different. To understand these implications, we investigate two concrete instances of (encrypted) range-query schemes (appeared in SODA '19 and CCS '22) that achieve differentially private access. We analyze their security guarantees using inference attacks to recover queries and data on real-world datasets. Our findings raise a critical concern that ensuring access leakage is differentially private either falls short of providing strong security for the queries and data, diverging from the initial goals, or offers only weak security but at a high efficiency/correctness cost. As part of our analysis, we also propose a generic security definition for DP access, and identify two general techniques for leakage mitigation, bucketization and partitioning, that may be of independent interest.},
booktitle = {Proceedings of the 2025 ACM SIGSAC Conference on Computer and Communications Security},
pages = {1754–1768},
numpages = {15},
keywords = {differential privacy, encrypted search, inference attacks},
location = {Taipei, Taiwan},
series = {CCS '25}
}

@inproceedings{10.1145/3719027.3765143,
author = {Fu, Chuanpu and Li, Qi and Bertino, Elisa and Xu, Ke},
title = {Training with Only 1.0 ‰ Samples: Malicious Traffic Detection via Cross-Modality Feature Fusion},
year = {2025},
isbn = {9798400715259},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3719027.3765143},
doi = {10.1145/3719027.3765143},
abstract = {Machine Learning (ML) based malicious traffic detection systems can accurately recognize unseen network attacks by learning from large-scale traffic datasets. However, deploying such systems across multiple networks involves substantial efforts to construct large training datasets for each network. This paper addresses the issue of training with minimal datasets, that is, achieving accurate malicious traffic detection by learning a small portion of traffic in entirely new network environments, thereby eliminating prohibitive labor costs associated with traffic dataset construction. We develop tFusion to effectively extract information from limited datasets by treating network traffic data as multimodal data, comprising features from multiple sensory modalities of packets, flows, and hosts. In particular, we design a dedicated crossmodal attention model that fuses fine-grained per-packet sequential features with coarse-grained per-flow and per-host statistical features, to synthesize correlations among the different granularities of traffic features. Moreover, we design a topology-driven contrastive learning approach that pre- trains the models while reducing topology-related biases, which allows tFusion to achieve generic detection across various networks. We deploy tFusion in an institutional network and measure its performance over five days. tFusion requires human experts to label only 1.0 ‰ traffic, yet it achieves 99.82\% accuracy when detecting various attacks. Meanwhile, it outperforms 14 existing methods by improving over 12.76\% accuracy on 11 existing datasets.},
booktitle = {Proceedings of the 2025 ACM SIGSAC Conference on Computer and Communications Security},
pages = {3930–3944},
numpages = {15},
keywords = {machine learning, malicious traffic detection, network security},
location = {Taipei, Taiwan},
series = {CCS '25}
}

@inproceedings{10.1145/3771678.3771682,
author = {Leon, Geovanni and Yauri, Jose},
title = {A Benchmark Dataset and Baseline Model for Disease Detection in Peruvian Cocoa Fruits Using YOLOv5},
year = {2025},
isbn = {9798400718809},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3771678.3771682},
doi = {10.1145/3771678.3771682},
abstract = {Cocoa production is crucial for the social and economic development of many families worldwide. Despite not ranking among the top cocoa producing countries globally, Peru is recognized for its high-quality product in international markets. The low productivity of cocoa is due to the lack of good agricultural practices and the increase of diseases and pests that affect it. This paper presents a new reference dataset that includes images of high resolution of diseases and pests on cocoa fruits or pods that were collected in the Valle del R\'{\i}o Apur\'{\i}mac, Ene, y Mantaro (VRAEM) region of Peru. The dataset contains images of five classes of cocoa fruits: Healthy, Phytophthora palmivora fungus, Moniliophthora roreri fungus, Moniliophthora perniciosa fungus, and Carmenta foraseminis pest. An early detection of diseases and pests in cocoa fruits, along with appropriate treatment, can help farmers mitigate their economic losses. In addition, a reference model for early detection of diseases in cocoa fruits using YOLOv5 is also provided, showing an excellent classification performance, with 97.06\% sensitivity and 97.25\% specificity in the binary classification of unhealthy versus healthy cocoa pods. Based on this baseline result, it can be concluded that the dataset is suitable for binary classification in real-world scenarios and can be used for future research.},
booktitle = {Proceedings of the 2025 8th International Conference on Systems Engineering - Cybersecurity \&amp; AI: Building a Reliable Digital Future},
pages = {23–30},
numpages = {8},
keywords = {Deep learning, Computer vision, Smart farming, YOLOv5, Cocoa disease detection, Peruvian cocoa diseases},
location = {
},
series = {CIIS '25}
}

@inproceedings{10.1145/3719027.3765061,
author = {Thomas, Fabian and Torres, Michael and Moghimi, Daniel and Schwarz, Michael},
title = {ExfilState: Automated Discovery of Timer-Free Cache Side Channels on ARM CPUs},
year = {2025},
isbn = {9798400715259},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3719027.3765061},
doi = {10.1145/3719027.3765061},
abstract = {Microarchitectural attacks and reverse-engineering efforts rely on inferring the cache state of cache lines. While high-resolution timers traditionally enable this, such timers are increasingly restricted or unavailable to unprivileged users on modern ARM64 systems. We introduce a fuzzing-based methodology to automatically discover instruction sequences that leak cache state into architectural state—without timing measurements. Our proof-of-concept, ExfilState, uses differential testing, F-score ranking, and covert-channel verification to identify architectural side channels on ARM64 CPUs. Across 160 devices with 37 microarchitectures—including smartphones, laptops, and cloud servers--ExfilState uncovers 5 undocumented side channels, 2 of which are reliably and widely exploitable. We demonstrate their practical impact with a timer-free Spectre variant, a cache-based AES key-recovery attack, and a novel defense mechanism that aborts sensitive algorithms on eviction of victim cache lines. Our findings show that architectural side channels are both real and exploitable, even in environments without timers, broadening the attack surface on modern ARM64 platforms.},
booktitle = {Proceedings of the 2025 ACM SIGSAC Conference on Computer and Communications Security},
pages = {2564–2578},
numpages = {15},
keywords = {architectural side channels, cpu fuzzing, microarchitecture},
location = {Taipei, Taiwan},
series = {CCS '25}
}

@inproceedings{10.1145/3768801.3768923,
author = {Su, Daopeng and Rao, Jiawei and Lu, Yucheng},
title = {Multi-Objective Optimization for Sustainable Cruise Tourism Management: A Case Study of Juneau, Alaska},
year = {2025},
isbn = {9798400715853},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3768801.3768923},
doi = {10.1145/3768801.3768923},
abstract = {This paper addresses the challenges of overtourism in cruise destinations through a novel multi-objective optimization model. Taking Juneau, Alaska as a case study, we develop a mathematical framework that simultaneously optimizes economic benefits, environmental protection, and social welfare. The model employs three decision variables: daily cruise arrivals, tourist volume, and visitor diversion ratio, with objectives to maximize tourism revenue, minimize per capita carbon emissions, and reduce infrastructure pressure. Using the NSGA-II algorithm, we obtain Pareto-optimal solutions that reveal significant trade-offs between objectives. Results indicate that limiting daily visitors to 12,000-14,000 and maintaining a diversion ratio of 0.2-0.3 achieves optimal balance across all objectives. Sensitivity analysis demonstrates that tourist tax rates between $15-20 effectively manage visitor flow while maintaining revenue stability. The model's successful adaptation to Venice's unique challenges validates its applicability to diverse tourism destinations. This research provides valuable insights for sustainable tourism management and policy development in overcrowded destinations.},
booktitle = {Proceedings of the 2025 2nd International Conference on Big Data and Digital Management},
pages = {753–756},
numpages = {4},
keywords = {Cruise Tourism Management, Multi-objective Optimization, Sustainable Tourism},
location = {
},
series = {ICBDDM '25}
}

@inproceedings{10.1145/3680207.3723461,
author = {Li, Yilong and Sheshadri, Ramanujan K and Sundaresan, Karthik and Chai, Eugene and Zeng, Yijing and Raghuram, Jayaram and Banerjee, Suman},
title = {Medusa: Scalable Multi-View Biometric Sensing in the Wild with Distributed MIMO Radars},
year = {2025},
isbn = {9798400711299},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3680207.3723461},
doi = {10.1145/3680207.3723461},
abstract = {Radio frequency (RF) techniques have shown promise for continuous contactless healthcare applications. However, real-world indoor environments pose challenges for existing systems, which may struggle to detect subtle physiological signals. This paper proposes Medusa, a novel wireless vital-sign sensing system designed for multi-view setups. It enables users to deploy distributed Multiple Input Multiple Output (MIMO) arrays into their daily living environments, facilitating vital-sign sensing in real-world settings. Unlike most existing single Commercial Off-The-Shelf (COTS) radar-based systems that operate under controlled settings Medusa's primary novelty lies in the design of a first-of-its-kind flexible multi-view vital sign sensing system that is view-agnostic, pose-agnostic, contactless, and can sense basic human vitals with good accuracy. Through our well-engineered hardware and software co-design, Medusa enables real-time processing of large distributed MIMO arrays, while balancing the tradeoff between Signal-to-Noise Ratio (SNR) and spatial diversity gain across each of its four distributed 4 \texttimes{} 4 sub-arrays for increased robustness. This is achieved using our novel unsupervised learning model which effectively recovers vital sign waveforms by decomposing the received signals. Extensive evaluations with 21 participants demonstrate Medusa's spatial diversity gain for real-world vital-sign monitoring, enabling free movement and orientation of subjects in both familiar and unfamiliar indoor environments.},
booktitle = {Proceedings of the 31st Annual International Conference on Mobile Computing and Networking},
pages = {78–92},
numpages = {15},
keywords = {free-movement vital sign monitoring, MIMO radar system, ultra-wide band (UWB), custom-designed platform, unsupervised learning},
location = {Kerry Hotel, Hong Kong, Hong Kong, China},
series = {ACM MOBICOM '25}
}

@inproceedings{10.1145/3680207.3723474,
author = {Pan, Hao and Wang, Yezhou and Liu, Jiting and Ma, Ruichun and Qiu, Lili and Chen, Yi-Chao and Xue, Guangtao and Ren, Ju},
title = {CGMM: Non-Invasive Continuous Glucose Monitoring in Wearables Using Metasurfaces},
year = {2025},
isbn = {9798400711299},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3680207.3723474},
doi = {10.1145/3680207.3723474},
abstract = {Non-invasive continuous glucose monitoring for diabetes patients remains challenging despite ongoing interest. This paper presents CGMM, a novel non-invasive wireless glucose monitoring system integrated into wearable devices. It features a specially designed metasurface that couples with the wearable's antenna and tissue fluid beneath the skin, amplifying frequency response changes caused by subtle glucose concentration variations. To address individual tissue variability and optimize the passive metasurface design, we develop a tunable metasurface and a one-shot calibration method to obtain the impedance for optimal resonance in glucose sensing environments with unknown parameters. The calibrated impedance is then used for the inverse design and fabrication of an economical passive metasurface. We implement prototypes of CGMM and conduct extensive experimental evaluations. In human experiments involving ten participants using the prototype with LibreVNA, the overall performance is quantified with relative errors ranging from -5.02\% to 6.93\% and an RMSE of 9.65 mg/dL.},
booktitle = {Proceedings of the 31st Annual International Conference on Mobile Computing and Networking},
pages = {283–298},
numpages = {16},
keywords = {glucose sensing, metasurface, wearables},
location = {Kerry Hotel, Hong Kong, Hong Kong, China},
series = {ACM MOBICOM '25}
}

@inproceedings{10.1145/3680207.3723472,
author = {Sharma, Neha and Bebawy, Mariam and Ng, Yik Yu and Hefeeda, Mohamed},
title = {GlucoSense: Non-Invasive Glucose Monitoring using Mobile Devices},
year = {2025},
isbn = {9798400711299},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3680207.3723472},
doi = {10.1145/3680207.3723472},
abstract = {Regular glucose monitoring is crucial for diabetic patients to avoid the risk of health complications such as stroke, kidney failure, heart disease, and even death. Most current devices for measuring glucose are costly and painful. We propose GlucoSense, a non-invasive glucose sensing solution on mobile devices. GlucoSense builds on the fact that glucose is an optically active molecule, which interacts with various wavelengths. We first conduct spectral analysis to demonstrate the feasibility of measuring glucose in the visible and near-infrared range (400–1000 nm), which is the range available on mobile devices. We also identify the relative importance of various spectral bands in this range. We further propose multiple practical designs for obtaining the required spectral bands for measuring glucose. We then design GlucoSense exploiting the sensing capabilities of modern smartphones combined with machine learning models. We conduct an ethics-approved user study with a diverse set of participants in terms of age, sex, ethnicity, and body mass index (BMI). We compare GlucoSense against a widely-used, FDA-approved glucose measuring device. Our results show that 80.4\% of GlucoSense predictions are within Zone A (clinically accurate), and the remaining 19.3\% are in Zone B (clinically acceptable) of the Clarke Error Grid (CEG). In addition, 99.7\% of the predictions are within the None and Slight risk zones of the Surveillance Error Grid (SEG), indicating their high accuracy. Both CEG and SEG are standard metrics for assessing glucose-measuring devices. These results were obtained by GlucoSense running on unmodified phones in realistic environments with diverse illuminations.},
booktitle = {Proceedings of the 31st Annual International Conference on Mobile Computing and Networking},
pages = {247–266},
numpages = {20},
keywords = {blood glucose, mobile health, hyperspectral imaging},
location = {Kerry Hotel, Hong Kong, Hong Kong, China},
series = {ACM MOBICOM '25}
}

@inproceedings{10.1145/3680207.3723484,
author = {Hou, Haozheng and Zheng, Bowen and Cheng, Sitong and Zhao, Xiaoguang and Wu, Peiheng and He, Lixing and Guo, Yunqi and Xing, Guoliang and Yan, Zhenyu},
title = {AquaScan: A Sonar-based Underwater Sensing System for Human Activity Monitoring},
year = {2025},
isbn = {9798400711299},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3680207.3723484},
doi = {10.1145/3680207.3723484},
abstract = {Human activity monitoring in the water is essential for pool management and drowning prevention. Existing camera-based solutions pose significant concerns about privacy and extra installation costs. Although sonars have been widely used for underwater sensing in open aquatic environments such as oceans and lakes, monitoring human activities with sonars in a pool setup is still challenging. In this work, we propose AquaScan, the first scanning sonar-based underwater sensing system for human activity monitoring. To overcome the low frame rate due to the sonar's physical limitation, we propose a novel scanning strategy and apply an image reconstruction method to accelerate the scanning speed without compromising the performance of motion detection. To overcome the dynamic interferences in the underwater scenario, we develop a novel signal processing pipeline based on a physical model to remove noises and localize human subjects. We further extract features like motion, time, and spatial information from sonar images and develop a state-transfer-based activity recognition system to recognize five common water activities, i.e., swimming, motionless, splashing, struggling, and drowning. We have deployed AquaScan on three public swimming pools for a total period of 94 hours. The evaluation results show that AquaScan can successfully recognize the five activities in the water with around 91.5\%.},
booktitle = {Proceedings of the 31st Annual International Conference on Mobile Computing and Networking},
pages = {438–452},
numpages = {15},
keywords = {underwater sensing system, sonar, human activity recognition},
location = {Kerry Hotel, Hong Kong, Hong Kong, China},
series = {ACM MOBICOM '25}
}

@article{10.1145/3772067,
author = {Khodayarseresht, Ehsan and Smolyakova, Sofya and Zhao, Lianying and Mansouri, Armin and Majumdar, Suryadipta and Conti, Mauro},
title = {ForenThings: An Interactive Framework for Crime Scene Reconstruction in IoT Forensics},
year = {2025},
issue_date = {February 2026},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {7},
number = {1},
url = {https://doi.org/10.1145/3772067},
doi = {10.1145/3772067},
abstract = {In IoT platforms, devices and sensors can interact with each other via smart apps that utilize automation settings preconfigured by users, resulting in significant amounts of potential forensic data. Existing IoT forensic approaches can pinpoint relevant data sources for specific activities in smart environments using static code analysis and instrumentation techniques. However, recent IoT platforms like SmartThings no longer run application code on their infrastructure, making access to source code impossible for existing IoT forensic solutions. To bridge this gap, this paper introduces ForenThings, an interactive framework for crime scene reconstruction in smart environments. The main idea is to convert each IoT device and smart app to a responsive agent, enabling them to participate in a forensic investigation of a security incident collaboratively. Instead of relying on static code analysis or instrumentation, ForenThings reconstructs the scene from the device and app events forwarded by the IoT platform. We develop a ForenThings prototype for the SmartThings platform and test its effectiveness for both normal scenarios and 12 real-world IoT attack scenarios. The evaluation shows that ForenThings can achieve 100\% data provenance coverage in reconstructing various crime scenes in a smart environment with negligible runtime and resource overhead.},
journal = {ACM Trans. Internet Things},
month = nov,
articleno = {5},
numpages = {31},
keywords = {IoT security, security incident investigation, forensics, provenance graph}
}

@article{10.1145/3777481,
author = {Yuan, Songhe and Yang, Laurence T. and Liu, Debin and Li, Jie},
title = {DPANet: Domain Pyramid Attention Network for Domain Generalization on Medical Image Segmentation in Connected Health},
year = {2025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3777481},
doi = {10.1145/3777481},
abstract = {Connected health integrates sensors, mobile devices, and information technology to realize the real-time collection and transmission of medical data, providing patients with more personalized and efficient medical services. In this context, medical image segmentation technology plays a vital role as a key digital medicine tool in connected health. However, its effective deployment across diverse clinical settings and data sources remains challenging due to inherent variations in imaging modalities, patient demographics, and device characteristics. Currently, connected health requires highly efficient AI models for real-world medical applications. The versatility of the model across diverse environments is of great significance. Domain Generalization (DG) has emerged as a crucial solution to address these challenges of connected health. Previous work focuses on the domain similarity calculation on the final layer output of the backbone model, which ignores the impact of the multi-scale features. In this paper, we proposed a Domain Pyramid Attention Network (DPANet), which aims to transfer knowledge from source domains to unseen domains for medical image segmentation at a multi-scale level. The overarching goal is to enhance the efficiency of connected health systems through this innovative knowledge transfer mechanism. DPANet is capable of learning multi-scale similarity between two kinds of domains through a Domain Similarity Pyramid Attention Module (DSPAM). We also designed Domain Prototypes (DP), which can enhance the flexibility of the knowledge pre-extracted from source domains for better transferability. A simple fusion method is adopted to merge the multi-scale features for the final segmentation prediction. DPANet is evaluated on Brain Tumor segmentation and Retina Fundus segmentation tasks, achieving an average Dice improvement of 1.14\% and 0.98\% on these two tasks, respectively.},
note = {Just Accepted},
journal = {ACM Trans. Comput. Healthcare},
month = nov,
keywords = {Connected Health, Domain Generalization, Attention Network, Multi-Scale Similarity, Domain Prototypes}
}

@article{10.1145/3768625,
author = {Zheng, Yu},
title = {Fusing Cross-Domain Knowledge from Multimodal Data to Solve Problems in the Physical World},
year = {2025},
issue_date = {February 2026},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {17},
number = {1},
issn = {2157-6904},
url = {https://doi.org/10.1145/3768625},
doi = {10.1145/3768625},
abstract = {The proliferation of artificial intelligence has enabled a diversity of applications that bridge the gap between digital and physical worlds. As physical environments are too complex to model through a single information acquisition approach, it is crucial to fuse multimodal data generated by different sources, such as sensors, devices, systems, and people, to solve a problem in the real world. Unfortunately, it is neither applicable nor sustainable to deploy new resources to collect original data from scratch for every problem. Thus, when data is inadequate in the domain of the problem, it is vital to fuse knowledge from multimodal data that is already available in other domains. We call this cross-domain knowledge fusion. Existing research focuses on fusing multimodal data in a single domain, supposing the knowledge from different datasets is intrinsically aligned; however, this assumption may not hold in the scenarios of cross-domain knowledge fusion. In this article, we formally define the cross-domain multimodal data fusion problem, discussing its unique challenges, differences, and advantages beyond data fusion in a single domain. We propose a four-layer framework, consisting of Domains, Links, Models, and Data layers, answering three key questions: “what to fuse,” “why can be fused,” and “how to fuse.” The Domains Layer selects relevant data from different domains for a given problem. The Links Layer reveals the philosophy of knowledge alignment beyond specific model structures. The Models Layer provides two knowledge fusion paradigms based on the fundamental mechanisms for processing data. The Data Layer turns data of different structures, resolutions, scales, and distributions into a consistent representation that can be fed into an AI model. With this framework, we can design solutions that fuse cross-domain multimodal data effectively for solving real-world problems.},
journal = {ACM Trans. Intell. Syst. Technol.},
month = nov,
articleno = {1},
numpages = {32},
keywords = {Knowledge fusion, data fusion, multimodal data, cross-domain, data ransformation, urban computing, spatio-temporal data, deep learning}
}

@inproceedings{10.1145/3733802.3764050,
author = {Schwarz, Peter and Pohle, Erik and Abidin, Aysajan and Preneel, Bart},
title = {Evaluating Ascon in Secure Multi-Party Computation using Reverse Multiplication-Friendly Embeddings},
year = {2025},
isbn = {9798400718984},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3733802.3764050},
doi = {10.1145/3733802.3764050},
abstract = {We present the first systematic study on communication-efficient evaluation of the lightweight cipher family Ascon within secure multi-party computation (MPC). By leveraging Ascon’s parallel, bit-oriented structure, we adapt its design using Reverse Multiplication-Friendly Embeddings (RMFEs, introduced by Cascudo et al. in CRYPTO’18) in a single-circuit evaluation, enabling efficient packing of groups of bits into field elements. Our protocol, which uses relatively small RMFEs, achieves substantial reductions in communication cost compared to baseline MPC protocols. For example, in a medium-sized setting (with n = 13 MPC parties), our protocol reduces the communication cost for an Ascon permutation by roughly (38\%). For large amounts of parties (e.g., n = 255), the reduction can reach (50\%). These improvements are achieved even though RMFEs only pack a few bits per field element, due to favorable amortization of both substitution and linear layers. We also provide a Boolean circuit implementation of Ascon in the MP-SPDZ framework, enabling straightforward benchmarking. Our findings are particularly beneficial for bandwidth-constrained environments where the use of lightweight ciphers, such as Ascon, is necessary due to the resource limitations of client devices, as in the case of transciphering data from IoT sensors. Since our optimizations target the Ascon permutation, they naturally extend to all cryptographic modes (encryption, decryption, hashing) defined for the standard.},
booktitle = {Proceedings of the 24th Workshop on Privacy in the Electronic Society},
pages = {60–74},
numpages = {15},
keywords = {Ascon, Secure Multi-Party Computation, Reverse Multiplication-Friendly Embeddings},
location = {
},
series = {WPES '25}
}

@inproceedings{10.1145/3757980.3757999,
author = {Alhasan, Khawla and Alhasan, Khaled and Velasco, Carlos and Altarriba Bertran, Ferran and Ali, Moneim and Covaci, Alexandra},
title = {Eating together apart: Designing immersive, multisensory commensality experiences in Virtual Reality},
year = {2025},
isbn = {9798400715129},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3757980.3757999},
doi = {10.1145/3757980.3757999},
abstract = {Immersive technologies offer new possibilities for reimagining how people eat together across distance. In this paper, we explore the experience of shared eating in Virtual Reality (VR) through a three-phase study: (i) an initial survey in which participants (n=32) described how they would design a shared eating experience in VR; (ii) the development of a multisensory immersive commensality prototype; (iii) and evaluations with 14 participants. Our findings show that immersive eating supports playful social connection and deepens sensory engagement. Enabled by multisensory, responsive design features, participants developed new rituals and engaged in playful, norm-breaking gestures typically discouraged in conventional dining. At the same time, immersive dining introduced new behavioural tensions, including overeating driven by environmental rewards and concerns about authenticity and cultural representation. Building on these insights, we outline key opportunities and challenges for future research.},
booktitle = {Proceedings of the 28th International Academic Mindtrek Conference},
pages = {164–175},
numpages = {12},
keywords = {Immersive Eating, Virtual Reality (VR), Commensality, Human Food Interaction, Multisensory Interaction, Food and Technology, Eating Behaviours},
location = {
},
series = {Mindtrek '25}
}

@inproceedings{10.1145/3772356.3772392,
author = {An, Jaechan and Zhu, Zeying and Miers, Ian and Liu, Zaoxing},
title = {Towards Verifiable Network Telemetry without Special Purpose Hardware},
year = {2025},
isbn = {9798400722806},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3772356.3772392},
doi = {10.1145/3772356.3772392},
abstract = {Verifiable network telemetry is crucial for ensuring transparency and trust in network measurements. However, telemetry logs (e.g., NetFlow records) often contain sensitive data, making public verification challenging. Recent work has attempted to address this problem using Trusted Execution Environments (TEEs), such as Intel SGX, to provide confidentiality and integrity guarantees. However, TEEs are known to suffer from complex deployment requirements and limited scalability. In this paper, we introduce a software-based approach utilizing the latest advances in Zero-knowledge Proofs (ZKPs) to enable verifiable network telemetry without revealing the underlying sensitive logs or relying on special-purpose hardware. Our system employs a general-purpose ZKP virtual machine (RISC Zero) to generate cryptographic proofs over NetFlow data, enabling operators to securely attest to network flow metrics. Our preliminary results indicate that our ZKP-based design offers a viable path toward overcoming deployment and scalability limitations inherent in the solutions that require special-purpose hardware.},
booktitle = {Proceedings of the 24th ACM Workshop on Hot Topics in Networks},
pages = {411–418},
numpages = {8},
keywords = {network telemetry, verifiable measurement, zero knowledge proof},
location = {UMD Campus, College Park, MD, USA},
series = {HotNets '25}
}

@article{10.1145/3771094,
author = {Li, Chunlin and Zhang, Zihao and Wang, Jiaqi and Yuan, Shaochong and Wang, Zonghe and Chai, Long and Li, Aoyong and Wan, Shaohua},
title = {Improved Multi-Agent Proximal Policy Optimization Algorithm for Resource Allocation with Radar-Perception in UAV-Assisted VEC},
year = {2025},
issue_date = {November 2025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {21},
number = {6},
issn = {1550-4859},
url = {https://doi.org/10.1145/3771094},
doi = {10.1145/3771094},
abstract = {In congested road environments, the spectrum resources available for Roadside Units (RSUs) are often insufficient to meet the communication needs of a large number of users simultaneously. To address this, Unmanned Aerial Vehicles (UAVs) can be deployed to supplement spectrum resources temporarily. This article proposes a UAV-assisted Vehicle Edge Computing (VEC) system, integrating UAVs to enhance RSU capabilities in congested scenarios. Traditional spectrum sensing techniques, however, struggle to autonomously monitor vehicular movements and maintain stable spectrum performance. To overcome this, we introduce radar sensing devices into the RSUs to improve perception accuracy and consistency. The integration of radar sensors, while beneficial, creates additional competition for limited system resources. We, therefore, formulate the resource allocation problem considering computation delay, communication rate, and perception data, constrained by spectrum resources, offloading decisions, and time-slot allocations. The problem is modeled as a Markov Decision Process (MDP), and we propose an Improved Multi-Agent Proximal Policy Optimization (IMAPPO) algorithm to optimize resource allocation under these constraints. The experimental results show that compared to baseline algorithms such as A3C, our proposed algorithm reduces the average task processing delay by 15.53\%, increases the radar estimation mutual information (MI) by 9.52\%, and improves the task completion rate by 4.1\%.},
journal = {ACM Trans. Sen. Netw.},
month = nov,
articleno = {58},
numpages = {28},
keywords = {UAV-assisted VEC, resource allocation, markov decision process, improved multi-agent proximal policy optimization algorithm}
}

@inproceedings{10.1145/3733816.3760753,
author = {Mondragon, Jennifer and Cruz, Gael and Rubio-Medrano, Carlos and Shastri, Dvijesh},
title = {"I Apologize For Not Understanding Your Policy": Exploring the Evaluation of User-Managed Access Control Policies by AI Virtual Assistants},
year = {2025},
isbn = {9798400719059},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3733816.3760753},
doi = {10.1145/3733816.3760753},
abstract = {The rapid evolution of Artificial Intelligence (AI)-based Virtual Assistants (VAs), e.g., Google Gemini, ChatGPT, Microsoft Copilot, and High-Flyer Deepseek, has turned them into convenient interfaces for managing emerging technologies such as Smart Homes, Smart Cars, and Electronic Health Records. By leveraging explicit commands, e.g., prompts, which can be even launched via voice, VAs provide a very natural interface for end-users. However, the proper specification and evaluation of User-Managed Access Control Policies (U-MAPs), the rules issued and managed by end-users to govern access to sensitive data and device functionality within these VAs, presents significant challenges as this process is crucial for preventing security vulnerabilities and privacy leaks without impacting user experience. This work-in-progress study provides an initial exploratory investigation on whether current publicly-available VAs can manage U-MAPs effectively across differing scenarios. By conducting unstructured to structured tests, we evaluated the comprehension of such VAs, revealing a lack of understanding in varying U-MAP approaches. Our research not only identifies key limitations, but offers valuable insights into how VAs can be further improved to manage complex authorization rules and adapt to dynamic changes.},
booktitle = {Proceedings of the 2025 Workshop on Human-Centered AI Privacy and Security},
pages = {43–53},
numpages = {11},
location = {
},
series = {HAIPS '25}
}

@inproceedings{10.1145/3749385.3749401,
author = {Topaz, Amanda and Montoya, Maria Fernanda and Patibanda, Rakesh and Andres, Josh and Mueller, Florian 'Floyd'},
title = {Blindfolded in the Air: Towards the Design of Interactive Aerial Play},
year = {2025},
isbn = {9798400714283},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3749385.3749401},
doi = {10.1145/3749385.3749401},
abstract = {The intersection of aerial acrobatics (movement on a suspended apparatus where the performer is off the ground) and interactive technology remains an underexplored area in HCI. In this autoethnographic study, we investigate the interplay between augmented eyesight and proprioception in adapting to the suspended environment. We developed a motion-sensitive blindfold mixed-reality headset application that enables wearers to transition between visibility and darkness based on their body’s orientation while rotating in a two-point harness. Analyzing videos, somaesthetic maps, and interviews, we observed that our design reduces visual and social distractions, facilitating inward focus on movement and breath. However, acclimation to both physical and mixed-reality systems is necessary for people to interact comfortably. The findings extend our understanding of designing interactive real-time visuomotor couplings between movements and mixed-reality in suspended environments, offering four themes and six design considerations to support the active body, aiming to enrich the possibilities for augmented aerial play.},
booktitle = {Proceedings of the First Annual Conference on Human-Computer Interaction and Sports},
articleno = {1},
numpages = {16},
keywords = {Aerial arts, Acrobatics, Extended Reality, Movement-based design, Suspended environments.},
location = {
},
series = {SportsHCI '25}
}

@inproceedings{10.1145/3731599.3767384,
author = {Esmaeilian, Anita and Ahmed, Kishwar},
title = {From Soil to Software: Experience from a STEM Workshop on Smart Plant Care and Teachable Machines},
year = {2025},
isbn = {9798400718717},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3731599.3767384},
doi = {10.1145/3731599.3767384},
abstract = {In this paper, we present our work on developing a sensor-based device capable of large-scale environmental data collection. We also outline how we integrated this technology into a STEM education workshop for high school students. Conducted over three consecutive days as part of the Toledo EXCEL program, the workshop aimed to introduce students to foundational computing concepts, including data acquisition, machine learning, and artificial intelligence through accessible, hands-on activities. Participants used a custom-built IoT sensor system in conjunction with visual programming tools like MakeCode to create a smart plant care assistant. They also explored basic machine learning by training classifiers using Teachable Machine. We describe both the technical development of the sensor device and its role in engaging students with real-world computing applications. Finally, we outline plans to enhance future workshops with topics such as parallel computing and real-time data visualization dashboards.},
booktitle = {Proceedings of the SC '25 Workshops of the International Conference for High Performance Computing, Networking, Storage and Analysis},
pages = {424–432},
numpages = {9},
keywords = {STEM education, AI literacy, Teachable Machine, image classification, sensors, MakeCode, high-performance computing, plant health, micro:bit, interactive learning},
location = {
},
series = {SC Workshops '25}
}

@inproceedings{10.1145/3770445.3770478,
author = {Qiu, Yilin},
title = {Future Sci-Fi Climate: An Interactive Device for Visualizing Urban Climate Change through Artistic and Sensor-Based Media},
year = {2025},
isbn = {9798400718519},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3770445.3770478},
doi = {10.1145/3770445.3770478},
abstract = {Amidst rapid global urbanization, cities serve as both engines of economic growth and critical zones for climate change impacts. Increasing sea levels, extreme weather events, and ecosystem degradation threaten urban sustainability and public health. At the same time, advancements in digital media are transforming visual communication, utilizing tools such as TouchDesigner (TD), Arduino, and sensor networks to facilitate dynamic, real-time media interactions that expand artistic possibilities. This project introduces Future Sci-Fi Climate, an interactive device designed to visualize global warming by linking audience actions to evolving climate scenarios. Tested in a laboratory environment, the device underwent rigorous evaluation of sensor accuracy, latency, visualization clarity, and transition effectiveness between scenarios. Findings indicate the device operates with stability, low latency, and accurate correlation between user input and climate modeling. Its primary aim is to enhance awareness and provoke reflection on human activity during the Anthropocene epoch.},
booktitle = {Proceedings of the 2025 International Conference on Generative AI and Digital Media Arts},
pages = {184–188},
numpages = {5},
keywords = {Arduino, TouchDesigner, climate visualization, environmental awareness, interactive device, media art},
location = {
},
series = {GAIDMA '25}
}

@inproceedings{10.1145/3712285.3759854,
author = {Fan, Hao and Huang, Zhuo and Ibrahim, Shadi and Gu, Lin and Wu, Song},
title = {EDDE: Container Deployment Framework Beyond the Cloud},
year = {2025},
isbn = {9798400714665},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3712285.3759854},
doi = {10.1145/3712285.3759854},
abstract = {Containers, renowned for their lightweight nature and flexibility, have seen growing adoption for deploying edge services such as web applications. However, existing cloud-oriented container deployment frameworks fail to address the unique challenges of edge environments, including geographical distribution, device heterogeneity, and resource constraints. This oversight leads to suboptimal performance for latency-sensitive edge services like HPC/AI-powered autonomous driving and edge gaming, which demand rapid startup and immediate responsiveness.Our investigation demonstrates that current on-demand image solutions require excessive client-registry communication, resulting in prolonged Round-Trip Time (RTT) - a particularly severe limitation in geographically distributed edge platforms. Furthermore, we observe that the user-space file system (e.g., FUSE), typically employed to handle device heterogeneity, introduces substantial overhead to the native I/O stack. More critically, our findings reveal that on-demand image solutions exacerbate storage pressure on resource-constrained edge devices. To overcome these challenges, we introduce EDDE, an edge-optimized container deployment framework that redesigns the on-demand image pipeline. EDDE achieves up to 9.8 \texttimes{} higher deployment efficiency than standard Docker. When compared to state-of-the-art on-demand solutions, EDDE delivers containers 147\% faster on average, reduces native I/O latency by up to 28\%, and decreases storage usage by an average of 34\%.},
booktitle = {Proceedings of the International Conference for High Performance Computing, Networking, Storage and Analysis},
pages = {570–585},
numpages = {16},
keywords = {Edge, Container Image, FUSE, Layers, On-demand},
location = {
},
series = {SC '25}
}

@inproceedings{10.1145/3721201.3721426,
author = {Clapham, John and Zhou, Michelle and MacDonald, Collin and Koltermann, Kenneth and Gao, Ye and Shao, Huajie},
title = {ElectroMeter: The Practical Electrolyte Measurement System},
year = {2025},
isbn = {9798400715396},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3721201.3721426},
doi = {10.1145/3721201.3721426},
abstract = {Maintaining a healthy electrolyte balance is crucial for everyday well-being. Beyond enhancing overall quality of life, adequate electrolyte replenishment plays a pivotal role in mitigating the risk of serious health conditions such as hypertension and heart disease. It is unnecessarily difficult for users to compare options and determine the electrolyte content of many commercially available beverage options. Consumers must rely on manufacturer claims and cannot easily verify the electrolyte contents of beverages or compare their best options. This paper presents ElectroMeter, a novel end-to-end sensor system capable of measuring and ranking the electrolyte content of any beverage using non-intrusive and cost-effective hardware. This system incorporates innovative sensor hardware that interfaces with a companion application to measure the electrolyte content in liquids. Our solution empowers individuals to measure and verify the electrolyte content of liquids. ElectroMeter can accurately rank the electrolyte content of 13 commercially available beverages with various levels of electrolyte content in agreement with a Multimeter ground truth method.},
booktitle = {Proceedings of the ACM/IEEE International Conference on Connected Health: Applications, Systems and Engineering Technologies},
pages = {164–175},
numpages = {12},
location = {Yeshiva University Museum, New York, NY, USA},
series = {CHASE '25}
}

@inproceedings{10.1145/3721201.3725431,
author = {Weerasekara, Thejan Bandara and Chandeepa, Chinthani and Amarasuriya, Oshan Sandeep and Hettiarachchi, Chathuranga},
title = {Privacy-Preserving Medical Advising System on Mobile Devices: On-Device PHI Anonymization, Medical Report Retrieval, and Cloud-Based RAG},
year = {2025},
isbn = {9798400715396},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3721201.3725431},
doi = {10.1145/3721201.3725431},
abstract = {Ensuring the confidentiality of information and accuracy especially related to medical data is a critical challenge in the development of digital health applications. This paper presents a novel approach for a medical chat application that is intended to preserve user privacy while ensuring the accuracy of responses. On-device privacy-preserving techniques and context-aware medical report retrieval mechanisms are engaged on Android mobile phones with cloud-based retrieval-augmented generation (RAG) in this system. A lightweight, transformer-based language model is leveraged for the anonymization of protected health information (PHI) directly on the user's mobile device with a medical report storage and a retriever ensuring private and sensitive information never leaves the device in its raw form. The cloud-based subsystem acts as the backend and is responsible for processing the anonymized requests, retrieving relevant medical knowledge, and generating accurate, context-aware responses using a large language model (LLM).},
booktitle = {Proceedings of the ACM/IEEE International Conference on Connected Health: Applications, Systems and Engineering Technologies},
pages = {447–452},
numpages = {6},
keywords = {protected health information (PHI), privacy-preserving systems, digital health privacy, cloud-based retrieval-augmented generation (RAG), on-device RAG, on-device processing, anonymization},
location = {Yeshiva University Museum, New York, NY, USA},
series = {CHASE '25}
}

@inproceedings{10.1145/3721201.3724418,
author = {Ansah, Stella and Chen, Diliang},
title = {Stride Length Estimation with Motion Data from the Contralateral Foot},
year = {2025},
isbn = {9798400715396},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3721201.3724418},
doi = {10.1145/3721201.3724418},
abstract = {Stride length estimation plays an important role in gait analysis, rehabilitation, and mobility assessment, offering insights into walking efficiency, balance, and musculoskeletal health. Gait depends on the coordinated movement of the stride foot and the contralateral foot. However, most studies have focused solely on estimating stride length using data from the stride foot, leaving the contribution of the contralateral foot largely unexplored. This study addresses this gap by investigating how capturing kinematic data from the contralateral foot can enhance stride length estimation using motion data from a smart insole system consisting of an IMU embedded in the mid-region of the insole and an LSTM model. A leave-one-subject-out evaluation was conducted with data from 10 healthy subjects to assess stride estimation under three conditions: utilizing IMU data from both feet, from the stride foot only, and from the contralateral foot only. The best-performing test case, with an average mean percentage absolute error of 7.67\%, was achieved when using data from both feet. Notably, kinematic data from the contralateral foot alone yielded a competitive error of 7.75\%, further highlighting its relevance. These findings demonstrate the importance of integrating motion data from contralateral feet to enhance stride length estimation while ensuring robust and reliable gait analysis. This study provides key insights for future research in wearable sensing, gait analysis, and AI-driven movement modeling, contributing to advancements in lower-limb mobility assessment and rehabilitation applications.},
booktitle = {Proceedings of the ACM/IEEE International Conference on Connected Health: Applications, Systems and Engineering Technologies},
pages = {407–411},
numpages = {5},
keywords = {stride length, inertial measurement unit, contralatral foot, gait analysis, deep learning},
location = {Yeshiva University Museum, New York, NY, USA},
series = {CHASE '25}
}

@inproceedings{10.1145/3721201.3724417,
author = {Ozolcer, Melik and Bae, Sang Won},
title = {Personalized Neural Modeling for Daily Injury Risk Assessment via Wearable Health Data},
year = {2025},
isbn = {9798400715396},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3721201.3724417},
doi = {10.1145/3721201.3724417},
abstract = {Despite advances in wearable technology, existing models for athletic injury prediction often lack personalization and proper temporal alignment, limiting their effectiveness. In this work, we introduce the Personalized Athlete Injury Risk Model (PAIR), a neural network designed to predict daily self-reported injury risk scores using wearable sensor data. Evaluations on 36 collegiate athletes across 3,000+ daily observations show that PAIR achieves an R-squared value of 0.506, outperforming a non-personalized baseline (0.302) and highlighting the benefits of our approach. Our key contributions include: (1) developing a personalized neural network model that captures athlete-specific patterns through individualized embeddings and advanced signal processing, and (2) demonstrating that personalization and robust temporal alignment significantly improve prediction performance and utility.},
booktitle = {Proceedings of the ACM/IEEE International Conference on Connected Health: Applications, Systems and Engineering Technologies},
pages = {401–406},
numpages = {6},
keywords = {injury risk prediction, wearable sensors, personalized modeling, neural networks, health informatics},
location = {Yeshiva University Museum, New York, NY, USA},
series = {CHASE '25}
}

@inproceedings{10.1145/3721201.3724415,
author = {Das Bhattacharjee, Sreyasee and Chhabria, Jatin and Pallapothula, Vamsi Kumar Naidu},
title = {ActDiffNet: Multisensor Affective State Recognition by Actively Synthesizing Minority Patterns via Conditional Diffusion},
year = {2025},
isbn = {9798400715396},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3721201.3724415},
doi = {10.1145/3721201.3724415},
abstract = {A key challenge in personalized ubiquitous healthcare is developing efficient wearable platforms that accurately classify biosignals while remaining adaptive to the evolving data patterns, particularly highlighting an individual's personal and other exterior context dynamics. However, several challenges plague machine learning applications involving biomedical signals, including limited data, imbalanced classes, difficulty accessing reliable annotated data, and noisy measurements. To this end, we propose an active learning model ActDiffNet for affective state recognition from multisensor signals that first leverage only a small annotated data collection to build an initial classifier, and later iteratively upgrade via a shortlisted set of synthesized 'hard' signals conditionally diffused by those unique signal patterns, on which the model has not been sufficiently trained yet. The proposed ActDiffNet converges faster, achieving comparable classification performance with 1–2 orders of magnitude fewer labeled samples than fully supervised approaches to attain a state-of-the-art accuracy of 78\%. An effective Context Conditioned Synthetic Signal Generation module that employs multiple sensor-specific copies of the conditioned U-Net to facilitate synthesizing signals that closely mimic the sensor and class-specific patterns of shortlisted 'hard' signals within its generated outputs. Extensive evaluation using two public datasets WESAD and CASE reports outperformance (e.g., 1.5 – 3\% improved accuracy) of the proposed ActDiffNet against state-of-the-art supervised or self-supervised models while delivering a consistently robust generalization all across.},
booktitle = {Proceedings of the ACM/IEEE International Conference on Connected Health: Applications, Systems and Engineering Technologies},
pages = {389–394},
numpages = {6},
keywords = {multisensor signal, wearable device, emotion recognition, data augmentation, diffusion},
location = {Yeshiva University Museum, New York, NY, USA},
series = {CHASE '25}
}

@inproceedings{10.1145/3721201.3721372,
author = {Chowdhury, Meghna Roy and Xuan, Wei and Sen, Shreyas and Zhao, Yixue and Ding, Yi},
title = {Predicting and Understanding College Student Mental Health with Interpretable Machine Learning},
year = {2025},
isbn = {9798400715396},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3721201.3721372},
doi = {10.1145/3721201.3721372},
abstract = {Mental health issues among college students have reached critical levels, affecting both academic performance and overall wellbeing. Predicting and understanding mental health status among college students is challenging due to three key barriers: the lack of large-scale longitudinal datasets, the prevalence of black-box machine learning models that offer little transparency, and a reliance on population-level analysis rather than personalized understanding.To tackle these challenges, this paper presents I-HOPE, the first Interpretable Hierarchical mOdel for Personalized mEntal health prediction. I-HOPE is a two-stage hierarchical model that connects raw behavioral features to mental health status through five defined behavioral categories as interaction labels. We evaluate I-HOPE on the College Experience Study, the longest longitudinal mobile sensing dataset. This dataset spans five years and captures data from both pre-pandemic periods and the COVID-19 pandemic. I-HOPE achieves a prediction accuracy of 91\%, significantly surpassing the 60–70\% accuracy of baseline methods. In addition, I-HOPE distills complex patterns into interpretable and individualized insights, enabling the future development of tailored interventions and improving mental health support.},
booktitle = {Proceedings of the ACM/IEEE International Conference on Connected Health: Applications, Systems and Engineering Technologies},
pages = {257–268},
numpages = {12},
keywords = {mental health, college students, interpretable machine learning, personalized prediction},
location = {Yeshiva University Museum, New York, NY, USA},
series = {CHASE '25}
}

@inproceedings{10.1145/3721201.3721380,
author = {Sahoo, Soumyashree and Hossain, Zakir and Shende, Chinmaey and Patel, Parit and Wang, Xinyu and Bi, Jinbo and Kamath, Jayesh and Russell, Alexander and Song, Dongjin and Wang, Bing},
title = {Smartphone Data Gathered Early in Depression Treatment Predicts Treatment Outcome},
year = {2025},
isbn = {9798400715396},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3721201.3721380},
doi = {10.1145/3721201.3721380},
abstract = {Predicting treatment outcomes early in depression care is crucial for guiding timely clinical decisions. Early identification of non-responders allows clinicians to adjust treatment strategies sooner, minimizing patient suffering and reducing strain on healthcare systems. This study explores whether smartphone data collected early, specifically, during the initial 2–4 weeks of treatment, can provide reliable insights into treatment outcome at the 12th week (the end of a treatment course). We integrate weekly medication surveys, daily mood and anxiety self-ratings, and location-based sensory features to develop machine learning models capable of predicting depression treatment outcomes 8 to 10 weeks before treatment completion. Our results demonstrate that smartphone data collected early in treatment can achieve prediction accuracy comparable to weekly clinical questionnaires, with improved performance when multiple data sources are combined. Using the data of first two weeks, F1 scores reach 0.60 with a single source of data and 0.68 with all three types of data combined. Extending the data to four weeks improves the corresponding accuracy to 0.67 of data) and 0.73, respectively, emphasizing the value of longer-term sequential data. Incorporating clinical questionnaire scores collected at baseline and the fourth week further enhances prediction accuracy, achieving a maximum F1 score of 0.77.},
booktitle = {Proceedings of the ACM/IEEE International Conference on Connected Health: Applications, Systems and Engineering Technologies},
pages = {93–104},
numpages = {12},
keywords = {depression treatment outcome prediction, smartphone data, machine learning, early treatment response, sequential data modeling, mental health AI},
location = {Yeshiva University Museum, New York, NY, USA},
series = {CHASE '25}
}

@inproceedings{10.1145/3721201.3725435,
author = {Gopireddy, Kavya and Wang, Yiting and Shen, Jingzhou and Jiang, Jason and Wang, Xuyu},
title = {A Dual-Modality Approach for Contactless Vital Sign Monitoring Using Camera and Wi-Fi CSI},
year = {2025},
isbn = {9798400715396},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3721201.3725435},
doi = {10.1145/3721201.3725435},
abstract = {Contactless monitoring of breathing patterns is essential for diagnosing conditions such as sleep disorders and lung diseases. However, existing methods such as Radio Frequency Identification (RFID), radar, Wi-Fi Channel State Information (CSI), and camera-based techniques face challenges like signal noise and environmental interference. To address these challenges, we propose a model that enhances the robustness of vital sign monitoring by integrating multiple sensing techniques. In this paper, we propose a dual-modality, device-free breathing detection system that integrates Wi-Fi CSI and camera-based sensing to classify breathing patterns into four categories: fast, normal, slow, and breath-holding. We also design a neural network model that integrates Wi-Fi-based and camera-based breathing sensing and integrate them into an ensemble neural network model for robust classification. Our results demonstrate that this approach significantly enhances both robustness and accuracy in breathing type prediction.},
booktitle = {Proceedings of the ACM/IEEE International Conference on Connected Health: Applications, Systems and Engineering Technologies},
pages = {470–475},
numpages = {6},
keywords = {wireless sensing, vital sign monitoring, wi-fi sensing, computer vision},
location = {Yeshiva University Museum, New York, NY, USA},
series = {CHASE '25}
}

@inproceedings{10.1145/3736425.3772100,
author = {Cao, Jinpu and Marshall, Larry Collin, Jr. and Codling, Jesse R and Sharma, Sudhendu Raj and Brown-Brandl, Tami and Fischer, Martin and Zhang, Pei and Noh, Hae Young and Dong, Yiwen},
title = {VibraFarrow: Pig Farrowing Time Prediction Using Ambient Floor Vibrations},
year = {2025},
isbn = {9798400719455},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3736425.3772100},
doi = {10.1145/3736425.3772100},
abstract = {Farrowing, the onset of parturition in mother pigs (i.e., sows), is a high-risk period for both the sow and her newborn piglets. Early and accurate prediction of farrowing time, along with monitoring indicators such as vital signs and pre-farrowing behaviors, enables timely assistance and can lead to lower stillbirth rates. However, existing methods have limitations: camera-based systems require constant lighting that disrupts pigs' circadian rhythms, while wearable sensors can cause discomfort to pigs and are prone to be damaged.We introduce VibraFarrow, a novel non-intrusive vibration sensing system that models pig-induced floor vibration data collected from the built environments to predict farrowing time. Specifically, VibraFarrow predicts whether a sow will farrow within the next 20 hours, enabling contact-free, long-term tracking of farrowing-related behaviors for pigs. The key challenge in developing VibraFarrow is the uncertainty of pre-farrowing behaviors embedded in the long-term vibration time series. First, pre-farrowing behaviors exhibit highly variable timing and duration, occurring intermittently and mixed with ambient noises, which complicates feature extraction over time. Second, the types and patterns of pre-farrowing behavior are uncertain, leading to unreliable predictions using a fixed set of explicit activities. To address the first challenge, VibraFarrow introduces Hierarchical Adaptive Window Selection (HAWS), a hierarchical method that adaptively selects time windows ranging from hours, minutes, to seconds and extracts farrowing-related features from long-term ambient vibration data. Furthermore, to overcome the uncertainty of pre-farrowing behavior patterns and types, VibraFarrow allows flexibility in extracting implicit indicators that are representative of pre-farrowing behaviors for specific time windows through unsupervised clustering. Finally, VibraFarrow fuses the implicit behavior indicators and other expert-defined features (e.g., heart and respiration rates) extracted by HAWS for farrowing time prediction.We deployed our system on a real-world farm for seven months, monitoring 18 farrowing events and collecting 384 hours of vibration data. The system achieved a weighted F1-score of 0.735, surpassing the baseline by up to 20\%. This improvement demonstrates floor vibration sensing as an effective, non-intrusive approach for farrowing prediction, with broader implications for occupant health and wellness management in built environments.},
booktitle = {Proceedings of the 12th ACM International Conference on Systems for Energy-Efficient Buildings, Cities, and Transportation},
pages = {150–160},
numpages = {11},
keywords = {pig, farrowing prediction, floor vibration, vital sign, unsupervised learning},
location = {Colorado School of Mines, Golden, CO, USA},
series = {BuildSys '25}
}

@inproceedings{10.1145/3736425.3772361,
author = {Jacob, Jeslu and Vaidya, Prasad},
title = {Phantom Load: An Immersive 3D Energy Detective Game},
year = {2025},
isbn = {9798400719455},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3736425.3772361},
doi = {10.1145/3736425.3772361},
abstract = {With the rapid rise in global energy consumption, decarbonizing and reducing energy waste in buildings is critical. This requires an in-depth understanding of interactions between building systems such as envelope, activities and plug loads, lighting, and air-conditioning design. These are often taught as theoretical subjects in academic curricula, with little emphasis on real-world application. As a result, students often graduate without practical knowledge of how building systems interact and struggle to solve operational issues effectively. Previous researchers have addressed this challenge by developing gamified e-learning modules that simulate building systems to provide realistic virtual experience in solving operational problems. Despite their reported early success, the projects that supported these have been discontinued, and those modules are no longer available.Further, reducing energy wastage requires awareness of hidden or unnoticed energy drains, often referred to as latent or phantom loads. These silently consume power and are frequently overlooked. Addressing such inefficiencies can lead to significant energy savings. To bridge this gap, informed by earlier gamified learning tools, we developed an interactive 3D computer game set in a realistic building environment. This paper reports on the framework used to develop the game, which can also inform future gamification of learning for energy efficiency.The game, Phantom Load, allows players to explore rooms, audit energy use, investigate HVAC systems, trace ductwork and piping, and make design or operational changes to improve thermal comfort and energy performance. Unlike earlier case-based modules, this game uses quests, treasure hunts, content unlocking, and troubleshooting to enhance engagement. A key challenge in gamified learning is sustaining intrinsic motivation. Phantom Load addresses this by creating a sense of purpose and presents a model for nurturing intrinsic motivation in digital learning. Players are encouraged to explore, solve problems, and think critically as they progress through complex scenarios, which makes learning more meaningful.An alpha version was tested with 50 players across age groups. Surveys show users found the game engaging and informative. The game supports Sustainable Development Goals 3, 4, 11, and 13, using immersive storytelling to equip future building professionals to improve building performance.},
booktitle = {Proceedings of the 12th ACM International Conference on Systems for Energy-Efficient Buildings, Cities, and Transportation},
pages = {477–481},
numpages = {5},
keywords = {gamified learning, energy efficiency, building systems, artificial intelligence, augmented reality, virtual reality, sustainability education, immersive learning, digital pedagogy},
location = {Colorado School of Mines, Golden, CO, USA},
series = {BuildSys '25}
}

@article{10.1145/3774908,
author = {Yuan, Xingyu and Li, He and Dong, Mianxiong and Ota, Kaoru},
title = {Adaptive Scheduling of Multimodal Large Language Model in Intelligent Edge Computing},
year = {2025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
issn = {1556-4665},
url = {https://doi.org/10.1145/3774908},
doi = {10.1145/3774908},
abstract = {Multimodal Large Language Models (MLLMs) integrate multimodal encoders with large language models (LLMs) to overcome the limitations of text-only models. Traditional LLMs are deployed on high-performance cloud servers, but MLLMs, which process multimodal data, face high transmission latency and privacy risks when tasks are offloaded to the cloud. Intelligent edge computing is a promising solution for supporting such latency-sensitive and privacy-sensitive tasks. However, the heterogeneity of edge environments makes efficient MLLM inference challenging. In this work, we enhance MLLM inference efficiency in heterogeneous edge environments by decoupling MLLM into LLM and multimodal encoders, deploying the LLM on high-performance devices and the multimodal encoders on lower-capability devices. Additionally, we observe that processing MLLM tasks in edge environments involves numerous configuration parameters that impact inference speed and energy consumption in an unknown and possibly time-varying fashion. To address this challenge, we present an adaptive scheduling algorithm that assigns parameters to tasks for minimizing energy consumption while meeting maximum latency constraints. The results of extensive experimental trials demonstrate that the proposed approach consistently outperforms existing state-of-the-art methods, achieving significant improvements in both latency reduction and energy efficiency.},
note = {Just Accepted},
journal = {ACM Trans. Auton. Adapt. Syst.},
month = nov,
keywords = {Multimodal large language model, Intelligent edge computing, Multi-armed bandit, Deep learning accelerator}
}

@inproceedings{10.1145/3736425.3772007,
author = {Wentzel, Freya and Ramanathan, Ganesh and Pourmirza, Zoya and Wang, Shuo},
title = {Learning on the Edge for Sensor Role Allocation in BLE IoT devices},
year = {2025},
isbn = {9798400719455},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3736425.3772007},
doi = {10.1145/3736425.3772007},
abstract = {Wireless Sensor Networks (WSNs) consist of distributed, resource-constrained sensor nodes that report on ambient environmental conditions and thus enable Building Automation (BA) systems to control technical systems. The embedded systems, in such WSNs, have to be rigorously optimised for power consumption because of their reliance on constrained energy sources (e.g., tiny batteries or energy harvested from the ambient). Despite significant progress in energy efficiency and usage, the potential for further improvement through intelligent allocation of sensors, in conjunction with the operation of the BA system has not been fully explored. This work aims to address this issue by using a machine learning model implemented using TinyML to intelligently allocate sensing tasks based on the needs of the automation system. Our system estimates the residual battery capacity of asynchronous sensor nodes using TinyML, enabling a centralised automation orchestrator to dynamically adjust the sensor node's duty cycling to meet BA sensing requirements. Preliminary results show improved efficiency in utilising the available energy and higher efficacy in fulfilling the tasks.},
booktitle = {Proceedings of the 12th ACM International Conference on Systems for Energy-Efficient Buildings, Cities, and Transportation},
pages = {271–276},
numpages = {6},
keywords = {wireless sensor networks, TinyML, bluetooth low energy, building automation systems},
location = {Colorado School of Mines, Golden, CO, USA},
series = {BuildSys '25}
}

@inproceedings{10.1145/3736425.3770103,
author = {Zaman, Zakia and Gauravaram, Praveen and Jha, Sanjay and Hu, Wen},
title = {Bloom-LLM: Privacy-Preserving Large Language Model for Load Forecasting},
year = {2025},
isbn = {9798400719455},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3736425.3770103},
doi = {10.1145/3736425.3770103},
abstract = {Accurate energy load forecasting is essential for optimising power systems across buildings, cities, and smart grids. Recently, large language models (LLMs) have shown remarkable capability in capturing complex temporal patterns in energy consumption data, outperforming both traditional and deep learning techniques. However, their reliance on detailed smart meter (SM) data poses significant privacy risks, as such fine-grained information is susceptible to inference attacks. To overcome these challenges, we introduce Privacy-Preserving Time-LLM, an innovative forecasting framework that combines LLM architectures with SM data encoded via Differentially Private Bloom Filters (DP-BF). This encoding safe-guards sensitive consumption data while preserving high predictive performance. Designed for secure cloud deployment, the framework reduces privacy risks associated with honest-but-curious service providers. It employs Low-Rank Adaptation (LoRA) for efficient fine-tuning and utilises Rotary Position Embedding (RoPE) to model temporal dependencies without accessing raw time-series inputs. We benchmark our approach against the widely used differentially private training method DP-SGD. Experimental results demonstrate that the Time-LLM trained on DP-BF-Encoded SM data consistently outperforms its DP-SGD counterpart, reducing forecasting error by approximately 29\% on average, highlighting an improved balance between privacy and utility. Compared to a state-of-the-art CNN baseline, our method achieves nearly 52\% better forecasting accuracy on DP-BF-Encoded data while maintaining up to 99\% membership privacy. Moreover, under adversarial attacks, models trained with DP-BF-Encoding show over 80\% reduced vulnerability relative to models trained on raw data, significantly enhancing robustness and stability. To the best of our knowledge, this is the first differentially private LLM-based framework for energy load forecasting using DP-BF-Encoding. It opens new possibilities for privacy-preserving analytics in smart grid environments, with extensibility to other time-series applications such as occupancy detection and demand disaggregation.},
booktitle = {Proceedings of the 12th ACM International Conference on Systems for Energy-Efficient Buildings, Cities, and Transportation},
pages = {128–138},
numpages = {11},
keywords = {LLM, load forecast, privacy},
location = {Colorado School of Mines, Golden, CO, USA},
series = {BuildSys '25}
}

@inproceedings{10.1145/3736425.3770100,
author = {Chang, Yen Cheng and Codling, Jesse and Dong, Yiwen and Zhang, Jiale and Noh, Hae Young and Zhang, Pei},
title = {ViLA: Leveraging General-Purpose Audio for Training Vibration-Based Stadium Crowd Monitoring Models},
year = {2025},
isbn = {9798400719455},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3736425.3770100},
doi = {10.1145/3736425.3770100},
abstract = {Crowd monitoring in sports stadiums is important to enhance public safety and improve audience experience. Existing approaches mainly rely on manual observation, cameras, and microphones, which can be disruptive and often raise privacy issues. Recently, floor vibration sensing has emerged as a less disruptive and more non-intrusive method for crowd monitoring in sports stadiums. However, because vibration-based crowd monitoring is newly developed, open-source datasets are lacking, making it challenging to develop data-driven models.In this paper, we introduce Vibration Leverages Audio (ViLA), a vibration-based crowd monitoring method that reduces the reliance on labeled data by pre-training with unlabeled cross-modality data. Specifically, ViLA is first pre-trained on general-purpose audio data in an unsupervised manner, and then fine-tuned with a limited amount of labeled vibration data in sensing domains. Through this approach, ViLA learns general spectral pattern representations from audio, then adapts this knowledge to vibrations. By leveraging general-purpose audio datasets, ViLA reduces the reliance on large quantities of domain-specific vibration data. This is particularly important in sensing environments characterized by high data variance and limited sensing durations, such as sports games. Our real-world experiments demonstrate that pre-training the vibration model using publicly available audio data (YouTube clips) achieved up to a 5.8X error reduction compared to the model without audio pre-training.},
booktitle = {Proceedings of the 12th ACM International Conference on Systems for Energy-Efficient Buildings, Cities, and Transportation},
pages = {96–106},
numpages = {11},
keywords = {floor vibration, crowd behavior, sports game, machine learning, cross-modality learning},
location = {Colorado School of Mines, Golden, CO, USA},
series = {BuildSys '25}
}

@inproceedings{10.1145/3736425.3771957,
author = {Gupta, Ragini and Mirza, Abbas Ali and Danilov, Claudiu and Eckhardt, Josh and Bernard, Keyshla and Nahrstedt, Klara},
title = {LLM-Powered Data Annotation for Bridging the Semantic Gap in Air Quality Monitoring},
year = {2025},
isbn = {9798400719455},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3736425.3771957},
doi = {10.1145/3736425.3771957},
abstract = {Accurately annotating raw sensor data with Air Quality Index (AQI) categories presents significant challenges in traditional approaches, primarily due to the fundamental semantic gap between low-level sensor readings and high-level air quality interpretations. Rule-based systems require perfect domain expertise and are prone to labeling errors and inconsistencies, while supervised machine learning models demand extensive labeled datasets and computational resources. This work explores an alternative paradigm by leveraging Large Language Models (LLMs) as virtual annotators to bridge this semantic gap, enabling direct interpretation of raw sensor data without explicit formulaic programming. We develop a comprehensive framework using GPT-3.5 Turbo to classify AQI categories from multi-variate sensor data collected from Chicago's Array of Things network. Our systematic evaluation reveals several key findings: the LLM achieves 82\% average accuracy using only pollutant data in zero-shot settings, improves to 88\% when prompts are supported with bootstrap examples, and gains an additional 4\% performance boost when augmented with environmental context (temperature, humidity). These results, validated through principled statistical analysis, demonstrate that LLMs can effectively overcome the semantic gap to comprehend complex sensor patterns and provide reliable AQI annotations. Our work establishes the viability of LLMs as scalable, context-aware virtual annotators for environmental monitoring, offering a promising solution to overcome the limitations of traditional annotation methods without relying on complex prompt-engineering or model fine-tuning.},
booktitle = {Proceedings of the 12th ACM International Conference on Systems for Energy-Efficient Buildings, Cities, and Transportation},
pages = {394–399},
numpages = {6},
keywords = {LLM, AQI, data annotation, semantic gap},
location = {Colorado School of Mines, Golden, CO, USA},
series = {BuildSys '25}
}

@inproceedings{10.1145/3746252.3761311,
author = {Lou, Haowei and Paik, Hye-young and Hu, Wen and Yao, Lina},
title = {ParaStyleTTS: Toward Efficient and Robust Paralinguistic Style Control for Expressive Text-to-Speech Generation},
year = {2025},
isbn = {9798400720406},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3746252.3761311},
doi = {10.1145/3746252.3761311},
abstract = {Controlling speaking style in text-to-speech (TTS) systems has become a growing focus in both academia and industry. While many existing approaches rely on reference audio to guide style generation, such methods are often impractical due to privacy concerns and limited accessibility. More recently, large language models (LLMs) have been used to control speaking style through natural language prompts; however, their high computational cost, lack of interpretability, and sensitivity to prompt phrasing limit their applicability in real-time and resource-constrained environments. In this work, we propose ParaStyleTTS, a lightweight and interpretable TTS framework that enables expressive style control from text prompts alone. ParaStyleTTS features a novel two-level style adaptation architecture that separates prosodic and paralinguistic speech style modeling. It allows fine-grained and robust control over factors such as emotion, gender, and age. Unlike LLM-based methods, ParaStyleTTS maintains consistent style realization across varied prompt formulations and is well-suited for real-world applications, including on-device and low-resource deployment. Experimental results show that ParaStyleTTS generates high-quality speech with performance comparable to state-of-the-art LLM-based systems while being 30x faster, using 8x fewer parameters, and requiring 2.5x less CUDA memory. Moreover, ParaStyleTTS exhibits superior robustness and controllability over paralinguistic speaking styles, providing a practical and efficient solution for style-controllable text-to-speech generation. Demo can be found at https://parastyletts.github.io/ParaStyleTTS_Demo/. Code can be found at https://github.com/haoweilou/ParaStyleTTS.},
booktitle = {Proceedings of the 34th ACM International Conference on Information and Knowledge Management},
pages = {1979–1988},
numpages = {10},
keywords = {generative artificial intelligence, multilingual style adaptation, speech generation, text-to-speech},
location = {Seoul, Republic of Korea},
series = {CIKM '25}
}

@inproceedings{10.1145/3694907.3765936,
author = {Schwartz, Daniel and Saunders, Lev A and Gomez, Nathalia and Osmanlioglu, Yusuf and Vallett, Richard and Dion, Genevieve and Shokoufandeh, Ali},
title = {Minimalist Neural Networks for Gesture Recognition on Wearable Capacitive Touch Textiles With Comparative User Study},
year = {2025},
isbn = {9798400712593},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3694907.3765936},
doi = {10.1145/3694907.3765936},
abstract = {Smart textiles embedded with capacitive touch sensors offer significant potential for intuitive gesture-based interaction, yet recognizing complex gestures on resource-constrained wearable devices remains challenging. This paper presents a minimalist neural network architecture specifically optimized for knitted capacitive touch interfaces. Our approach efficiently recognizes single and multi-touch gestures including taps, swipes, and pinches with accuracy exceeding 90\% on training data and 80\% on testing data. To assess real-world usability, we conducted a comparative user study evaluating participant performance with our knitted interface against a conventional trackpad in a gesture-controlled gaming scenario. Results demonstrated comparable overall performance between both interfaces, with participants achieving similar game scores despite the novelty of the textile interface. Statistical analysis revealed rapid user adaptation to the textile interface, with performance stabilizing after initial trials while the standard trackpad showed continuous improvement throughout testing. Quantitative metrics were supplemented by qualitative feedback highlighting the comfort and tactile appeal of the textile interface. This work advances the practical deployment of smart textile gesture recognition systems by addressing both technical performance requirements and usability considerations for real-world applications.},
booktitle = {Proceedings of the 2025 ACM Symposium on Spatial User Interaction},
articleno = {4},
numpages = {11},
keywords = {Smart Textiles, Capacitive Touch Sensing, Gesture Recognition, Minimalist Neural Networks, Human-Computer Interaction, Wearable Computing, Embedded Systems, User Studies},
location = {
},
series = {SUI '25}
}

@inproceedings{10.1145/3694907.3765932,
author = {Pluisch, Martin and Gugenheimer, Jan and Kruijff, Ernst},
title = {Context-Aware Application Recommendations in Augmented Reality},
year = {2025},
isbn = {9798400712593},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3694907.3765932},
doi = {10.1145/3694907.3765932},
abstract = {Augmented reality displays are evolving into devices that can seamlessly integrate virtual content into users’ physical environments in a context-sensitive manner, promising to support users more fluidly in their tasks. However, dynamically adapting applications to the user’s environment presents challenges that require a real-time understanding of the user’s current context. While recent computer vision approaches for context detection have made progress, they often lack a semantic understanding of the interplay between the user, their surroundings, and the system state. In this paper, we investigate how context-aware application recommendations affects user experience and task performance in AR. To this end, we evaluate a real-time system that uses a large multimodal model integrated with a Microsoft HoloLens 2. The system processes application metadata and front-facing camera images to recommend contextually relevant apps. In a user study, we compared three interaction modes for selecting apps: a fully automatic mode that proactively switches to the suggested app, a recommendation-based mode that highlights a suggested app without launching it, and a manual mode requiring user selection. Our study showed that automatic context-aware app switching significantly improved task efficiency and reduced cognitive load compared to the other modes, without diminishing users’ sense of control. Participants preferred the automated mode, which enabled smoother workflows and enhanced usability.},
booktitle = {Proceedings of the 2025 ACM Symposium on Spatial User Interaction},
articleno = {25},
numpages = {11},
keywords = {Augmented Reality, Context-Aware Systems, User Experience, Recommender Systems, Large Language Models, Large Multimodal Models, Human-Computer Interaction},
location = {
},
series = {SUI '25}
}

@inproceedings{10.1145/3749893.3749901,
author = {Yu, Chueh-Fu and Tseng, Bo-Yu and Ko, Yi-Chun and You, Chuang-Wen},
title = {Mah\={o}o: An Emotive Narrative Tool for Weather-Related Emotion Reframing through XR Interaction and Tangible Experience},
year = {2025},
isbn = {9798400715327},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3749893.3749901},
doi = {10.1145/3749893.3749901},
abstract = {Mah\={o}o explores the potential of XR technologies as narrative tools to reframe emotional experiences associated with rainy weather. By transforming rain, commonly associated with negative emotions, into an interactive, multisensory landscape, Mah\={o}o invites participants to participate in embodied reinterpretations of climatic affect. Centered around a tangible umbrella interface that evolves into a blooming flower, the project integrates narrative-driven interaction, hybrid physical-virtual choreography, and real-time sensory feedback. Participants collaboratively gather clouds, summon rain, and dance alongside the spirit character, reshaping the emotional meaning of rain through embodied movement and immersive interaction. Presented at an international VR festival with 129 interactive sessions, Mah\={o}o demonstrated significant emotional impact, transforming perceptions of rain from gloom to vitality. This work highlights how participatory XR environments and tangible interfaces can intervene in culturally embedded affective schema, offering new strategies for emotional regulation and everyday sensory reimagination.},
booktitle = {Proceedings of the Conference on Animation and Interactive Art},
pages = {222–229},
numpages = {8},
keywords = {Extended Reality, Weather-Related Emotion, Umbrella, Affective Design, Embodied interface design},
location = {
},
series = {Expanded '25}
}

@inproceedings{10.1145/3737902.3768360,
author = {Huang, Runxi and Ouyang, Xiaomin},
title = {PipeMLLM: Accelerating on-device Multimodal LLM Inference via Speculative Sensing and Encoding},
year = {2025},
isbn = {9798400719790},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3737902.3768360},
doi = {10.1145/3737902.3768360},
abstract = {Real-time inference of multimodal LLMs on edge devices has promising applications in autonomous driving, fall detection, and wearable interaction. However, such systems face challenges due to high resource demands and variable decoding latency. We propose PipeMLLM, an efficient on-device inference framework for multimodal LLMs through decoding-aware sensing and encoding. By decomposing the complete inference task into fine-grained units, PipeMLLM enables parallel and adaptive processing across modalities, while mitigating accuracy drop with an efficient temporal aggregation module. To adapt to runtime constraints, it incorporates a lightweight optimizer that dynamically selects sensing and model configurations based on input complexity and LLM decoding overhead. We evaluate PipeMLLM on the NuScenes-Mini-QA dataset and Nvidia Jetson Xavier. The results show that it achieves efficient and accurate inference, effectively balancing encoding and decoding.},
booktitle = {Proceedings of the 2nd International Workshop on Edge and Mobile Foundation Models},
pages = {49–55},
numpages = {7},
keywords = {Deep Learning, Edge Computing, Multimodal Large Language Model, Multimodal Sensing and Inference},
location = {Hong Kong, China},
series = {EdgeFM '25}
}

@inproceedings{10.1145/3737905.3769283,
author = {Zuniga, Agustin and Khan, Musfira and Nguyen, Ngoc Thi and Motlagh, Naser Hossein and Sarhaddi, Fatemeh and Safaei, Zahra and Wang, Yangyang and Radeta, Marko and Flores, Huber and Tarkoma, Sasu and Nurmi, Petteri},
title = {Thermal Smart Plants: Thermal Sensing for Non-Intrusive Device Energy Disaggregation},
year = {2025},
isbn = {9798400719820},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3737905.3769283},
doi = {10.1145/3737905.3769283},
abstract = {We contribute an innovative and non-intrusive method for disaggregating the energy load of different devices using thermal and environmental sensors embedded in plant containers. Indoor plants are ubiquitous, and obtaining containers with sensors that monitor growth conditions is becoming increasingly common. Our work harnesses these developments, providing a non-intrusive and real-time monitoring system that uses residual thermal radiation to identify nearby appliances and disaggregate them. Proof-of-concept experiments considering devices with high and low energy profiles demonstrate that our approach can accurately identify electric appliances and support the disaggregation of power measurements for more accurate load monitoring.},
booktitle = {Proceedings of the 2025 ACM International Workshop on Thermal Sensing and Computing},
pages = {28–33},
numpages = {6},
keywords = {electricity consumption, indoor monitoring, internet of things, pervasive sensing, smart plants, thermal imaging},
location = {Hong Kong, China},
series = {HotSense '25}
}

@inproceedings{10.1145/3757232.3757250,
author = {Areo, Olumide Gabriel and Oyewale, Christianah Titilope and Issa, Nurudeen},
title = {Hybrid Solar-Wind System: A Green Energy Alternative to Fossil-Fuel Generators for Women Entrepreneurs in Northern Nigeria.},
year = {2025},
isbn = {9798400718496},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3757232.3757250},
doi = {10.1145/3757232.3757250},
abstract = {This study examines the potential of hybrid solar wind systems as a sustainable alternative to fossil fuel generators for women entrepreneurs in northern Nigeria, a region where more than 85 million people lack reliable electricity access. Using a mixed methods approach, the research investigates energy usage patterns, renewable energy awareness levels, and the feasibility of adopting solar-wind hybrid systems among women-led micro, small, and medium enterprises (MSMEs). Findings reveal that while the national grid remains the primary energy source, 2.2\% of 2,537 participants surveyed use wind energy, and 19.3\% adopt some form of solar energy. The survey evaluated monthly energy consumption patterns from lower- and middle-income earners, revealing that a smaller percentage (15.6\%) spent between N25,000 (USD 16.30) and N50,000 (USD 32.60), while 27.1\% spent between N15,000 (USD 9.78) and N25,000 (USD 16.30) on energy every month. This implies that a significant portion of the income generated by women-owned businesses in Northern Nigeria is spent on energy costs rather than being used for business investment readiness activities. The paper highlights the necessity of specific environmental policies, such as local production and circular economy initiatives for solar and wind hybrid materials and pay-as-you-go financing models. The inclusion of vulnerable community groups for gender-sensitive business thinking models will contribute to Nigeria’s Sustainable Development Goals (SDGs), fostering inclusive economic growth. Solar-wind hybrid systems can become a significant alternative to reduce energy poverty and empower women-led businesses by utilising Northern Nigeria’s abundant solar radiation and wind speed.},
booktitle = {Proceedings of the 5th Biennial African Human Computer Interaction Conference},
pages = {256–266},
numpages = {11},
keywords = {green energy, energy poverty, solar wind hybrid, women-led business, Micro, Small and Medium Enterprises (MSMEs), northern Nigeria, generator, fossil-fuel (gasoline), gender equality, inclusion, climate action.},
location = {
},
series = {AfriCHI '25}
}

