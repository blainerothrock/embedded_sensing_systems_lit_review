@inproceedings{10.1145/3746059.3747611,
author = {Tan, Sean Rui Xiang and Chan, Mun Choon and Han, Jun},
title = {UniKey: Enabling Surface-Based Typing with Commodity Smartwatches via Cross-Modal Learning},
year = {2025},
isbn = {9798400720376},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3746059.3747611},
doi = {10.1145/3746059.3747611},
abstract = {With the rise of mobile technologies such as augmented and virtual reality (AR/VR) and wearables, as well as smart TVs, the large form factor of traditional keyboards is becoming increasingly impractical. Sensing typing on surfaces offers a potential alternative, but most current solutions rely on either expensive, custom hardware or extensive user bootstrapping and calibration. In this paper, we envision Unikey, an approach to surface-based typing that uses only a commodity smartwatch to detect finger taps on a flat surface. By seamlessly adapting to the user’s existing typing habits on conventional keyboards, Unikey eliminates the need for both specialized equipment and burdensome sensor data collection, reducing overhead for users. To demonstrate the feasibility of our approach, we implement a proof-of-concept and evaluate our technique with comprehensive real-world experiments under varying conditions. Participants were invited to type while wearing smartwatches, resulting in over 2,700 minutes of recorded typing. Our experiments show that Unikey can achieve an equivalent average top-5 word error rate of 6.45\%, indicating a potential solution simple, everyday text-entry tasks.},
booktitle = {Proceedings of the 38th Annual ACM Symposium on User Interface Software and Technology},
articleno = {64},
numpages = {16},
keywords = {Text entry, ubiquitous computing, virtual reality, smartwatch, keystroke dynamics},
location = {
},
series = {UIST '25}
}

@inproceedings{10.1145/3746059.3747648,
author = {Zhang, Sen and Miao, Yuxuan and Taylor, Jazlin and Luo, Yiyue},
title = {MagTex: Machine-Knitted Magnetoactive Textiles for Bidirectional Human-Machine Interface},
year = {2025},
isbn = {9798400720376},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3746059.3747648},
doi = {10.1145/3746059.3747648},
abstract = {Bidirectional human–machine interfaces (HMIs) provide both sensing and haptic feedback, enabling responsive and intuitive interactions across a wide range of applications, including assistive technologies, robotics, and augmented/virtual reality (AR/VR). In this paper, we present MagTex, a bidirectional HMI platform realized through digitally machine-knitted magnetoactive textiles. MagTex integrates sensing and haptic feedback within a single, wearable interface by embedding soft magnetoactive fibers into machine-knitted electromagnets. MagTex delivers localized vibrotactile feedback through the galvanomagnetic effect and achieves motion sensing via electromagnetic induction. We describe the digital fabrication workflow, material characterization, circuits implementation, and system integration in detail. A user study confirms both the perceptibility of the haptic feedback and the thermal property of the textile system. We demonstrate the capability of MagTex through three application scenarios: a wireless smart sleeve for game control, a tactile Braille display glove, and a closed-loop smart knee brace for real-time running feedback. Overall, MagTex offers a soft, scalable, and compact solution for bidirectional HMIs.},
booktitle = {Proceedings of the 38th Annual ACM Symposium on User Interface Software and Technology},
articleno = {134},
numpages = {15},
keywords = {E-textile; wearable human-machine interface; haptics feedback; sensing; magnetoactive fiber},
location = {
},
series = {UIST '25}
}

@inproceedings{10.1145/3746059.3747802,
author = {Honnet, Cedric and Babatain, Wedyan and Luo, Yiyue and Kilic Afsar, Ozgun and Bensahel, Chloe and Nicita, Sarah and Zhu, Yunyi and Danielescu, Andreea and Gershenfeld, Neil and Paradiso, Joseph},
title = {FiberCircuits: A Miniaturization Framework To Manufacture Fibers That Embed Integrated Circuits},
year = {2025},
isbn = {9798400720376},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3746059.3747802},
doi = {10.1145/3746059.3747802},
abstract = {While electronics miniaturization has propelled the evolution of technology from desktops to compact wearables, most devices are still rigid and bulky, often leading to abandonment. To enable interfaces that can truly disappear and seamlessly integrate into daily life, the next evolutionary leap will require further miniaturization to achieve full conformability. With FiberCircuits, we offer design and fabrication guidelines for the manufacturing of high-density circuits that are thin enough for full encapsulation within fibers. Our demonstrations include a 1.4 mm-wide ARM microcontroller with sensors as small as 0.9 mm-wide and arrays of 1 mm-wide addressable LEDs, which were woven into our interactive textiles. We provide example applications from fitness to VR, and propose a scalable fabrication process to enable large-scale deployment. To accelerate future research in HCI, we also made our platform Arduino-compatible, created custom libraries, and open-sourced all the materials. Finally, our technical characterizations demonstrate FiberCircuits’ durability, thanks to its silicone encapsulation for waterproofness and braiding for robustness. From wearables to insertables or even implantables, we believe that by making miniature circuits accessible to researchers and beyond, FiberCircuits will open possibilities for new scalable interfaces that embody imperceptible computing.},
booktitle = {Proceedings of the 38th Annual ACM Symposium on User Interface Software and Technology},
articleno = {130},
numpages = {18},
keywords = {HCI, Embedded Systems, Wearables, Miniaturization, eTextiles, Open Source, Rapid Prototyping, Scalable Manufacturing.},
location = {
},
series = {UIST '25}
}

@inproceedings{10.1145/3746059.3747695,
author = {Zhou, Haozhe and Arakawa, Riku and Agarwal, Yuvraj and Goel, Mayank},
title = {IMUCoCo: Enabling Flexible On-Body IMU Placement for Human Pose Estimation and Activity Recognition},
year = {2025},
isbn = {9798400720376},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3746059.3747695},
doi = {10.1145/3746059.3747695},
abstract = {IMUs are regularly used to sense human motion, recognize activities, and estimate full-body pose. Users are typically required to place sensors in predefined locations that are often dictated by common wearable form factors and the machine learning model’s training process. Consequently, despite the increasing number of everyday devices equipped with IMUs, the limited adaptability has significantly constrained the user experience to only using a few well-explored device placements (e.g.,&nbsp;wrist and ears). In this paper, we rethink IMU-based motion sensing by acknowledging that signals can be captured from any point on the human body. We introduce IMU over Continuous Coordinates (IMUCoCo), a novel framework that maps signals from a variable number of IMUs placed on the body surface into a unified feature space based on their spatial coordinates. These features can be plugged into downstream models for pose estimation and activity recognition. Our evaluations demonstrate that IMUCoCo supports accurate pose estimation in a wide range of typical and atypical sensor placements. Overall, IMUCoCo supports significantly more flexible use of IMUs for motion sensing than the state-of-the-art, allowing users to place their sensors-laden devices according to their needs and preferences. The framework also supports the ability to change device locations depending on the context and suggests placement depending on the use case.},
booktitle = {Proceedings of the 38th Annual ACM Symposium on User Interface Software and Technology},
articleno = {91},
numpages = {16},
keywords = {pose estimation, activity recognition, on-body IMU},
location = {
},
series = {UIST '25}
}

@article{10.1145/3758321,
author = {Kumar, Gaurav and Nanote, Kushal Pravin and Lal, Sohan and Prasad, Yamuna and Ahlawat, Satyadev},
title = {Robust LFSR-based Scrambling to Mitigate Stencil Attack on Main Memory},
year = {2025},
issue_date = {September 2025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {24},
number = {5s},
issn = {1539-9087},
url = {https://doi.org/10.1145/3758321},
doi = {10.1145/3758321},
abstract = {Main memory plays a pivotal role in the storage of computational data in a wide range of applications, including highly sensitive assets such as banking transactions, cryptographic keys, and user credentials. However, memory systems remain vulnerable to advanced physical and side-channel attacks, including cold boot attacks that exploit residual data after power-down. To mitigate such risks, Intel’s DDR3 memory scrambler uses a Linear Feedback Shift Register (LFSR)-based stream cipher to obscure memory contents. Nevertheless, this mechanism has been shown to be susceptible to stencil attack, a cold boot technique that reconstructs the scrambling key by leveraging the linear and periodic nature of the keystream. This article proposes a novel, lightweight, and secure scrambling architecture based on a generic LFSR designed to enhance the security of DDR3 memory against cold boot attacks. The proposed generic LFSR-based mechanism eliminates differential keystream periodicity by introducing an address- and seed-dependent LFSR structure, thereby rendering differential key recovery techniques computationally infeasible. Furthermore, unlike traditional AES-based memory encryption that incurs high latency and area overhead, the proposed approach achieves comparable security guarantees with low hardware complexity and zero access latency. The hardware implementation results on the Xilinx VCU118 FPGA show that the proposed scheme consumes only 252 LUTs, 256 registers and 104 slices, comparable to the Intel DDR3 scrambler, while offering superior resilience against the cold boot, warm boot, and probing attacks. These results demonstrate the practicality of the proposed scheme for secure memory systems in resource-constrained environments.},
journal = {ACM Trans. Embed. Comput. Syst.},
month = sep,
articleno = {102},
numpages = {22},
keywords = {DRAM security, LFSR, memory scrambling, memory disclosure attacks, stencil attack}
}

@article{10.1145/3736643,
author = {Azfar, Talha and Huang, Kaicong and Ke, Ruimin},
title = {Enhancing Disaster Resilience with UAV-Assisted Edge Computing: A Reinforcement Learning Approach to Managing Heterogeneous Edge Devices},
year = {2025},
issue_date = {March 2026},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {3},
number = {1},
url = {https://doi.org/10.1145/3736643},
doi = {10.1145/3736643},
abstract = {Edge sensing and computing are rapidly becoming part of intelligent infrastructure architecture, leading to operational reliance on such systems in disaster or emergency situations. In such scenarios, there is a high chance of power supply failure due to power grid issues, and communication system issues due to base stations losing power or being damaged by the elements, e.g., flooding, wildfires, and so on. Mobile edge computing in the form of unmanned aerial vehicles (UAVs) has been proposed to provide computation offloading from these devices to conserve their battery, while the use of UAVs as relay network nodes has also been investigated previously. This article considers the use of UAVs with further constraints on power and connectivity to prolong the life of the network while also ensuring that the data is received from the edge devices in a timely manner. Reinforcement learning is used to investigate numerous scenarios of various levels of power and communication failure. This approach is able to identify the device most likely to fail in a given scenario, thus providing priority guidance for maintenance personnel. The evacuations of a rural town and urban downtown area are also simulated to demonstrate the effectiveness of the approach at extending the life of the most critical edge devices.},
journal = {ACM J. Auton. Transport. Syst.},
month = sep,
articleno = {3},
numpages = {21},
keywords = {Edge computing, infrastructure resilience, unmanned aerial vehicles, reinforcement learning}
}

@inproceedings{10.1145/3711875.3729164,
author = {Medaranga, Sooriya Patabandige Pramuka and Chinthalapani, Rajashekar Reddy and Yan, Wenqing and Dutta, Prabal and Varshney, Ambuj},
title = {Unraveling the Missing Link in Low-power Communication: An Autodyning Receiver Architecture that Achieves a Long Range},
year = {2025},
isbn = {9798400714535},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3711875.3729164},
doi = {10.1145/3711875.3729164},
abstract = {Wireless communication remains the most power-intensive operation in embedded systems. Decades of research have enabled radio transmitters to operate at power levels as low as tens of μWs while maintaining practical communication ranges. However, achieving power-efficient reception over similarly useful distances has received significantly less attention. State-of-the-art low-power receivers typically rely on Schottky diode-based envelope detectors, which are inherently limited in sensitivity and unable to support complex modulation schemes. We introduce SoMix, the Single Oscillator Mixer receiver, a novel architecture that uses tunnel diode oscillators to overcome these limitations. Specifically, we demonstrate the autodyning property of tunnel diode oscillators, allowing a single circuit to generate both a carrier signal and perform signal downconversion, thus merging two traditionally power-hungry analog tasks into one energy-efficient step. The SoMix front-end consumes less than 100 μW while supporting high-sensitivity reception. Through injection-locking, SoMix stabilizes its tunnel diode oscillator using even a weak external carrier signal, allowing it to receive frequency-modulated transmissions from distances greater than 100 meters in line-of-sight environments. We also demonstrate that the SoMix exhibits robustness in complex real-world scenarios. SoMix outperforms state-of-the-art receivers in power, range, and functionality.},
booktitle = {Proceedings of the 23rd Annual International Conference on Mobile Systems, Applications and Services},
pages = {96–109},
numpages = {14},
keywords = {embedded systems, backscatter, sensors, tunnel diodes, receivers},
location = {Hilton Anaheim, Anaheim, CA, USA},
series = {MobiSys '25}
}

@inbook{10.1145/3711875.3729143,
author = {Jiang, Nan and Zhou, Qihang and Qian, Feifan and Chen, Jiayun and Huang, Heqing and Jia, Xiaoqi and Du, Haichao},
title = {Chameleon: Towards Building Least-privileged TEE via Functionality-based Resource Re-grouping},
year = {2025},
isbn = {9798400714535},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3711875.3729143},
abstract = {TrustZone-assisted Trusted Execution Environment (TEE) has been widely employed in mobile devices to protect sensitive applications. With increased customization demands, Trusted Applications (TAs) have become more flexible and complex, exposing numerous vulnerabilities within the TEE. Furthermore, due to the unrestricted Trusted Operating System (TOS) services provided to TA, an attacker can exploit vulnerabilities to compromise the whole TEE system. In this paper, we propose a novel customized TOS partition approach, called Chameleon, to enhance the security of the TrustZone-assisted TEE system. Inspired by the principle of least privilege and our TEE vulnerability analysis, we first categorize the TOS into TOS service modules and basic kernel modules. Then, we selectively encapsulate these modules into distinct Capsules based on the TA's functional requirements, providing each TA with a separate execution environment (TA-entity). To enforce access control and confine vulnerable modules within a TA-entity, we introduce T-Visor, which serves as our Trusted Computing Base. Our prototype implementation, built upon Linaro's OP-TEE, requires only 2.9K Lines of Code (LoC) modifications. Evaluation on a Hikey960 board demonstrates that Chameleon reduces the attack surface of TOS services to 51\% and mitigates 122 out of 138 CVEs (88.41\%) with negligible performance overhead.},
booktitle = {Proceedings of the 23rd Annual International Conference on Mobile Systems, Applications and Services},
pages = {487–499},
numpages = {13}
}

@inbook{10.1145/3711875.3729154,
author = {Deram, Sai Pavan and Rossanese, Marco and Garcia-Saavedra, Andres and Shah, Syed Waqas Haider and Sciancalepore, Vincenzo and Widmer, Joerg and Costa-Perez, Xavier},
title = {RISENSE: Long-Range In-Band Wireless Control of Passive Reconfigurable Intelligent Surfaces},
year = {2025},
isbn = {9798400714535},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3711875.3729154},
abstract = {Reconfigurable Intelligent Surfaces (RIS) are a promising technology for creating smart radio environments by controlling wireless propagation. However, several factors hinder the integration of RIS technology into existing cellular networks, including the incompatibility of RIS control interfaces with 5G PHY/MAC procedures for synchronizing radio scheduling decisions and RIS operation, and the cost and energy limitations of passive RIS technology. This paper presents RISENSE, a system for practical RIS integration in cellular networks. First, we propose a novel, low-cost, and low-power RIS design capable of decoding control messages without complex baseband operations or additional RF chains, utilizing a power sensor and a network of microstrip lines and couplers. Second, we design an effective in-band wireless RIS control interface, compatible with 5G PHY/MAC procedures, that embeds amplitude-modulated (AM) RIS control commands directly into standard OFDM-modulated 5G data channels. Finally, we propose a low-overhead protocol that supports swift on-demand RIS re-configurability, making it adaptable to varying channel conditions and user mobility, while minimizing the wastage of 5G OFDM symbols. Our experiments validate the design of RISENSE and our evaluation shows that our system can re-configure a RIS at the same pace as users move, boosting 5G coverage where static or slow RIS controllers cannot.},
booktitle = {Proceedings of the 23rd Annual International Conference on Mobile Systems, Applications and Services},
pages = {347–360},
numpages = {14}
}

@inbook{10.1145/3711875.3729153,
author = {Zou, Yang and Na, Xin and Sun, Yimiao and Chen, Yande and He, Yuan},
title = {Satori: In-band Analog Backscatter for Audio Transmission},
year = {2025},
isbn = {9798400714535},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3711875.3729153},
abstract = {In IoT applications such as environmental monitoring and industrial security surveillance, audio sensors are increasingly used, among which wireless sensors are preferred. In order to achieve a sustained transmission, low-power wireless technology such as backscatter has been widely considered. However, existing backscatter systems encounter difficulties in audio transmissions due to the high power consumption from the complicated digital processing and fast frequency-shifting clocks. In this paper, we propose Satori, the first-of-its-kind in-band analog backscatter system for audio transmission with ultra-low power consumption. Satori eliminates the need for in-place digital processing by directly embedding analog audio voltages into backscattered WiFi symbols through analog modulation. It also avoids the power consumption of the frequency-shifting clock by transmitting the audio within the excitation WiFi signal's band. We implement the Satori prototype and evaluate it under various settings. The results indicate that Satori can transmit audio at a sampling rate of 41.67 kHz and achieve a SNR exceeding 18 dB.},
booktitle = {Proceedings of the 23rd Annual International Conference on Mobile Systems, Applications and Services},
pages = {83–95},
numpages = {13}
}

@article{10.1145/3744563,
author = {Zhang, Yufan and Li, Hangliang and Li, Yanjun and Ye, Zhi and Chen, Yuzhe and Yang, Zhe and Chi, Kaikai},
title = {GS-Tag: Design of a Generic Sensor Tag Based on RF Switches and COTS RFID System},
year = {2025},
issue_date = {September 2025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {21},
number = {5},
issn = {1550-4859},
url = {https://doi.org/10.1145/3744563},
doi = {10.1145/3744563},
abstract = {With the development of the Internet of Things (IoT), substantial research efforts have been devoted to extending the sensing capability of commercial off-the-shelf (COTS) radio-frequency identification (RFID) tags. State-of-the-art approaches either demand sophisticated hardware redesign or are constrained to specific sensing capability, leading to increased costs and limited scalability. In this article, we present the design of a generic sensor tag (GS-Tag) based on RF switches and COTS RFID system for transmission of generic sensor data. RF switches are connected in parallel with the RFID chip, and the GS-Tag modulates the sensor data by controlling the RF switches. Specifically, with the RF switches turned on, the tag’s chip is short-circuited, rendering it unreadable; conversely, turning off the RF switches makes the tag readable. The reader demodulates the data through the compatible electronic product code (EPC) protocol. A subtle dual RF switch scheme is adopted to extend the communication range. In addition to the battery-powered solution, we integrate an RF energy-harvesting module, develop a high-efficiency energy management circuit, and design an efficient task scheduling strategy to enable the GS-Tag to operate in a battery-free mode. We implement a prototype of GS-Tag with COTS RFID devices. Comprehensive experiments demonstrate that our designed GS-Tag can achieve an average packet reception rate (PRR) exceeding 99\%, exhibits robustness to environmental disturbance, and facilitates coexistence of six GS-Tags with an average PRR of over 91\%. Due to the dual RF switch scheme, the communication range of GS-Tag extends to 12 m. Besides, GS-Tag has an extremely low power consumption of just 3.98 μW. A practical application is developed to accurately monitor temperature and ambient light intensity in an office environment while maintaining low power consumption. Our designed GS-Tag presents a cost-effective and compatible solution for expanding the sensing capabilities of COTS RFID system.},
journal = {ACM Trans. Sen. Netw.},
month = sep,
articleno = {48},
numpages = {18},
keywords = {Sensor tag, RFID system, backscatter communication, RF switch, impedance match}
}

@article{10.1145/3748330,
author = {Zhang, Youwei and Liu, Zhi and Wu, Celimuge and Li, Jie and Tang, Suhua},
title = {WiCG: Heartbeat Sensing Using COTS WiFi Devices with Common Antenna},
year = {2025},
issue_date = {September 2025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {21},
number = {5},
issn = {1550-4859},
url = {https://doi.org/10.1145/3748330},
doi = {10.1145/3748330},
abstract = {Vital sign detection, based on Channel State Information (CSI) from commercial off-the-shelf (COTS) WiFi devices, has become a popular research area. Previous works in this field mainly focus on respiration, while heartbeat sensing has not been well studied yet, because its signal is very weak and overwhelmed by hardware noises and the respiration signal. Different from existing research that exploits directional antenna, the proposed WiCG (WiFi CardioGram) system uses common antennas, and not only accurately senses heartbeat rate but also provides the heartbeat signal for further analysis in complex real-life home scenes. Specifically, we first propose an effective denoising solution for Wi-Fi CSI by exploiting its spatial structure, which exhibits strong correlation among the In-phase/Quadrature components. Leveraging this characteristic with Principal Component Analysis (PCA) achieves effective reduction of ambient noise in both the amplitude and phase of the CSI. Then, we introduce a heartbeat enhancement scheme that utilizes the periodicity of the heartbeat signal. By applying Singular Spectrum Analysis (SSA), the complex effects of residual noise and respiratory interference are effectively mitigated. Extensive experiments have proven that WiCG can effectively sense the heartbeat rate. In a real deployment environment, the average detection error can be reduced to 0.28 bpm, close to current commercial heartbeat sensors.},
journal = {ACM Trans. Sen. Netw.},
month = sep,
articleno = {50},
numpages = {30},
keywords = {WiFi, CSI, heartbeat sensing, denoising}
}

@inbook{10.1145/3760023.3760120,
author = {Fang, Zhiwen},
title = {Adaptive QoS-Aware Cloud–Edge Collaborative Architecture for Real-Time Smart Water Service Management},
year = {2025},
isbn = {9798400715969},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3760023.3760120},
abstract = {As urban water network being more and more intelligent, it becomes an urgent problem to solve how to execute resource scheduling and data process in an efficient and adaptable way and not affect real time and service quality. In this paper, we present an Adaptive QoS-Aware Cloud–Edge Collaborative Architecture (A-QCEA) empowered by a combined edge computing), cloud infrastructure, IoT perception network, AI-enhegrated optimization mechanism, and network security strategy to facilitate real-time smart water service management system of next generation. It is highly extended based on the cloud-edge-device three-layer IoT model which exists, and a multi-layer dynamic QoS-aware scheduling scheme and an edge-first data processing strategy are put forward. One is using a small inference engine, which is deployed on the edge device to achieve local data preprocessing and anomaly detection on the water quality and flow rate, thus, reducing data upload delay and cloud load. Second, the cloud layer utilizes flexible containerized computing system, and employs deep reinforcement learning model to forecast the IoT task load and dynamically allocate the computing, storage and network resources according to the different QoS level. Subsequently, low-power IoT communications protocols are implemented for ensuring reliable sensor and pumping station data backhaul to the infrastructure. Thereafter, end-to-end data encryption and edge access control methods are employed in the system, to ensure secure control commands transportation for water utilities. Lastly, in the scheduling core, we innovatively designed a fusion model with graph attention network(GAT) and time-aware LSTM to achieve the context-aware collaborative perception and resource prediction based on multi-source data, and offer the intelligent support for QoS level optimization. Experimental results demonstrate that the developed architecture achieves a remarkable improvement in task response time, resource utilization, and service continuity in the water environment.},
booktitle = {Proceedings of the 2025 International Conference on Management Science and Computer Engineering},
pages = {606–611},
numpages = {6}
}

@inproceedings{10.1145/3731806.3731830,
author = {Katsumata, Masashi},
title = {Learner Face Detection and Analysis in Smart Learning Environments},
year = {2025},
isbn = {9798400710124},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3731806.3731830},
doi = {10.1145/3731806.3731830},
abstract = {The widespread adoption of wearable smart devices has increased expectations for the development of personalized learning environments. These environments offer real-time analysis of learners' study states by utilizing sensor data from wearable devices and tablets, as well as facial image data captured during learning sessions. In this study, we propose a smart learning environment that integrates multiple smart devices, with a particular focus on detecting and analyzing learners' facial images recorded by the front camera of a tablet used as a learning terminal. Facial image analysis was performed using the InsightFace library, which accurately extracts facial landmarks from angled facial images. The results highlight the feasibility of capturing learners' facial orientations using this monitoring function and explore how these data can contribute to enhancing smart learning environments.},
booktitle = {Proceedings of the 2025 14th International Conference on Software and Computer Applications},
pages = {238–241},
numpages = {4},
keywords = {Learning User Interface, Personalized Learning, Smart Devices, Smart Learning},
location = {
},
series = {ICSCA '25}
}

@inbook{10.1145/3760023.3760134,
author = {Wan, Wenkai and Yan, Guihai and He, Panbo and Li, Yumeng and Chen, Yue},
title = {A Risk Index Model for Construction Projects Based on Multi-Source Data},
year = {2025},
isbn = {9798400715969},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3760023.3760134},
abstract = {With the increasing complexity of construction projects and the accelerating pace of urbanization, safety management on construction sites faces growing challenges. To address the limitations of traditional safety management approaches in terms of timeliness, system integration, and intelligence, this paper proposes a novel risk index model for construction projects based on multi-source data. The model categorizes safety risks into five key dimensions: worker, equipment, work activities, subcontractors, and civilization \&amp; environment. Over 800 refined evaluation indicators are extracted across these dimensions. Using the Analytic Hierarchy Process (AHP), weights are assigned to each indicator to develop a quantifiable and traceable safety evaluation method. By integrating perception technologies such as AI cameras, sensors, and drones with a multimodal large-model analysis engine, the system enables dynamic risk behavior identification, indicator matching, and automated scoring. The risk scores for each category are aggregated via a MaaS (Management-as-a-Service) platform to generate an overall safety index for the site, supporting functions such as early warning, closed-loop rectification, and re-evaluation. The proposed model establishes a full-cycle intelligent management process covering perception, analysis, evaluation, warning, rectification, and feedback. Pilot implementations demonstrate significant improvements in risk detection rate, response speed, and rectification efficiency, indicating strong engineering applicability and potential for broader adoption. This research offers theoretical support and practical guidance for achieving intrinsic safety and building intelligent construction sites in the industry.},
booktitle = {Proceedings of the 2025 International Conference on Management Science and Computer Engineering},
pages = {704–715},
numpages = {12}
}

@article{10.1145/3695879,
author = {Wang, Xiaodong and Qi, Longyun and Wei, Xingshen and Zhu, Weiping and Jiang, Haitao and Guan, Zhitao},
title = {AED: A Novel Approach for Intrusion Detection without Abnormal Samples in Big Data Environment},
year = {2025},
issue_date = {September 2025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {17},
number = {3},
issn = {1936-1955},
url = {https://doi.org/10.1145/3695879},
doi = {10.1145/3695879},
abstract = {The rapid advance of multimedia devices, including sensors, cameras, and mobile phones, has given rise to the prevalence of Internet of Multimedia Things (IoMT), generating huge volumes of application-oriented multimedia data. At the same time, network security issues in the multimedia big data environment also increases. Network intrusion detection (NID) system demonstrates its power in preventing cyber-attacks against multimedia platforms. However, the existing NID methods that are based on machine learning or deep learning classifiers may fail when there is a lack of abnormal traffic samples for training in the real-world scenario. We propose a novel approach for intrusion detection based on deep AutoEncoder and Differential comparison named AED, which only requires the normal traffic samples in the training phase. We conduct extensive experiments on two real-world datasets to evaluate the effectiveness of the proposed AED. The experimental results show that AED can outperform the baseline methods of three categories in terms of accuracy, precision, recall, and F1-score.},
journal = {J. Data and Information Quality},
month = sep,
articleno = {17},
numpages = {20},
keywords = {Intrusion detection system, Deep autoencoder, Internet of Multimedia Things, Machine learning}
}

@inproceedings{10.1145/3731806.3731829,
author = {Zhao, Ge-Zhi and Tan, Yi-Fei and Abdul Karim, Hezerul and Cheeng, Tze-Hang and Chia, Ching-King},
title = {Leveraging Machine Learning Techniques to Obtain Data for Virtual Sensors},
year = {2025},
isbn = {9798400710124},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3731806.3731829},
doi = {10.1145/3731806.3731829},
abstract = {The Internet-of-Things (IoT) has revolutionised smart devices by enabling real-time monitoring through remote sensors.  It is the most essential element particularly in smart sensing industrial applications such as environmental monitoring and industrial automation.  These sensors provide crucial raw data to be analysed and accurate prediction of events of equipment breakdowns or preventive maintenance is required.  However, if a physical sensor fails to function normally, virtual sensors can facilitate the missing data during downtime.  Virtual sensors utilise predictive models to forecast the missing data, leveraging historical data and patterns from previously trained events to forecast sensor readings under the same conditions. In this research, the authors build a predictive model to generate data for a malfunctioned sensor by using actual data from other functional sensors.  The hybrid setup between physical and virtual sensors will complement each other during operations to ensure fail-safe operation. In the research methodology, data from five sensors were analysed with predictive models of random forest.  Data were trained on four of the sensors to predict the next day's readings of the fifth sensor.  The experiment examined the impact of training various data durations (5, 10, and 15 days).  The results revealed promising outcomes across all three training data sizes. Notably, the random forest regression model achieved better performance with larger training datasets, highlighting the impact of dataset size on model effectiveness.},
booktitle = {Proceedings of the 2025 14th International Conference on Software and Computer Applications},
pages = {290–294},
numpages = {5},
keywords = {Internet of Things (IoT), data fusion, physical sensors, predictive model, virtual sensors},
location = {
},
series = {ICSCA '25}
}

@inproceedings{10.1145/3762329.3762344,
author = {Gao, Jianxin and Zhu, Quanpeng and Fu, Baoyan and Zhang, Xinyan},
title = {The Design of an Environmental Monitoring System for University Sports Venues Based on ZigBee Technology In Jiangxi Teachers College},
year = {2025},
isbn = {9798400718625},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3762329.3762344},
doi = {10.1145/3762329.3762344},
abstract = {This study addresses the need for timely and comprehensive indoor environmental data collection and remote monitoring in sports venues. Based on the ZigBee protocol, and through the integrated application of sensor technology and automatic detection technology, a wireless monitoring system for indoor air environment parameters in sports venues is designed. The system enables real-time wireless monitoring of indoor air quality parameters—such as carbon dioxide and formaldehyde—as well as thermal environmental parameters including temperature, humidity, and wind speed. The system consists of two main components: a data acquisition terminal and a data receiver. The data acquisition terminal integrates multiple sensors, including temperature and humidity sensors, wind speed sensors, carbon dioxide sensors, and formaldehyde sensors. The data receiver communicates with a computer via a serial interface, handling the upload of environmental data and the execution of commands from the computer. Communication between the data acquisition terminals and the data receiver is carried out over a ZigBee network, configured in a star topology. The number of terminal devices can be adjusted, making the monitoring area of the system highly flexible and scalable. The system's overall hardware and software design follows a modular architecture. The overall scheme of the hardware and software of the system adopts modular design. The hardware of the system includes the peripheral circuit of the processor, the communication interface circuit between the hardware module and the processor, and the power supply circuit. The software includes network management and data transmission programs. The data transmission program loads various hardware module drivers to achieve data transmission, including sensor data drivers and LCD display programs. The system effectively achieves real-time indoor environmental data collection and remote transmission by employing this technical solution. It provides a front-end data acquisition platform to support the development of the environmental monitoring framework, assessment technologies, and evaluation standards for the gymnasium of Jiangxi Teachers College. Ultimately, it offers data support for creating a comfortable and safe sporting environment in indoor facilities.},
booktitle = {Proceedings of the 2nd International Conference on Artificial Intelligence of Things and Computing},
pages = {79–83},
numpages = {5},
keywords = {Jiangxi Teachers College, Zigbee technology, environmental monitoring system, university sports venues},
location = {
},
series = {AITC '25}
}

@inproceedings{10.1145/3762329.3762347,
author = {Pan, Chenling and Yuan, Hanyu and Pei, Zhiyong and Bing, Zhenkai and Tao, Lei and Wang, Shaohui and Liu, Tong},
title = {Design and Realization of IoT-Based Intelligent Environmental Control System for Tomato Production in Multi-Span Greenhouses},
year = {2025},
isbn = {9798400718625},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3762329.3762347},
doi = {10.1145/3762329.3762347},
abstract = {In the field of facility agriculture, intelligent transformation has become a key path to address labor shortages, low resource utilization efficiency, and the need for precise environmental regulation. This study focuses on developing a low-cost and highly scalable tomato greenhouse intelligent control platform, dedicated to achieving multi-source data fusion processing and unmanned production mode. The platform architecture relies on IoT sensing technology to build a perception layer, which collects environmental parameters in real-time through various sensors deployed in the greenhouse, such as temperature, humidity, and light intensity, utilizing a cloud edge collaborative control mechanism to ensure efficient data processing and rapid response, achieving precise control of the greenhouse environment. In terms of decision support, the neural network algorithm is introduced to conduct in-depth analysis and decision-making on collected data, optimize resource allocation, and improve tomato yield and quality. This platform proposes a dynamic fusion model of multi-source data, which can integrate multiple pieces of information from different sensors and historical databases, providing a comprehensive basis for precise regulation. The platform adopts a modular and scalable architecture, which facilitates flexible expansion of functional modules or integration of new sensor devices according to actual production needs, ensuring the long-term applicability and maintainability of the system. A set of resource optimization control strategies has been developed to minimize energy consumption and resource waste while ensuring a suitable tomato growth environment, and to improve the economic benefits and sustainable development capabilities of facility agriculture. The research results provide effective technical solutions for the intelligent upgrading of facility agriculture, promoting the development of tomato production towards high efficiency, precision, and intelligence.},
booktitle = {Proceedings of the 2nd International Conference on Artificial Intelligence of Things and Computing},
pages = {95–101},
numpages = {7},
keywords = {Environmental Control, Intelligent Greenhouse, Smart Agriculture, Tomato Greenhouse Management},
location = {
},
series = {AITC '25}
}

@inproceedings{10.1145/3742460.3742977,
author = {Nikseresht, Fateme and Sobral, Victor Ariel Leal and Mostafavi, Moeen and Campbell, Brad},
title = {Sensor-free Microclimate Monitoring Using Existing LoRaWAN Signal Characteristics},
year = {2025},
isbn = {9798400719868},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3742460.3742977},
doi = {10.1145/3742460.3742977},
abstract = {Long-range wireless protocols enable large-scale Internet of Things (IoT) applications and vast sensor deployments. The growth of such deployments presents a unique opportunity for wireless sensing, as these devices generate spatially distributed wireless signals. Instead of today's convention of new projects requiring new hardware, expensive deployments, and increased ongoing maintenance costs, we propose a technique to leverage existing wireless signals from already deployed sensors to perform wide-area sensing—for free. And unlike typical wireless sensing approaches that generate new wireless signals for sensing, our approach uses unmodified devices and wireless signals already captured by LoRaWAN gateways to monitor the environment.We demonstrate the practicality of this technique by designing and building a microclimate monitoring system that targets temperature using an XGBoost regression model trained on received signal strength indicator (RSSI) and signal-to-noise ratio (SNR). Through eight months of data collection in a four-season humid subtropical city, we reveal a dynamic correlation between temperature and LoRaWAN signal characteristics that vary with seasonal climate changes. Our methodology estimates local temperature with a mean absolute error (MAE) of 0.99 °C, compared to 1.41 °C from the nearest city weather station (CWS). Our system particularly provides more accurate estimates than the CWS during periods of peak summer heat and deep winter cold extremes. These results highlight the feasibility, efficiency, and scalability of leveraging existing LoRaWAN networks as a sustainable, sensor-free solution for urban environmental monitoring.},
booktitle = {Proceedings of the International Workshop on Environmental Sensing Systems for Smart Cities},
pages = {1–7},
numpages = {7},
keywords = {RF sensing, LoRaWAN, RSSI, SNR, microclimate monitoring},
location = {Hilton Anaheim, Anaheim, CA, USA},
series = {EnvSys '25}
}

@article{10.1145/3757926,
author = {Bhatia, Munish},
title = {Cognitive Decision Modeling for Quality of Service in Domestic Pipeline Network},
year = {2025},
issue_date = {October 2025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {16},
number = {5},
issn = {2157-6904},
url = {https://doi.org/10.1145/3757926},
doi = {10.1145/3757926},
abstract = {The Internet of Things (IoT) has transformed the industrial sector. This study presents a novel framework for real-time evaluation of service quality in residential gas pipeline networks. IoT devices collect critical operational and environmental data, which are processed through a fog-cloud architecture using Bayesian modeling. This enables the calculation of a comprehensive Quality of Service Measure (QSM) and a Service Quality Delivery Value (SQDV) to assess and interpret service performance. A two-level decision-tree model further supports decisions by regulators and end-users. The framework was validated using 73,462 service interaction records, showing significant improvements over existing approaches: reduced data delay (179.01 s), high classification performance (Specificity: 94.22\%, Sensitivity: 92.78\%, Precision: 93.15\%), enhanced decision-making (Accuracy: 95.45\%, Error Rate: 1.29\%), improved reliability (93.69\%), and robust system stability (73.25\%).},
journal = {ACM Trans. Intell. Syst. Technol.},
month = sep,
articleno = {118},
numpages = {23},
keywords = {Service Quality, Internet of Things, Domestic Gas Pipeline, Decision Tree}
}

@article{10.1145/3754449,
author = {Iraci, Grant and Chuang, Cheng-En and Hu, Raymond and Ziarek, Lukasz},
title = {Rate-Based Session Types for IoT Systems},
year = {2025},
issue_date = {September 2025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {47},
number = {3},
issn = {0164-0925},
url = {https://doi.org/10.1145/3754449},
doi = {10.1145/3754449},
abstract = {We develop a session types framework for implementing and validating rate-based message passing systems in Internet of Things (IoT) domains. To model the indefinite repetition present in many embedded and IoT systems, we introduce a timed process calculus with a periodic recursion primitive. This allows us to model rate-based computations and communications inherent to these application domains. We introduce a definition of rate-based session types in a binary session types setting and a new compatibility relationship, which we call rate compatibility. Programs which type-check enjoy the standard session types guarantees as well as rate error freedom—meaning processes which exchanges messages do so at the same rate. Rate compatibility is defined through a new notion of type expansion, a relation that allows communication between processes of differing periods by synthesizing and checking a common superperiod type. We prove type preservation and rate error freedom for our system and show a decidable method for type checking based on computing superperiods for a collection of processes. We implement a prototype of our type system including rate compatibility via an embedding into the native type system of Rust. We apply this framework to a range of examples from our target domain such as Android software sensors, wearable devices, and sound processing. Our framework is used to implement a heart rate sensor application that runs on a commercially available smartwatch.},
journal = {ACM Trans. Program. Lang. Syst.},
month = sep,
articleno = {15},
numpages = {39},
keywords = {session types, type systems, rate-based systems}
}

@inbook{10.1145/3756423.3756518,
author = {Wang, Shizhan and Bai, Wenle and Dang, Xiangwei and Yan, Yiming},
title = {A millimeter-wave radar data optimization algorithm based on cross-modal learning},
year = {2025},
isbn = {9798400714351},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3756423.3756518},
abstract = {With the rapid development of sensors, there is an increasing demand for their perception performance in complex environments. Currently, the main types of environmental perception sensors are visual sensors, LiDAR sensors, and millimeter-wave radar sensors. LiDAR can provide high-precision point cloud data under normal conditions, but its performance is limited in complex environments, such as smoke. Millimeter-wave radar has higher robustness in harsh weather and low visibility conditions, but its point cloud data quality and precision are significantly lower than LiDAR due to limitations in sensor performance. To address this issue, this paper proposes a cross-modal learning-based millimeter-wave radar data optimization algorithm. The radar is trained using a diffusion model. Building upon the original model, we introduce an innovative hierarchical attention mechanism. By combining local self-attention and global cross-attention, the local self-attention captures detailed features, while global cross-attention enhances contextual fusion. This addresses the issue of detail loss and context integration in traditional attention mechanisms under high-resolution conditions. Compared to the original attention mechanism, the proposed approach reduces computational complexity and hardware memory usage while maintaining accuracy, and it improves processing speed. Additionally, based on the model's parameter characteristics, the latest Lion learning rate optimizer is selected to replace the original RAdam optimizer, which accelerates training speed and reduces the number of steps required for convergence, thereby improving training efficiency. Experimental results demonstrate that the proposed method can increase the number of millimeter-wave radar point clouds by 10\%.},
booktitle = {Proceedings of the 2025 International Conference on Artificial Intelligence and Smart Manufacturing},
pages = {578–586},
numpages = {9}
}

@inproceedings{10.1145/3756423.3756489,
author = {Xiao, Fang and Xiao, Ni},
title = {AI-Driven Intelligent Monitoring and Green Design System for Rural Ecological Environment},
year = {2025},
isbn = {9798400714351},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3756423.3756489},
doi = {10.1145/3756423.3756489},
abstract = {As the rural Revitalization strategy goes deeper, protecting the environment and smart monitoring become very important things. This paper builds a smart monitoring system for rural environment using AI technology, where deep learning helps to analyze environmental data smartly, and IoT sensors make real-time monitoring networks for environmental factors, also a green design system platform is developed based on cloud computing. The research finds that this smart monitoring system can well find environmental risks, guess pollution trends, and plan ecological restoration smartly, while the green design system can make better use of resources, improve ecosystem services, and give scientific support for building rural ecological civilization.},
booktitle = {Proceedings of the 2025 International Conference on Artificial Intelligence and Smart Manufacturing},
pages = {403–407},
numpages = {5},
keywords = {Artificial Intelligence, Green Design, Rural Revitalization, ecological Environment, intelligent Monitoring},
location = {
},
series = {ICAISM '25}
}

@inbook{10.1145/3756423.3756446,
author = {Wang, Zefang and Xu, Lunquan},
title = {Research on Fault Diagnosis System of Touch Screen Based on Pressure Sensor},
year = {2025},
isbn = {9798400714351},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3756423.3756446},
abstract = {With the rapid development of industry, the newly added equipment is also evolving towards being large, complex, precise, high-speed, and capable of continuous operation. Real-time monitoring of the operational status of touch screen devices, timely detection of early faults, identification of fault sources, and elimination of faults can provide crucial guarantees for the safety of enterprise equipment or personnel. Since the vibration signal varies with the state of the touchscreen component, it can reflect the mechanical operation status. Therefore, through the analysis and processing of vibration signals, the nature and severity of the problem can be determined, thereby analyzing and monitoring the real-time operating status of the touch screen. To achieve real-time monitoring of the touchscreen status, the vibration signal acquisition, signal processing and signal analysis adopted should have the characteristics of high real-time performance, good portability, strong anti-interference ability and adaptability to various environments. The piezoelectric sensor with small size, fast response and wide adaptability is used to collect the signal of the touch screen status. High-speed acquisition of vibration signals and high-speed data communication are carried out using FPGA chips. The signal processing function of LABVIEW is used to process the vibration signal in real time. Real-time analysis enables the monitoring and fault detection of different touch screens in different environments at a relatively low cost, or it is used to assist in fault detection and fault data recording.},
booktitle = {Proceedings of the 2025 International Conference on Artificial Intelligence and Smart Manufacturing},
pages = {145–151},
numpages = {7}
}

@inbook{10.1145/3756423.3756545,
author = {Zhao, Zhiyao and Fu, Tingyu and Yan, Yifei and Han, Bingchen and Xiong, Yueling and Wu, Peng},
title = {The Design of Small-Scale Intelligent Hovercraft},
year = {2025},
isbn = {9798400714351},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3756423.3756545},
abstract = {To overcome the limitations of traditional hovercraft in complex sea conditions and multifunctional collaborative applications, our team has designed a small intelligent unmanned hovercraft featuring an efficient cushion-lifting system. Based on the core principles of the air-spring model and simulation studies of cushion flow characteristics, we utilized Abaqus software to deeply explore the hovercraft's water-entry dynamics and attitude variations under varying pressures, achieving precise capture of airbag centroid velocity and displacement. A physical model was constructed for CFD simulations, laying a solid foundation for aerodynamic design optimization. The hovercraft integrates multiple sensors, including LIDAR and sonar, to form a comprehensive environmental perception matrix for real-time of obstacle, current and terrain. Driven by data, the intelligent control system incorporates machine learning and expert systems for smart decision-making, enabling precise control of parameters such as speed and steering to achieve adaptive navigation in complex waters or terrains. This innovation opens up new avenues for multi-domain applications and leads the trend in hovercraft technology transformation.},
booktitle = {Proceedings of the 2025 International Conference on Artificial Intelligence and Smart Manufacturing},
pages = {742–745},
numpages = {4}
}

@inbook{10.1145/3756423.3756544,
author = {Wu, Si and Hong, Dan and Li, Yamei},
title = {Exploration of the Application of Intelligent Inspection Technology in Construction Engineering},
year = {2025},
isbn = {9798400714351},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3756423.3756544},
abstract = {This paper discusses the application of intelligent inspection technology in construction engineering, focusing on the limitations of traditional inspection methods and the advantages of intelligent inspection technology. Traditional inspection methods, such as visual inspection method, infrared thermal camera local scanning method and traditional non-destructive testing method, are low-cost and easy to implement, but there are problems such as low efficiency, high risk and incomplete coverage. With the development of intelligent construction technology, intelligent means such as unmanned aerial vehicle (UAV) curtain wall inspection and CCTV pipeline endoscopic inspection have gradually become the core driving force to improve the efficiency and accuracy of engineering inspection. UAV curtain wall inspection realizes rapid and comprehensive inspection of ultra-high-rise building curtain wall by integrating high-definition camera, infrared thermal camera, LIDAR and other sensors, while CCTV pipeline endoscopic inspection can comprehensively observe the rupture, deformation, corrosion and other conditions of the pipeline, and realize the long-distance inspection and save the video. Through the actual case study, intelligent detection technology in terms of efficiency, cost, accuracy, safety are significantly better than the traditional manual detection. However, the large-scale application of intelligent inspection still faces challenges, such as the influence of drones by complex meteorological conditions, and the lack of adaptability of CCTV equipment in the environment of narrow bends. This paper aims to provide theoretical basis and practical reference for the digital transformation in the field of construction engineering inspection.},
booktitle = {Proceedings of the 2025 International Conference on Artificial Intelligence and Smart Manufacturing},
pages = {735–741},
numpages = {7}
}

@inproceedings{10.1145/3760269.3760343,
author = {Xie, Yanfu and Jiang, Siyuan and Qiao, Yongli},
title = {Soft-Support Graphene Resonator with Phononic Crystal},
year = {2025},
isbn = {9798400714313},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3760269.3760343},
doi = {10.1145/3760269.3760343},
abstract = {The development of high-performance sensors has become critically important in aviation, aerospace, and related technological fields. Graphene, with its exceptional mechanical and electrical properties, has emerged as a promising material for advancing sensor capabilities, sparking significant academic and industrial interest. As a novel sensing element, graphene-based resonators demonstrate extraordinary sensitivity owing to their atomic-scale thickness. Nevertheless, practical applications of these resonators at ambient temperatures face challenges due to insufficient environmental robustness and operational stability. These limitations are intrinsically tied to the relatively low Q-factor. To overcome this challenge, this study establishes a theoretical framework for energy dissipation dilution in graphene resonators, enabling systematic analysis of energy loss distribution patterns. Building upon this theoretical foundation, we introduce an innovative approach utilizing phononic crystal soft-support architectures to suppress vibrational energy dissipation. Through computational modeling and validation, the design and fabrication of graphene resonators incorporating these engineered support structures are optimized. This methodology not only advances fundamental understanding of energy dissipation mechanisms but also provides a practical pathway for enhancing resonator performance. The integration of phononic crystal principles offers a breakthrough in Q-factor enhancement, positioning graphene resonators as viable candidates for next-generation high-precision sensing systems.},
booktitle = {Proceedings of the 2025 5th International Conference on Automation Control, Algorithm and Intelligent Bionics},
pages = {466–473},
numpages = {8},
keywords = {Graphene resonator, Phononic crystal, Quality factor, Soft-support},
location = {
},
series = {ACAIB '25}
}

@article{10.1145/3767743,
author = {Imran, Naveed and Zhang, Jian and Ali, Jehad and Hameed, Sana and Alenazi, Mohammed J.F. and Song, Houbing},
title = {CamWave-Emo: Advanced Contactless Emotion Detection from Facial Expression Analysis Using Camera Labeling and mm-wave Sensing},
year = {2025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
issn = {1551-6857},
url = {https://doi.org/10.1145/3767743},
doi = {10.1145/3767743},
abstract = {This study introduces a novel dual-modality emotion recognition system that combines mm-wave radar with camera-based labeling to provide accurate and privacy-preserving emotion detection. The mm-wave radar captures subtle physiological signals through micro-Doppler and time-frequency characteristics, while the camera assists in labeling facial expressions. The radar data is transformed into spectrograms, which are then fused with camera datasets to train deep learning models, employing convolutional layers for feature extraction and recurrent layers for temporal pattern recognition. Performance evaluation, conducted across a wide range of real-world occlusion and interference scenarios, shows that the system achieves 98.5\% accuracy, 0.98 F1-score, and 0.98 recall, significantly outperforming traditional systems. Other experiments, including those for multi-person interference, hand-held paper occlusion, and industrial goggles, achieved accuracy rates of 92\%, 91\%, and 92\%, respectively. The system’s latency for real-time processing is 60.5 ms on edge devices like the NVIDIA Jetson, making it suitable for applications requiring low-latency emotion recognition. Additionally, radar parameter optimization, such as adjusting the ADC sample rate and chirp size, has been shown to improve classification accuracy. These findings highlight the system’s robustness and adaptability to varying environmental conditions and its potential use in privacy-sensitive applications, including healthcare, security, and interactive media. Future work will explore radar-only systems, further reducing dependence on visual data, and investigate more advanced deep learning techniques to improve performance, scalability, and real-time deployment.},
note = {Just Accepted},
journal = {ACM Trans. Multimedia Comput. Commun. Appl.},
month = sep,
keywords = {Millimeter Wave Radar, Emotion Recognition, Facial Expression, Deep Learning}
}

@article{10.1145/3768157,
author = {Sharma, Ritik and Kapur, Ritu and Bhavsar, Arnav and Dutt, Varun and Kumar, Bhupender and Kanwar, Vikrant},
title = {DiaBreath: A Low-Cost, Non-Invasive Diabetes Monitor via Breath},
year = {2025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3768157},
doi = {10.1145/3768157},
abstract = {Diabetes mellitus is a chronic metabolic disorder that necessitates frequent blood glucose monitoring, usually through painful and inconvenient methods. Volatile organic compounds (VOCs) in breath have been used as biomarkers for diabetes detection in non-invasive, Internet of Things (IoT)-based devices. Nevertheless, the cost, compactness, and mobility challenges of existing devices limit their general adoption. We present DiaBreath, a novel, affordable, non-invasive multi-sensor device for the early prediction of diabetes, solving these challenges. DiaBreath consists of a) a dataset of 552 patient breath samples, b) a stable machine-learning pipeline to predict diabetes based on feature engineering, c) a simple interface to generate pre-diagnostic reports, and d) an optimal six-VOC sensor combination that is chosen with an ablation study. DiaBreath exhibits superior predictive power, with an accuracy of 97.6\%, to enable efficient and scalable early diagnosis in public health centers, especially in resource-constrained settings. DiaBreath’s low cost and compact size make it highly adaptable for implementation in rural and underserved regions, where access to timely diabetes screening is limited. This technology improves non-invasive diabetes monitoring, making early diagnosis more cost-effective and accessible globally.},
note = {Just Accepted},
journal = {ACM Trans. Comput. Healthcare},
month = sep,
keywords = {Diabetes detection, Breath analysis, Machine learning, Neural networks, Sensor optimization, Ablation study, Smart healthcare devices, Internet of Things (IoT) in healthcare}
}

@inbook{10.1145/3757749.3757829,
author = {Fan, Jingjing and Xing, Kaiwen and Mao, Jun and Gui, Xinyue and Li, Chengyang},
title = {Insights of Oil-Gas AIoT: Core technologies and Their Significance},
year = {2025},
isbn = {9798400713347},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3757749.3757829},
abstract = {The oil and gas industry is encountering significant challenges, including inefficient data acquisition and processing within IoT frameworks, growing global energy demands, and heightened pressure to reduce environmental risks. In response, the integration of Artificial Intelligence of Things (AIoT) technologies has gained prominence across core domains such as sensing, communication, data analysis, and intelligent control. Technologies like wireless sensor networks (WSN), ZigBee, 5G, and a range of AI algorithms support end-to-end capabilities—enabling comprehensive monitoring, real-time data transmission, and automated decision-making throughout oil production operations. This integration has led to notable improvements in production efficiency and safety oversight, contributing to the broader advancement of operational intelligence within the sector.Furthermore, progress in fusion technologies is expected to accelerate the transition toward digital, intelligent, and interconnected systems, offering new momentum for sustainable development. To fully realize the potential of AIoT in the industry, targeted research and development strategies are required to address emerging technical and systemic challenges. Priorities should include reinforcing foundational research in AIoT, encouraging collaboration across sectors, and establishing unified industry standards to guide effective and secure implementation.},
booktitle = {Proceedings of the 2025 2nd International Conference on Computer and Multimedia Technology},
pages = {471–476},
numpages = {6}
}

@inbook{10.1145/3757749.3757828,
author = {Mao, Xintao and Zai, Shougang and Ge, Yan and Sun, Zhongsheng},
title = {Study of Cyclone-type Dust Removal Device for Gas Flow Sensor},
year = {2025},
isbn = {9798400713347},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3757749.3757828},
abstract = {To improve the environmental adaptability of hot-film gas flow sensors, a cyclone-type dust removal device is designed. By analyzing the gas flow field and dust dynamics characteristics, the DPM two-phase flow model and the RNG k-ε turbulence model are selected for simulation. The parameters of the cyclone structure are determined by orthogonal tests to make it have the highest dust removal efficiency. Then the effects of the dust diameter, dust concentration, and inlet flow rate on the dust removal efficiency are analyzed by simulation and experiment. It is demonstrated that cyclone-type dust removal device has a good removal efficiency of up to 80\%, which meets the application requirements in some non-filtered situations and poor air quality environments to reduce the dust deposition on the surface of the sensor chip.},
booktitle = {Proceedings of the 2025 2nd International Conference on Computer and Multimedia Technology},
pages = {465–470},
numpages = {6}
}

@inproceedings{10.1145/3759928.3759966,
author = {Tao, Xiufeng and Calderon, Aldrin D.},
title = {Research on Positioning and Grasping Technology of Industrial Robot Based on Visual Recognition},
year = {2025},
isbn = {9798400715884},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3759928.3759966},
doi = {10.1145/3759928.3759966},
abstract = {With the rapid economic growth, our country's intelligent manufacturing sector has encountered new development opportunities. Traditional robots can perform specific tasks according to instructions, but as work environments have become more complex, modern robots are equipped with multiple sensors to adapt to these challenging conditions. This paper focuses on the needs of robot automation for positioning and grasping in industrial production, delving into the technology of industrial robot positioning and grasping based on visual recognition. By integrating visual recognition with robot motion control, the study explores image preprocessing, feature extraction, positioning algorithms, and grasping strategies. Experimental results show that this technology significantly enhances the accuracy and efficiency of robot positioning and grasping, providing technical support for the advancement of industrial automation and offering broad application prospects across various fields.},
booktitle = {Proceedings of the 2nd International Conference on Image Processing, Machine Learning, and Pattern Recognition},
pages = {220–224},
numpages = {5},
keywords = {Image processing, Industrial robots, Positioning and crawling, Visual recognition},
location = {
},
series = {IPMLP '25}
}

@article{10.1145/3767335,
author = {Zhang, Yu and Chen, Renhai and Zhang, Gong and Wang, Peng and Xin, Yao and Keji, Huang and Brinkmann, Andr\'{e}},
title = {HyTorC: Hybrid Address Translation for SSDs supporting Compression},
year = {2025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
issn = {1553-3077},
url = {https://doi.org/10.1145/3767335},
doi = {10.1145/3767335},
abstract = {High-capacity solid-state drives (SSDs) with expected capacities of one PByte and more will address cloud storage and archiving environments previously dominated by magnetic disks. These new applications are very cost-sensitive, so unnecessary overhead must be reduced as much as possible without sacrificing the performance advantages of SSDs. An expensive component within a scale-up SSD is the on-device memory to map host logical page numbers to flash pages. This paper therefore proposes HyTorC, which builds on the idea of S-FTL to represent sequentially stored logical pages using bitmaps instead of providing one entry per logical page. HyTorC extends this idea by introducing, for the first time in an FTL, compression of these bitmaps using run-length encoding, and by investigating the effects of background scrubbing to realign randomly written pages into contiguous runs. This background scrubbing allows HyTorC to keep large portions of the mapping table in block mapping mode, further reducing the memory footprint. HyTorC retains the flexibility of the page mapping scheme and supports compression of logical blocks within the SSD, allowing multiple compressed logical pages to be stored within a single physical page. HyTorC is fully implemented in an open-channel SSD. Our tests show that HyTorC can reduce memory consumption by an average of 98.9\% over standard page mapping, 95.6\% over the DFTL scheme, 87.3\% over S-FTL, and 56.5\% over the learned index-based approach LeaFTL for the Alibaba Cloud block traces, and by 98.6\% over standard page mapping, 95.5\% over the DFTL scheme, 84.1\% over S-FTL, and 61.5\% over LeaFTL for the Microsoft Research Cambridge traces. HyTorC focuses on the memory footprint of the FTL and not on performance. However, the performance evaluation shows that HyTorC achieves similar performance compared to page mapping and FTLs based on learned indexes.},
note = {Just Accepted},
journal = {ACM Trans. Storage},
month = sep
}

@article{10.1145/3766069,
author = {Uprety, Ishparsh. and Agnello, Griffen and Zhao, Xinghui},
title = {Optimizing Deep Learning Based Autonomous Driving Applications on Edge Devices},
year = {2025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3766069},
doi = {10.1145/3766069},
abstract = {With recent advances in computing and sensing technologies, autonomous driving has gained increasing interest and become a promising platform to support the next generation intelligent transportation systems. A critical requirement for autonomous driving systems is to be able to utilize AI and machine learning techniques to make reliable decisions on edge devices in a timely manner. Deploying reliable machine learning models on edge devices in a real-time environment is a challenging task. Real-time applications such as traffic surveillance or traffic sign detection require consistently low latency in order for the device to keep up with its environment. Edge devices are able to compute machine learning tasks without needing to offload computation to a cloud server, however they often have limited resources which present challenges for computationally intensive deep learning applications. Therefore, the optimization of neural network models for autonomous driving applications is pivotal for real-time performance on resource-constrained edge devices. In this paper, we present a comprehensive study on utilizing deep learning optimization techniques to enable efficient and effective decision-making for autonomous driving applications. Our contributions include the implementation of channel and fine-grained pruning on YOLOv8, direct optimization of detection layers, and the integration of INT8 quantization using NVIDIA TensorRT. These methods significantly improve computational efficiency while preserving the model accuracy. Experimental evaluations on the Jetson Orin Nano demonstrate significant improvements in inference speed and memory utilization with minimal accuracy degradation. This work highlights the feasibility of deploying state-of-the-art object detection models in resource-constrained autonomous driving systems.},
note = {Just Accepted},
journal = {ACM J. Auton. Transport. Syst.},
month = sep,
keywords = {Optimization, Deep Learning, Autonomous Driving, Edge Computing, Resource Constraints}
}

@article{10.1145/3765735,
author = {Das, Ajoy and Uddin, Gias and Chowdhury, Shaiful and Akhond, Mostafijur Rahman and Hemmati, Hadi},
title = {Applications and Challenges of Fairness APIs in Machine Learning Software},
year = {2025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
issn = {1049-331X},
url = {https://doi.org/10.1145/3765735},
doi = {10.1145/3765735},
abstract = {Machine Learning software systems are frequently used in our day-to-day lives. Some of these systems are used in various sensitive environments to make life-changing decisions. Therefore, it is crucial to ensure that these AI/ML systems do not make any discriminatory decisions for any specific groups or populations. In that vein, different bias detection and mitigation open-source software libraries (aka API libraries) are being developed and used. In this paper, we conduct a qualitative study to understand in what scenarios these open-source fairness APIs are used in the wild, how they are used, and what challenges the developers of these APIs face while developing and adopting these libraries. We have analyzed 204 GitHub repositories (from a list of 1885 candidate repositories) which used 13 APIs that are developed to address bias in ML software. We found that these APIs are used for two primary purposes (i.e., learning and solving real-world problems), targeting 17 unique use-cases. Our study suggests that developers are not well-versed in bias detection and mitigation; they face lots of troubleshooting issues, and frequently ask for opinions and resources. Our findings can be instrumental for future bias-related software engineering research, and for guiding educators in developing more state-of-the-art curricula.},
note = {Just Accepted},
journal = {ACM Trans. Softw. Eng. Methodol.},
month = sep,
keywords = {bias, api, github, fairness}
}

@article{10.1145/3715133,
author = {Gokarn, Ila and Hu, Yigong and Abdelzaher, Tarek and Misra, Archan},
title = {RA-MOSAIC: Resource Adaptive Edge AI Optimization over Spatially Multiplexed Video Streams},
year = {2025},
issue_date = {September 2025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {21},
number = {9},
issn = {1551-6857},
url = {https://doi.org/10.1145/3715133},
doi = {10.1145/3715133},
abstract = {Sustaining real-time, high-fidelity AI-based vision perception on edge devices is challenging due to both the high computational overhead of increasingly “deeper” Deep Neural Networks (DNNs) and the increasing resolution/quality of camera sensors. Such high-throughput vision perception is even more challenging in multi-tenancy systems, where video streams from multiple such high-quality cameras need to share the same GPU resource on a single edge device. Criticality-aware canvas-based processing is a promising paradigm that decomposes multiple concurrent video streams into Regions of Interest (RoI) and spatially channels the limited computational resources to selected RoI with higher “resolution,” thereby moderating the tradeoff between computational load, task fidelity, and processing throughput. RA-MOSAIC (Resource Adaptive MOSAIC) employs such canvas-based processing, while further tuning the incoming video streams and available resources on-demand to allow the system to adapt to dynamic changes in workload (often arising from variations in the number or size of relevant objects observed by individual cameras). RA-MOSAIC utilizes two distinct and synergistic concepts. First, at the camera sensor, a bandwidth-adaptive and lightweight Bandwidth-Adaptive Camera Transmission (BACT) method applies differential downsampling to create mixed-resolution individual frames that preferentially preserve resolution for critical RoIs, before being transmitted to the edge node. Second, at the edge, BACT video streams received from multiple cameras are decomposed into multi-scale RoI tiles and spatially packed using a novel workload-adaptive bin-packing strategy into a single “canvas frame.” Notably, the canvas frame itself is dynamically sized such that the edge device can opportunistically provide higher processing throughput for selected high-priority tiles during periods of lower aggregate workloads. To demonstrate RA-MOSAIC’s gains in processing throughput and perception fidelity, we evaluate RA-MOSAIC on a single NVIDIA Jetson TX2 edge device for two benchmark tasks—Drone-based Pedestrian Detection and Automatic License Plate Recognition. In a bandwidth-constrained wireless environment, RA-MOSAIC employs a batch size of 1 to pack up to 6 concurrent video streams on a dynamically sized canvas frame to provide (i) 14.3\% gain in object detection accuracy and (ii) 11.11\% gain in throughput on average (up to 20 FPS per camera, cumulatively 120 FPS), over our previous work MOSAIC, a naive canvas-based baseline. Compared to prior state-of-the-art baselines such as batched inference over extracted RoI, RA-MOSAIC provides a very significant, 29.6\% gain in accuracy for a comparable throughput. Similarly, RA-MOSAIC dramatically outperforms bandwidth-adaptive baselines, such as First Come First Serve (FCFS) ( (leq 1\%)  accuracy gain but 5.6\texttimes{} or 566.67\% throughput gain) and uniform grid packing (17\% accuracy improvement and 5\% throughput gain).},
journal = {ACM Trans. Multimedia Comput. Commun. Appl.},
month = sep,
articleno = {247},
numpages = {25},
keywords = {Edge AI, Machine Perception, Canvas-based Processing}
}

@article{10.1145/3743711,
author = {Feng, Yuan-Ling and Chan, Liwei},
title = {JettingPointer: Enabling Skin-to-Pointer Midair Touch Interaction on Minimal Wearables Using Integrated Airflow Haptic Cues},
year = {2025},
issue_date = {September 2025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {9},
number = {5},
url = {https://doi.org/10.1145/3743711},
doi = {10.1145/3743711},
abstract = {We introduce JettingPointer, a skin-to-pointer interaction technique that enables accurate near-surface 2D touch input on minimal wearable devices, such as smart glasses. The core component is an airflow jet, embedded in the glasses frame, that functions as a haptic pointer by providing localized feedback to the finger skin during touch interactions performed above the frame. Users activate functions by aligning their finger phalanx with the airflow stream, guided by proprioception and a distinct point sensation. We optimized the airflow using fluid dynamics principles and characterized the required flow rate for stable tactile perception. In Study 1, we validated its perceptual clarity, confirming that a perceptible point sensation could be reliably achieved within 20 mm of the nozzle. In Study 2, participants performed eyes-free touch tasks with nearly three times greater accuracy when supported by haptic feedback (7.49mm vs. 21.85mm error). These findings demonstrate the potential of JettingPointer as a practical method for enabling proprioception-guided, near-surface interaction on compact wearables, with implications for expanding dense input in space-constrained form factors.},
journal = {Proc. ACM Hum.-Comput. Interact.},
month = sep,
articleno = {MHCI019},
numpages = {18},
keywords = {Near-Surface Haptics; Airflow-Based Haptic Feedback; Proprioceptive Touch Interaction; Wearable Interaction; Skin-Based Input}
}

@article{10.1145/3743737,
author = {Miyashita, Kai and Amesaka, Takashi and Hanayama, Shogo and Yamamoto, Takumi and Sugiura, Yuta},
title = {ScanRing: Hybrid Authentication System in a Ring Device Using a Distance Sensor and an IMU Sensor},
year = {2025},
issue_date = {September 2025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {9},
number = {5},
url = {https://doi.org/10.1145/3743737},
doi = {10.1145/3743737},
abstract = {Smart rings are used for contactless payment, smart lock operation, and health monitoring. For applications such as electronic payment and unlocking smart locks, the implementation of a user authentication system in smart rings is essential; however, some challenges remain. Fingerprint authentication is sensitive to fingertip conditions, while face authentication faces difficulties with miniaturization, power efficiency, and privacy. This study proposes ScanRing, a hybrid authentication system using a distance sensor and an IMU sensor in a smart ring. By moving the ring device laterally in front of the face, the distance sensor captures facial structure data, while the IMU sensor records the user’s motion characteristics. These combined datasets enable robust user authentication without relying on cameras, which enhances privacy while supporting a compact and power-efficient design. A user study (N = 30) demonstrated that ScanRing achieved an average authentication accuracy of 98.41&nbsp; (\%)  under stable conditions.},
journal = {Proc. ACM Hum.-Comput. Interact.},
month = sep,
articleno = {MHCI026},
numpages = {23},
keywords = {Motion-based Authentication; Smart Ring; Hybrid Biometric Authentication; Facial Structure Sensing}
}

@article{10.1145/3743724,
author = {Schmidmaier, Matthias and Rupp, Jonathan and Harrich, Cedrik and Mayer, Sven},
title = {Using Nonverbal Cues in Empathic Multi-Modal LLM-Driven Chatbots for Mental Health Support},
year = {2025},
issue_date = {September 2025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {9},
number = {5},
url = {https://doi.org/10.1145/3743724},
doi = {10.1145/3743724},
abstract = {Despite their popularity in providing digital mental health support, mobile conversational agents primarily rely on verbal input, which limits their ability to respond to emotional expressions. We therefore envision using the sensory equipment of today’s devices to increase the nonverbal, empathic capabilities of chatbots. We initially validated that multi-modal LLMs (MLLM) can infer emotional expressions from facial expressions with high accuracy. In a user study (N=200), we then investigated the effects of such multi-modal input on response generation and perceived system empathy in emotional support scenarios. We found significant effects on cognitive and affective dimensions of linguistic expression in system responses, yet no significant increases in perceived empathy. Our research demonstrates the general potential of using nonverbal context to adapt LLM response behavior, providing input for future research on augmented interaction in empathic MLLM-based systems.},
journal = {Proc. ACM Hum.-Comput. Interact.},
month = sep,
articleno = {MHCI039},
numpages = {34},
keywords = {human-computer interaction, LLM, multi-modal LLM, empathy, context awareness, nonverbal communciation, mental health}
}

@inproceedings{10.1145/3746469.3746566,
author = {Huang, Yanlong and Yang, Aihua and Wu, Qiong},
title = {Optimizing Teaching Approaches in Adolescent Ethics Education via Generative Artificial Intelligence},
year = {2025},
isbn = {9798400713811},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3746469.3746566},
doi = {10.1145/3746469.3746566},
abstract = {The utilization of generative artificial intelligence (GAI) tools like ChatGPT and DeepSeek is bringing about significant changes in educational practices and learning environments. This alteration underlines the necessity to look into how AI can enhance ethics education for the youth. This research reveals that the capabilities of GAI match up well with the requirements of youth ethics education in four principal ways: (1) crafting immersive, multi-sensory scenarios to boost student interest. By creating such scenarios, students can get more engaged and excited about learning. (2) Employing adaptive methods for precise interventions. This means being able to adjust the teaching approach according to each student's specific situation to make the intervention more effective. (3) Generating personalized content to customize the delivery of knowledge. Every student is different, and personalized content can better meet their individual learning needs. (4) Offering real-time analysis to improve teaching methods. With real-time analysis, teachers can quickly understand how students are doing and make timely adjustments. Based on these connections, this study puts forward a framework that incorporates GAI into crucial parts of the teaching process: integrating comprehensive learning data. This helps to have a more complete understanding of students' learning progress. Developing evidence-based strategies. So that teaching decisions are made with solid evidence. Creating differentiated content. To cater to the diverse needs of students. And assessing outcomes in multiple dimensions. This integration not only enhances the efficiency of moral education but also provides a scalable model for applying AI-driven teaching innovations across different subjects.},
booktitle = {Proceedings of the 2nd Guangdong-Hong Kong-Macao Greater Bay Area Education Digitalization and Computer Science International Conference},
pages = {619–624},
numpages = {6},
keywords = {Adolescent ethics education, Generative artificial intelligence, Method optimization},
location = {
},
series = {EDCS '25}
}

@article{10.1145/3765628,
author = {Wan, Hanwen and Cheng, Jiu and Deng, Yixuan and Wu, Donghao and Chen, Yifei and Lin, Zexin and Liu, Jialu and Yu, Jiangfan and Ji, Xiaoqiang},
title = {Towards Physics Aware Embodied Control with Graph based Object-centric Learning},
year = {2025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
issn = {2378-962X},
url = {https://doi.org/10.1145/3765628},
doi = {10.1145/3765628},
abstract = {Understanding physics is crucial for intelligent robots and embodied agents to sense the world, move and manipulate objects, interact safely with their environment, and optimize motions and processes. In this paper, we propose GraphSlot, a slot-based object-centric learning framework that leverages graph neural networks to model object interactions. GraphSlot dynamically constructs graphs based on the spatial proximity of objects and external influence from gravity. Embedding information from neighbors is propagated between connected nodes. Through comprehensive experiments on simulation datasets, we demonstrate that GraphSlot achieves state-of-the-art performance with a remarkable enhancement of 8.5\% in foreground Adjusted Rand Index (fg-ARI) comparing to the baseline SAVi-L model. As part of our evaluation, we design a real-world ball-catching game environment to test the physical intuition of our proposed model. GraphSlot shows promise for slot-based methods with physical understanding common sense.},
note = {Just Accepted},
journal = {ACM Trans. Cyber-Phys. Syst.},
month = sep,
keywords = {Embodied Perception, Object-centric Learning}
}

@article{10.1145/3749468,
author = {Shen, Vivian and Yang, Xiaoying and Harrison, Chris and Zhang, Yang},
title = {Hapt-Aids: Self-Powered, On-Body Haptics for Activity Monitoring},
year = {2025},
issue_date = {September 2025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {9},
number = {3},
url = {https://doi.org/10.1145/3749468},
doi = {10.1145/3749468},
abstract = {Wearables are becoming increasingly useful, primarily due to their activity-monitoring features that enable various healthcare applications. Everyday devices like smartwatches, however, often have complex ecosystems and convoluted interfaces. These devices need constant charging and can be difficult to use, cumbersome for users interested in only simple applications. As an alternative, simpler everyday wearable, we present Hapt-Aids, self-powered on-body tags that passively monitor user activities and deliver haptic notifications. Our small-footprint devices 1) harvest energy from activity-specific sources, 2) use this energy as sensor information, and 3) convert this energy into haptic actuation using only analog hardware, without digital components or firmware. This structurally simple, triple-purpose design makes our system extremely low maintenance while being cost- and energy-efficient, leading to a friendly user experience. We present our proof-of-concept system design: a custom, unique architecture formed through theoretical modeling and evaluation studies, and we build four demo applications. Through in-lab benchmark testing and user studies, we demonstrate the potential of Hapt-Aids as alternative low-cost, easy-to-use wearables.},
journal = {Proc. ACM Interact. Mob. Wearable Ubiquitous Technol.},
month = sep,
articleno = {129},
numpages = {26},
keywords = {Activity Sensing, Energy Harvesting, Haptics, Self-Powered, Wearable Health}
}

@article{10.1145/3749485,
author = {Koh, Youngji and Lee, Chanhee and Joung, Eunki and Lee, Hyunsoo and Lee, Uichin},
title = {Harnessing Home IoT for Self-tracking Emotional Wellbeing: Behavioral Patterns, Self-reflection, and Privacy Concerns},
year = {2025},
issue_date = {September 2025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {9},
number = {3},
url = {https://doi.org/10.1145/3749485},
doi = {10.1145/3749485},
abstract = {The home environment plays a critical role in shaping daily routines that influence emotional wellbeing. While previous research has leveraged mobile and wearable devices to track emotional wellbeing indicators, these approaches often suffer from limited adherence and data gaps when users are not actively engaged. To address this, we further explore home IoT sensing as a passive and unobtrusive modality for monitoring emotional wellbeing. We conducted a four-week user study (N=20), collecting data from mobile devices, wearables, and home IoT sensors. Our quantitative analysis showed that incorporating home IoT data better captured associations between domestic routines and emotional wellbeing than mobile and wearable data alone. However, domestic activity patterns varied significantly across participants, highlighting the personalized nature of domestic routines. To further investigate these differences, we developed an informatics tool for participants to visualize and reflect on their behavioral data. Semi-structured interviews revealed that participants found home IoT data intuitive and insightful in understanding their emotional wellbeing, leading to a positive shift in privacy concerns. Our findings highlight home IoT sensing as a promising tool for tracking emotional wellbeing and provide design implications for future sensor-enabled home healthcare services.},
journal = {Proc. ACM Interact. Mob. Wearable Ubiquitous Technol.},
month = sep,
articleno = {96},
numpages = {36},
keywords = {Internet of Things, Personal informatics, Privacy, Self-reflection, Self-tracking, Smart home}
}

@article{10.1145/3749551,
author = {Ying, Qijun and Cao, Zehua and Wu, Ziyu and Deng, Wenwu and Zhong, Yuchen and Diao, Yukun and Cai, XiaoHui},
title = {FoRM: Foot-driven Reconstruction of Human Motion Using Dual-Modal Plantar Pressure and Inertial Sensing},
year = {2025},
issue_date = {September 2025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {9},
number = {3},
url = {https://doi.org/10.1145/3749551},
doi = {10.1145/3749551},
abstract = {Human motion reconstruction has wide applications in health monitoring, human-computer interaction, and virtual reality. While vision-based methods have made significant strides, they face challenges in daily scenarios due to occlusion, privacy concerns, and environmental constraints. Alternative approaches using wearable sensors often require complex device deployment or raise privacy issues. To address these challenges, we explore foot-based sensing as a non-invasive solution that maintains mobility and practicality. Supporting this approach, we construct a dual-modal human motion dataset with synchronized plantar pressure and inertial measurements, demonstrating the feasibility of reconstructing full-body motion using only foot-based sensing through a dual-modal motion reconstruction network. To enhance global motion reconstruction accuracy, we develop a motion-aware trajectory estimation strategy and implement a two-stage reconstruction pipeline that separates orientation estimation from other motion parameters. Our experiments show a Mean Per Joint Position Error of 69.43mm and a Root Trajectory Error of 0.267m for 2-second predictions. This work presents a practical approach for non-invasive and privacy-preserving motion capture. Code and dataset are available for research purposes at this link.},
journal = {Proc. ACM Interact. Mob. Wearable Ubiquitous Technol.},
month = sep,
articleno = {145},
numpages = {41},
keywords = {Human Motion Reconstruction, Pressure and Inertial Sensing, Smart Shoes, Tactile Sensing}
}

@article{10.1145/3749465,
author = {Xiao, Yi and Sharma, Harshit and Kaur, Sawinder and Bergen-Cico, Dessa and Salekin, Asif},
title = {Human Heterogeneity Invariant Stress Sensing},
year = {2025},
issue_date = {September 2025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {9},
number = {3},
url = {https://doi.org/10.1145/3749465},
doi = {10.1145/3749465},
abstract = {Stress affects physical and mental health, and wearable devices have been widely used to detect daily stress through physiological signals. However, these signals vary due to factors such as individual differences and health conditions, making generalizing machine learning models difficult. To address these challenges, we present Human Heterogeneity Invariant Stress Sensing (HHISS), a domain generalization approach designed to find consistent patterns in stress signals by removing person-specific differences. This helps the model perform more accurately across new people, environments, and stress types not seen during training. Its novelty lies in proposing a novel technique called person-wise sub-network pruning intersection to focus on shared features across individuals, alongside preventing overfitting by leveraging continuous labels while training. The present study focuses on people with opioid use disorder (OUD)---a group where stress responses can change dramatically depending on the presents of opioids in their system, including daily timed medication for OUD (MOUD). Since stress often triggers cravings, a model that can adapt well to these changes could support better OUD rehabilitation and recovery. We tested HHISS on seven different stress datasets---four which we collected ourselves and three public datasets. Four are from lab setups, one from a controlled real-world driving setting, and two are from real-world in-the-wild field datasets with no constraints. The present study is the first known to evaluate how well a stress detection model works across such a wide range of data. Results show HHISS consistently outperformed state-of-the-art baseline methods, proving both effective and practical for real-world use. Ablation studies, empirical justifications, and runtime evaluations confirm HHISS's feasibility and scalability for mobile stress sensing in sensitive real-world applications.},
journal = {Proc. ACM Interact. Mob. Wearable Ubiquitous Technol.},
month = sep,
articleno = {142},
numpages = {42},
keywords = {Neural network pruning, Out-of-Distribution Generalization, Stress Detection, Wearable Data}
}

@article{10.1145/3749471,
author = {Meng, Chengzhen and He, Chenming and Wang, Dequan and Xiao, Yuxuan and Wang, Lingyu and Fan, Xiaoran and Zhang, Lu and Zhang, Yanyong},
title = {GR-Fall: A Fall Detection System with Gait Recognition for Indoor Environments Using SISO mmWave Radar},
year = {2025},
issue_date = {September 2025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {9},
number = {3},
url = {https://doi.org/10.1145/3749471},
doi = {10.1145/3749471},
abstract = {Fall detection is essential for safeguarding the health of elderly persons, enabling timely alerts to family members or the community. Millimeter-wave (mmWave) radar offers an effective solution, as it is privacy-preserving, non-invasive, and highly sensitive to motion. However, most existing approaches rely on multi-input, multi-output mmWave radar to generate 4D point clouds or range-angle heatmaps, significantly raising device costs. In this paper, we propose GR-Fall, a fall detection system with integrated gait recognition designed for indoor environments using single-input, single-output mmWave radar. To achieve high performance in various environments, we develop a data augmentation algorithm for target heatmaps and a cross-attention-based heatmap fusion framework for efficient fall detection. Furthermore, we introduce an innovative fall alarm mechanism based on joint fall-gait detection. This mechanism activates alerts when a person is detected having difficulty moving after a fall, thus minimizing unnecessary alarms and reducing strain on community resources. To evaluate GR-Fall, we recruit 33 volunteers and collect 5,799 instances across four different environments. Experimental results show that GR-Fall achieves 98.1\% precision and 98.7\% recall in new environments and with new participants, outperforming other state-of-the-art heatmap-based methods.},
journal = {Proc. ACM Interact. Mob. Wearable Ubiquitous Technol.},
month = sep,
articleno = {118},
numpages = {26},
keywords = {Fall Detection, Wireless Sensing, mmWave Radar}
}

@article{10.1145/3749508,
author = {Li, Jiachen and Li, Xiwen and Steinberg, Justin and Choube, Akshat and Yao, Bingsheng and Xu, Xuhai and Wang, Dakuo and Mynatt, Elizabeth and Mishra, Varun},
title = {Vital Insight: Assisting Experts' Context-Driven Sensemaking of Multi-modal Personal Tracking Data Using Visualization and Human-in-the-Loop LLM},
year = {2025},
issue_date = {September 2025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {9},
number = {3},
url = {https://doi.org/10.1145/3749508},
doi = {10.1145/3749508},
abstract = {Passive tracking methods, such as phone and wearable sensing, have become dominant in monitoring human behaviors in modern ubiquitous computing studies. While there have been significant advances in machine-learning approaches to translate periods of raw sensor data to model momentary behaviors, (e.g., physical activity recognition), there still remains a significant gap in the translation of these sensing streams into meaningful, high-level, context-aware insights that are required for various applications (e.g., summarizing an individual's daily routine). To bridge this gap, experts often need to employ a context-driven sensemaking process in real-world studies to derive insights. For instance, current approaches in the field can reliably predict "walking outdoors" by contextualizing accelerometer and GPS data. Sensemaking, however, involves being able to notice patterns of periodic "walking" and "stationary" events, and even infer "walking the dog" after realizing the alignment with regular routines reported through surveys or self-reports. This process often requires manual effort and can be challenging even for experienced researchers due to the complexity of human behaviors.We conducted three rounds of user studies with 21 experts to explore solutions to address challenges with sensemaking. We follow a human-centered design process to identify needs and design, iterate, build, and evaluate Vital Insight (VI), a novel, LLM-assisted, prototype system to enable human-in-the-loop inference (sensemaking) and visualizations of multimodal passive sensing data from smartphones and wearables. Using the prototype as a technology probe, we observe experts' interactions with it and develop an expert sensemaking model that explains how experts move between direct data representations and AI-supported inferences to explore, question, and validate insights. Through this iterative process, we also synthesize and discuss a list of design implications for the design of future AI-augmented visualization systems to better assist experts' sensemaking processes in multi-modal health sensing data.},
journal = {Proc. ACM Interact. Mob. Wearable Ubiquitous Technol.},
month = sep,
articleno = {101},
numpages = {37},
keywords = {AI-assisted Sensemaking, Large Language Models, Personal Tracking, Thematic Analysis}
}

@article{10.1145/3749474,
author = {Choube, Akshat and Le, Ha and Li, Jiachen and Ji, Kaixin and Swain, Vedant Das and Mishra, Varun},
title = {GLOSS: Group of LLMs for Open-ended Sensemaking of Passive Sensing Data for Health and Wellbeing},
year = {2025},
issue_date = {September 2025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {9},
number = {3},
url = {https://doi.org/10.1145/3749474},
doi = {10.1145/3749474},
abstract = {The ubiquitous presence of smartphones and wearables has enabled researchers to build prediction and detection models for various health and behavior outcomes using passive sensing data from these devices. Achieving a high-level, holistic understanding of an individual's behavior and context, however, remains a significant challenge. Due to the nature of the passive sensing data, sensemaking --- the process of interpreting and extracting insights - requires both domain knowledge and technical expertise, creating barriers for different stakeholders. Existing systems designed to support sensemaking are not open-ended or cannot perform complex data triangulation. In this paper, we present a novel sensemaking system, Group of LLMs for Open-ended Sensemaking (GLOSS), for open-ended sensemaking capable of performing complex multimodal triangulation to derive insights. We demonstrate that GLOSS significantly outperforms commonly used Retrieval-Augmented Generation (RAG) technique, achieving 87.93\% accuracy and 66.19\% consistency compared to RAG's 29.31\% accuracy and 52.85\% consistency. Furthermore, we showcase the promise of GLOSS using four use cases inspired by prior and ongoing work in UbiComp and HCI communities. Finally, we discuss the potential of GLOSS, the broader implications, and the limitations of our work.},
journal = {Proc. ACM Interact. Mob. Wearable Ubiquitous Technol.},
month = sep,
articleno = {76},
numpages = {32},
keywords = {digital health \&amp; wellbeing, large language models, mobile sensing, sensemaking, wearables}
}

@article{10.1145/3749480,
author = {Wang, Zeyu and Yu, Ruotong and Wang, Xiangyang and Ding, Jiexin and Tang, Jiankai and Fang, Jun and He, Zhe and Li, Zhuojun and R\"{o}ddiger, Tobias and Xu, Weiye and Zhang, Xiyuxing and Gao, Huan-ang and Gao, Nan and Yu, Chun and Shi, Yuanchun and Wang, Yuntao},
title = {Computing with Smart Rings: A Systematic Literature Review},
year = {2025},
issue_date = {September 2025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {9},
number = {3},
url = {https://doi.org/10.1145/3749480},
doi = {10.1145/3749480},
abstract = {A smart ring is a wearable electronic device in the form of a ring that incorporates diverse sensors and computing technologies to perform a variety of functions. Designed for use with fingers, smart rings are capable of sensing more subtle and abundant hand movements, thus making them a good platform for interaction. Meanwhile, fingers are abundant with blood vessels and nerve endings and accustomed to wearing rings, providing an ideal site for continuous health monitoring through smart rings, which combine comfort with the ability to capture vital biometric data, making them suitable for all-day wear. We collected in total of 206 smart ring-related publications and conducted a systematic literature review. We provide a taxonomy regarding the sensing and feedback modalities, applications, and phenomena. We review and categorize these literatures into four main areas: (1) interaction - input, (2) interaction - output, (3) passive sensing - in body feature, (4) passive sensing - out body activity. This comprehensive review highlights the current advancements within the field of smart ring and identifies potential areas for future research.},
journal = {Proc. ACM Interact. Mob. Wearable Ubiquitous Technol.},
month = sep,
articleno = {137},
numpages = {54},
keywords = {Smart rings, Wearable computing, finger augmentation, finger-attached, finger-mounted, finger-worn}
}

