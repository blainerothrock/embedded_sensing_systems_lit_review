@inproceedings{10.1145/3594739.3610768,
author = {Cabral, Alex and Waldo, Jim},
title = {Designing Large-Scale Wireless Sensor Networks for Urban Environmental Sensing},
year = {2023},
isbn = {9798400702006},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3594739.3610768},
doi = {10.1145/3594739.3610768},
abstract = {Hardware and software advances have paved the way for large-scale environmental urban sensor networks, but there is no guidance on where to place a finite number of nodes and how to assess the network design. In this work, I develop and test two quality metrics for urban sensor networks—one that focuses on the impacts of urban form and one that acknowledges cities as social spaces. I then propose a data-driven algorithm grounded in urban planning theory for a new urban sensor network design. Through real-world deployments and simulations using open data, I will compare my proposed design and quality metrics to those used in prior sensor networks. This work will enable the deployment of environmental sensor networks that produce useful citywide data for numerous stakeholders despite the complexities of urban environments.},
booktitle = {Adjunct Proceedings of the 2023 ACM International Joint Conference on Pervasive and Ubiquitous Computing \&amp; the 2023 ACM International Symposium on Wearable Computing},
pages = {253–257},
numpages = {5},
keywords = {Environmental Sensing, Sensor Networks, Smart Cities, Urban Sensing},
location = {Cancun, Quintana Roo, Mexico},
series = {UbiComp/ISWC '23 Adjunct}
}

@inproceedings{10.1145/3594739.3611327,
author = {Ferreira-Brito, Filipa and Ferreira, Jo\~{a}o and Vieira, Madalena and Guerreiro, Jo\~{a}o and Guerreiro, Tiago},
title = {Digital Therapeutics with Virtual Reality and Sensors},
year = {2023},
isbn = {9798400702006},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3594739.3611327},
doi = {10.1145/3594739.3611327},
abstract = {Digital Therapeutics (DTx) is an emerging field within Digital Health that is rapidly growing and holds promise for addressing anxiety-related disorders. Moreover, the combination of virtual reality (VR) and wearable sensors holds great potential for developing affordable, accessible, and effective DTx solutions. In this paper, we present our conception of a fully customised DTx for managing and supporting anxiety-related disorders therapy. We highlight five key assumptions that should be considered when developing such a DTx. These assumptions include the customisation of virtual environments (VEs); integration of physiological data and patient feedback; the use of dashboards for data visualisation; session replay and identification of peak response moments; and patient empowerment throughout the therapeutic process. By embracing these assumptions, we describe the main components constituting this DTx and emphasise fundamental features to fulfil the identified assumptions. Furthermore, we explore some of the potential benefits and challenges of DTx applied to mental health.},
booktitle = {Adjunct Proceedings of the 2023 ACM International Joint Conference on Pervasive and Ubiquitous Computing \&amp; the 2023 ACM International Symposium on Wearable Computing},
pages = {611–614},
numpages = {4},
keywords = {Anxiety-related disorders, DTx, Exposure therapy, Mental health, Sensors, Virtual reality},
location = {Cancun, Quintana Roo, Mexico},
series = {UbiComp/ISWC '23 Adjunct}
}

@inproceedings{10.1145/3594739.3612874,
author = {Nishiyama, Yuuki and Sezaki, Kaoru},
title = {Smartwatch-Based Sensing Framework for Continuous Data Collection: Design and Implementation},
year = {2023},
isbn = {9798400702006},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3594739.3612874},
doi = {10.1145/3594739.3612874},
abstract = {Smartwatches are an increasingly popular technology that employs advanced sensors (e.g., location, motion, and microphone) comparable to those used by smartphones. Passive mobile sensing, a method of acquiring human behavior data from mobile and wearable devices inconspicuously, is widely used in research fields related to behavior analysis. In combination with machine learning, passive mobile sensing can be used to interpret various human and environmental contexts without requiring user intervention. Because smartwatches are always worn on the wrist, they have the potential to collect data that cannot be collected by smartphones. However, the effective use of smartwatches as platforms for passive mobile sensing poses challenges in terms of battery life, storage, and communication. To address these challenges, we designed and implemented a tailored framework for off-the-shelf smartwatches. We evaluated power consumption under eight different sensing conditions using three smartwatches. The results demonstrate that the framework can collect sensor data with a battery life of 16-31 h depending on the settings. Finally, we considered potential future solutions for optimizing power consumption in passive sensing with off-the-shelf smartwatches.},
booktitle = {Adjunct Proceedings of the 2023 ACM International Joint Conference on Pervasive and Ubiquitous Computing \&amp; the 2023 ACM International Symposium on Wearable Computing},
pages = {620–625},
numpages = {6},
keywords = {battery consumption, environmental sound collection, motion sensor, passive sensing framework, smartwatch},
location = {Cancun, Quintana Roo, Mexico},
series = {UbiComp/ISWC '23 Adjunct}
}

@inproceedings{10.1145/3594739.3610744,
author = {Shintani, Kaede and Rizk, Hamada and Yamaguchi, Hirozumi},
title = {Eco-Friendly Sensing for Human Activity Recognition},
year = {2023},
isbn = {9798400702006},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3594739.3610744},
doi = {10.1145/3594739.3610744},
abstract = {With the increasing number of IoT devices, there is a growing demand for energy-free sensors. Human activity recognition holds immense value in numerous daily healthcare applications. However, the majority of current sensing modalities consume energy, thus limiting their sustainable adoption. In this paper, we present a novel activity recognition system that not only operates without requiring energy for sensing but also harvests energy. Our proposed system utilizes photovoltaic cells, attached to the wrist and shoes, as eco-friendly sensing devices for activity recognition. By capturing photovoltaic readings and employing a deep transformer model with powerful learning capabilities, the system effectively recognizes user activities. To ensure robust performance across various subjects, time periods, and lighting conditions, the system incorporates feature extraction and different processing modules. The evaluation of the proposed system on realistic indoor and outdoor environments demonstrated its ability to recognize activities with an accuracy of 91.7\%.},
booktitle = {Adjunct Proceedings of the 2023 ACM International Joint Conference on Pervasive and Ubiquitous Computing \&amp; the 2023 ACM International Symposium on Wearable Computing},
pages = {492–498},
numpages = {7},
keywords = {Energy harvesting, activity recognition, energy-free sensing},
location = {Cancun, Quintana Roo, Mexico},
series = {UbiComp/ISWC '23 Adjunct}
}

@inproceedings{10.1145/3594739.3610677,
author = {Zhang, Han and Wang, Leijie and Sheng, Yilun and Xu, Xuhai and Mankoff, Jennifer and Dey, Anind K.},
title = {A Framework for Designing Fair Ubiquitous Computing Systems},
year = {2023},
isbn = {9798400702006},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3594739.3610677},
doi = {10.1145/3594739.3610677},
abstract = {Over the past few decades, ubiquitous sensors and systems have been an integral part of humans’ everyday life. They augment human capabilities and provide personalized experiences across diverse contexts such as healthcare, education, and transportation. However, the widespread adoption of ubiquitous computing has also brought forth concerns regarding fairness and equitable treatment. As these systems can make automated decisions that impact individuals, it is essential to ensure that they do not perpetuate biases or discriminate against specific groups. While fairness in ubiquitous computing has been an acknowledged concern since the 1990s, it remains understudied within the field. To bridge this gap, we propose a framework that incorporates fairness considerations into system design, including prioritizing stakeholder perspectives, inclusive data collection, fairness-aware algorithms, appropriate evaluation criteria, enhancing human engagement while addressing privacy concerns, and interactive improvement and regular monitoring. Our framework aims to guide the development of fair and unbiased ubiquitous computing systems, ensuring equal treatment and positive societal impact.},
booktitle = {Adjunct Proceedings of the 2023 ACM International Joint Conference on Pervasive and Ubiquitous Computing \&amp; the 2023 ACM International Symposium on Wearable Computing},
pages = {366–373},
numpages = {8},
keywords = {Fairness, Framework, Ubiquitous Computing Systems},
location = {Cancun, Quintana Roo, Mexico},
series = {UbiComp/ISWC '23 Adjunct}
}

@inproceedings{10.1145/3594739.3612875,
author = {Aldaweesh, Sarah and Van Kleek, Max and Shadbolt, Nigel},
title = {Mobile Sensing and Engagement Features in Arabic Mental Well-Being Apps: Systematic Search and Analysis},
year = {2023},
isbn = {9798400702006},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3594739.3612875},
doi = {10.1145/3594739.3612875},
abstract = {Various mobile apps have been released to track and promote mental health and well-being. Despite the high interest in developing these apps, they suffer from high attrition rates. These apps have limited utility if they are delivered in a manner that does not maintain individuals’ engagement. Engagement features are therefore a critical factor to consider for fostering intended benefits. While there is considerable research on analysing the engagement features of these apps available in English, our understanding of engagement features in such Arabic apps is limited. Moreover, much less is known about mobile sensing in Arabic apps. To address this gap, we systematically searched app stores, identified 110 apps available in Arabic, and analyzed their features based on existing mHealth assessment frameworks. Our analysis found that available Arabic apps poorly implemented engagement features, apart from basic features such as sharing and reminders. Surprisingly, Arabic apps missed mobile sensing capabilities and AI applications. This paper highlights the importance of employing mobile sensing and persuasive design principles in the future design of Arabic apps.},
booktitle = {Adjunct Proceedings of the 2023 ACM International Joint Conference on Pervasive and Ubiquitous Computing \&amp; the 2023 ACM International Symposium on Wearable Computing},
pages = {626–631},
numpages = {6},
keywords = {Arabic mobile apps, app review, engagement, mHealth, mental health, mobile sensing, persuasive design, well-being},
location = {Cancun, Quintana Roo, Mexico},
series = {UbiComp/ISWC '23 Adjunct}
}

@inproceedings{10.1145/3594739.3611328,
author = {Boukhechba, Mehdi and Reynoso, Elena and Pandis, Ioannis and Mosca, Kenneth and Hristov, Rumen and Yue, Shichao and Ai, Yuqing and Rahul, Hariharan and Katabi, Dina and Morris, Mark and Avey, Stefan},
title = {Digital Phenotyping of Autoimmune Diseases Using Non-Contact Radio Frequency Sensing: A Longitudinal Study Comparing Systemic Lupus Erythematosus and Healthy Participants},
year = {2023},
isbn = {9798400702006},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3594739.3611328},
doi = {10.1145/3594739.3611328},
abstract = {Recent ubiquitous sensing technologies make it possible to capture streaming digital data that reports aspects of a patient’s physiology, behavior, and symptoms both quantitatively and in real time. As a result, it may be possible to develop streaming disease readouts that are more accurate and less obtrusive than relying on patient and caregiver reports alone. This study investigates the feasibility of leveraging physiological and behavioral signals extracted from a radio frequency sensing device to characterize metrics indicative of breathing, mobility, and sleep patterns. We investigate the variations in these signals between individuals with Systemic Lupus Erythematosus (SLE) and healthy participants in a 6-months longitudinal, exploratory, in-home study involving 19 SLE and 28 healthy participants. Results show that many signals (e.g., breathing rate, sleep efficiency, and gait speed) significantly distinguish SLE and healthy participants and demonstrate the potential of using remote sensing as an unobtrusive low-burden tool to assess disease symptoms continuously and in real time.},
booktitle = {Adjunct Proceedings of the 2023 ACM International Joint Conference on Pervasive and Ubiquitous Computing \&amp; the 2023 ACM International Symposium on Wearable Computing},
pages = {615–619},
numpages = {5},
keywords = {Digital Phenotyping, Non-Contact Sensing, Systemic Lupus Erythematosus},
location = {Cancun, Quintana Roo, Mexico},
series = {UbiComp/ISWC '23 Adjunct}
}

@inproceedings{10.1145/3594739.3610673,
author = {Fan, Xiaoran and Thormundsson, Trausti},
title = {Design Earable Sensing Systems: Perspectives and Lessons Learned from Industry},
year = {2023},
isbn = {9798400702006},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3594739.3610673},
doi = {10.1145/3594739.3610673},
abstract = {Earables computing is an emerging research community as the industry witnesses the soaring of True Wireless Stereo (TWS) Active Noise Canceling (ANC) earbuds in the past ten years. There is an increasing trend of newly initiated earable research spanning across mobile health, user-interfaces, speech processing, and context-awareness. Head-worn devices are anticipated to be the next generation Mobile Computing and Human-Computer Interaction (HCI) platform. In this paper, we share our design experiences and lessons learned in building hearable sensing systems from the industry perspective. We also give our takes on future directions of the earable research.},
booktitle = {Adjunct Proceedings of the 2023 ACM International Joint Conference on Pervasive and Ubiquitous Computing \&amp; the 2023 ACM International Symposium on Wearable Computing},
pages = {342–345},
numpages = {4},
keywords = {Earable Computing, Mobile Computing, Wearable Devices},
location = {Cancun, Quintana Roo, Mexico},
series = {UbiComp/ISWC '23 Adjunct}
}

@inproceedings{10.1145/3594739.3612904,
author = {Li, Jiarong and Ge, Changshuo and Tao, Jun and Wang, Jingyang and Xu, Xiaomin and Chen, Xinlei and Gui, Weihua and Liang, Xiaojun and Ding, Wenbo},
title = {SolareSkin: Self-powered Visible Light Sensing Through a Solar Cell E-Skin},
year = {2023},
isbn = {9798400702006},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3594739.3612904},
doi = {10.1145/3594739.3612904},
abstract = {SolareSkin is a self-powered and ubiquitous electronic skin equipped with ultraflexible organic solar cells for visible light sensing and energy harvesting. This dual-functional system captures light signals, transforms them into electrical impulses and enables multi-class gesture and activity recognition. Its design employs a photocurrent model that allows solar cells to serve as energy harvesters and visible light sensors simultaneously. The solar cells demonstrate a decent conversion rate of incident light into electricity, supporting an efficient, sustainable operation. Additionally, the system incorporates advanced system integration with a low-powered data collection board embedded with wireless transmission modules and an intuitive user interface. An algorithm is employed for signal analysis with data pre-processing methods and several machine learning models. The data pre-processing methods comprise filtering, scaling, normalization, segmentation, and downsampling of raw sensor data to reduce noise and increase prediction accuracy. The machine learning model evaluation focuses on three algorithms: Support Vector Machines (SVM), K-Nearest Neighbors (KNN), and Random Forest, due to their efficiency with high-dimensional, nonlinear data. The experimental results suggest the excellent performance of SVM in recognizing 7-class finger gestures and 7-class body activities, with accuracies of 97.3\% and 96.7\%, respectively. This advancement in electronic skin technology is promising for ubiquitous human-centric sensing, enabling various applications such as healthcare monitoring, human-computer interaction, and smart homes.},
booktitle = {Adjunct Proceedings of the 2023 ACM International Joint Conference on Pervasive and Ubiquitous Computing \&amp; the 2023 ACM International Symposium on Wearable Computing},
pages = {664–669},
numpages = {6},
keywords = {Electronic Skin, Energy harvesting, Human activity recognition, Visible light sensing},
location = {Cancun, Quintana Roo, Mexico},
series = {UbiComp/ISWC '23 Adjunct}
}

@inproceedings{10.1145/3594739.3610730,
author = {Pulsipher, Andrew and Giannakos, Michail},
title = {Towards a Taxonomy of Human-Building Interactions},
year = {2023},
isbn = {9798400702006},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3594739.3610730},
doi = {10.1145/3594739.3610730},
abstract = {Built environments (BE) are increasingly integrating sensing and interactivity capabilities, changing how we co-exist and live. In recent years, HCI, ubiquitous computing, and architecture have contributed to the interdisciplinary field of Human-Building Interaction (HBI). HBI represents the growing complexities of human experience within BE, which includes utilizing sensing capabilities to gracefully support people’s needs. We present an initial taxonomy classifying interactions with HBI devices, the HBI Interactivity Taxonomy, a novel contribution to this field. We employed an integrative research strategy, sampling device descriptions from commercial and academic sources. Taxonomy features were extracted through thematic analysis. The resulting list of characteristics describes how users interact with HBI devices. We offer an initial version of this taxonomy as a tool to facilitate communication and enhance the design and evaluation of future HBI devices in both academia and industry.},
booktitle = {Adjunct Proceedings of the 2023 ACM International Joint Conference on Pervasive and Ubiquitous Computing \&amp; the 2023 ACM International Symposium on Wearable Computing},
pages = {411–416},
numpages = {6},
keywords = {human-building interaction, smart-environments, taxonomy, ubiquitous computing},
location = {Cancun, Quintana Roo, Mexico},
series = {UbiComp/ISWC '23 Adjunct}
}

@inproceedings{10.1145/3594739.3610724,
author = {Wang, Yida and Chen, Yi-Chao},
title = {Non-Contact Thermal Haptics for VR},
year = {2023},
isbn = {9798400702006},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3594739.3610724},
doi = {10.1145/3594739.3610724},
abstract = {In the realm of virtual reality (VR), haptic feedback plays a pivotal role in enhancing user immersion. However, the implementation of non-contact thermal haptics presents numerous challenges. In this study, we introduce a novel approach for creating thermal haptic feedback in a VR environment, combining an ultrasonic phased array with a heating circuit. Our design generates multiple beams that deliver heated air to the user, thus simulating the sensation of temperature change. This approach enables an immersive, responsive VR experience that dynamically adjusts the temperature of the surrounding air based on the VR content. The innovation resides in our method’s ability to overcome traditional phased array limitations, such as grating lobes and high hardware costs, by leveraging the directionality of ultrasonic transducers within the array. This results in a more cost-effective, compact, and efficient thermal haptic feedback system. Our work thus offers a significant contribution to the field of VR, presenting a new way of enhancing user immersion through non-contact thermal haptics.},
booktitle = {Adjunct Proceedings of the 2023 ACM International Joint Conference on Pervasive and Ubiquitous Computing \&amp; the 2023 ACM International Symposium on Wearable Computing},
pages = {386–390},
numpages = {5},
keywords = {non-contact, temperature, thermal haptic, virtual reality},
location = {Cancun, Quintana Roo, Mexico},
series = {UbiComp/ISWC '23 Adjunct}
}

@inproceedings{10.1145/3594739.3610670,
author = {Li, Jiao and Liu, Yang and Li, Zhenjiang and Zhang, Jin},
title = {EarPass: Continuous User Authentication with In-ear PPG},
year = {2023},
isbn = {9798400702006},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3594739.3610670},
doi = {10.1145/3594739.3610670},
abstract = {In the rapidly expanding universe of smart IoT, earable devices, such as smart headphones and hearing aids, are gaining remarkable popularity. As we anticipate a future where a myriad of sophisticated applications—interaction, communication, health monitoring, and fitness guidance—migrate to earable devices handling sensitive and private information, the need for a robust, continuous authentication system for these devices becomes more critical than ever. Yet, current earable-based solutions, which rely predominantly on audio signals, are marred by inherent drawbacks such as privacy concerns, high costs, and noise interference. In light of these challenges, we investigate the potential of leveraging photoplethysmogram (PPG) sensors, which monitor key cardiac activities and reflect the uniqueness of an individual’s cardiac system, for earable authentication. Our study presents EarPass, an innovative ear-worn system that introduces a novel pipeline for the extraction and classification of in-ear PPG features to enable continuous user authentication. Initially, we preprocess the input in-ear PPG signals to facilitate this feature extraction and classification. Additionally, we present a method for detecting and eliminating motion artifacts (MAs) caused by head motions. Through extensive experiments, we not only demonstrate the effectiveness of our proposed design, but also establish the feasibility of using in-ear PPG for continuous user authentication—a significant stride towards more secure and efficient earable technologies.},
booktitle = {Adjunct Proceedings of the 2023 ACM International Joint Conference on Pervasive and Ubiquitous Computing \&amp; the 2023 ACM International Symposium on Wearable Computing},
pages = {327–332},
numpages = {6},
keywords = {PPG sensing, earable authentication, machine learning, wearable security},
location = {Cancun, Quintana Roo, Mexico},
series = {UbiComp/ISWC '23 Adjunct}
}

@inproceedings{10.1145/3594739.3612879,
author = {Hassan, Muhammad and Bashir, Masooda},
title = {Unveiling Privacy Measures in Mental Health Applications},
year = {2023},
isbn = {9798400702006},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3594739.3612879},
doi = {10.1145/3594739.3612879},
abstract = {Mental health conditions have become a global public health issue, especially in the context of the COVID-19 pandemic. To cope with the increasing demand for mental health services, many people have turned to smartphone applications that offer various mental health solutions, such as therapy, counseling, and self-help. However, these applications also pose significant privacy risks for their users, as they collect and share sensitive personal and health information with third parties, often without adequate consent or transparency. In this study, we examine the privacy policies of popular mental health smartphone applications using the Fair Information Practice Principles (FIPPs), a widely recognized privacy framework. Our objective is to assess the extent to which these applications adhere to the FIPPs guidelines and to identify the gaps and challenges in their privacy practices. We hope that our findings can inform and guide policy makers and application developers to design more user-centric and robust privacy policies that ensure the safety and security of users’ information.},
booktitle = {Adjunct Proceedings of the 2023 ACM International Joint Conference on Pervasive and Ubiquitous Computing \&amp; the 2023 ACM International Symposium on Wearable Computing},
pages = {648–654},
numpages = {7},
keywords = {Mental Health Application, Policy Analysis, Privacy Policies},
location = {Cancun, Quintana Roo, Mexico},
series = {UbiComp/ISWC '23 Adjunct}
}

@inproceedings{10.1145/3615452.3617940,
author = {Jia, Jing and Humphrey, Julianne D'Avirro and Darji, Parth and Zhang, Binsheng and Liu, Yao},
title = {VCRS: A Novel Approach to Virtual Reality Cycling for Balance Rehabilitation},
year = {2023},
isbn = {9798400703393},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3615452.3617940},
doi = {10.1145/3615452.3617940},
abstract = {This paper presents the hardware and software design of Virtual Cycling Rehab System (VCRS), a novel and affordable system for balance rehabilitation via virtual reality (VR). The system integrates real-time sensor communication with an Oculus Quest-based virtual environment created in Unity. This integration enables precise avatar movement and facilitates the assessment of lateral balance during cycling rehab sessions. The accelerometer data from one side of the pedals is accurately translated into in-game physics to create realistic avatar movement. The system also utilizes gyroscope data to calculate and display a graphic representation of the patient's balancing score to guide the patient's lateral balance. Physicians can monitor the session via live mirroring the VR HMD and graphed balance data on a local device. At the end of each session, the user receives feedback in the form of session time, game score, and a percentage indicating their level of lateral balance.},
booktitle = {Proceedings of the 1st ACM Workshop on Mobile Immersive Computing, Networking, and Systems},
pages = {254–260},
numpages = {7},
keywords = {virtual reality, rehabilitation, VR cycling},
location = {Madrid, Spain},
series = {ImmerCom '23}
}

@inproceedings{10.1145/3615452.3617941,
author = {Ganj, Ashkan and Zhao, Yiqin and Galbiati, Federico and Guo, Tian},
title = {Toward Scalable and Controllable AR Experimentation},
year = {2023},
isbn = {9798400703393},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3615452.3617941},
doi = {10.1145/3615452.3617941},
abstract = {To understand how well a proposed augmented reality (AR) solution works, existing papers often conducted tailored and isolated evaluations for specific AR tasks, e.g., depth or lighting estimation, and compared them to easy-to-setup baselines, either using datasets or resorting to time-consuming data capturing. Conceptually simple, it can be extremely difficult to evaluate an AR system fairly and in scale to understand its real-world performance. The difficulties arise for three key reasons: lack of control of the physical environment, the time-consuming data capturing, and the difficulties to reproduce baseline results.This paper presents our design of an AR experimentation platform, ExpAR, aiming to provide scalable and controllable AR experimentation. ExpAR is envisioned to operate as a standalone deployment or a federated platform; in the latter case, AR researchers can contribute physical resources, including scene setup and capturing devices, and allow others to time share these resources. Our design centers around the generic sensing-understanding-rendering pipeline and is driven by the evaluation limitations observed in recent AR systems papers. We demonstrate the feasibility of this vision with a preliminary prototype and our preliminary evaluations suggest the importance of further investigating different device capabilities to stream in 30 FPS.},
booktitle = {Proceedings of the 1st ACM Workshop on Mobile Immersive Computing, Networking, and Systems},
pages = {237–246},
numpages = {10},
keywords = {augmented reality, experimentation platform},
location = {Madrid, Spain},
series = {ImmerCom '23}
}

@inproceedings{10.1145/3615452.3617937,
author = {Scargill, Tim and Hadziahmetovic, Majda and Gorlatova, Maria},
title = {Invisible Textures: Comparing Machine and Human Perception of Environment Texture for AR},
year = {2023},
isbn = {9798400703393},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3615452.3617937},
doi = {10.1145/3615452.3617937},
abstract = {Mobile augmented reality (AR) has a wide range of promising applications, but its efficacy is subject to the impact of environment texture on both machine and human perception. Performance of the machine perception algorithm underlying accurate positioning of virtual content, visual-inertial SLAM (VI-SLAM), is known to degrade in low-texture conditions, but there is a lack of data in realistic scenarios. We address this through extensive experiments using a game engine-based emulator, with 112 textures and over 5000 trials. Conversely, human task performance and response times in AR have been shown to increase in environments perceived as textured. We investigate and provide encouraging evidence for invisible textures, which result in good VI-SLAM performance with minimal impact on human perception of virtual content. This arises from fundamental differences between VI-SLAM-based machine perception, and human perception as described by the contrast sensitivity function. Our insights open up exciting possibilities for deploying ambient IoT devices that display invisible textures, as part of systems which automatically optimize AR environments.},
booktitle = {Proceedings of the 1st ACM Workshop on Mobile Immersive Computing, Networking, and Systems},
pages = {229–236},
numpages = {8},
keywords = {augmented reality, VI-SLAM, perception, texture},
location = {Madrid, Spain},
series = {ImmerCom '23}
}

@inproceedings{10.1145/3609437.3609448,
author = {Li, Xiaojuan and Zhang, Yu and Zhu, Zhengyan and Yao, Yuan and Zhou, Xingshe},
title = {UbiCap: A Capability-based Run-time Model for Heterogeneous Sensors Management in Ubiquitous Operating System},
year = {2023},
isbn = {9798400708947},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3609437.3609448},
doi = {10.1145/3609437.3609448},
abstract = {The Ubiquitous Operating System(UOS) is a new type of operating system in response to the new patterns and scenarios of future human-cyber-physical ternary ubiquitous computing. Compared with traditional operating systems, one of the fundamental requirements of UOS is to adaptively manage numerous heterogeneous sensors according to dynamic environments and diverse tasks. However, traditional management focuses on the sensors’ parameters and interfaces without highlighting the perception effect that is users’ concern and dynamic changing. It also lacks a unified management approach for heterogeneous sensors. To overcome the limitations, we propose a novel heterogeneous sensors dynamic management model UbiCap, i.e., Ubiquitous Capability, which is based on the capability abstraction and adaptive run-time capability management mechanism. The capability provides a unified abstract for heterogeneous sensors. The adaptive run-time capability management mechanism transfers the management object from low-level hardware sensors to high-level sensing capability. The capability required and the available capability are matched to support run-time adaptive sensors selection. We implement a software prototype iS2ROS(intelligent Sensor Selection Robot Operating System) based on the UbiCap model. We then simulate a forest fire spot monitoring scenario where iS2ROS selects the optimal image sensor during the identification task execution while light or weather condition changes. Experiment results show that the iS2ROS achieves comparative sensing effectiveness through UbiCap with 50\% power consumption lower compared to the traditional both-sensors approach.},
booktitle = {Proceedings of the 14th Asia-Pacific Symposium on Internetware},
pages = {134–143},
numpages = {10},
keywords = {Capability, Heterogeneous Sensors Management, Ubiquitous Operating System, adaptive, run-time},
location = {Hangzhou, China},
series = {Internetware '23}
}

@article{10.1145/3610038,
author = {Lenhart, Anna and Park, Sunyup and Zimmer, Michael and Vitak, Jessica},
title = {"You Shouldn't Need to Share Your Data": Perceived Privacy Risks and Mitigation Strategies Among Privacy-Conscious Smart Home Power Users},
year = {2023},
issue_date = {October 2023},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {7},
number = {CSCW2},
url = {https://doi.org/10.1145/3610038},
doi = {10.1145/3610038},
abstract = {Fueled by Internet-of-Things technologies and spanning a wide range of sensors, speakers, and cameras, smart homes promise to make our lives easier and automate routine tasks. From speakers to security cameras, smart home devices (SHDs) answer our questions, monitor our home environment, and conserve energy. They also collect significant data, ranging from on/off commands to audio and video data, and they do this in some of our most private spaces. In this paper, we explore the privacy risks associated with SHDs by focusing on privacy-conscious smart home power users--those who spend significant time and money to research, install, and integrate devices throughout their homes and engage in advanced device and network management strategies to mitigate privacy concerns. Drawing on data from 10 focus groups with 32 privacy-conscious power users, we identify the key privacy risks they perceive from this technology, as well as how they mitigate those risks through increasingly complex strategies. Our findings reveal that navigating the technical landscape that makes up the smart home environment--including what data is collected, what options are available for managing or restricting data flows, and who has access to data collected by SHDs--is complex and often confusing, even for people who spend significant time researching devices and integration options. We use these findings to argue for further development of tools that are transparent, easy to use, and aligned with the privacy needs of a diverse userbase.},
journal = {Proc. ACM Hum.-Comput. Interact.},
month = oct,
articleno = {247},
numpages = {34},
keywords = {IoT, internet of things, power users, privacy, security, smart homes, trust}
}

@article{10.1145/3610083,
author = {Zieglmeier, Valentin and Pretschner, Alexander},
title = {Rethinking People Analytics With Inverse Transparency by Design},
year = {2023},
issue_date = {October 2023},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {7},
number = {CSCW2},
url = {https://doi.org/10.1145/3610083},
doi = {10.1145/3610083},
abstract = {Employees work in increasingly digital environments that enable advanced analytics. Yet, they lack oversight over the systems that process their data. That means that potential analysis errors or hidden biases are hard to uncover. Recent data protection legislation tries to tackle these issues, but it is inadequate. It does not prevent data misusage while at the same time stifling sensible use cases for data.We think the conflict between data protection and increasingly data-driven systems should be solved differently. When access to an employees' data is given, all usages should be made transparent to them, according to the concept of inverse transparency. This allows individuals to benefit from sensible data usage while addressing the potentially harmful consequences of data misusage. To accomplish this, we propose a new design approach for workforce analytics software we refer to as inverse transparency by design.To understand the developer and user perspectives on the proposal, we conduct two exploratory studies with students. First, we let small teams of developers implement analytics tools with inverse transparency by design to uncover how they judge the approach and how it materializes in their developed tools. We find that architectural changes are made without inhibiting core functionality. The developers consider our approach valuable and technically feasible. Second, we conduct a user study over three months to let participants experience the provided inverse transparency and reflect on their experience. The study models a software development workplace where most work processes are already digital. Participants perceive the transparency as beneficial and feel empowered by it. They unanimously agree that it would be an improvement for the workplace. We conclude that inverse transparency by design is a promising approach to realize accepted and responsible people analytics.},
journal = {Proc. ACM Hum.-Comput. Interact.},
month = oct,
articleno = {292},
numpages = {29},
keywords = {HR analytics, data sovereignty, privacy by design, qualitative study}
}

@article{10.1145/3610048,
author = {Van Driel, Martine and Vines, John and Barros Pena, Bel\'{e}n and Koteyko, Nelya},
title = {Understanding Autistic Adults' Use of Social Media},
year = {2023},
issue_date = {October 2023},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {7},
number = {CSCW2},
url = {https://doi.org/10.1145/3610048},
doi = {10.1145/3610048},
abstract = {Autism is a developmental condition that impacts 1 in 100 people citeNationalAutisticSociety2021. It affects autistic people's interactional and sensory preferences and behaviours. Autistic people can find interactions difficult in part due to sensory overwhelm. Interacting online can provide a positive alternative that allows for interactions on their own terms. However, most social media platforms are designed by neurotypical standards and can therefore inhibit full participation by autistic users. We demonstrate through the analysis of 34 semi-structured interviews with autistic adults that current social media design is not sufficient for creating an inclusive environment and enabling participation from autistic adults. We identified six themes across the interviews: (1) 'Social Media compared to In-Person Interactions', (2) 'Social Media as Enabling/Overwhelming', (3) 'Perceived Social Norms', (4) 'Keeping Connected and Finding New Communities', (5) 'Keeping Control through Systematic Practices', and (6) 'Being Authentic'. The themes demonstrate the attention that autistic adults give to online interaction, suggesting that online interactions may be just as fraught as in-person interactions have been shown to be. In order to become more inclusive of autistic adults, we recommend that social media platforms expand low-effort participation features, provide increased control over algorithmic content, support expression of intent and tone, aid discovery of interactional norms, and reinforce interest-based sociality.},
journal = {Proc. ACM Hum.-Comput. Interact.},
month = oct,
articleno = {257},
numpages = {23},
keywords = {autism, inclusive design, interviews, participatory research, qualitative research}
}

@inproceedings{10.1145/3584371.3613006,
author = {Liu, Mengjing and Elbadry, Mohammed and Hua, Yindong and Xie, Zongxing and Ye, Fan},
title = {Proteus: Towards a Manageability-focused Home-based Health Monitoring Infrastructure},
year = {2023},
isbn = {9798400701269},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3584371.3613006},
doi = {10.1145/3584371.3613006},
abstract = {A data collection infrastructure is vital for generating sufficient amounts and diversity of data necessary for developing algorithms in home-based health monitoring. However, the manageability---deployment and operation efforts---of such an infrastructure has long been overlooked. Even a small size of a dozen homes may incur enormous manual efforts on the research team, including installing, configuring and updating of sensor, edge devices; continuous monitoring for faults and errors to prevent data losses, and integrating new sensing modalities. In this paper, we present Proteus, an easily managed infrastructure designed to automate much of the work in deploying and operating such systems. Proteus includes: i) scalable, continuous deployment and update of devices with automatic bootstrapping; ii) automatic fault and error monitoring and recovery with watchdogs and LED feedback, and complementary edge and cloud storage backups; and iii) an easy-to-use data-agnostic pipeline for integrating new modalities. We demonstrate our system's robustness through different sets of experiments: 3 sensor nodes running for 24 days sending data (17.3 Mbps aggregate rate), and 16 emulated sensors (92.8 Mbps aggregate rate). All such experiments have data loss rates less than 1\%. Further we reduce human efforts by 25-fold and code required for adding new data modality by 25-fold. Our results show that Proteus is a promising solution for enabling research teams to effectively manage home-based health monitoring at small to medium sizes.},
booktitle = {Proceedings of the 14th ACM International Conference on Bioinformatics, Computational Biology, and Health Informatics},
articleno = {49},
numpages = {6},
location = {Houston, TX, USA},
series = {BCB '23}
}

@inproceedings{10.1145/3584371.3613015,
author = {Nnamdi, Micky C. and Ben Tamo, Junior and Stackpole, Sara and Shi, Wenqi and Marteau, Benoit and Wang, May Dongmei},
title = {Model Confidence Calibration for Reliable COVID-19 Early Screening via Audio Signal Analysis},
year = {2023},
isbn = {9798400701269},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3584371.3613015},
doi = {10.1145/3584371.3613015},
abstract = {Advanced sensors in mobile devices have served as an effective screening tool for COVID-19 diagnosis, and an alternative to reverse transcription-polymerase chain reaction (rRT-PCR) tests, particularly in underdeveloped countries. In this study, we present a deep-learning approach to enable COVID-19 rapid diagnosis using cough signals. We then leverage spline calibration to enhance the reliability of predictions by calibrating model confidence. We conduct extensive experiments on the Coswara dataset to demonstrate the effectiveness of the proposed calibration approach in audio signal analysis. Our finding suggested that calibration could substantially enhance the reliability of COVID-19 early detection when compared to the uncalibrated model. Furthermore, our Spline calibration-based method outperformed other calibration methods, achieving an expected calibration error (ECE) of 0.148, an area under the receiver operating characteristic (AUROC) of 0.812, a Brier Loss of 0.189, and a logarithmic (Log) Loss of 0.584. The proposed confidence calibration framework on modern neural networks may enhance the reliability and trustworthiness of mobile healthcare for infectious respiratory disease screening in real-world applications.},
booktitle = {Proceedings of the 14th ACM International Conference on Bioinformatics, Computational Biology, and Health Informatics},
articleno = {39},
numpages = {6},
keywords = {confidence calibration, audio signal analysis, COVID-19},
location = {Houston, TX, USA},
series = {BCB '23}
}

@inproceedings{10.1145/3604571.3604578,
author = {Ng, Shi Hui and Soon, Lay-Ki and Su, Tin Tin},
title = {Emotion-Aware Chatbot with Cultural Adaptation for Mitigating Work-Related Stress},
year = {2023},
isbn = {9798400707612},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3604571.3604578},
doi = {10.1145/3604571.3604578},
abstract = {The accessibility to affordable and yet effective mental health support is limited due to various barriers. Given the proliferation of technology, chatbots for mental health support has been widely used. Being mindful of the users’ cultural background and the ability to respond with empathy are perceived as important factors that contribute to the usability and effective communication with chatbots. Nonetheless, cultural adaptation and emotional sensitivity in mental health chatbots are not thoroughly investigated. Hence, this work aims to design and implement an emotion-aware chatbot which incorporates cultural-adaptation that could provide effective Cognitive Behavioural Therapy (CBT) interventions to Malaysian community. The emotion detection model was developed using BERT and achieved an accuracy of 0.89. For cultural adaptation, besides localised contents, Google Cloud Translation API was used as the machine translation model between Malay to English. A user study was then carried out to assess the effectiveness of emotion sensitivity and cultural adaptation in CBT-based mental health support. The ablation study shows that CBT, cultural adaptation and emotional sensitivity have positive impact on the effectiveness and usability of mental health chatbots.},
booktitle = {Proceedings of the Asian HCI Symposium 2023},
pages = {41–50},
numpages = {10},
keywords = {Mental health intervention, chatbot, cultural adaptation, emotion detection},
location = {Online, Indonesia},
series = {Asian CHI '23}
}

@inproceedings{10.1145/3615453.3616513,
author = {Collaco, Oren Rodney and Tripathi, Asheesh and da Silva, Aloizio P.},
title = {Enabling AI/ML-based Incumbent Detection in a CBRS Experimental Network Through OpenSAS},
year = {2023},
isbn = {9798400703409},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3615453.3616513},
doi = {10.1145/3615453.3616513},
abstract = {Efficient spectrum management is crucial for the Citizen Broadband Radio Service (CBRS), promoting shared radio frequency spectrum use. The US Federal Communications Commission (FCC) designated the frequency range of 3550 MHz to 3700 MHz for three types of users: incumbent users, Priority Access License (PAL) users, and General Authorized Access (GAA) users. The Spectrum Access System (SAS) coordinates spectrum sharing among user tiers by using Environment Sensing Capabilities (ESC) sensors to detect incumbent users and prioritize their access while operating in uninformed incumbent detection mode. Machine Learning (ML) based techniques can be used for incumbent detection and enforce incumbent protection through SAS. Virginia Tech researchers have developed an open-source SAS for spectrum-sharing experimentation. In this work, we leverage the open-source SAS by enabling and testing Wireless Innovation Forum (WInnForum) standards (.i.e CBRS Base Station Device (CBSD) interface), implementing an ML-based incumbent radar detection mechanism using a feedforward neural network in an Software-defined Radio (SDR)-based experimental CBRS network deployed at CCI xG testbed and naming it "OpenSAS". If the presence of the incumbent is determined with at least a certainty of 85\%, the incumbent protection is triggered. In 500 trials, the model achieves 95.83\% validation accuracy in detecting the radar signal, and in Over the air (OTA) tests, it achieves 85.35\% accuracy.},
booktitle = {Proceedings of the 17th ACM Workshop on Wireless Network Testbeds, Experimental Evaluation \&amp; Characterization},
pages = {25–32},
numpages = {8},
keywords = {CBRS, ESC, GAA, Incumbent, PAL, SAS, Spectrum Sharing},
location = {Madrid, Spain},
series = {WiNTECH '23}
}

@inproceedings{10.1145/3570361.3613271,
author = {Zhang, Qingzhao and Zhang, Xumiao and Zhu, Ruiyang and Bai, Fan and Naserian, Mohammad and Mao, Z. Morley},
title = {Robust Real-time Multi-vehicle Collaboration on Asynchronous Sensors},
year = {2023},
isbn = {9781450399906},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3570361.3613271},
doi = {10.1145/3570361.3613271},
abstract = {Cooperative perception significantly enhances the perception performance of connected autonomous vehicles. Instead of purely relying on local sensors with limited range, it enables multiple vehicles and roadside infrastructures to share sensor data to perceive the environment collaboratively. Through our study, we realize that the performance of cooperative perception systems is limited in real-world deployment due to (1) out-of-sync sensor data during data fusion and (2) inaccurate localization of occluded areas. To address these challenges, we develop RAO, an innovative, effective, and lightweight cooperative perception system that merges asynchronous sensor data from different vehicles through our novel designs of motion-compensated occupancy flow prediction and on-demand data sharing, improving both the accuracy and coverage of the perception system. Our extensive evaluation, including real-world and emulation-based experiments, demonstrates that RAO outperforms state-of-the-art solutions by more than 34\% in perception coverage and by up to 14\% in perception accuracy, especially when asynchronous sensor data is present. RAO consistently performs well across a wide variety of map topologies and driving scenarios. RAO incurs negligible additional latency (8.5 ms) and low data transmission overhead (10.9 KB per frame), making cooperative perception feasible.},
booktitle = {Proceedings of the 29th Annual International Conference on Mobile Computing and Networking},
articleno = {57},
numpages = {15},
keywords = {cooperative perception, autonomous cars, vehicular networks, LiDAR},
location = {Madrid, Spain},
series = {ACM MobiCom '23}
}

@inproceedings{10.1145/3616131.3616139,
author = {Singh, Balbir and Gorbenko, Anatoliy and Palczewska, Anna and Tawfik, Hissam},
title = {Application of Machine Learning Techniques to Predict Teenage Obesity Using Earlier Childhood Measurements from Millennium Cohort Study},
year = {2023},
isbn = {9798400707339},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3616131.3616139},
doi = {10.1145/3616131.3616139},
abstract = {Obesity is a major global concern with more than 2.1 billion people overweight or obese worldwide, which amounts to almost 30\% of the global population. If the current trend continues, the overweight and obese population is likely to increase to 41\% by 2030. Individuals developing signs of weight gain or obesity are also at the risk of developing serious illnesses such as type 2 diabetes, respiratory problems, heart disease, stroke, and even death. It is essential to detect childhood obesity as early as possible since children who are either overweight or obese in their younger age tend to stay obese in their adult lives. This research utilises the vast amount of data available via UK's millennium cohort study to construct machine learning driven framework to predict young people at the risk of becoming overweight or obese. The focus of this paper is to develop a framework to predict childhood obesity using earlier childhood data and other relevant features. The use of novel data balancing technique and inclusion of additional relevant features resulted in sensitivity, specificity, and F1-score of 77.32\%, 76.81\%, and 77.02\% respectively. The proposed technique utilises easily obtainable features making it suitable to be used in a clinical and non-clinical environment.},
booktitle = {Proceedings of the 2023 7th International Conference on Cloud and Big Data Computing},
pages = {55–60},
numpages = {6},
keywords = {Body mass index, classification, machine learning, millennium cohort study, obesity},
location = {Manchester, United Kingdom},
series = {ICCBDC '23}
}

@inproceedings{10.1145/3570361.3592499,
author = {Li, Huining and Qian, Xiaoye and Ma, Ruokai and Xu, Chenhan and Li, Zhengxiong and Li, Dongmei and Lin, Feng and Huang, Ming-Chun and Xu, Wenyao},
title = {TherapyPal: Towards a Privacy-Preserving Companion Diagnostic Tool based on Digital Symptomatic Phenotyping},
year = {2023},
isbn = {9781450399906},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3570361.3592499},
doi = {10.1145/3570361.3592499},
abstract = {As the demand for precision medicine rapidly grows, companion diagnostics is proposed to monitor and evaluate therapeutic effects for adjusting medicine plans in time. Although a set of clinical companion diagnostics tools (e.g., polymerase chain reaction) have been investigated, they are expensive and only accessible in a lab environment, which hinders the promotion to broader patients. In light of this situation, we take the first steps towards developing a real-world companion diagnostic tool by leveraging mobile technology. In this paper, we present TherapyPal, a privacy-preserving medicine effectiveness computational framework by harnessing semantic hashing-based digital symptomatic phenotyping. Specifically, sensor data captured from daily-life activities is first transformed into spectrograms. Then, we develop a hashing learning network to extract privacy-masked symptomatic phenotypes on smartphones. Afterward, symptomatic hashes at different medicine states are fed to a contrastive learning network in the cloud for treatment effectiveness detection. To evaluate the performance, we conduct a clinical study among 65 Parkinson's disease (PD) patients under dopaminergic drug treatment. The results show that TherapyPal can achieve around 84.1\% medicine effectiveness detection accuracy among patients and above 0.925 privacy-masked scores for protecting each private attribute, which validates the reliability and security of TherapyPal to be used as a real-world companion diagnostics tool.},
booktitle = {Proceedings of the 29th Annual International Conference on Mobile Computing and Networking},
articleno = {34},
numpages = {15},
keywords = {mobile health, privacy-preserving, digital phenotyping},
location = {Madrid, Spain},
series = {ACM MobiCom '23}
}

@inproceedings{10.1145/3570361.3592515,
author = {Zhang, Xi and Zhang, Yu and Shi, Zhenguo and Gu, Tao},
title = {mmFER: Millimetre-wave Radar based Facial Expression Recognition for Multimedia IoT Applications},
year = {2023},
isbn = {9781450399906},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3570361.3592515},
doi = {10.1145/3570361.3592515},
abstract = {Facial expression recognition plays a vital role to enable emotional awareness in multimedia Internet of Things applications. Traditional camera or wearable sensor based approaches may compromise user privacy or cause discomfort. Recent device-free approaches open a promising direction by exploring Wi-Fi or ultrasound signals reflected from facial muscle movements, but limitations exist such as poor performance in presence of body motions and not being able to detect multiple targets. To bridge the gap, we propose mmFER, a novel millimeter wave (mmWave) radar based system that extracts facial muscle movements associated with mmWave signals to recognize facial expressions. We propose a novel dual-locating approach based on MIMO that explores spatial information from raw mmWave signals for face localization in space, eliminating ambient noise. In addition, collecting mmWave training data can be very costly in practice, and insufficient training dataset may lead to low accuracy. To overcome, we design a cross-domain transfer pipeline to enable effective and safe model knowledge transformation from image to mmWave. Extensive evaluations demonstrate that mmFER achieves an accuracy of 80.57\% on average within a detection range between 0.3m and 2.5m, and it is robust to various real-world settings.},
booktitle = {Proceedings of the 29th Annual International Conference on Mobile Computing and Networking},
articleno = {23},
numpages = {15},
keywords = {mmWave, facial expression recognition, deep learning},
location = {Madrid, Spain},
series = {ACM MobiCom '23}
}

@inproceedings{10.1145/3615984.3616505,
author = {Zhou, Fujia and Zhu, Guangxu and Li, Xiaoyang and Li, Hang and Shi, Qingjiang},
title = {Towards Pervasive Sensing: A multimodal approach via CSI and RGB image modalities fusion},
year = {2023},
isbn = {9798400703645},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3615984.3616505},
doi = {10.1145/3615984.3616505},
abstract = {Channel state information (CSI) and RGB (Red, Green, Blue) image are two fundamental modalities for accurate human activity recognition (HAR). CSI data is privacy preserving, independent of viewing angle and lighting, while RGB image data can provide useful information after processed by deep learning (DL) methods. However, both modalities have inherent disadvantages. CSI modality is with high environmental dependence, causing unstable fluctuations in wireless signals. RGB image modality is heavily restricted by camera facing angle and lighting condition. Hence, we propose a general multimodal fusion framework for HAR tasks based on both CSI and RGB image modalities. Distinct from other literatures on multimodal fusion mainly based on vision modalities, we utilized CSI modality from wireless domain along with RGB images to realize more comprehensive human activity sensing. Both early fusion and late fusion strategies are formulated and developed, with multiple models constructed from two modern unimodal frameworks to constitute corresponding fusion models. Experiments are conducted on a synchronous CSI and RGB image human activity dataset and validate the advantage of the proposed multimodal fusion design comparing with unimodal approaches.},
booktitle = {Proceedings of the 3rd ACM MobiCom Workshop on Integrated Sensing and Communications Systems},
pages = {25–30},
numpages = {6},
keywords = {CSI, RGB image, human activity recognition, multimodal fusion},
location = {Madrid, Spain},
series = {ISACom '23}
}

@inproceedings{10.1145/3606180.3606184,
author = {Zhao, Chunxiang},
title = {Application of Precise Mapping of Glacier Information Based on Intelligent GPS System},
year = {2023},
isbn = {9781450399609},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3606180.3606184},
doi = {10.1145/3606180.3606184},
abstract = {Glacier is the product of climate, which is highly sensitive to global climate change, and is the most rapid and significant response to environmental change and climate change. Therefore, in the context of global warming, the study of glacier change is of great significance to the global climate change, global warming and the sustainable development of human society. Different GPS monitoring is the main method for the study of glacier movement. GPS technology was proposed by European and American countries in the 1990s, and its application in industrial and agricultural production has been quite mature, and it has become an important information technology means in the world. It not only promotes industrial automation but also provides data processing functions. Based on the research of GPS positioning technology, this paper establishes a new type of precise geospatial measurement system. The system is built with visualization and data processing as the core content; it has the characteristics of automatic identification and three-dimensional coordinate transformation. It can realize the effective combination of traditional map and satellite remote sensing network, and this can complete elevation control and highly precise positioning. It can also display digital information in real time when the precision requirement is lower. The results of this paper are instructive for data processing using high-density based GPS dynamic single-point localization measurement methods for ice surface topographic measurements.},
booktitle = {Proceedings of the 2023 6th International Conference on Geoinformatics and Data Analysis},
pages = {19–23},
numpages = {5},
keywords = {GPS technology, Precise surveying and mapping, System design, glacier},
location = {Marseille, France},
series = {ICGDA '23}
}

@article{10.1145/3591867,
author = {Hutiri, Wiebke (Toussaint) and Ding, Aaron Yi and Kawsar, Fahim and Mathur, Akhil},
title = {Tiny, Always-on, and Fragile: Bias Propagation through Design Choices in On-device Machine Learning Workflows},
year = {2023},
issue_date = {November 2023},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {32},
number = {6},
issn = {1049-331X},
url = {https://doi.org/10.1145/3591867},
doi = {10.1145/3591867},
abstract = {Billions of distributed, heterogeneous, and resource constrained IoT devices deploy on-device machine learning (ML) for private, fast, and offline inference on personal data. On-device ML is highly context dependent and sensitive to user, usage, hardware, and environment attributes. This sensitivity and the propensity toward bias in ML makes it important to study bias in on-device settings. Our study is one of the first investigations of bias in this emerging domain and lays important foundations for building fairer on-device ML. We apply a software engineering lens, investigating the propagation of bias through design choices in on-device ML workflows. We first identify reliability bias as a source of unfairness and propose a measure to quantify it. We then conduct empirical experiments for a keyword spotting task to show how complex and interacting technical design choices amplify and propagate reliability bias. Our results validate that design choices made during model training, like the sample rate and input feature type, and choices made to optimize models, like light-weight architectures, the pruning learning rate, and pruning sparsity, can result in disparate predictive performance across male and female groups. Based on our findings, we suggest low effort strategies for engineers to mitigate bias in on-device ML.},
journal = {ACM Trans. Softw. Eng. Methodol.},
month = sep,
articleno = {155},
numpages = {37},
keywords = {Bias, on-device machine learning, embedded machine learning, design choices, fairness, audio keyword spotting, personal data}
}

@inproceedings{10.1145/3613330.3613345,
author = {Zhang, Fan and Tan, Xiao and Chen, Liyu and Li, Yang and Duan, Yu},
title = {Optimal control system for safety angle of human ankle joint during sports training},
year = {2023},
isbn = {9798400707520},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3613330.3613345},
doi = {10.1145/3613330.3613345},
abstract = {In order to solve the problems of traditional ankle joint safety angle control systems, such as poor stability of the PWM control unit and low accuracy of ankle joint angle control, this paper designs the human ankle joint's safety angle optimization control system. Firstly, the human ankle joint safety angle is determined by judging the changes in the physiological characteristics of the ankle joint during sports training. Secondly, the hardware part design of the new optimized control system is completed by designing a power supply module, sensor module, and serial communication module. Thirdly, the software part of the new optimized control system is designed through the main program design, performance functions design, and PWM control unit reinforcement design. Finally, by simulating the system operation environment, the design comparison experiment results show that the stability of the PWM control unit and the accuracy of ankle joint angle control are greatly improved after the optimized system compared with the traditional system.},
booktitle = {Proceedings of the 2023 7th International Conference on Deep Learning Technologies},
pages = {65–70},
numpages = {6},
keywords = {Sports training, ankle joint, exercise training, optimal control, performance function, physiological characteristic, safety angle, serial communication},
location = {Dalian, China},
series = {ICDLT '23}
}

@inproceedings{10.1145/3607947.3608064,
author = {Goel, Aarti and Kumar, Devender and Sharma, Deepak Kumar},
title = {Cryptanalysis of an Authentication Scheme for WSN within an IoT Environment},
year = {2023},
isbn = {9798400700224},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3607947.3608064},
doi = {10.1145/3607947.3608064},
abstract = {Across the world, intruders are constantly on the lookout to exploit security weaknesses which brings the risk of jeopardy to the data of companies, governments, monitoring, and healthcare organizations. With this arises the demand for the Internet of Things (IoT) to authenticate users using unique signatures generated by each device. In this paper, we investigate the RCBE-AS technique for wireless sensor networks (WSN) in an IoT scenario, as described by Singh et al. The model is discovered to be vulnerable to a wide range of attacks, including user tracing, smart card (SC) loss attacks, denial-of-service attacks, attacks on sensor nodes that are not anonymous, hostile and ineffective password changes, and a problem with perfect forward secrecy.},
booktitle = {Proceedings of the 2023 Fifteenth International Conference on Contemporary Computing},
pages = {587–590},
numpages = {4},
keywords = {Attacks., Authentication, Cryptography, IoT, Security, WSN},
location = {Noida, India},
series = {IC3-2023}
}

@inproceedings{10.1145/3607947.3608012,
author = {Jaiswal, Varshali and Suman, Preetam and Suman, Amrit and Padhy, Sasmita},
title = {Intelligent Hardware for Preventing Road Accidents Through the Use of Image Processing},
year = {2023},
isbn = {9798400700224},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3607947.3608012},
doi = {10.1145/3607947.3608012},
abstract = {Road transportation is the most common and oldest mode of transportation. It provides quick connectivity to small businesses having customers nearby areas, transportation of perceivable products in nearby markets. Not only the nearby market, also for international market supply transferring goods from the supply unit to the railway station, ports, or airports. Also, from day to day life commute from home to the office for a service class person, from home to schools/colleges for students, commuting to hospitals, banks, malls are done by road transportation only. It has an essential contribution to economic growth. Although road transportation is an essential and most common mode of connectivity, it has a higher probability of road crashes than any other transportation mode. These results a lot of injuries, deaths in every year and every city. Government has lot of road safety protocols, rules, and regulations to prevent road accidents. Every year government is spending a lot for road safety. Not only government car/vehicle manufacture keep on redesigning the vehicle with multiple inbuilt safety equipment’s. This paper is proposing a device with a key feature of lane detection. The device is featured with monitoring of engine, tires and other peripherals. The device can be mounted in vehicle, and can make an ordinary vehicle to semi-smart vehicle. This paper explains a feature of the device that is lane detection. An identification of tracks and obstruction on streets is not an easy task to detect with proximity sensors and an IR sensor. So that a digital image processing based lane detection technique had been implemented in this paper. This technique is very efficient to detect the road path and obstructions on the street on different scope of ecological conditions under which these frameworks work: rain, shadow, daylight, day, night, haze and so forth.},
booktitle = {Proceedings of the 2023 Fifteenth International Conference on Contemporary Computing},
pages = {313–321},
numpages = {9},
keywords = {Canny Edge Detector, Hough Transform, Lane detection},
location = {Noida, India},
series = {IC3-2023}
}

@inproceedings{10.1145/3607947.3607969,
author = {Apat, Hemant K and Alkhayyat, Ahmed and Vidyarthi, Ankit and Barik, Rabindra K},
title = {Leveraging Towards Serverless Edge Computing Model for Intelligent IoMT Applications},
year = {2023},
isbn = {9798400700224},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3607947.3607969},
doi = {10.1145/3607947.3607969},
abstract = {Internet of Medical Things(IoMT) devices connect billions of sensors consisting of a large volume of computation-intensive and time-sensitive tasks in the health sector. These tasks need to be processed or executed by different computational devices used in the network infrastructure for getting meaningful information. Due to the resource-constrained nature of IoMT devices, the devices mostly offload these tasks to various edge devices. The IoMT-Cloud paradigm provides different services storage, computation, and communication for the execution of various IoMT applications with elasticity and scalability on the pay-per-use model. Despite the wonderful benefits of cloud computing, there are various issues that remain unsolved like the response time of an IoMT application must satisfy hard deadlines, and Quality of Service(QoS) parameters. In order to improve the response time, and QoS, a decentralized distributed computing paradigm named Edge computing has emerged as a potential solution to provide computing and networking resources at the edge of the network for different IoT application domains. In this article, a serverless edge computing framework is proposed that provides various IoMT services to emerging healthcare applications. It also provides the mathematical derivations of the model along with its client IoMT applications layer, edge layer, and cloud layer.},
booktitle = {Proceedings of the 2023 Fifteenth International Conference on Contemporary Computing},
pages = {127–132},
numpages = {6},
keywords = {FaaS, Internet of Medical Things, QoS, cloud computing, edge computing, fog computing, serverless computing},
location = {Noida, India},
series = {IC3-2023}
}

@article{10.1145/3610897,
author = {Arabi, Abul Al and Wang, Xue and Zhang, Yang and Kim, Jeeeun},
title = {E3D: Harvesting Energy from Everyday Kinetic Interactions Using 3D Printed Attachment Mechanisms},
year = {2023},
issue_date = {September 2023},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {7},
number = {3},
url = {https://doi.org/10.1145/3610897},
doi = {10.1145/3610897},
abstract = {The increase of distributed embedded systems has enabled pervasive sensing, actuation, and information displays across buildings and surrounding environments, yet also entreats huge cost expenditure for energy and human labor for maintenance. Our daily interactions, from opening a window to closing a drawer to twisting a doorknob, are great potential sources of energy but are often neglected. Existing commercial devices to harvest energy from these ambient sources are unaffordable, and DIY solutions are left with inaccessibility for non-experts preventing fully imbuing daily innovations in end-users. We present E3D, an end-to-end fabrication toolkit to customize self-powered smart devices at low cost. We contribute to a taxonomy of everyday kinetic activities that are potential sources of energy, a library of parametric mechanisms to harvest energy from manual operations of kinetic objects, and a holistic design system for end-user developers to capture design requirements by demonstrations then customize augmentation devices to harvest energy that meets unique lifestyle.},
journal = {Proc. ACM Interact. Mob. Wearable Ubiquitous Technol.},
month = sep,
articleno = {84},
numpages = {31},
keywords = {energy harvesting}
}

@article{10.1145/3610904,
author = {Tabatabaie, Mahan and He, Suining and Shin, Kang G.},
title = {Cross-Modality Graph-based Language and Sensor Data Co-Learning of Human-Mobility Interaction},
year = {2023},
issue_date = {September 2023},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {7},
number = {3},
url = {https://doi.org/10.1145/3610904},
doi = {10.1145/3610904},
abstract = {Learning the human--mobility interaction (HMI) on interactive scenes (e.g., how a vehicle turns at an intersection in response to traffic lights and other oncoming vehicles) can enhance the safety, efficiency, and resilience of smart mobility systems (e.g., autonomous vehicles) and many other ubiquitous computing applications. Towards the ubiquitous and understandable HMI learning, this paper considers both "spoken language" (e.g., human textual annotations) and "unspoken language" (e.g., visual and sensor-based behavioral mobility information related to the HMI scenes) in terms of information modalities from the real-world HMI scenarios. We aim to extract the important but possibly implicit HMI concepts (as the named entities) from the textual annotations (provided by human annotators) through a novel human language and sensor data co-learning design.To this end, we propose CG-HMI, a novel Cross-modality Graph fusion approach for extracting important Human-Mobility Interaction concepts from co-learning of textual annotations as well as the visual and behavioral sensor data. In order to fuse both unspoken and spoken "languages", we have designed a unified representation called the human--mobility interaction graph (HMIG) for each modality related to the HMI scenes, i.e., textual annotations, visual video frames, and behavioral sensor time-series (e.g., from the on-board or smartphone inertial measurement units). The nodes of the HMIG in these modalities correspond to the textual words (tokenized for ease of processing) related to HMI concepts, the detected traffic participant/environment categories, and the vehicle maneuver behavior types determined from the behavioral sensor time-series. To extract the inter- and intra-modality semantic correspondences and interactions in the HMIG, we have designed a novel graph interaction fusion approach with differentiable pooling-based graph attention. The resulting graph embeddings are then processed to identify and retrieve the HMI concepts within the annotations, which can benefit the downstream human-computer interaction and ubiquitous computing applications. We have developed and implemented CG-HMI into a system prototype, and performed extensive studies upon three real-world HMI datasets (two on car driving and the third one on e-scooter riding). We have corroborated the excellent performance (on average 13.11\% higher accuracy than the other baselines in terms of precision, recall, and F1 measure) and effectiveness of CG-HMI in recognizing and extracting the important HMI concepts through cross-modality learning. Our CG-HMI studies also provide real-world implications (e.g., road safety and driving behaviors) about the interactions between the drivers and other traffic participants.},
journal = {Proc. ACM Interact. Mob. Wearable Ubiquitous Technol.},
month = sep,
articleno = {125},
numpages = {25},
keywords = {Human-mobility interaction, cross-modality graph interaction fusion, human-mobility interaction concept extraction, language and sensor data co-learning, named entity recognition}
}

@article{10.1145/3610916,
author = {Wang, Zhiyuan and Larrazabal, Maria A. and Rucker, Mark and Toner, Emma R. and Daniel, Katharine E. and Kumar, Shashwat and Boukhechba, Mehdi and Teachman, Bethany A. and Barnes, Laura E.},
title = {Detecting Social Contexts from Mobile Sensing Indicators in Virtual Interactions with Socially Anxious Individuals},
year = {2023},
issue_date = {September 2023},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {7},
number = {3},
url = {https://doi.org/10.1145/3610916},
doi = {10.1145/3610916},
abstract = {Mobile sensing is a ubiquitous and useful tool to make inferences about individuals' mental health based on physiology and behavior patterns. Along with sensing features directly associated with mental health, it can be valuable to detect different features of social contexts to learn about social interaction patterns over time and across different environments. This can provide insight into diverse communities' academic, work and social lives, and their social networks. We posit that passively detecting social contexts can be particularly useful for social anxiety research, as it may ultimately help identify changes in social anxiety status and patterns of social avoidance and withdrawal. To this end, we recruited a sample of highly socially anxious undergraduate students (N=46) to examine whether we could detect the presence of experimentally manipulated virtual social contexts via wristband sensors. Using a multitask machine learning pipeline, we leveraged passively sensed biobehavioral streams to detect contexts relevant to social anxiety, including (1) whether people were in a social situation, (2) size of the social group, (3) degree of social evaluation, and (4) phase of social situation (anticipating, actively experiencing, or had just participated in an experience). Results demonstrated the feasibility of detecting most virtual social contexts, with stronger predictive accuracy when detecting whether individuals were in a social situation or not and the phase of the situation, and weaker predictive accuracy when detecting the level of social evaluation. They also indicated that sensing streams are differentially important to prediction based on the context being predicted. Our findings also provide useful information regarding design elements relevant to passive context detection, including optimal sensing duration, the utility of different sensing modalities, and the need for personalization. We discuss implications of these findings for future work on context detection (e.g., just-in-time adaptive intervention development).},
journal = {Proc. ACM Interact. Mob. Wearable Ubiquitous Technol.},
month = sep,
articleno = {134},
numpages = {26},
keywords = {Machine Learning, Passive Sensing, Social Anxiety, Social Contexts}
}

@article{10.1145/3610932,
author = {Shende, Chinmaey and Sahoo, Soumyashree and Sam, Stephen and Patel, Parit and Morillo, Reynaldo and Wang, Xinyu and Ware, Shweta and Bi, Jinbo and Kamath, Jayesh and Russell, Alexander and Song, Dongjin and Wang, Bing},
title = {Predicting Symptom Improvement During Depression Treatment Using Sleep Sensory Data},
year = {2023},
issue_date = {September 2023},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {7},
number = {3},
url = {https://doi.org/10.1145/3610932},
doi = {10.1145/3610932},
abstract = {Depression is a serious mental illness. The current best guideline in depression treatment is closely monitoring patients and adjusting treatment as needed. Close monitoring of patients through physician-administered follow-ups or self-administered questionnaires, however, is difficult in clinical settings due to high cost, lack of trained professionals, and burden to the patients. Sensory data collected from mobile devices has been shown to provide a promising direction for long-term monitoring of depression symptoms. Most existing studies in this direction, however, focus on depression detection; the few studies that are on predicting changes in depression are not in clinical settings. In this paper, we investigate using one type of sensory data, sleep data, collected from wearables to predict improvement of depression symptoms over time after a patient initiates a new pharmacological treatment. We apply sleep trend filtering to noisy sleep sensory data to extract high-level sleep characteristics and develop a family of machine learning models that use simple sleep features (mean and variation of sleep duration) to predict symptom improvement. Our results show that using such simple sleep features can already lead to validation F1 score up to 0.68, indicating that using sensory data for predicting depression improvement during treatment is a promising direction.},
journal = {Proc. ACM Interact. Mob. Wearable Ubiquitous Technol.},
month = sep,
articleno = {121},
numpages = {21},
keywords = {Depression, Machine Learning, Mental Health, Sensory Data, Wearables}
}

@article{10.1145/3610892,
author = {Laporte, Matias and Gjoreski, Martin and Langheinrich, Marc},
title = {LAUREATE: A Dataset for Supporting Research in Affective Computing and Human Memory Augmentation},
year = {2023},
issue_date = {September 2023},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {7},
number = {3},
url = {https://doi.org/10.1145/3610892},
doi = {10.1145/3610892},
abstract = {The latest developments in wearable sensors have resulted in a wide range of devices available to consumers, allowing users to monitor and improve their physical activity, sleep patterns, cognitive load, and stress levels. However, the lack of out-of-the-lab labelled data hinders the development of advanced machine learning models for predicting affective states. Furthermore, to the best of our knowledge, there are no publicly available datasets in the area of Human Memory Augmentation. This paper presents a dataset we collected during a 13-week study in a university setting. The dataset, named LAUREATE, contains the physiological data of 42 students during 26 classes (including exams), daily self-reports asking the students about their lifestyle habits (e.g. studying hours, physical activity, and sleep quality) and their performance across multiple examinations. In addition to the raw data, we provide expert features from the physiological data, and baseline machine learning models for estimating self-reported affect, models for recognising classes vs breaks, and models for user identification. Besides the use cases presented in this paper, among which Human Memory Augmentation, the dataset represents a rich resource for the UbiComp community in various domains, including affect recognition, behaviour modelling, user privacy, and activity and context recognition.},
journal = {Proc. ACM Interact. Mob. Wearable Ubiquitous Technol.},
month = sep,
articleno = {106},
numpages = {41},
keywords = {affect, affective computing, datasets, human memory augmentation, learning, physiological signals, student performance}
}

@article{10.1145/3610913,
author = {Hu, Jiawei and Wang, Yanxiang and Jia, Hong and Hu, Wen and Hassan, Mahbub and Kusy, Brano and Uddin, Ashraf and Youssef, Moustafa},
title = {Iris: Passive Visible Light Positioning Using Light Spectral Information},
year = {2023},
issue_date = {September 2023},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {7},
number = {3},
url = {https://doi.org/10.1145/3610913},
doi = {10.1145/3610913},
abstract = {We propose a novel Visible Light Positioning (VLP) method, called Iris, that leverages light spectral information (LSI) to localize individuals in a completely passive manner. This means that the user does not need to carry any device, and the existing lighting infrastructure remains unchanged. Our method uses a background subtraction approach to accurately detect changes in ambient LSI caused by human movement. Furthermore, we design a Convolutional Neural Network (CNN) capable of learning and predicting user locations from the LSI change data.To validate our approach, we implemented a prototype of Iris using a commercial-off-the-shelf light spectral sensor and conducted experiments in two typical real-world indoor environments: a 25 m2 one-bedroom apartment and a 13.3m \texttimes{} 8.4m office space. Our results demonstrate that Iris performs effectively in both artificial lighting at night and in highly dynamic natural lighting conditions during the day. Moreover, Iris outperforms the state-of-the-art passive VLP techniques significantly in terms of localization accuracy and the required density of light sensors.To reduce the overhead associated with multi-channel spectral sensing, we develop and validate an algorithm that can minimize the required number of spectral channels for a given environment. Finally, we propose a conditional Generative Adversarial Network (cGAN) that can artificially generate LSI and reduce data collection effort by 50\% without sacrificing localization accuracy.},
journal = {Proc. ACM Interact. Mob. Wearable Ubiquitous Technol.},
month = sep,
articleno = {97},
numpages = {27},
keywords = {Ambient light, Light Spectral Information, Visible Light Positioning}
}

@article{10.1145/3610895,
author = {Mahmud, Saif and Li, Ke and Hu, Guilin and Chen, Hao and Jin, Richard and Zhang, Ruidong and Guimbreti\`{e}re, Fran\c{c}ois and Zhang, Cheng},
title = {PoseSonic: 3D Upper Body Pose Estimation Through Egocentric Acoustic Sensing on Smartglasses},
year = {2023},
issue_date = {September 2023},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {7},
number = {3},
url = {https://doi.org/10.1145/3610895},
doi = {10.1145/3610895},
abstract = {In this paper, we introduce PoseSonic, an intelligent acoustic sensing solution for smartglasses that estimates upper body poses. Our system only requires two pairs of microphones and speakers on the hinges of the eyeglasses to emit FMCW-encoded inaudible acoustic signals and receive reflected signals for body pose estimation. Using a customized deep learning model, PoseSonic estimates the 3D positions of 9 body joints including the shoulders, elbows, wrists, hips, and nose. We adopt a cross-modal supervision strategy to train our model using synchronized RGB video frames as ground truth. We conducted in-lab and semi-in-the-wild user studies with 22 participants to evaluate PoseSonic, and our user-independent model achieved a mean per joint position error of 6.17 cm in the lab setting and 14.12 cm in semi-in-the-wild setting when predicting the 9 body joint positions in 3D. Our further studies show that the performance was not significantly impacted by different surroundings or when the devices were remounted or by real-world environmental noise. Finally, we discuss the opportunities, challenges, and limitations of deploying PoseSonic in real-world applications.},
journal = {Proc. ACM Interact. Mob. Wearable Ubiquitous Technol.},
month = sep,
articleno = {111},
numpages = {28},
keywords = {Acoustic sensing, Cross-modal supervision, Deep learning, Human pose estimation, Smart/AR glasses}
}

@article{10.1145/3610881,
author = {Li, Jiyang and Huang, Lin and Shah, Siddharth and Jones, Sean J. and Jin, Yincheng and Wang, Dingran and Russell, Adam and Choi, Seokmin and Gao, Yang and Yuan, Junsong and Jin, Zhanpeng},
title = {SignRing: Continuous American Sign Language Recognition Using IMU Rings and Virtual IMU Data},
year = {2023},
issue_date = {September 2023},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {7},
number = {3},
url = {https://doi.org/10.1145/3610881},
doi = {10.1145/3610881},
abstract = {Sign language is a natural language widely used by Deaf and hard of hearing (DHH) individuals. Advanced wearables are developed to recognize sign language automatically. However, they are limited by the lack of labeled data, which leads to a small vocabulary and unsatisfactory performance even though laborious efforts are put into data collection. Here we propose SignRing, an IMU-based system that breaks through the traditional data augmentation method, makes use of online videos to generate the virtual IMU (v-IMU) data, and pushes the boundary of wearable-based systems by reaching the vocabulary size of 934 with sentences up to 16 glosses. The v-IMU data is generated by reconstructing 3D hand movements from two-view videos and calculating 3-axis acceleration data, by which we are able to achieve a word error rate (WER) of 6.3\% with a mix of half v-IMU and half IMU training data (2339 samples for each), and a WER of 14.7\% with 100\% v-IMU training data (6048 samples), compared with the baseline performance of the 8.3\% WER (trained with 2339 samples of IMU data). We have conducted comparisons between v-IMU and IMU data to demonstrate the reliability and generalizability of the v-IMU data. This interdisciplinary work covers various areas such as wearable sensor development, computer vision techniques, deep learning, and linguistics, which can provide valuable insights to researchers with similar research objectives.},
journal = {Proc. ACM Interact. Mob. Wearable Ubiquitous Technol.},
month = sep,
articleno = {107},
numpages = {29},
keywords = {Human computer interaction, computer vision, data augmentation, sign language recognition}
}

@article{10.1145/3610900,
author = {Yang, Xiaoying and Wang, Xue and Dong, Gaofeng and Yan, Zihan and Srivastava, Mani and Hayashi, Eiji and Zhang, Yang},
title = {Headar: Sensing Head Gestures for Confirmation Dialogs on Smartwatches with Wearable Millimeter-Wave Radar},
year = {2023},
issue_date = {September 2023},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {7},
number = {3},
url = {https://doi.org/10.1145/3610900},
doi = {10.1145/3610900},
abstract = {Nod and shake of one's head are intuitive and universal gestures in communication. As smartwatches become increasingly intelligent through advances in user activity sensing technologies, many use scenarios of smartwatches demand quick responses from users in confirmation dialogs, to accept or dismiss proposed actions. Such proposed actions include making emergency calls, taking service recommendations, and starting or stopping exercise timers. Head gestures in these scenarios could be preferable to touch interactions for being hands-free and easy to perform. We propose Headar to recognize these gestures on smartwatches using wearable millimeter wave sensing. We first surveyed head gestures to understand how they are performed in conversational settings. We then investigated positions and orientations to which users raise their smartwatches. Insights from these studies guided the implementation of Headar. Additionally, we conducted modeling and simulation to verify our sensing principle. We developed a real-time sensing and inference pipeline using contemporary deep learning techniques, and proved the feasibility of our proposed approach with a user study (n=15) and a live test (n=8). Our evaluation yielded an average accuracy of 84.0\% in the user study across 9 classes including nod and shake as well as seven other signals -- still, speech, touch interaction, and four non-gestural head motions (i.e., head up, left, right, and down). Furthermore, we obtained an accuracy of 72.6\% in the live test which reveals rich insights into the performance of our approach in various realistic conditions.},
journal = {Proc. ACM Interact. Mob. Wearable Ubiquitous Technol.},
month = sep,
articleno = {138},
numpages = {28},
keywords = {Gestural input, Head gestures, Millimeter-wave radar, Smartwatch, Wearable interaction}
}

@article{10.1145/3610885,
author = {Wang, Juexing and Wang, Guangjing and Zhang, Xiao and Liu, Li and Zeng, Huacheng and Xiao, Li and Cao, Zhichao and Gu, Lin and Li, Tianxing},
title = {PATCH: A Plug-in Framework of Non-blocking Inference for Distributed Multimodal System},
year = {2023},
issue_date = {September 2023},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {7},
number = {3},
url = {https://doi.org/10.1145/3610885},
doi = {10.1145/3610885},
abstract = {Recent advancements in deep learning have shown that multimodal inference can be particularly useful in tasks like autonomous driving, human health, and production line monitoring. However, deploying state-of-the-art multimodal models in distributed IoT systems poses unique challenges since the sensor data from low-cost edge devices can get corrupted, lost, or delayed before reaching the cloud. These problems are magnified in the presence of asymmetric data generation rates from different sensor modalities, wireless network dynamics, or unpredictable sensor behavior, leading to either increased latency or degradation in inference accuracy, which could affect the normal operation of the system with severe consequences like human injury or car accident. In this paper, we propose PATCH, a framework of speculative inference to adapt to these complex scenarios. PATCH serves as a plug-in module in the existing multimodal models, and it enables speculative inference of these off-the-shelf deep learning models. PATCH consists of 1) a Masked-AutoEncoder-based cross-modality imputation module to impute missing data using partially-available sensor data, 2) a lightweight feature pair ranking module that effectively limits the searching space for the optimal imputation configuration with low computation overhead, and 3) a data alignment module that aligns multimodal heterogeneous data streams without using accurate timestamp or external synchronization mechanisms. We implement PATCH in nine popular multimodal models using five public datasets and one self-collected dataset. The experimental results show that PATCH achieves up to 13\% mean accuracy improvement over the state-of-art method while only using 10\% of training data and reducing the training overhead by 73\% compared to the original cost of retraining the model.},
journal = {Proc. ACM Interact. Mob. Wearable Ubiquitous Technol.},
month = sep,
articleno = {130},
numpages = {24},
keywords = {Multi-task Learning, Multimodal Learning, Neural Networks, Non-blocking Inference}
}

@article{10.1145/3610920,
author = {Kim, Jiha and Nam, Younho and Lee, Jungeun and Suh, Young-Joo and Hwang, Inseok},
title = {ProxiFit: Proximity Magnetic Sensing Using a Single Commodity Mobile toward Holistic Weight Exercise Monitoring},
year = {2023},
issue_date = {September 2023},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {7},
number = {3},
url = {https://doi.org/10.1145/3610920},
doi = {10.1145/3610920},
abstract = {Although many works bring exercise monitoring to smartphone and smartwatch, inertial sensors used in such systems require device to be in motion to detect exercises. We introduce ProxiFit, a highly practical on-device exercise monitoring system capable of classifying and counting exercises even if the device stays still. Utilizing novel proximity sensing of natural magnetism in exercise equipment, ProxiFit brings (1) a new category of exercise not involving device motion such as lower-body machine exercise, and (2) a new off-body exercise monitoring mode where a smartphone can be conveniently viewed in front of the user during workouts. ProxiFit addresses common issues of faint magnetic sensing by choosing appropriate preprocessing, negating adversarial motion artifacts, and designing a lightweight yet noise-tolerant classifier. Also, application-specific challenges such as a wide variety of equipment and the impracticality of obtaining large datasets are overcome by devising a unique yet challenging training policy. We evaluate ProxiFit on up to 10 weight machines (5 lower- and 5 upper-body) and 4 free-weight exercises, on both wearable and signage mode, with 19 users, at 3 gyms, over 14 months, and verify robustness against user and weather variations, spatial and rotational device location deviations, and neighboring machine interference.},
journal = {Proc. ACM Interact. Mob. Wearable Ubiquitous Technol.},
month = sep,
articleno = {105},
numpages = {32},
keywords = {exercise monitoring, magnetic sensing, proximity sensing, wearable}
}

@inproceedings{10.1145/3609987.3610002,
author = {Kounalaki, Maria and Simou, Ioulia and Komninos, Andreas},
title = {Pseudo-haptic and Self-haptic Feedback During VR Text Entry},
year = {2023},
isbn = {9798400708886},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3609987.3610002},
doi = {10.1145/3609987.3610002},
abstract = {The use of virtual reality (VR) equipment is becoming increasingly common in people’s daily lives concerning a variety of applications and utilities. Text entry in the VR environment has always been a challenge and a main subject of research in HCI, especially when it comes to human-centered and user-friendly interfaces and implementations. To assist occasional text entry on small VR keyboards without specialised sensing equipment or external devices, we compare a single-finger method relying on pseudo-haptic feedback, and a novel bimanual approach that exploits the self-haptic feedback method. In a user study (n=24), we find that both methods have comparable performance but also distinct advantages and disadvantages, demonstrating good learnability and promising prospects for further refinement.},
booktitle = {Proceedings of the 2nd International Conference of the ACM Greek SIGCHI Chapter},
articleno = {15},
numpages = {8},
keywords = {datasets, gaze detection, neural networks, text tagging},
location = {Athens, Greece},
series = {CHIGREECE '23}
}

@inproceedings{10.1145/3613372.3613378,
author = {Dalcin, Guilherme and Bolzan, Willian and Lazzari, Luan and Farias, Kleinner},
title = {Recommendation of UML Model Conflicts: Unveiling the Biometric Lens for Conflict Resolution},
year = {2023},
isbn = {9798400707872},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3613372.3613378},
doi = {10.1145/3613372.3613378},
abstract = {Model merging assumes a pivotal role in numerous model-centric software development tasks, e.g., evolving UML models to add new features or even reconciling UML models developed collaboratively by distributed development teams. Usually, UML model elements to-be-merged conflict with each other. Unfortunately, resolving conflicts remains a highly cognitive and error-prone task. Today, wearable devices capable of capturing biometric data are a reality. Recent studies indicate that the developer’s cognitive indicators may affect developers while performing development tasks. However, the current literature has neglected the recommendation of conflicts sensitive to the cognitive activities of software developers. This study, therefore, introduces BACR, a biometric-aware approach to recommend UML model conflicts using machine learning. BACR helps UML model merging to push a step forward, recommending model conflicts based on appropriate biometric indicators and using a behavior sequence transformer model. Our approach is based on four scientific institutions. It represents the first effort in supporting the prioritization of cognitively relevant UML model conflicts by developers, mitigating the risk of making incorrect decisions and preventing potential downstream issues.},
booktitle = {Proceedings of the XXXVII Brazilian Symposium on Software Engineering},
pages = {83–88},
numpages = {6},
keywords = {Biometrics, Cognitive Load, Model Merging, Software Modeling},
location = {Campo Grande, Brazil},
series = {SBES '23}
}

@inproceedings{10.1145/3613372.3613387,
author = {Segalotto, Matheus and Bolzan, Willian and Farias, Kleinner},
title = {Effects of Modularization on Developers' Cognitive Effort in Code Comprehension Tasks: A Controlled Experiment},
year = {2023},
isbn = {9798400707872},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3613372.3613387},
doi = {10.1145/3613372.3613387},
abstract = {Developers invest the cognitive effort to comprehend instructions in source code. Cognitive effort refers to the cognitive processing of a human being’s brain required to complete a cognitive task. The cognitive effort invested by developers can vary depending on the complexity of how instructions in source code are structured. To implement features, developers can write all instructions in a single method (non-modular) or even modularize it into several methods (modular). However, little is known about the effects of modularizing instructions in source code on the developers’ cognitive effort. Hence, adopting modularization practices ends up being a cognitive effort-insensitive task. This paper, therefore, reports on a controlled experiment that investigates the effects of modularization on the cognitive effort of developers while comprehending instructions in (non-)modular code. We evaluated the modularization of instructions with the participation of 35 developers who performed 10 comprehension tasks using a wearable EEG device. The main results suggest that developers tend to invest less cognitive effort to understand instructions in modular code rather than in non-modular code. However, developers spend more temporal effort to understand instructions in modular code, and this extra time is not converted into a higher rate of correct code comprehension. Our findings shed light on improving the state of the art of modularization practices by making them sensitive to the developers’cognitive effort.},
booktitle = {Proceedings of the XXXVII Brazilian Symposium on Software Engineering},
pages = {206–215},
numpages = {10},
keywords = {Code Comprehension, Cognitive Effort, EEG, Modularization},
location = {Campo Grande, Brazil},
series = {SBES '23}
}

@article{10.1145/3615450,
author = {Wang, Jingxian and Zhang, Junbo and Li, Ke and Pan, Chengfeng and Majidi, Carmel and Kumar, Swarun},
title = {Locating Everyday Objects Using NFC Textiles},
year = {2023},
issue_date = {October 2023},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {66},
number = {10},
issn = {0001-0782},
url = {https://doi.org/10.1145/3615450},
doi = {10.1145/3615450},
abstract = {This paper builds a Near-Field Communication (NFC) based localization system that allows ordinary surfaces to locate surrounding objects with high accuracy in the near-field. While there is rich prior work on device-free localization using far-field wireless technologies, the near-field is less explored. Prior work in this space operates at extremely small ranges (a few centimeters), leading to designs that sense close proximity rather than location. We propose TextileSense, a near-field beamforming system that can track everyday objects made of conductive materials (for example, a human hand) even if they are a few tens of centimeters away. We use multiple flexible NFC coil antennas embedded in ordinary and irregularly shaped surfaces we interact with in smart environments---furniture, carpets, and so forth. We design and fabricate specialized textile coils woven into the fabric of the furniture and easily hidden by acrylic paint. We then develop a near-field blind beam-forming algorithm to efficiently detect surrounding objects, and use a data-driven approach to further infer their location. A detailed experimental evaluation of TextileSense shows an average accuracy of 3.5 cm in tracking the location of objects of interest within a few tens of centimeters from the furniture.},
journal = {Commun. ACM},
month = sep,
pages = {107–114},
numpages = {8}
}

