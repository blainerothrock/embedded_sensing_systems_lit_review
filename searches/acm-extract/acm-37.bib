@inproceedings{10.1145/3495243.3567652,
author = {Dang, Tuan and Tran, Trung and Nguyen, Khang and Pham, Tien and Pham, Nhat and Vu, Tam and Nguyen, Phuc},
title = {IoTree: a battery-free wearable system with biocompatible sensors for continuous tree health monitoring},
year = {2022},
isbn = {9781450391818},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3495243.3567652},
doi = {10.1145/3495243.3567652},
abstract = {In this paper, we present a low-maintenance, wind-powered, battery-free, biocompatible, tree wearable, and intelligent sensing system, namely IoTree, to monitor water and nutrient levels inside a living tree. IoTree system includes tiny-size, biocompatible, and implantable sensors that continuously measure the impedance variations inside the living tree's xylem, where water and nutrients are transported from the root to the upper parts. The collected data are then compressed and transmitted to a base station located at up to 1.8 kilometers (approximately 1.1 miles) away. The entire IoTree system is powered by wind energy and controlled by an adaptive computing technique called block-based intermittent computing, ensuring the forward progress and data consistency under intermittent power and allowing the firmware to execute with the most optimal memory and energy usage. We prototype IoTree that opportunistically performs sensing, data compression, and long-range communication tasks without batteries. During in-lab experiments, IoTree also obtains the accuracy of 91.08\% and 90.51\% in measuring 10 levels of nutrients, NH3 and K2O, respectively. While tested with Burkwood Viburnum and White Bird trees in the indoor environment, IoTree data strongly correlated with multiple watering and fertilizing events. We also deployed IoTree on a grapevine farm for 30 days, and the system is able to provide sufficient measurements every day.},
booktitle = {Proceedings of the 28th Annual International Conference on Mobile Computing And Networking},
pages = {352–366},
numpages = {15},
location = {Sydney, NSW, Australia},
series = {MobiCom '22}
}

@inproceedings{10.1145/3548608.3559295,
author = {Qu, Fukang and Huang, Rui and Lu, Haoxian},
title = {Design of an Intelligent Handling Robot},
year = {2022},
isbn = {9781450397179},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3548608.3559295},
doi = {10.1145/3548608.3559295},
abstract = {Traditional industrial robots can only repeat the planned path mechanically because they don't have the ability to obtain external information, so they can't complete the task well when the environment is unknown or the precise model of the workpiece can't be known. In this paper, a new type of intelligent handling robot is designed, and its structural design part is introduced in detail. In the control system part, JETSON NANO is the main controller, which integrates various sensors such as binocular camera, gyroscope and accelerometer, and is coupled with the software and hardware of micro deep learning computer to realize the system integration of control, image transmission and machine vision. The test results show that the system can complete the transportation work well.},
booktitle = {Proceedings of the 2022 2nd International Conference on Control and Intelligent Robotics},
pages = {724–728},
numpages = {5},
location = {Nanjing, China},
series = {ICCIR '22}
}

@inproceedings{10.1145/3495243.3560532,
author = {Li, Liyao and Xie, Yaxiong and Xiong, Jie and Hou, Ziyu and Zhang, Yingchun and We, Qing and Wang, Fuwei and Fang, Dingyi and Chen, Xiaojiang},
title = {SmartLens: sensing eye activities using zero-power contact lens},
year = {2022},
isbn = {9781450391818},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3495243.3560532},
doi = {10.1145/3495243.3560532},
abstract = {As the most important organs of sense, human eyes perceive 80\% information from our surroundings. Eyeball movement is closely related to our brain health condition. Eyeball movement and eye blink are also widely used as an efficient human-computer interaction scheme for paralyzed individuals to communicate with others. Traditional methods mainly use intrusive EOG sensors or cameras to capture eye activity information. In this work, we propose a system named SmartLens to achieve eye activity sensing using zero-power contact lens. To make it happen, we develop dedicated antenna design which can be fitted in an extremely small space and still work efficiently to reach a working distance more than 1 m. To accurately track eye movements in the presence of strong self-interference, we employ another tag to track the user's head movement and cancel it out to support sensing a walking or moving user. Comprehensive experiments demonstrate the effectiveness of the proposed system. At a distance of 1.4 m, the proposed system can achieve an average accuracy of detecting the basic eye movement and blink at 89.63\% and 82\%, respectively.},
booktitle = {Proceedings of the 28th Annual International Conference on Mobile Computing And Networking},
pages = {473–486},
numpages = {14},
keywords = {IOT, backscatter, battery-free, contact lens, eye movement sensing, low cost, wireless},
location = {Sydney, NSW, Australia},
series = {MobiCom '22}
}

@inproceedings{10.1145/3548608.3559189,
author = {Zhou, Yuan and Dong, Liangxiong},
title = {Time-consuming Calculation and Simulation of Unmanned Surface Vessel (USV) Steering Based on Dynamic Window Approach (DWA)},
year = {2022},
isbn = {9781450397179},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3548608.3559189},
doi = {10.1145/3548608.3559189},
abstract = {The conventional dynamic window approach (DWA) model lacks the time planning capability when simulating the steering process of an unmanned surface vessel (USV). In this paper, we propose a steering time-consuming calculation based on the DWA method in an actual context. In this study, the channel environment model established by the MATLAB software is examined, and the DWM model is modified to calculate the time-consuming steering process of an underwater vessel. Simulations with different steering angles are conducted to verify the applicability and effectiveness of the model in solving this problem of underwater vessel steering in an actual environment. A set of parameters such as heading deviation weight, safety distance weight, sailing speed weight, and simulated trajectory time are selected, and the optimized parameters are screened out according to their sensitivity to the results. The research results show that our proposed method can improve the USV planning ability and enhance the effectiveness of handling related path planning problems.},
booktitle = {Proceedings of the 2022 2nd International Conference on Control and Intelligent Robotics},
pages = {181–185},
numpages = {5},
location = {Nanjing, China},
series = {ICCIR '22}
}

@inproceedings{10.1145/3548608.3561131,
author = {Jing, Daiyuan},
title = {Design and Implementation of a Batteryless Pedometer based on a Motion Tracking Sensor},
year = {2022},
isbn = {9781450397179},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3548608.3561131},
doi = {10.1145/3548608.3561131},
abstract = {This paper proposes a batteryless pedometer device. It is a wearable device which can sufficiently collect motional energy during human movements and convert it into electrical energy to power the pedometer. To achieve functions mentioned above, this paper first introduces a low-cost implementation scheme for the pedometer, including sensor, microprocessor, and a wireless communication protocol. Secondly, the paper gives a scheme about motion energy capture and power supply, including a swing energy capture device that match the motion characteristic and an efficient power management unit. Lastly, a prototype of the pedometer device and its corresponding user interface are established to verify the feasibility of above sections from the perspective of functional realization.},
booktitle = {Proceedings of the 2022 2nd International Conference on Control and Intelligent Robotics},
pages = {19–22},
numpages = {4},
location = {Nanjing, China},
series = {ICCIR '22}
}

@inproceedings{10.1145/3545729.3545784,
author = {Lee, Tian-Fu and Huang, Wei-Jie},
title = {Security Analysis of Authentication and Key Agreement for Internet of Drones},
year = {2022},
isbn = {9781450396301},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3545729.3545784},
doi = {10.1145/3545729.3545784},
abstract = {Drones in the Internet of Drones (IoD) have been widely used in various fields, such as military reconnaissance, climate and environmental detection, logistics and transportation, and disaster relief and so on. There are many challenges related to security, privacy and energy consumption when collecting and transferring data between sensors embedded in drones. Recently, Zhang et al. developed a lightweight authentication and key agreement scheme for IoD to address these issues. Their developed scheme realized mutual authentication and key agreement of drones and users by adopting lightweight hash and bitwise XOR operations. The authors demonstrate that their proposed scheme provides better security requirements and more efficient than related schemes. However, this study shows the limitations of Zhang et al.'s scheme, which leads to their scheme may be subject to some potential attacks and cannot satisfy the session key security and untraceability properties.},
booktitle = {Proceedings of the 6th International Conference on Medical and Health Informatics},
pages = {271–275},
numpages = {5},
keywords = {Internet of Drones, authentication and key agreement, network security},
location = {Virtual Event, Japan},
series = {ICMHI '22}
}

@inproceedings{10.1145/3545729.3545759,
author = {Moesgen, Tim and Salovaara, Antti and Pouta, Emmi and Pyykko, Rebecka and Xiao, Yu},
title = {Vibrotactile Motion Guidance for Stroke Rehabilitation: A Comparative Study},
year = {2022},
isbn = {9781450396301},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3545729.3545759},
doi = {10.1145/3545729.3545759},
abstract = {Stroke is one of the most common causes of death globally and a reason for severe impairments. Many stroke survivors report a loss of muscle strength and, thus, need to regain motor control of their upper limbs with rehabilitation. In some cases, patients may compensate for muscle weakness with harmful compensatory movements using other muscles. We envision that VR-based training can provide multimodal feedback during sensorimotor training to avoid compensatory movements. However, feedback may be hampered by changes in patients’ somatosensory system, resulting in both weakened and intensified tactile perceptions. We explored the differences in perception of vibration metaphors for motion guidance between healthy participants and stroke patients and assessed the efficiency of multimodal feedback for the correction of arm trajectory. Multimodal stimuli for trajectory correction benefited the patients but there were also differences in their tactile perception. These patient-specific findings call for the involvement of patients in the design process of haptic rehabilitation devices, following the recommendations of patient-centric healthcare.},
booktitle = {Proceedings of the 6th International Conference on Medical and Health Informatics},
pages = {147–152},
numpages = {6},
keywords = {motion guidance, rehabilitation, stroke, vibrotactile feedback},
location = {Virtual Event, Japan},
series = {ICMHI '22}
}

@inproceedings{10.1145/3503161.3548386,
author = {Zhao, Yiqin and Wei, Sheng and Guo, Tian},
title = {Privacy-preserving Reflection Rendering for Augmented Reality},
year = {2022},
isbn = {9781450392037},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3503161.3548386},
doi = {10.1145/3503161.3548386},
abstract = {When the virtual objects consist of reflective materials, the required lighting information to render such objects can consist of privacy-sensitive information outside the current camera view. In this paper, we show, for the first time, that accuracy-driven multi-view environment lighting can reveal out-of-camera scene information and compromise privacy. We present a simple yet effective privacy attack that extracts sensitive scene information such as human faces and text from rendered objects under several application scenarios.To defend against such attacks, we develop a novel IPC2S defense and a conditional R2 defense. Our IPC2S defense, combined with a generic lighting reconstruction method, preserves the scene geometry while obfuscating the privacy-sensitive information. As a proof-of-concept, we leverage existing OCR and face detection models to identify text and human faces from past camera observations and blur the color pixels associated with detected regions. We evaluate the visual quality impact of our defense by comparing rendered virtual objects to ones rendered with a generic multi-lighting reconstruction technique, ARKit, and R2 defense. Our visual and quantitative results demonstrate that our defense leads to structurally similar reflections with up to 0.98 SSIM score across various rendering scenarios while preserving sensitive information by reducing the automatic extraction success rate to at most 8.8\%.},
booktitle = {Proceedings of the 30th ACM International Conference on Multimedia},
pages = {2909–2918},
numpages = {10},
keywords = {augmented reality, photorealistic rendering, visual privacy},
location = {Lisboa, Portugal},
series = {MM '22}
}

@inproceedings{10.1145/3503161.3548238,
author = {Ni, Jianyuan and Ngu, Anne H.H. and Yan, Yan},
title = {Progressive Cross-modal Knowledge Distillation for Human Action Recognition},
year = {2022},
isbn = {9781450392037},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3503161.3548238},
doi = {10.1145/3503161.3548238},
abstract = {Wearable sensor-based Human Action Recognition (HAR) has achieved remarkable success recently. However, the accuracy performance of wearable sensor-based HAR is still far behind the ones from the visual modalities-based system (i.e., RGB video, skeleton and depth). Diverse input modalities can provide complementary cues and thus improve the accuracy performance of HAR, but how to take advantage of multi-modal data on wearable sensor-based HAR has rarely been explored. Currently, wearable devices, i.e., smartwatches, can only capture limited kinds of non-visual modality data. This hinders the multi-modal HAR association as it is unable to simultaneously use both visual and non-visual modality data. Another major challenge lies in how to efficiently utilize multi-modal data on wearable devices with their limited computation resources. In this work, we propose a novel Progressive Skeleton-to-sensor Knowledge Distillation (PSKD) model which utilizes only time-series data, i.e., accelerometer data, from a smartwatch for solving the wearable sensor-based HAR problem. Specifically, we construct multiple teacher models using data from both teacher (human skeleton sequence) and student (time-series accelerometer data) modalities. In addition, we propose an effective progressive learning scheme to eliminate the performance gap between teacher and student models. We also designed a novel loss function called Adaptive-Confidence Semantic (ACS), to allow the student model to adaptively select either one of the teacher models or the ground-truth label it needs to mimic. To demonstrate the effectiveness of our proposed PSKD method, we conduct extensive experiments on Berkeley-MHAD, UTD-MHAD and MMAct datasets. The results confirm that the proposed PSKD method has competitive performance compared to the previous mono sensor-based HAR methods.},
booktitle = {Proceedings of the 30th ACM International Conference on Multimedia},
pages = {5903–5912},
numpages = {10},
keywords = {knowledge distillation, machine learning, progressive learning, sensor-based human activity recognition},
location = {Lisboa, Portugal},
series = {MM '22}
}

@inproceedings{10.1145/3503161.3551598,
author = {Sharma, Gulshan and Dhall, Abhinav and Subramanian, Ramanathan},
title = {A Transformer Based Approach for Activity Detection},
year = {2022},
isbn = {9781450392037},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3503161.3551598},
doi = {10.1145/3503161.3551598},
abstract = {Non-invasive physiological sensors allow for the collection of user-specific data in realistic environments. In this paper, using physiological data, we investigate the effectiveness of Convolutional Neural Network (CNN) based feature embeddings and Transformer architecture for the human activity recognition task. 1D-CNN representation is used for the heart rate, and 2D-CNN is used for short-term Fourier transformation of the accelerometer data. Post fusion, the feature is input into a transformer. The experiments are performed on the harAGE dataset. The findings indicate the discriminative ability of the feature-fusion on transformer-based architecture, and the method outperforms the harAGE baseline by an absolute 3.7\%.},
booktitle = {Proceedings of the 30th ACM International Conference on Multimedia},
pages = {7155–7159},
numpages = {5},
keywords = {cnn, human activity recognition, transformers},
location = {Lisboa, Portugal},
series = {MM '22}
}

@inproceedings{10.1145/3546155.3546659,
author = {Ros\'{e}n, Anton Poikolainen and Normark, Maria and Wiberg, Mikael},
title = {Noticing the Environment – A Design Ethnography of Urban Farming},
year = {2022},
isbn = {9781450396998},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3546155.3546659},
doi = {10.1145/3546155.3546659},
abstract = {Sustainable HCI attempts to shift focus beyond humans, to care for both ourselves and our environment. In this paper, we build on this growing interest and contribute with a design ethnography of urban farming. We focus on practices of observing and gathering data about the environment which we frame as ‘noticing’. In our analysis, three approaches to noticing the environment were identified, and design suggestions were developed for each approach: Green Thumbs (control-oriented), Dirty Nails (sensibility-oriented) and BeeNoculars (appreciation-oriented). The design suggestions, presented as posters, focus on ways to improve the alignment of the acquisition and display of data with the identified approaches. We discuss two themes: the noticing and balancing of systemic relations and needs, and sensory-rich experiences of the environment. The paper contributes to a broader discussion in HCI of how technologies could create a different understanding of and relationship to the environment.},
booktitle = {Nordic Human-Computer Interaction Conference},
articleno = {34},
numpages = {13},
keywords = {Environmental Sensing, Ethnography, Noticing, Urban farming},
location = {Aarhus, Denmark},
series = {NordiCHI '22}
}

@inproceedings{10.1145/3549555.3549573,
author = {Carrara, Fabio and Pasco, Lorenzo and Gennaro, Claudio and Falchi, Fabrizio},
title = {Learning to Detect Fallen People in Virtual Worlds},
year = {2022},
isbn = {9781450397209},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3549555.3549573},
doi = {10.1145/3549555.3549573},
abstract = {Falling is one of the most common causes of injury in all ages, especially in the elderly, where it is more frequent and severe. For this reason, a tool that can detect a fall in real time can be helpful in ensuring appropriate intervention and avoiding more serious damage. Some approaches available in the literature use sensors, wearable devices, or cameras with special features such as thermal or depth sensors. In this paper, we propose a Computer Vision deep-learning based approach for human fall detection based on largely available standard RGB cameras. A typical limitation of this kind of approaches is the lack of generalization to unseen environments. This is due to the error generated during human detection and, more generally, due to the unavailability of large-scale datasets that specialize in fall detection problems with different environments and fall types. In this work, we mitigate these limitations with a general-purpose object detector trained using a virtual world dataset in addition to real-world images. Through extensive experimental evaluation, we verified that by training our models on synthetic images as well, we were able to improve their ability to generalize. Code to reproduce results is available at https://github.com/lorepas/fallen-people-detection.},
booktitle = {Proceedings of the 19th International Conference on Content-Based Multimedia Indexing},
pages = {126–130},
numpages = {5},
keywords = {object detection, scarce data, virtual worlds for synthetic data, visual fallen people detection},
location = {Graz, Austria},
series = {CBMI '22}
}

@inproceedings{10.1145/3549555.3549574,
author = {Pegia, Maria Eirini and Moumtzidou, Anastasia and Gialampoukidis, Ilias and J\'{o}nsson, Bj\"{o}rn \TH{}\'{o}r and Vrochidis, Stefanos and Kompatsiaris, Ioannis},
title = {BiasUNet: Learning Change Detection over Sentinel-2 Image Pairs},
year = {2022},
isbn = {9781450397209},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3549555.3549574},
doi = {10.1145/3549555.3549574},
abstract = {The availability of satellite images has increased due to the fast development of remote sensing technology. As a result several deep learning change detection methods have been developed to capture spatial changes from multi temporal satellite images that are of great importance in remote sensing, monitoring environmental changes and land use. Recently, a supervised deep learning network called FresUNet has been proposed, which performs a pixel-level change detection from image pairs. In this paper, we extend this method by inserting a Bayesian framework that uses Monte Carlo Dropout, motivated by a recent work in image segmentation. The proposed Bayesian FresUNet (BiasUNet) approach is shown to outperform four state-of-the-art deep learning networks on Sentinel-2 ONERA Satellite Change Detection (OSCD) benchmark dataset, both in terms of precision and quality.},
booktitle = {Proceedings of the 19th International Conference on Content-Based Multimedia Indexing},
pages = {142–148},
numpages = {7},
keywords = {Change Detection, Deep Learning, Sentinel-2, Supervised Learning},
location = {Graz, Austria},
series = {CBMI '22}
}

@article{10.1145/3531228,
author = {Wu, Xian and Huang, Chao and Robles-Granda, Pablo and Chawla, Nitesh V.},
title = {Representation Learning on Variable Length and Incomplete Wearable-Sensory Time Series},
year = {2022},
issue_date = {December 2022},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {13},
number = {6},
issn = {2157-6904},
url = {https://doi.org/10.1145/3531228},
doi = {10.1145/3531228},
abstract = {The prevalence of wearable sensors (e.g., smart wristband) is creating unprecedented opportunities to not only inform health and wellness states of individuals, but also assess and infer personal attributes, including demographic and personality attributes. However, the data captured from wearables, such as heart rate or number of steps, present two key challenges: (1) the time series is often of variable length and incomplete due to different data collection periods (e.g., wearing behavior varies by person); and (2) there is inter-individual variability to external factors like stress and environment. This article addresses these challenges and brings us closer to the potential of personalized insights about an individual, taking the leap from quantified self to qualified self. Specifically, HeartSpace proposed in this article learns embedding of the time-series data with variable length and missing values via the integration of a time-series encoding module and a pattern aggregation network. Additionally, HeartSpace implements a Siamese-triplet network to optimize representations by jointly capturing intra- and inter-series correlations during the embedding learning process. The empirical evaluation over two different real-world data presents significant performance gains over state-of-the-art baselines in a variety of applications, including user identification, personality prediction, demographics inference, job performance prediction, and sleep duration estimation.},
journal = {ACM Trans. Intell. Syst. Technol.},
month = sep,
articleno = {97},
numpages = {21},
keywords = {Representation learning, wearable-sensory time series}
}

@inproceedings{10.1145/3549015.3555669,
author = {Tahaei, Mohammad and Bernd, Julia and Rashid, Awais},
title = {Privacy, Permissions, and the Health App Ecosystem: A&nbsp;Stack&nbsp;Overflow&nbsp;Exploration},
year = {2022},
isbn = {9781450397001},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3549015.3555669},
doi = {10.1145/3549015.3555669},
abstract = {Health data is considered to be sensitive and personal; both governments and software platforms have enacted specific measures to protect it. Consumer apps that collect health data are becoming more popular, but raise new privacy concerns as they collect unnecessary data, share it with third parties, and track users. However, developers of these apps are not necessarily knowingly endangering users’ privacy; some may simply face challenges working with health features. To scope these challenges, we qualitatively analyzed 269 privacy-related posts on Stack Overflow by developers of health apps for Android- and iOS-based systems. We found that health-specific access control structures (e.g., enhanced requirements for permissions and authentication) underlie several privacy-related challenges developers face. The specific nature of problems often differed between the platforms, for example additional verification steps for Android developers, or confusing feedback about incorrectly formulated permission scopes for iOS. Developers also face problems introduced by third-party libraries. Official documentation plays a key part in understanding privacy requirements, but in some cases, may itself cause confusion. We discuss implications of our findings and propose ways to improve developers’ experience of working with health-related features—and consequently to improve the privacy of their apps’ end users.},
booktitle = {Proceedings of the 2022 European Symposium on Usable Security},
pages = {117–130},
numpages = {14},
keywords = {developer forums, health apps, software developers, usable privacy},
location = {Karlsruhe, Germany},
series = {EuroUSEC '22}
}

@inproceedings{10.1145/3549015.3554204,
author = {Mehrnezhad, Maryam and Shipp, Laura and Almeida, Teresa and Toreini, Ehsan},
title = {Vision: Too Little too Late? Do the Risks of FemTech already Outweigh the Benefits?},
year = {2022},
isbn = {9781450397001},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3549015.3554204},
doi = {10.1145/3549015.3554204},
abstract = {Abstract: Female-oriented technologies (FemTech) promise to enable women to take control of their bodies and lives, helping them overcome the many existing challenges in medical care and research. From lack of data about women in general, to bias and discrimination in health studies, data sets, and algorithms, FemTech has come a long way to centre women in the design and development of such systems. Yet, the FemTech industry remains largely unregulated, particularly when it comes to security, privacy, and safety. These issues can lead to catastrophe given the highly sensitive nature of the data FemTech technologies handle. In this paper, we show how such threats are already putting women at risk; where in some cases, the lack of proper security and privacy safeguards can put human life at risk. We also present the results of some of our ongoing research on the massive data collection of FemTech about end-users and others (baby, partner, family, etc.). We set an agenda for research on the security and privacy of FemTech and call for a better legal framework to regulate FemTech.},
booktitle = {Proceedings of the 2022 European Symposium on Usable Security},
pages = {145–150},
numpages = {6},
keywords = {Cybersecurity, Data Protection Laws, FemTech, Privacy},
location = {Karlsruhe, Germany},
series = {EuroUSEC '22}
}

@inproceedings{10.1145/3527049.3527098,
author = {Shmatko, Alexey and Kichigin, Oleg and Goncharova, Natalia and Dorofeeva, Lyudmila and Roslyakova, Natalia},
title = {Digitalization and Knowledge-Based Economy of Smart Cities: Development Scenarios},
year = {2022},
isbn = {9781450386944},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3527049.3527098},
doi = {10.1145/3527049.3527098},
abstract = {This study aims to assess potential changes in the existing approaches to urban development within the national scale. The paper focuses on the development of such an approach that would encourage digital transformation in cities with the maximum number of benefits for their residents. Cluster analysis of the Russian regions allowed articulating various development scenarios for each cluster in terms of digitalization and improvements in the knowledge-based economy. Apart from changing the urban environment as it is, information technologies alter the very notion of how the regions can be integrated into the social and economic space. This fact makes even more sense regarding the emergence of digital inequality and disproportions in the development and distribution of new knowledge. Thereby, decent living standards in the regions end up undermined. Global changes of early 2020 will certainly lead to transformations in consumer behavior and thinking behind business processes, which will change the needs for the urban environment to meet. The core requirements include infrastructure security, state regulation, social security, localization of production and consumption, as well as changes in the consumption patterns. It should be noted that improvements in the public policy of the Russian Federation can be implemented only when guided by the identified scenarios and factors influencing urban transformation. In this regard, all the incorporated digital solutions are expected to enhance comfort, which does not necessarily mean an overwhelming set of tools, but high quality and an idea behind their use. The introduction of digital technologies is no longer a matter that can be neglected or prioritized by the authorities. It has been immersed in the system of public administration to such an extent that there is now no other way but to use its effectiveness as a competitive advantage of the region. At the regional level, the competition for investors is so harsh at the moment that the ability to embrace the full potential of digitalization turns out to be the key to success, determining the speed for an investor to access the required infrastructure and start their commercial activities},
booktitle = {Proceedings of the 3rd International Scientific Conference on Innovations in Digital Economy},
pages = {165–171},
numpages = {7},
keywords = {digital economy, digitalization, infrastructure potential, regional development, smart cities},
location = {Saint - Petersburg, Russian Federation},
series = {SPBPU IDE '21}
}

@article{10.1145/3523063,
author = {Verma, Rohit and Pargal, Sugandh and Das, Debasree and Parbat, Tanusree and Kambalapalli, Sai Shankar and Mitra, Bivas and Chakraborty, Sandip},
title = {Impact of Driving Behavior on Commuter’s Comfort During Cab Rides: Towards a New Perspective of Driver Rating},
year = {2022},
issue_date = {December 2022},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {13},
number = {6},
issn = {2157-6904},
url = {https://doi.org/10.1145/3523063},
doi = {10.1145/3523063},
abstract = {Commuter comfort in cab rides affects driver rating as well as the reputation of ride-hailing firms like Uber/Lyft. Existing research has revealed that commuter comfort not only varies at a personalized level but also is perceived differently on different trips for the same commuter. Furthermore, there are several factors, including driving behavior and driving environment, affecting the perception of comfort. Automatically extracting the perceived comfort level of a commuter due to the impact of the driving behavior is crucial for a timely feedback to the drivers, which can help them to meet the commuter’s satisfaction. In light of this, we surveyed around 200 commuters who usually take such cab rides and obtained a set of features that impact comfort during cab rides. Following this, we develop a system Ridergo which collects smartphone sensor data from a commuter, extracts the spatial time series feature from the data, and then computes the level of commuter comfort on a five-point scale with respect to the driving. Ridergo uses a Hierarchical Temporal Memory model-based approach to observe anomalies in the feature distribution and then trains a multi-task learning-based neural network model to obtain the comfort level of the commuter at a personalized level. The model also intelligently queries the commuter to add new data points to the available dataset and, in turn, improve itself over periodic training. Evaluation of Ridergo on 30 participants shows that the system could provide efficient comfort score with high accuracy when the driving impacts the perceived comfort.},
journal = {ACM Trans. Intell. Syst. Technol.},
month = sep,
articleno = {87},
numpages = {25},
keywords = {Commuter comfort, sparse data, Hierarchical Temporal Memory, multi-task learning}
}

@article{10.1145/3556639,
author = {Parizi, Farshid Salemi and Whitmire, Eric and Patel, Shwetak},
title = {AuraRing: precise electromagnetic finger tracking},
year = {2022},
issue_date = {October 2022},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {65},
number = {10},
issn = {0001-0782},
url = {https://doi.org/10.1145/3556639},
doi = {10.1145/3556639},
abstract = {Wearable computing platforms, such as smartwatches and head-mounted mixed reality displays, demand new input devices for high-fidelity interaction. We present AuraRing, a wearable magnetic tracking system designed for tracking fine-grained finger movement. The hardware consists of a ring with an embedded electromagnetic transmitter coil and a wristband with multiple sensor coils. By measuring the magnetic fields at different points around the wrist, AuraRing estimates the five degree-of-freedom pose of the ring. AuraRing is trained only on simulated data and requires no runtime supervised training, ensuring user and session independence. It has a dynamic accuracy of 4.4 mm, as measured through a user evaluation with optical ground truth. The ring is completely self-contained and consumes just 2.3 mW of power.},
journal = {Commun. ACM},
month = sep,
pages = {85–92},
numpages = {8}
}

@inproceedings{10.1145/3543712.3543740,
author = {Chen, Yen-Jen and Lin, En-Cheng},
title = {Design and Implementation of Hardware and Peripheral System for IoT Gateway},
year = {2022},
isbn = {9781450396226},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3543712.3543740},
doi = {10.1145/3543712.3543740},
abstract = {This paper uses Linkit Smart 7688 Duo development board developed by MediaTek as the core of the overall IoT gateway system design, which compares other development boards and IoT gateways on the market. Smart 7688 Duo development board is about 40\% lower in price than Raspberry Pi, and the hardware CPU clock is higher than NEXCOM NIO 51 gateway. This implementation provides a low-cost and highly customizable solution that allows system integrators to more effectively provide their customers with the most appropriate IT services. The proposed IoT gateway design utilizes the Linkit Smart 7688 Duo with MIPS and MCU dual-core chip, Arduino development environment and industrial protocol Modbus to design the data transfer of each sensor in the peripheral system. The IoT gateway obtains the sensor data and transmits it to the server using Message Queuing Telemetry Transport (MQTT). The data acquisition accuracy of the developed MCU program was measured with 2 sensors of hydrogen sulfide (H2S) and methane (CH4). The overall system architecture and peripheral systems are designed to realize the IoT gateway taking into account the internal heat dissipation and module wiring, and also the appearance of the chassis is designed to carry the IoT gateway system, so as to achieve a high-quality product prototype that is accurate, economical, and customizable.},
booktitle = {Proceedings of the 2022 8th International Conference on Computer Technology Applications},
pages = {268–274},
numpages = {7},
keywords = {Gateway, IoT, MCU, MQTT, Modbus},
location = {Vienna, Austria},
series = {ICCTA '22}
}

@article{10.1145/3484201,
author = {Gazi, Firoj and Ahmed, Nurzaman and Misra, Sudip and Wei, Wei},
title = {Reinforcement Learning-Based MAC Protocol for Underwater Multimedia Sensor Networks},
year = {2022},
issue_date = {August 2022},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {18},
number = {3},
issn = {1550-4859},
url = {https://doi.org/10.1145/3484201},
doi = {10.1145/3484201},
abstract = {High propagation delay, high error probability, floating node mobility, and low data rates are the key challenges for Underwater Wireless Multimedia Sensor Networks (UMWSNs). In this article, we propose RL-MAC, a Reinforcement Learning (RL)–based Medium Access Control (MAC) protocol for multimedia sensing in an Underwater Acoustic Network (UAN) environment. The proposed scheme uses Transmission Opportunity (TXOP) for relay nodes in a multi-hop network for improved efficiency concerning the mobility of the relays and sensor nodes. The access point (AP) and relay nodes calculate traffic demands from the initial contention of the sensor nodes. Our solution uses Q-learning to enhance the contention mechanism at the initial phase of multimedia transmission. Based on the traffic demands, RL-MAC allocates TXOP duration for the uplink multimedia reception. Further, the Structural Similarity Index Measure (SSIM) and compression techniques are used for calculating the image quality at the receiver end and reducing the image at the destination, respectively. We implement a prototype of the proposed scheme over an off-the-shelf, low-cost hardware setup. Moreover, extensive simulation over NS-3 shows a significant packet delivery ratio and throughput compared with the existing state-of-the-art.},
journal = {ACM Trans. Sen. Netw.},
month = sep,
articleno = {37},
numpages = {25},
keywords = {Underwater Wireless Multimedia Sensor Networks (UMWSNs), underwater sensor networks, underwater IoT, Underwater Acoustic Network (UAN), reinforcement learning, Structural Similarity Index Measure (SSIM), Medium Access Control (MAC) protocol}
}

@inproceedings{10.1145/3545922.3545931,
author = {Huai, Lin},
title = {Improvement of Distance Resistance Training Teaching Based on Wearable Equipment and Training Auxiliary System},
year = {2022},
isbn = {9781450396660},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3545922.3545931},
doi = {10.1145/3545922.3545931},
abstract = {Driven by the prospective of future education, the new educational concepts brought about by technological progress will promote the diversified development of educational models. Online education based on the Internet is advanced in dealing with crises and breaking down educational barriers, and can be applied to daily teaching. Physical education is different from theoretical courses, and its unique practicality breaks through the local information flow of teaching content. It enriches the connotation of distance teaching. Starting from the three stages of pre-training, mid-training and post-training involved in resistance training teaching, aiming at improving muscle quality and health On the premise of avoiding injury, the study puts forward a comprehensive environmental concept of external, internal and psychological environment of the body. In the improved teaching environment, resistance training teaching needs comprehensive technology and equipment support. The study is a systematic solution based on wearable equipment and training auxiliary system. Through sensors, virtual reality and AI technology, the individual comprehensive environment is monitored and corrected to achieve the expectant training effect.},
booktitle = {Proceedings of the 8th International Conference on E-Society, e-Learning and e-Technologies},
pages = {50–56},
numpages = {7},
keywords = {AI, Motion capture, Resistance training, Sensor, Sport, VR, Wearable equipment},
location = {Rome, Italy},
series = {ICSLT '22}
}

@inproceedings{10.1145/3543174.3545252,
author = {Hock, Philipp and Colley, Mark and Askari, Ali and Wagner, Tobias and Baumann, Martin and Rukzio, Enrico},
title = {Introducing VAMPIRE – Using Kinaesthetic Feedback in Virtual Reality for Automated Driving Experiments},
year = {2022},
isbn = {9781450394154},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3543174.3545252},
doi = {10.1145/3543174.3545252},
abstract = {Investigating trust, acceptance, and attitudes towards automated driving is often investigated in simulator experiments. Therefore, behavioral validity is a crucial aspect of automated driving studies. However, static simulators have reduced behavioral validity because of their inherent safe environment. We propose VAMPIRE (VR automated movement platform for immersive realistic experiences), a movement platform designed to increase the sensation of realism in automated driving simulator studies using an automated wheelchair. In this work, we provide a detailed description to build the prototype (including software components and assembly instructions), a proposal for safety precautions, an analysis of possible movement patterns for overtaking scenarios, and practical implications for designers and practitioners. We provide all project-related files as auxiliary materials.},
booktitle = {Proceedings of the 14th International Conference on Automotive User Interfaces and Interactive Vehicular Applications},
pages = {204–214},
numpages = {11},
keywords = {Automated vehicles, Immersive technology, driving simulator, on-road simulation., user studies},
location = {Seoul, Republic of Korea},
series = {AutomotiveUI '22}
}

@inproceedings{10.1145/3543758.3543766,
author = {Sch\"{a}fer, Alexander and Reis, Gerd and Stricker, Didier},
title = {The Gesture Authoring Space: Authoring Customised Hand Gestures for Grasping Virtual Objects in Immersive Virtual Environments},
year = {2022},
isbn = {9781450396905},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3543758.3543766},
doi = {10.1145/3543758.3543766},
abstract = {Natural user interfaces are on the rise. Manufacturers for Augmented, Virtual, and Mixed Reality head mounted displays are increasingly integrating new sensors into their consumer grade products, allowing gesture recognition without additional hardware. This offers new possibilities for bare handed interaction within virtual environments. This work proposes a hand gesture authoring tool for object specific grab gestures allowing virtual objects to be grabbed as in the real world. The presented solution uses template matching for gesture recognition and requires no technical knowledge to design and create custom tailored hand gestures. In a user study, the proposed approach is compared with the pinch gesture and the controller for grasping virtual objects. The different grasping techniques are compared in terms of accuracy, task completion time, usability, and naturalness. The study showed that gestures created with the proposed approach are perceived by users as a more natural input modality than the others.},
booktitle = {Proceedings of Mensch Und Computer 2022},
pages = {85–95},
numpages = {11},
keywords = {augmented reality, bare handed, gesture, grasping, hand gestures, manipulation, mixed reality, virtual object grabbing, virtual reality},
location = {Darmstadt, Germany},
series = {MuC '22}
}

@article{10.1145/3536424,
author = {Yau, Cheuk-Wang and Jewsakul, Sukanya and Luk, Man-Ho and Lee, Angela P. Y. and Chan, Yun-Hin and Ngai, Edith C. H. and Pong, Philip W. T. and Lui, King-Shan and Liu, Jiangchuan},
title = {NB-IoT Coverage and Sensor Node Connectivity in Dense&nbsp;Urban&nbsp;Environments: An Empirical Study},
year = {2022},
issue_date = {August 2022},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {18},
number = {3},
issn = {1550-4859},
url = {https://doi.org/10.1145/3536424},
doi = {10.1145/3536424},
abstract = {Wireless sensor networks have enabled smart infrastructures and novel applications. With the recent roll-out of Narrowband IoT (NB-IoT) cellular radio technology, wireless sensors can be widely deployed for data collection in cities around the world. However, empirical evidence regarding the coverage and connectivity of NB-IoT in dense urban areas is limited. This article presents an empirical study that focuses on evaluating the coverage and connectivity of NB-IoT in a dense urban environment. We have designed an NB-IoT sensor node and deployed over 100 of them in high-rise apartment buildings in Hong Kong. These sensor nodes utilize a commercial NB-IoT network to collect high-resolution water flow data for machine learning model training and provide timely feedback to users. We collect and analyze the empirical NB-IoT signal measurements from the sensor nodes deployed in various challenging outdoor and indoor environments for over three months. These empirical measurements reveal correlations between NB-IoT connectivity and sensor installation environments. We also observe that inter-cell interference, as a result of coverage by multiple neighboring NB-IoT cells in a dense urban environment, is a source of connectivity degradation. We discuss potential issues that IoT application designers and system integrators might encounter in practical NB-IoT devices deployment, and we propose a transmission decision algorithm based on signal measurements for mitigating energy wasted due to transmission failures. Finally, we demonstrate the results and the benefits of using high-resolution water flow data collected by our purpose-built NB-IoT sensor nodes for studying the patterns of domestic water consumption in Hong Kong.},
journal = {ACM Trans. Sen. Netw.},
month = sep,
articleno = {49},
numpages = {36},
keywords = {Narrowband Internet of Things, NB-IoT, low-power wide-area network, LPWAN, sensor node, flow sensor, water meter}
}

@inproceedings{10.1145/3543434.3543455,
author = {Mohamed, Sapraz and Han, Shengnan},
title = {Translating Human Values to Design Requirements: The Case of Developing Digital Government Collaborative Platform (DGCP) for Environmental Sustainability in Sri Lanka},
year = {2022},
isbn = {9781450397490},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3543434.3543455},
doi = {10.1145/3543434.3543455},
abstract = {This paper aims to translate human values to the design requirements for developing a Digital Government Collaborative Platform (DGCP) for environmental sustainability in Sri Lanka. In the study, van de Poel's value hierarchy guides the value translation process. The human values are thoroughly reviewed and converted into norms and subsequently into design requirements with the consultation of information system design experts and environment-related government authority officers in Sri Lanka. As a result, thirty-one design requirements are identified for the design of DGCP. The study contributes new knowledge to the Value Sensitive Design literature in translating human values to design requirements, especially in an e-government system for a developing country. Further, the study emphasizes the importance of considering legal acts, policy, and other regulations in designing e-government artifacts such as the DGCP for environmental sustainability.},
booktitle = {Proceedings of the 23rd Annual International Conference on Digital Government Research},
pages = {54–61},
numpages = {8},
keywords = {Digital Government Collaborative Platform, E-government, Environmental Sustainability, Value Sensitive Design},
location = {Virtual Event, Republic of Korea},
series = {dg.o '22}
}

@inproceedings{10.1145/3503229.3547063,
author = {Fadhlillah, Hafiyyan Sayyid},
title = {Multidisciplinary variability management for cyber-physical production systems},
year = {2022},
isbn = {9781450392068},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3503229.3547063},
doi = {10.1145/3503229.3547063},
abstract = {Cyber-Physical Production Systems (CPPSs) are complex, versatile systems interacting with the environment by sensors and actuators. Specific customer demands and technical requirements lead to high engineering efforts for the control software of CPPSs, especially when following a clone-and-own approach to reuse, as is still common in industry. Utilizing systematic variability management to derive and configure control software variants from a product line could help to reduce the cost of developing and/or maintaining CPPSs. However, modeling CPPS variability is challenging as knowledge from multiple disciplines (e.g., mechanics, electrics, software) is needed, which is either implicit in practice or expressed in multiple heterogeneous engineering artifacts with diverse semantics. Furthermore, techniques commonly used to implement CPPS control software (e.g., graphical programming or modeling languages) do not have any formal mechanism to express variability. In this paper, we report on our ongoing efforts to create a multidisciplinary variability management approach for CPPSs, particularly CPPS control software. We designed our approach as an integrated approach providing configuration options based on related heterogeneous variability models from multiple disciplines. Our integrated approach can generate control software based on related domain-specific implementation artifacts.},
booktitle = {Proceedings of the 26th ACM International Systems and Software Product Line Conference - Volume B},
pages = {23–28},
numpages = {6},
keywords = {cyber-physical production systems, product configuration, software product lines, variability modeling},
location = {Graz, Austria},
series = {SPLC '22}
}

@inproceedings{10.1145/3549737.3549764,
author = {Vonitsanos, Gerasimos and Panagiotakopoulos, Theodor and Kanavos, Andreas and Kameas, Achilles},
title = {An Apache Spark Framework for IoT-enabled Waste Management in Smart Cities},
year = {2022},
isbn = {9781450395977},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3549737.3549764},
doi = {10.1145/3549737.3549764},
abstract = {The diffusion of small low cost sensors has opened new opportunities in terms of designing real-time monitoring systems in several application fields. Internet of Things (IoT) is a new branch of Information and Communication Technologies that connects vast amounts of heterogeneous sensing devices and other smart objects through different network protocols in order to provide large scale interoperability and underpin the development of novel applications. A fundamental application domain regarding IoT refers to smart cities, which offer a fertile ground for implementing technological advances to enhance urban management, ensure environmental sustainability and improve the quality of living. In this paper, we propose an innovative framework aiming at collecting, monitoring and processing streams of data received in real-time by IoT sensor devices while measuring the waste level of waste bins in a distributed environment.},
booktitle = {Proceedings of the 12th Hellenic Conference on Artificial Intelligence},
articleno = {23},
numpages = {7},
keywords = {Apache Spark, Classification, Internet of Things (IoT), Machine Learning, Smart Cities, Urban Waste},
location = {Corfu, Greece},
series = {SETN '22}
}

@inproceedings{10.1145/3524458.3547260,
author = {Kri\v{z}man\v{c}i\'{c}, Marko and Rabbel, Tim-Lucas and Buss, Eduard and Wahby, Mostafa and Hamann, Heiko and Bogdan, Stjepan},
title = {Distributed Connectivity Control in Bio-Hybrid Wireless Sensor Networks},
year = {2022},
isbn = {9781450392846},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3524458.3547260},
doi = {10.1145/3524458.3547260},
abstract = {In the WatchPlant project, we aim to develop a bio-hybrid wireless sensor network (WSN) that uses natural plants as sensors for a variety of environmental conditions. One of the major challenges in such a system is managing connectivity while balancing higher data throughput with energy conservation. In this work, connectivity is controlled through the so-called Fiedler value, the second smallest eigenvalue of the Laplacian of the communication graph. We propose a distributed connectivity control method that relies on consensus-based topology estimation, and in which links in the graph are added or removed according to the values of the Fiedler eigenvector obtained from the estimated adjacency matrix. The proposed strategy for estimating and maintaining connectivity was validated in a simulation and in a physical proof-of-concept WSN consisting of several single-board mini-computers.},
booktitle = {Proceedings of the 2022 ACM Conference on Information Technology for Social Good},
pages = {250–257},
numpages = {8},
keywords = {consensus, distributed control, multi-agent systems, network topology},
location = {Limassol, Cyprus},
series = {GoodIT '22}
}

@article{10.1145/3550294,
author = {Hiremath, Shruthi K. and Nishimura, Yasutaka and Chernova, Sonia and Pl\"{o}tz, Thomas},
title = {Bootstrapping Human Activity Recognition Systems for Smart Homes from Scratch},
year = {2022},
issue_date = {September 2022},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {6},
number = {3},
url = {https://doi.org/10.1145/3550294},
doi = {10.1145/3550294},
abstract = {Smart Homes have come a long way: From research laboratories in the early days, through (almost) neglect, to their recent revival in real-world environments enabled through the existence of commodity devices and robust, standardized software frameworks. With such availability, human activity recognition (HAR) in smart homes has become attractive for many real-world applications, especially in the domain of Ambient Assisted Living. Yet, getting started with an activity recognition system in specific smart homes, which are highly specialized spaces inhabited by individuals with idiosyncratic behaviors and habits, is a non-trivial endeavor. We present an approach for bootstrapping HAR systems for individual smart homes from scratch. At the beginning of the life cycle of a smart home, our system passively observes activities and derives rich representations for sensor data-action units-which are then aggregated into activity models through motif learning with minimal supervision. The resulting HAR system is then capable of recognizing relevant, most frequent activities in a smart home. We demonstrate the effectiveness of our bootstrapping procedure through experimental evaluations on CASAS datasets that show the practical value of our approach.},
journal = {Proc. ACM Interact. Mob. Wearable Ubiquitous Technol.},
month = sep,
articleno = {119},
numpages = {27},
keywords = {human activity recognition, pattern recognition, smart-home}
}

@inproceedings{10.1145/3524458.3547262,
author = {Mazzolai, Barbara and Kraus, Tobias and Pirrone, Nicola and Kooistra, Lammert and De Simone, Antonio and Cottin, Antoine and Margheri, Laura},
title = {Advancing environmental intelligence through novel approaches in soft bioinspired robotics and allied technologies: I-Seed project position paper for Environmental Intelligence in Europe},
year = {2022},
isbn = {9781450392846},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3524458.3547262},
doi = {10.1145/3524458.3547262},
abstract = {The EU-funded FET Proactive Environmental Intelligence project “I-Seed” (Grant Agreement n. 101017940, https://www.iseedproject.eu/) targets towards the development of a radically simplified and environmentally friendly approach for environmental monitoring. Specifically, I-Seed aims at developing a new generation of self-deployable and biodegradable soft miniaturized robots, inspired by the morphology and dispersion abilities of plant seeds, able to perform low-cost, environmentally responsible, in-situ measurements. The natural functional mechanisms of seeds dispersal offer a rich source of robust, highly adaptive, mass and energy efficient mechanisms, and behavioral and morphological intelligence, which can be selected and implemented for advanced, but simple, technological inventions. I-Seed robots are conceived as unique in their movement abilities because inspired by passive mechanisms and materials of natural seeds, and unique in their environmentally friendly design because made of all biodegradable components. Sensing is based on a chemical transduction mechanism in a stimulus-responsive sensor material with fluorescence-based optical readout, which can be read via one or more drones equipped with fluorescent LiDAR technology and a software able to perform a real time georeferencing of data. The I-Seed robotic ecosystem is envisioned to be used for collecting environmental data in-situ with high spatial and temporal resolution across large remote areas where no monitoring data are available, and thus for extending current environmental sensor frameworks and data analysis systems.},
booktitle = {Proceedings of the 2022 ACM Conference on Information Technology for Social Good},
pages = {265–268},
numpages = {4},
keywords = {Bioinspired robotics, LiDAR, Unmanned Aerial Vehicles (UAVs), aerial robotics, biodegradable technologies, chemical transduction sensing, environmental intelligence, multi-functional materials, plant biology, soft robotics},
location = {Limassol, Cyprus},
series = {GoodIT '22}
}

@inproceedings{10.1145/3524458.3547228,
author = {Prandi, Catia and Cecilia, Jos\'{e} Maria and Manzoni, Pietro and Pe\~{n}a-Haro, Salvador and Pierson, Don and Colom, William and Blanco, Pablo and Garc\`{\i}a, Constancio Amurrio and Navarro, Inmaculada Jim\'{e}nez and Senent, Javier},
title = {On integrating intelligent infrastructure and participatory monitoring for environmental modelling: the SMARTLAGOON approach},
year = {2022},
isbn = {9781450392846},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3524458.3547228},
doi = {10.1145/3524458.3547228},
abstract = {In the critical context of Mar Menor, the largest saltwater coastal lagoon in Europe, which is experiencing an ecological crisis, the paper describes the intelligent environmental infrastructure we are developing as part of the SMARTLAGOON project. In particular, we here present our strategy to collect both (i) real-time environmental data exploiting an intelligent infrastructure which comprises a smart buoy and AI models running on cameras and a mobile application, and (ii) socio-environmental data engaging citizen scientists (including environmental NGO members, children) and extracting people opinions and topic trends from social media via our social media sensing tool. The integration of such data will feed our Digital Twin. The integration of such data will feed our Digital Twin, a power tool that will be designed to allow stakeholders to understand how the variables of interest will affect the sustainability of Mar Menor in the future.},
booktitle = {Proceedings of the 2022 ACM Conference on Information Technology for Social Good},
pages = {236–243},
numpages = {8},
keywords = {Citizen Science, Digital Twin, Environmental Intelligence, SMARTLAGOON},
location = {Limassol, Cyprus},
series = {GoodIT '22}
}

@article{10.1145/3550289,
author = {Cho, Hyunsung and Mathur, Akhil and Kawsar, Fahim},
title = {FLAME: Federated Learning across Multi-device Environments},
year = {2022},
issue_date = {September 2022},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {6},
number = {3},
url = {https://doi.org/10.1145/3550289},
doi = {10.1145/3550289},
abstract = {Federated Learning (FL) enables distributed training of machine learning models while keeping personal data on user devices private. While we witness increasing applications of FL in the area of mobile sensing, such as human activity recognition (HAR), FL has not been studied in the context of a multi-device environment (MDE), wherein each user owns multiple data-producing devices. With the proliferation of mobile and wearable devices, MDEs are increasingly becoming popular in ubicomp settings, therefore necessitating the study of FL in them. FL in MDEs is characterized by being not independent and identically distributed (non-IID) across clients, complicated by the presence of both user and device heterogeneities. Further, ensuring efficient utilization of system resources on FL clients in a MDE remains an important challenge. In this paper, we propose FLAME, a user-centered FL training approach to counter statistical and system heterogeneity in MDEs, and bring consistency in inference performance across devices. FLAME features (i) user-centered FL training utilizing the time alignment across devices from the same user; (ii) accuracy- and efficiency-aware device selection; and (iii) model personalization to devices. We also present an FL evaluation testbed with realistic energy drain and network bandwidth profiles, and a novel class-based data partitioning scheme to extend existing HAR datasets to a federated setup. Our experiment results on three multi-device HAR datasets show that FLAME outperforms various baselines by 4.3-25.8\% higher F1 score, 1.02-2.86x greater energy efficiency, and up to 2.06x speedup in convergence to target accuracy through fair distribution of the FL workload.},
journal = {Proc. ACM Interact. Mob. Wearable Ubiquitous Technol.},
month = sep,
articleno = {107},
numpages = {29},
keywords = {Federated Learning, Human Activity Recognition}
}

@article{10.1145/3550314,
author = {R\"{o}ddiger, Tobias and Clarke, Christopher and Breitling, Paula and Schneegans, Tim and Zhao, Haibin and Gellersen, Hans and Beigl, Michael},
title = {Sensing with Earables: A Systematic Literature Review and Taxonomy of Phenomena},
year = {2022},
issue_date = {September 2022},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {6},
number = {3},
url = {https://doi.org/10.1145/3550314},
doi = {10.1145/3550314},
abstract = {Earables have emerged as a unique platform for ubiquitous computing by augmenting ear-worn devices with state-of-the-art sensing. This new platform has spurred a wealth of new research exploring what can be detected on a wearable, small form factor. As a sensing platform, the ears are less susceptible to motion artifacts and are located in close proximity to a number of important anatomical structures including the brain, blood vessels, and facial muscles which reveal a wealth of information. They can be easily reached by the hands and the ear canal itself is affected by mouth, face, and head movements. We have conducted a systematic literature review of 271 earable publications from the ACM and IEEE libraries. These were synthesized into an open-ended taxonomy of 47 different phenomena that can be sensed in, on, or around the ear. Through analysis, we identify 13 fundamental phenomena from which all other phenomena can be derived, and discuss the different sensors and sensing principles used to detect them. We comprehensively review the phenomena in four main areas of (i) physiological monitoring and health, (ii) movement and activity, (iii) interaction, and (iv) authentication and identification. This breadth highlights the potential that earables have to offer as a ubiquitous, general-purpose platform.},
journal = {Proc. ACM Interact. Mob. Wearable Ubiquitous Technol.},
month = sep,
articleno = {135},
numpages = {57},
keywords = {ear wearable, ear-attached, ear-based, ear-mounted, ear-worn, earables, earbuds, earphones, earpiece, headphones, hearables}
}

@article{10.1145/3550305,
author = {Paredes, Luis and Ipsita, Ananya and Mesa, Juan C. and Martinez Garrido, Ramses V. and Ramani, Karthik},
title = {StretchAR: Exploiting Touch and Stretch as a Method of Interaction for Smart Glasses Using Wearable Straps},
year = {2022},
issue_date = {September 2022},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {6},
number = {3},
url = {https://doi.org/10.1145/3550305},
doi = {10.1145/3550305},
abstract = {Over the past decade, augmented reality (AR) developers have explored a variety of approaches to allow users to interact with the information displayed on smart glasses and head-mounted displays (HMDs). Current interaction modalities such as mid-air gestures, voice commands, or hand-held controllers provide a limited range of interactions with the virtual content. Additionally, these modalities can also be exhausting, uncomfortable, obtrusive, and socially awkward. There is a need to introduce comfortable interaction techniques for smart glasses and HMDS without the need for visual attention. This paper presents StretchAR, wearable straps that exploit touch and stretch as input modalities to interact with the virtual content displayed on smart glasses. StretchAR straps are thin, lightweight, and can be attached to existing garments to enhance users' interactions in AR. StretchAR straps can withstand strains up to 190\% while remaining sensitive to touch inputs. The strap allows the effective combination of these inputs as a mode of interaction with the content displayed through AR widgets, maps, menus, social media, and Internet of Things (IoT) devices. Furthermore, we conducted a user study with 15 participants to determine the potential implications of the use of StretchAR as input modalities when placed on four different body locations (head, chest, forearm, and wrist). This study reveals that StretchAR can be used as an efficient and convenient input modality for smart glasses with a 96\% accuracy. Additionally, we provide a collection of 28 interactions enabled by the simultaneous touch-stretch capabilities of StretchAR. Finally, we facilitate recommendation guidelines for the design, fabrication, placement, and possible applications of StretchAR as an interaction modality for AR content displayed on smart glasses.},
journal = {Proc. ACM Interact. Mob. Wearable Ubiquitous Technol.},
month = sep,
articleno = {134},
numpages = {26},
keywords = {Human AR interaction, Wearables, augmented reality, cyber-physical systems, interactions, stretchable electronics}
}

@article{10.1145/3550284,
author = {Mollyn, Vimal and Ahuja, Karan and Verma, Dhruv and Harrison, Chris and Goel, Mayank},
title = {SAMoSA: Sensing Activities with Motion and Subsampled Audio},
year = {2022},
issue_date = {September 2022},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {6},
number = {3},
url = {https://doi.org/10.1145/3550284},
doi = {10.1145/3550284},
abstract = {Despite advances in audio- and motion-based human activity recognition (HAR) systems, a practical, power-efficient, and privacy-sensitive activity recognition system has remained elusive. State-of-the-art activity recognition systems often require power-hungry and privacy-invasive audio data. This is especially challenging for resource-constrained wearables, such as smartwatches. To counter the need for an always-on audio-based activity classification system, we first make use of power and compute-optimized IMUs sampled at 50 Hz to act as a trigger for detecting activity events. Once detected, we use a multimodal deep learning model that augments the motion data with audio data captured on a smartwatch. We subsample this audio to rates ≤ 1 kHz, rendering spoken content unintelligible, while also reducing power consumption on mobile devices. Our multimodal deep learning model achieves a recognition accuracy of 92.2\% across 26 daily activities in four indoor environments. Our findings show that subsampling audio from 16 kHz down to 1 kHz, in concert with motion data, does not result in a significant drop in inference accuracy. We also analyze the speech content intelligibility and power requirements of audio sampled at less than 1 kHz and demonstrate that our proposed approach can improve the practicality of human activity recognition systems.},
journal = {Proc. ACM Interact. Mob. Wearable Ubiquitous Technol.},
month = sep,
articleno = {132},
numpages = {19},
keywords = {Artifact or System, Location-Aware/Contextual Computing, Sensors}
}

@inproceedings{10.1145/3524458.3547255,
author = {Mertzimekis, Theodoros and Lagaki, Varvara and Madesis, Ioannis and Siltzovalis, Georgios and Petra, Eleni and Nomikou, Paraskevi and Batista, Pedro and Cabecinhas, David and Pascoal, Antonio and Sebastiao, Luis and Escartin, Javier and Kebkal, Konstantin and Karantzalos, Konstantinos and Douskos, Valsamis and Mallios, Angelos and Nikolopoulos, Konstantinos},
title = {RAMONES and Environmental Intelligence: Progress Update},
year = {2022},
isbn = {9781450392846},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3524458.3547255},
doi = {10.1145/3524458.3547255},
abstract = {RAMONES is an EU H2020 FET Proactive Project which aims to offer a new fleet of instruments to perform continuous and in situ measurements of natural and artificial radioactivity in the marine environment as part of its main objectives. Those instruments will be developed, optimized, validated and deployed in the field, based on implementing specific functional characteristics, optimizing integrated solutions, and fine-tuning their overall architecture. The main effort in RAMONES is to define the new state-of-the-art in radioactivity monitoring in ocean ecosystems investing on innovative stationary and mobile platforms. RAMONES will develop light-weight, high-resolution, power-efficient radiation spectrometers integrated aboard autonomous underwater vehicles. A benthic laboratory will additionally be developed as a multi-instrument platform to offer high-resolution spectroscopy and imaging capabilities equipped with additional sensors. Radioactivity monitoring will offer several opportunities to understand the dose impact on ocean ecosystems in various extreme locations, such as underwater volcanoes, seismic faults or deep-ocean drilling locations. Artificial intelligence and robotics will core factors in achieving the new state-of-the-art in coordinated navigation and decision making, and will provide the tools for risk forecasting and risk mitigation. In this paper, a progress update on RAMONES instruments is reported, jointly with a report on the RAMONES contributions to the Environmental Intelligence initiative.},
booktitle = {Proceedings of the 2022 ACM Conference on Information Technology for Social Good},
pages = {244–249},
numpages = {6},
keywords = {Environmental Intelligence, Marine Robotics and Applications, Ocean Ecosystems, Radioactivity Monitoring},
location = {Limassol, Cyprus},
series = {GoodIT '22}
}

@inproceedings{10.1145/3524458.3547221,
author = {Bardi, Sara and Palazzi, Claudio Enrico},
title = {Smart Hydroponic Greenhouse: Internet of Things and Soilless Farming},
year = {2022},
isbn = {9781450392846},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3524458.3547221},
doi = {10.1145/3524458.3547221},
abstract = {Population growth and rapid climate change are leading to a reduction in arable lands and this requires an immediate solution. Hydroponic cultivation is one of the best approaches developed in recent years since this method requires water as a means of nutrition rather than soil. Thanks to its characteristics, hydroponics can solve many problems not only with regard to food supply but also health diseases such as allergy to heavy metals. However, this type of cultivation requires a lot of effort to ensure a perfect environmental condition and a balanced nutritional solution. For this reason, IoT technology is usually applied to automate all these processes. In this work we present a prototype of a hydroponic greenhouse integrated with IoT technology and a Dashboard for viewing data in real time. The sensors applied can monitor the temperature and humidity of the greenhouse, the water level in the basin and the amount of light. In the prototype there is also the possibility to turn on or off some electronic components. The aim of this work is to build a basic system for an automatic hydroponic greenhouse that can be customized or amplified according to your needs.},
booktitle = {Proceedings of the 2022 ACM Conference on Information Technology for Social Good},
pages = {212–217},
numpages = {6},
keywords = {Hydroponic, IoT, Smart Farming},
location = {Limassol, Cyprus},
series = {GoodIT '22}
}

@article{10.1145/3550295,
author = {Shen, Cheng and Huang, Jun and Sun, Guangyu and Chen, Jingshu},
title = {Electromagnetic Fingerprinting of Memory Heartbeats: System and Applications},
year = {2022},
issue_date = {September 2022},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {6},
number = {3},
url = {https://doi.org/10.1145/3550295},
doi = {10.1145/3550295},
abstract = {This paper presents MemScope, a system that fingerprints devices via electromagnetic sensing of their memory heartbeats, i.e., the clock signal that synchronizes memory and memory controller. MemScope leverages the enhanced resolution and security of memory heartbeat fingerprint, which has enriched spectral features thanks to the spread spectrum generation of memory clock, and cannot be concealed as long as the device accesses its memory during computing. MemScope employs signal processing algorithms that allow it to hear the memory heartbeats of devices from a distance, in the presence of noise, and in crowded environments where multiple devices coexist. It then fingerprints memory heartbeats using machine learning tools. Measurements on a set of 65 devices over a month validate the robustness of fingerprint against time variation, and show a high precision and recall. We then use the neural network to build a detector to defend against possible replay attacks. Finally, we further demonstrate the effectiveness of MemScope in two application scenarios, (i) detecting wireless identity spoofing and (ii) identifying and localizing unauthorized hidden cameras.},
journal = {Proc. ACM Interact. Mob. Wearable Ubiquitous Technol.},
month = sep,
articleno = {138},
numpages = {23},
keywords = {device fingerprinting, electromagnetic radiation, side-channel}
}

@article{10.1145/3550307,
author = {Cao, Yetong and Li, Fan and Chen, Huijie and liu, Xiaochen and Zhang, Li and Wang, Yu},
title = {Guard Your Heart Silently: Continuous Electrocardiogram Waveform Monitoring with Wrist-Worn Motion Sensor},
year = {2022},
issue_date = {September 2022},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {6},
number = {3},
url = {https://doi.org/10.1145/3550307},
doi = {10.1145/3550307},
abstract = {In recent years, particular attention has been devoted to continuous electrocardiogram (ECG) waveform monitoring due to its numerous applications. However, existing solutions require users to be confined to particular locations, rely on dedicated and expensive hardware, or require active user participation. The constrained recording conditions prevent them from being deployed in many practical application scenarios. In view of this, we present VibCardiogram, a continuous and reliable design for estimating ECG waveform shape via ubiquitous wrist-worn wearables; it renders a personal ECG waveform shape estimating system with prolonged recording time accessible to a larger sector of the population. Instead of adding auxiliary sensors to wearables, VibCardiogram leverages the widely integrated motion sensor to characterize cardiac activities, and interpret them to generate an alternative signal that has the same waveform shape as the ECG signal. Specifically, VibCardiogram extracts the cardiogenic body vibrations from noisy sensor data. As the waveform variability and inconstant period hinder the segmentation of cardiac cycles, VibCardiogram extracts features and realizes accurate segmentation via machine learning. To parse cardiac activities from vibration signals, we build a deep-learning pipeline associating the encoder-decoder framework and Generative Adversarial Networks. With dedicated construction and training, it can estimate the ECG waveform accurately. Experiments with 20 participants show that VibCardiogram can achieve an average estimation error of 5.989\% for waveform amplitude estimation, which is within the 10\% margins regulated by the American National Standards Institute. Moreover, the promising results further confirm that VibCardiogram effectively extracts Heart Rate Variability features and supports downstream applications.},
journal = {Proc. ACM Interact. Mob. Wearable Ubiquitous Technol.},
month = sep,
articleno = {103},
numpages = {29},
keywords = {ECG, Wearable, cardiogenic body vibration, deep learning}
}

@article{10.1145/3550318,
author = {Feng, Chao and Wang, Nan and Jiang, Yicheng and Zheng, Xia and Li, Kang and Wang, Zheng and Chen, Xiaojiang},
title = {Wi-Learner: Towards One-shot Learning for Cross-Domain Wi-Fi based Gesture Recognition},
year = {2022},
issue_date = {September 2022},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {6},
number = {3},
url = {https://doi.org/10.1145/3550318},
doi = {10.1145/3550318},
abstract = {Contactless RF-based sensing techniques are emerging as a viable means for building gesture recognition systems. While promising, existing RF-based gesture solutions have poor generalization ability when targeting new users, environments or device deployment. They also often require multiple pairs of transceivers and a large number of training samples for each target domain. These limitations either lead to poor cross-domain performance or incur a huge labor cost, hindering their practical adoption. This paper introduces Wi-Learner, a novel RF-based sensing solution that relies on just one pair of transceivers but can deliver accurate cross-domain gesture recognition using just one data sample per gesture for a target user, environment or device setup. Wi-Learner achieves this by first capturing the gesture-induced Doppler frequency shift (DFS) from noisy measurements using carefully designed signal processing schemes. It then employs a convolution neural network-based autoencoder to extract the low-dimensional features to be fed into a downstream model for gesture recognition. Wi-Learner introduces a novel meta-learner to "teach" the neural network to learn effectively from a small set of data points, allowing the base model to quickly adapt to a new domain using just one training sample. By so doing, we reduce the overhead of training data collection and allow a sensing system to adapt to the change of the deployed environment. We evaluate Wi-Learner by applying it to gesture recognition using the Widar 3.0 dataset. Extensive experiments demonstrate Wi-Learner is highly efficient and has a good generalization ability, by delivering an accuracy of 93.2\% and 74.2\% - 94.9\% for in-domain and cross-domain using just one sample per gesture, respectively.},
journal = {Proc. ACM Interact. Mob. Wearable Ubiquitous Technol.},
month = sep,
articleno = {114},
numpages = {27},
keywords = {Deep learning, Domain adaption, Gesture recognition, Wi-Fi}
}

@article{10.1145/3550329,
author = {Liu, Jialin and Li, Dong and Wang, Lei and Zhang, Fusang and Xiong, Jie},
title = {Enabling Contact-free Acoustic Sensing under Device Motion},
year = {2022},
issue_date = {September 2022},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {6},
number = {3},
url = {https://doi.org/10.1145/3550329},
doi = {10.1145/3550329},
abstract = {Recent years have witnessed increasing attention from both academia and industry on contact-free acoustic sensing. Due to the pervasiveness of audio devices and fine granularity of acoustic sensing, it has been applied in numerous fields, including human-computer interaction and contact-free health sensing. Though promising, the limited working range hinders the wide adoption of acoustic sensing in real life. To break the sensing range limit, we propose to deploy the acoustic device on a moving platform (i.e., a robot) to support applications that require larger coverage and continuous sensing. In this paper, we propose SonicBot, a system that enables contact-free acoustic sensing under device motion. We propose a sequence of signal processing schemes to eliminate the impact of device motion and then obtain clean target movement information that is previously overwhelmed by device movement. We implement SonicBot using commercial audio devices and conduct extensive experiments to evaluate the performance of the proposed system. Experiment results show that our system can achieve a median error of 1.11 cm and 1.31 mm for coarse-grained and fine-grained tracking, respectively. To showcase the applicability of our proposed system in real-world settings, we perform two field studies, including coarse-grained gesture sensing and fine-grained respiration monitoring when the acoustic device moves along with a robot.},
journal = {Proc. ACM Interact. Mob. Wearable Ubiquitous Technol.},
month = sep,
articleno = {128},
numpages = {27},
keywords = {acoustic signals, contact-free sensing, device motion, large-scale}
}

@inproceedings{10.1145/3546790.3546805,
author = {Sengupta, Jonah and Liu, Susan and Andreou, Andreas},
title = {RetinoSim: an Event-based Data Synthesis Tool for Neuromorphic Vision Architecture Exploration},
year = {2022},
isbn = {9781450397896},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3546790.3546805},
doi = {10.1145/3546790.3546805},
abstract = {Neuromorphic vision sensors (NVS), also known as silicon retina, capture aspects of the biological functionality of the mammalian retina by transducing incident photocurrent into an asynchronous stream of spikes that denote positive and negative changes in intensity. Current state-of-the-art devices are effectively leveraged in a variety of settings, but still suffer from distinct disadvantages as they are transitioned into high performance environments, such as space and autonomy. This paper provides an outline and demonstration of a data synthesis tool that gleans characteristics from the retina and allows the user to not only convert traditional video into neuromorphic data, but characterize design tradeoffs and inform future endeavors. Our retinomorphic model, RetinoSim, incorporates aspects of current NVS to allow for accurate data conversion while providing biologically-inspired features to improve upon this baseline. RetinoSim was implemented in MATLAB with a Graphical User Interface frontend to allow for expeditious video conversion and architecture exploration. We demonstrate that the tool can be used for real-time conversion for sparse event streams, exploration of frontend configurations, and duplication of existing event datasets.},
booktitle = {Proceedings of the International Conference on Neuromorphic Systems 2022},
articleno = {15},
numpages = {9},
keywords = {Data Synthesis, Event-based Sensors, Neuromorphic Vision, Software Modeling, Video Converter},
location = {Knoxville, TN, USA},
series = {ICONS '22}
}

@article{10.1145/3550331,
author = {Miao, Shenghuan and Chen, Ling and Hu, Rong and Luo, Yingsong},
title = {Towards a Dynamic Inter-Sensor Correlations Learning Framework for Multi-Sensor-Based Wearable Human Activity Recognition},
year = {2022},
issue_date = {September 2022},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {6},
number = {3},
url = {https://doi.org/10.1145/3550331},
doi = {10.1145/3550331},
abstract = {Multi-sensor-based wearable human activity recognition (WHAR) is a research hotspot in the field of ubiquitous computing. Extracting effective features from multi-sensor data is essential to improve the performance of activity recognition. Despite the excellent achievements of previous works, the challenge remains for modelling the dynamic correlations between sensors. In this paper, we propose a lightweight yet efficient GCN-based dynamic inter-sensor correlations learning framework called DynamicWHAR for automatically learning the dynamic correlations between sensors. DynamicWHAR is mainly composed of two modules: Initial Feature Extraction and Dynamic Information Interaction. Firstly, Initial Feature Extraction module performs data-to-feature transformation to extract the initial features of each sensor. Subsequently, Dynamic Information Interaction module explicitly models the specific interaction intensity between any two sensors, and performs dynamic information aggregation between sensors by the learned interaction intensity. Extensive experiments on four diverse WHAR datasets and two different resource-constrained devices validate that DynamicWHAR outperforms the SOTA models in both recognition performance and computational complexity.},
journal = {Proc. ACM Interact. Mob. Wearable Ubiquitous Technol.},
month = sep,
articleno = {130},
numpages = {25},
keywords = {graph convolution network, human activity recognition, information fusion, wearable sensors}
}

@article{10.1145/3548657,
author = {Yu, Ping and Ni, Wei and Liu, Ren Ping and Zhang, Zhaoxin and Zhang, Hua and Wen, Qiaoyan},
title = {Efficient Encrypted Range Query on Cloud Platforms},
year = {2022},
issue_date = {July 2022},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {6},
number = {3},
issn = {2378-962X},
url = {https://doi.org/10.1145/3548657},
doi = {10.1145/3548657},
abstract = {In the Internet of Things (IoT) era, various IoT devices are equipped with sensing capabilities and employed to support clinical applications. The massive electronic health records (EHRs) are expected to be stored in the cloud, where the data are usually encrypted, and the encrypted data can be used for disease diagnosis. There exist some numeric health indicators, such as blood pressure and heart rate. These numeric indicators can be classified into multiple ranges, and each range may represent an indication of normality or abnormity. Once receiving encrypted IoT data, the CS maps it to one of the ranges, achieving timely monitoring and diagnosis of health indicators. This article presents a new approach to identify the range that an encrypted numeric value corresponds to without exposing the explicit value. We establish the sufficient and necessary condition to convert a range query to matchings of encrypted binary sequences with the minimum number of matching operations. We further apply the minimization of range queries to design and implement a secure range query system, where numeric health indicators encrypted independently by multiple IoT devices can be cohesively stored and efficiently queried by using Lagrange polynomial interpolation. Comprehensive performance studies show that the proposed approach can protect both the health records and range query against untrusted cloud platforms and requires less computational and communication cost than existing techniques.},
journal = {ACM Trans. Cyber-Phys. Syst.},
month = sep,
articleno = {27},
numpages = {23},
keywords = {Internet-of-Things (IoT), range query, 0- and 1-encoding, searchable encryption}
}

@article{10.1145/3450350,
author = {Pham, Van-Trung and Nguyen, Tu N. and Liu, Bing-Hong and Thai, My T. and Dumba, Braulio and Lin, Tong},
title = {Minimizing Latency for Data Aggregation in Wireless Sensor Networks: An Algorithm&nbsp;Approach},
year = {2022},
issue_date = {August 2022},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {18},
number = {3},
issn = {1550-4859},
url = {https://doi.org/10.1145/3450350},
doi = {10.1145/3450350},
abstract = {In wireless sensor networks (WSNs), especially in underwater sensor networks, the problem of reporting data to the sink with minimum latency has been widely discussed in many research works. Many studies address using data aggregation to report the same type of data to the sink without data collision in a short period of time. However, due to the rapid development of sensor technology in recent years, a sensor is allowed to have multiple sensing capabilities, that is, it can generate and collect different types of data. Because different types of data have different meanings and required aggregation functions, only the data that belong to the same type are allowed to be aggregated. In addition, due to the interference of the environment or noise, the links in the WSNs are often not bidirectional. This motivates us to study the problem of using minimum latency scheduling to aggregate and report data to the sink without data collision in multiple-data-type WSNs having unidirectional links, which is shown to be NP-hard in the article. The Relative-Collision-Graph-Based Scheduling Algorithm&nbsp;(RCGBSA) is proposed accordingly. Simulations are conducted to demonstrate the performance of the RCGBSA.},
journal = {ACM Trans. Sen. Netw.},
month = aug,
articleno = {30},
numpages = {21},
keywords = {Wireless sensor networks, network latency, data collision, data aggregation, NP-hard}
}

@inproceedings{10.1145/3546632.3546887,
author = {Qi, Xia and Zhang, Xiaoman and Xu, Hanting},
title = {A System Dynamics Approach for Sensitivity Analysis of BIM Technology Application Risk},
year = {2022},
isbn = {9781450396363},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3546632.3546887},
doi = {10.1145/3546632.3546887},
abstract = {The application scope of BIM technology in the engineering field is gradually expanding, but the risk of BIM technology cannot be ignored. Based on the literature review, this paper analyzes the risk factors of BIM technology and constructs a system dynamics model of BIM technology application risk including the aspects of BIM operation environment, organizational cognition, technology investment, and application environment. Through the sensitivity analysis of exogenous variables, which are regarded as the decisive role in the system as a whole, it is determined that BIM operational environment risk and organizational cognitive risk are easily affected by the change of risk value of risk factors, and the risk factors of the accuracy of data, the complexity of BIM software operation, the unclear ownership of data and the imperfect contract system have a significant impact on BIM application risk.},
booktitle = {Proceedings of the 2022 International Conference on Computational Infrastructure and Urban Planning},
pages = {99–107},
numpages = {9},
keywords = {BIM, risk, sensitivity analysis, system dynamics},
location = {Nanchang, China},
series = {CIUP '22}
}

@inproceedings{10.1145/3489517.3530519,
author = {Poirot, Valentin and Harms, Oliver and Martens, Hendric and Landsiedel, Olaf},
title = {BlueSeer: AI-driven environment detection via BLE scans},
year = {2022},
isbn = {9781450391429},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3489517.3530519},
doi = {10.1145/3489517.3530519},
abstract = {IoT devices rely on environment detection to trigger specific actions, e.g., for headphones to adapt noise cancellation to the surroundings. While phones feature many sensors, from GNSS to cameras, small wearables must rely on the few energy-efficient components they already incorporate. In this paper, we demonstrate that a Bluetooth radio is the only component required to accurately classify environments and present BlueSeer, an environment-detection system that solely relies on received BLE packets and an embedded neural network. BlueSeer achieves an accuracy of up to 84\% differentiating between 7 environments on resource-constrained devices, and requires only ~ 12 ms for inference on a 64 MHz microcontroller-unit.},
booktitle = {Proceedings of the 59th ACM/IEEE Design Automation Conference},
pages = {871–876},
numpages = {6},
keywords = {BLE, bluetooth low energy, embedded neural network, environment classification, environment detection},
location = {San Francisco, California},
series = {DAC '22}
}

@inproceedings{10.1145/3489517.3530489,
author = {Malawade, Arnav Vaibhav and Mortlock, Trier and Faruque, Mohammad Abdullah Al},
title = {EcoFusion: energy-aware adaptive sensor fusion for efficient autonomous vehicle perception},
year = {2022},
isbn = {9781450391429},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3489517.3530489},
doi = {10.1145/3489517.3530489},
abstract = {Autonomous vehicles use multiple sensors, large deep-learning models, and powerful hardware platforms to perceive the environment and navigate safely. In many contexts, some sensing modalities negatively impact perception while increasing energy consumption. We propose EcoFusion: an energy-aware sensor fusion approach that uses context to adapt the fusion method and reduce energy consumption without affecting perception performance. EcoFusion performs up to 9.5\% better at object detection than existing fusion methods with approximately 60\% less energy and 58\% lower latency on the industry-standard Nvidia Drive PX2 hardware platform. We also propose several context-identification strategies, implement a joint optimization between energy and performance, and present scenario-specific results.},
booktitle = {Proceedings of the 59th ACM/IEEE Design Automation Conference},
pages = {481–486},
numpages = {6},
location = {San Francisco, California},
series = {DAC '22}
}

@inproceedings{10.1145/3538969.3544419,
author = {Mu\~{n}oz, Antonio},
title = {Secure Mobile Agents on Embedded Boards: a TPM based solution},
year = {2022},
isbn = {9781450396707},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3538969.3544419},
doi = {10.1145/3538969.3544419},
abstract = {Security can be considered one of the essential aspects of any software system today. The current landscape is constantly evolving and new computing models are appearing at the same time as different attacks emerge. All this means that there is an increasing need for new security solutions. Among the different aspects that are opening up, this work focuses on the protection of sensitive data. In particular, an environment based on mobile agents is considered, which contains sensitive information that needs to be protected. To simulate an Internet of Things (IoT) environment, the agencies on which the agents run are deployed on Raspberry Pi devices.},
booktitle = {Proceedings of the 17th International Conference on Availability, Reliability and Security},
articleno = {104},
numpages = {7},
keywords = {Cryptographic Hardware, Embedded Boards, IoT, Raspberry pi, Secure Mobile Agent, TPM(Trusted Platform Module)},
location = {Vienna, Austria},
series = {ARES '22}
}

