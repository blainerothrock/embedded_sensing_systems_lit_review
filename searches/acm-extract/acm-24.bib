@inproceedings{10.1145/3627050.3631578,
author = {Wang, Jinjin and Du, Yizhou and Wang, Xiangyu and Ma, Chengyan and Lu, Di and Xi, Ning},
title = {TEE-Assisted Time-Scale Database Management System on IoT devices},
year = {2024},
isbn = {9798400708541},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3627050.3631578},
doi = {10.1145/3627050.3631578},
abstract = {Internet of Things (IoT) devices are usually vulnerable to attackers due to design imperfections and a lack of security measures. Since these devices are commonly used to collect data, safeguarding the security of data originating from them becomes an imperative priority. Encrypted database is a solution that takes both data security and availability into account. However, due to the resource-constrained nature of IoT devices, the implementation of existing encrypted databases poses challenges. Furthermore, existing encrypted databases only ensure data storage security, but they overlook data confidentiality while it is being processed in the device’s memory. To address the above issues, we devised a TEE-assisted encrypted database for managing sensitive information on embedded devices. By leveraging the protective capabilities offered by Trusted Execution Environment (TEE), our design can protect the confidentiality and integrity of data in a full life-cycle. Additionally, as IoT devices are frequently employed for collecting time-series data, we addressed the challenge of high-frequency data insertion by utilizing the Switchless-Feature and changing the data storage structure. Experiments demonstrate that our system’s data operation time is 30-60\% faster than that of a similar solution, SMAUG&nbsp;[4], and it significantly enhances performance for high-frequency data insertion.},
booktitle = {Proceedings of the 13th International Conference on the Internet of Things},
pages = {253–259},
numpages = {7},
keywords = {IoT devices, Trusted Execution Environment, data security, encrypted database},
location = {Nagoya, Japan},
series = {IoT '23}
}

@inproceedings{10.1145/3627050.3631575,
author = {Sorysz, Joanna and Krupp, Lars and Nshimyimana, Dominique and Lukowicz, Paul},
title = {Beyond the Pocket: Preparing a Study on the Variations of Wearable Device Location},
year = {2024},
isbn = {9798400708541},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3627050.3631575},
doi = {10.1145/3627050.3631575},
abstract = {Wearable devices have become ubiquitous in our daily lives, constantly collecting and analyzing data based on our activities. However, what these devices measure and, therefore, the accuracy of algorithms using this data can be influenced by the device’s placement. For instance, a smartphone in a handbag might not track steps as accurately as one in a trouser pocket. The varied locations in which individuals wear devices is underexplored. We intend to conduct a cross-sectional study surveying the most common ways people wear and utilize wearables in their daily lives. We expect the results of this study to influence how research and industry use the sensor data produced by wearable devices, ultimately leading to more precise algorithms that produce satisfying results for a more diverse set of users.},
booktitle = {Proceedings of the 13th International Conference on the Internet of Things},
pages = {228–231},
numpages = {4},
keywords = {Human Computer Interaction, Internet of Things, Study, Wearables},
location = {Nagoya, Japan},
series = {IoT '23}
}

@inproceedings{10.1145/3627050.3627065,
author = {Tverdal, Simeon and Goknil, Arda and Nguyen, Phu and Husom, Erik Johannes and Sen, Sagar and Ruh, Jan and Flamigni, Francesca},
title = {Edge-based Data Profiling and Repair as a Service for IoT},
year = {2024},
isbn = {9798400708541},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3627050.3627065},
doi = {10.1145/3627050.3627065},
abstract = {With the proliferation of IoT devices and the consequent exponential growth in data generation, ensuring data quality has become a critical challenge in IoT applications. Erroneous data can significantly impact the reliability and effectiveness of decision-making processes and downstream analytics. Leveraging the computational abilities of edge devices enables data profiling and repair tasks at the edge, allowing for immediate remediation of erroneous data within the data stream and improved scalability through distributed repair across multiple edge devices. Cloud-based data profiling and repair methods have been extensively researched, but limited computational resources constrain their applicability at edge/fog devices. To overcome this limitation and enhance generalizability, Machine Learning (ML) offers a promising solution, allowing sensor substitution, missing value prediction, and corrupt data replacement. ML-based data repair techniques can be flexibly deployed at the edge using containerized repair services for real-time data repair. In this paper, we propose and assess EDPRaaS (Edge-based Data Profiling and Repair as a Service), a novel approach designed for efficient data quality profiling and repair in IoT environments. EDPRaaS incorporates an ML-based data repair component, enabling real-time data repair at the edge. It leverages pandas profiling and Great Expectations tools for data profiling, providing comprehensive insights into the dataset and detecting data quality issues.},
booktitle = {Proceedings of the 13th International Conference on the Internet of Things},
pages = {17–24},
numpages = {8},
keywords = {Edge computing, data profiling, data quality, data repair},
location = {Nagoya, Japan},
series = {IoT '23}
}

@inproceedings{10.1145/3627050.3627064,
author = {El Jaouhari, Saad and Etiabi, Yaya},
title = {FedCTI: Federated Learning and Cyber Threat Intelligence on the Edge for secure IoT Networks},
year = {2024},
isbn = {9798400708541},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3627050.3627064},
doi = {10.1145/3627050.3627064},
abstract = {The rapid increase in the number of Internet of Things (IoT) has brought numerous benefits and conveniences, but it has also introduced significant cybersecurity challenges. IoT devices are often connected to networks and to the internet, making them potential targets for cyberattacks (e.g., Mirai attack). As the IoT ecosystem grows, there’s a pressing need to enhance cybersecurity measures to ensure the protection of these interconnected devices and the data they handle. On the other hand, Cyber Threat Intelligence (CTI) involves the collection, analysis, and distribution of information about potential and ongoing cyber threats. CTI helps organizations understand the threat landscape and take proactive measures to mitigate risks. In the context of IoT, having timely and accurate CTI is crucial for identifying emerging threats and vulnerabilities. While sharing CTI knowledge is important, doing so in a distributed IoT environment presents challenges. The data generated and collected by IoT devices can be sensitive and private, making it essential to find ways to share CTI knowledge without compromising data privacy. This research focuses on leveraging Federated Learning (FL) techniques to facilitate secure and privacy-preserving CTI knowledge sharing in IoT networks by proposing a solution called FedCTI. This paper explores the potential benefits, architecture, experiments, and challenges associated with using FL for sharing CTI knowledge to secure IoT systems.},
booktitle = {Proceedings of the 13th International Conference on the Internet of Things},
pages = {98–104},
numpages = {7},
keywords = {Attacks, Cyber Threat Intelligence, Cybersecurity, Defense, Federated learning, IoT, Knowledge, Mitigation, Threats},
location = {Nagoya, Japan},
series = {IoT '23}
}

@inproceedings{10.1145/3627050.3627056,
author = {Mayumi, Daiki and Nakamura, Yugo and Matsuda, Yuki and Misaki, Shinya and Yasumoto, Keiichi},
title = {Kaolid: a Lid-type Olfactory Interface to Present Retronasal Smell towards Beverage Flavor Augmentation},
year = {2024},
isbn = {9798400708541},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3627050.3627056},
doi = {10.1145/3627050.3627056},
abstract = {In this paper, we introduce Kaolid, an olfactory interface that uses a lid mechanism to augment the flavor of beverages by delivering scents as retronasal smell. Kaolid aims to promote the consumption of healthier beverages by intensifying their perceived taste through the release of scents during drinking. The system features a compact olfactory display and an IMU sensor, triggering scents in response to drinking movements. It comes in two models: a straw-type for cold beverages and a cup-type for hot drinks. We tested the interface using sparkling and hot water and measured its efficacy in enhancing perceived sweetness when paired with scents. Results showed significant enhancements in all evaluation metrics (taste satisfaction, perceived sweetness, and preference) with the straw-type device. Notably, the perceived sweetness increased by an amount equivalent to about 2.88 grams of sugar when a retronasal smell was introduced compared to when no scent was present. This innovative interface holds promise in elevating the flavor of sugar-free drinks and could support those aiming to limit sugar consumption. Furthermore, this research contributes to the future of IoT systems for health support by harnessing the power of scent, opening avenues for novel approaches in sensory-driven well-being advancements.},
booktitle = {Proceedings of the 13th International Conference on the Internet of Things},
pages = {1–8},
numpages = {8},
keywords = {Drinking activity recognition, Internet of things, Olfactory device, Persuasive technology, Tasting change},
location = {Nagoya, Japan},
series = {IoT '23}
}

@article{10.1145/3641511,
author = {Alsubhi, Arwa and Babatunde, Simeon and Tobias, Nicole and Sorber, Jacob},
title = {Stash: Flexible Energy Storage for Intermittent Sensors},
year = {2024},
issue_date = {March 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {23},
number = {2},
issn = {1539-9087},
url = {https://doi.org/10.1145/3641511},
doi = {10.1145/3641511},
abstract = {Batteryless sensors promise a sustainable future for sensing, but they face significant challenges when storing and using environmental energy. Incoming energy can fluctuate unpredictably between periods of scarcity and abundance, and device performance depends on both incoming energy and how much a device can store. Existing batteryless devices have used fixed or run-time selectable front-end capacitor banks to meet the energy needs of different tasks. Neither approach adapts well to rapidly changing energy harvesting conditions, nor does it allow devices to store excess energy during times of abundance without sacrificing performance. This article presents Stash, a hardware back-end energy storage technique that allows batteryless devices to charge quickly and store excess energy when it is abundant, extending their operating time and carrying out additional tasks without compromising the main ones. Stash performs like a small capacitor device when small capacitors excel and like a large capacitor device when large capacitors excel, with no additional software complexity and negligible power overhead. We evaluate Stash using two applications—temperature sensing and wearable activity monitoring—under both synthetic solar energy and recorded solar and thermal traces from various human activities. Our results show that Stash increased sensor coverage by up to 15\% under variable energy-harvesting conditions when compared to competitor configurations that used fixed small, large, and reconfigurable front-end energy storage.},
journal = {ACM Trans. Embed. Comput. Syst.},
month = mar,
articleno = {18},
numpages = {23},
keywords = {Batteryless, intermittent computing, energy harvesting}
}

@article{10.1145/3641861,
author = {Sah, Ramesh Kumar and Ghasemzadeh, Hassan},
title = {Adversarial Transferability in Embedded Sensor Systems: An Activity Recognition Perspective},
year = {2024},
issue_date = {March 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {23},
number = {2},
issn = {1539-9087},
url = {https://doi.org/10.1145/3641861},
doi = {10.1145/3641861},
abstract = {Machine learning algorithms are increasingly used for inference and decision-making in embedded systems. Data from sensors are used to train machine learning models for various smart functions of embedded and cyber-physical systems ranging from applications in healthcare, autonomous vehicles, and national security. However, recent studies have shown that machine learning models can be fooled by adding adversarial noise to their inputs. The perturbed inputs are called adversarial examples. Furthermore, adversarial examples designed to fool one machine learning system are also often effective against another system. This property of adversarial examples is called adversarial transferability and has not been explored in wearable systems to date. In this work, we take the first stride in studying adversarial transferability in wearable sensor systems from four viewpoints: (1) transferability between machine learning models; (2) transferability across users/subjects of the embedded system; (3) transferability across sensor body locations; and (4) transferability across datasets used for model training. We present a set of carefully designed experiments to investigate these transferability scenarios. We also propose a threat model describing the interactions of an adversary with the source and target sensor systems in different transferability settings. In most cases, we found high untargeted transferability, whereas targeted transferability success scores varied from 0\% to 80\%. The transferability of adversarial examples depends on many factors such as the inclusion of data from all subjects, sensor body position, number of samples in the dataset, type of learning algorithm, and the distribution of source and target system dataset. The transferability of adversarial examples decreased sharply when the data distribution of the source and target system became more distinct. We also provide guidelines and suggestions for the community for designing robust sensor systems. Code and dataset used in our analysis is publicly available here.1},
journal = {ACM Trans. Embed. Comput. Syst.},
month = mar,
articleno = {20},
numpages = {31},
keywords = {Sensor systems, human activity recognition, adversarial machine learning, adversarial transferability}
}

@inproceedings{10.1145/3610977.3634957,
author = {Song, Seung Yun and Marin, Nadja and Xiao, Chenzhang and Mansouri, Mahshid and Ramos, Joao and Chen, Yu and Bleakney, Adam W. and Mcdonagh, Deana C. and Norris, William R. and Elliott, Jeannette R. and Malik, Patricia B. and Hsiao-Wecksler, Elizabeth T.},
title = {Driving a Ballbot Wheelchair with Hands-Free Torso Control},
year = {2024},
isbn = {9798400703225},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3610977.3634957},
doi = {10.1145/3610977.3634957},
abstract = {A novel wheelchair called PURE (Personalized Unique Rolling Experience) that uses hands-free (HF) torso lean-to-steer control has been developed for manual wheelchair users (mWCUs). PURE addresses limitations of current wheelchairs, such as the inability to use both hands for life experiences instead of propulsion. PURE uses a ball-based robot drivetrain to offer a compact, self-balancing, omnidirectional mobile device. A custom sensor system converts rider torso motions into direction and speed commands to control PURE, which is especially useful if a rider has minimal torso range of motion. We explored whether PURE's HF control performed as well as a traditional joystick (JS) human-robot interface and mWCUs, who may have reduced torso motion, performed as well as able-bodied users (ABUs). 10 mWCUs and 10 ABUs were trained and tested to drive PURE through courses replicating indoor environments. Each participant adjusted personal sensitivity settings for both HF and JS control. Repeated-measures MANOVA tests suggested that the effectiveness (number of collisions), efficiency (completion time), comfort (NASA TLX scores except physical demand), and robustness (index of performances) were similar for HF and JS control and between mWCUs and ABUs for all sections. These results suggest that PURE provides an effective method for controlling this new omnidirectional wheelchair by only using torso motion thus leaving both hands to be used for other tasks during propulsion.},
booktitle = {Proceedings of the 2024 ACM/IEEE International Conference on Human-Robot Interaction},
pages = {678–686},
numpages = {9},
keywords = {lean-to-steer, mobile robot, mobility device, self-balancing},
location = {Boulder, CO, USA},
series = {HRI '24}
}

@article{10.1145/3638250,
author = {Nouma, Saif E. and Yavuz, Attila A.},
title = {Trustworthy and Efficient Digital Twins in Post-Quantum Era with Hybrid Hardware-Assisted Signatures},
year = {2024},
issue_date = {June 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {20},
number = {6},
issn = {1551-6857},
url = {https://doi.org/10.1145/3638250},
doi = {10.1145/3638250},
abstract = {Digital Twins (DT) virtually model cyber-physical objects via sensory inputs by simulating or monitoring their behavior. Therefore, DTs usually harbor vast quantities of Internet of Things (IoT) components (e.g., sensors) that gather, process, and offload sensitive information (e.g., healthcare) to the cloud. It is imperative to ensure the trustworthiness of such sensitive information with long-term and compromise-resilient security guarantees. Digital signatures provide scalable authentication and integrity with non-repudiation and are vital tools for DTs. Post-quantum cryptography (PQC) and forward-secure signatures are two fundamental tools to offer long-term security and breach resiliency. However, NIST-PQC signature standards are exorbitantly costly for embedded DT components and are infeasible when forward-security is also considered. Moreover, NIST-PQC signatures do not admit aggregation, which is a highly desirable feature to mitigate the heavy storage and transmission burden in DTs. Finally, NIST recommends hybrid PQ solutions to enable cryptographic agility and transitional security. Yet, there is a significant gap in the state of the art in the achievement of all these advanced features simultaneously. Therefore, there is a significant need for lightweight digital signatures that offer compromise resiliency and compactness while permitting transitional security into the PQ era for DTs.We create a series of highly lightweight digital signatures called Hardware-ASisted Efficient Signature (HASES) that meets the above requirements. The core of HASES&nbsp;is a hardware-assisted cryptographic commitment construct oracle (CCO) that permits verifiers to obtain expensive commitments without signer interaction. We created three HASES&nbsp;schemes: PQ-HASES&nbsp;is a forward-secure PQ signature, LA-HASES&nbsp;is an efficient aggregate Elliptic-Curve signature, and HY-HASES&nbsp;is a novel hybrid scheme that combines PQ-HASES&nbsp;and LA-HASES&nbsp;with novel strong nesting and sequential aggregation. HASES&nbsp;does not require a secure-hardware on the signer. We prove that HASES&nbsp;schemes are secure and implemented them on commodity hardware and and 8-bit AVR ATmega2560. Our experiments confirm that PQ-HASES&nbsp;and LA-HASES&nbsp;are two magnitudes of times more signer efficient than their PQ and conventional-secure counterparts, respectively. HY-HASES&nbsp;outperforms NIST PQC and conventional signature combinations, offering a standard-compliant transitional solution for emerging DTs. We open-source HASES&nbsp;schemes for public-testing and adaptation.},
journal = {ACM Trans. Multimedia Comput. Commun. Appl.},
month = mar,
articleno = {156},
numpages = {30},
keywords = {Multimedia authentication, digital twins, post-quantum security, cyber-security}
}

@inproceedings{10.1145/3626252.3630820,
author = {Mills, Alan and White, Jonathan and Legg, Phil},
title = {Cyber Funfair: Creating Immersive and Educational Experiences for Teaching Cyber Physical Systems Security},
year = {2024},
isbn = {9798400704239},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3626252.3630820},
doi = {10.1145/3626252.3630820},
abstract = {Delivering meaningful and inspiring cyber security education for younger audiences can often be a challenge due to limited expertise and resources. Key to any outreach activity is that it both develops a learner's curiosity, as well as providing educational objectives. To address this need, we developed a novel learning and awareness activity that addresses the Cyber Physical Systems (CPS) Security knowledge area as mapped by the Cyber Security Body of Knowledge (CyBOK). At the core of our activity is the integration of the Raspberry Pi device with LEGO SPIKE kits. LEGO SPIKE is part of the LEGO Education system that combines colourful LEGO building blocks with motors and sensors, creating an adaptable and engaging learning environment. This hands-on approach allows participants to witness the tangible consequences of cyber and network actions in a physical and engaging format. To evaluate the effectiveness of the activity, we used the activity as part of an outreach activity day attended by approximately 300 students aged between 12-14 from schools across the West of England. Participants of the activity were surveyed and the results showed an increase in understanding of CPS specific and wider cyber security for over 90\% of respondents. Activity engagement was also well received with no negative feedback. We report on our survey findings and discuss best practices to support other practitioners in developing hands-on interactive experiences for engaging and educational cyber security activities.},
booktitle = {Proceedings of the 55th ACM Technical Symposium on Computer Science Education V. 1},
pages = {847–852},
numpages = {6},
keywords = {cyber physical systems, cyber security education},
location = {Portland, OR, USA},
series = {SIGCSE 2024}
}

@inproceedings{10.1145/3638569.3638580,
author = {Thulasi, K and Balakrishnan, Sumathi and Yue, Lu and Monpreeyadee, Rattana and Fatima, Syeda Rahmathunnisa and Bin Rosli, Mohammad Izhar Shafiq and Wei, Giok Qi and Malarvili, MB},
title = {IoT-Enabled Wearable Prototype: Detecting Signs of Depression},
year = {2024},
isbn = {9798400716331},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3638569.3638580},
doi = {10.1145/3638569.3638580},
abstract = {The emergence of the Internet of Things (IoT) offers new possibilities for mental health care, including remote monitoring and early detection of depressive symptoms. This paper presents the design and development of a smart monitoring system called "MindTrack" aimed at addressing the long-term treatment and monitoring challenges of depression. MindTrack is composed of smart wearable devices integrated with a real-time monitoring desktop application. It passively monitors patients’ behavioral and physiological data, enabling an objective assessment of depressive symptoms. The proposed architecture combines Analog-to-Digital Converters (ADCs) and WiFi-HaLoW (IEEE 802.11ah) protocols for efficient data transmission, edge computing and cloud connectivity incorporation for storage and analysis, various sensor utilization in the perception layer to track the patient's well-being and includes a patient-oriented smart wearable device operating system (OS) and a desktop application for psychologists to monitor and aid in treatment planning. None of the existing studies utilized a comprehensive combination of sensors specifically tailored for monitoring patients with Major Depressive Disorder (MDD). Moreover, there's limited focus on efficient power resources and security risk management. Hence, this paper proposes Mindtrack as a reliable and usable solution for improving specialized mental health care and addressing the challenges associated with MDD treatment and monitoring.},
booktitle = {Proceedings of the 2023 7th International Conference on Computational Biology and Bioinformatics},
pages = {78–84},
numpages = {7},
keywords = {Internet of Things, Major depressive disorder, Monitoring, Wearable Device},
location = {Kuala Lumpur, Malaysia},
series = {ICCBB '23}
}

@inproceedings{10.1145/3626252.3630892,
author = {Kramarczuk, Kristina and Atchison, Kate and Hilliard, Monica and Plane, Jandelyn and Bond, Sally and Rudy, Caitlin and Weintrop, David},
title = {Micro-internships and Career Focused Programs as Mechanisms for Diversifying Computing},
year = {2024},
isbn = {9798400704239},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3626252.3630892},
doi = {10.1145/3626252.3630892},
abstract = {The demand for computing talent is at an all-time high, but not everyone feels equally welcome or has equal access to pursue opportunities in technology fields. Women, non-binary, Black, Hispanic/Latino/a/x, and first-generation students are the least likely to have access to paid undergraduate internships that lead to job opportunities in technology companies. This experience report discusses two programs designed to address the lack of internships among historically excluded populations: a micro-internship program and a career program. We present data showing the role that each program played in creating professional pathways for racially diverse undergraduate women and non-binary students. Both programs prepare these undergraduates for professional environments by exposing them to tech careers and developing their social capital through professional networking. Quantitative and qualitative data were collected as well as summer employment plans to evaluate the effectiveness of the program. We present the short- and long-term impact of each program on students' career interests and sense of belonging in computing. A summary of lessons learned from implementing each program are also shared for stakeholders interested in designing similar programs.},
booktitle = {Proceedings of the 55th ACM Technical Symposium on Computer Science Education V. 1},
pages = {694–700},
numpages = {7},
keywords = {computing careers, undergraduate computing education, workforce development},
location = {Portland, OR, USA},
series = {SIGCSE 2024}
}

@inproceedings{10.1145/3638837.3638856,
author = {Zhu, Peizhi and Li, Dajun and Guo, Lihui and Lin, Fanqiang},
title = {Design of RTOS-based Wireless Remote Monitoring System for Indoor Environment},
year = {2024},
isbn = {9798400709265},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3638837.3638856},
doi = {10.1145/3638837.3638856},
abstract = {With the development of low-cost microcontrollers, sensors and wireless communications, intelligent environment monitoring based on the Internet of Things (IoT) has become possible. In this paper, an indoor environment monitoring system constructed by sensor network is realized. The system consists of distributed sensing nodes, which contain temperature and humidity, human infrared, voice recognition and camera sensors, etc. The nodes are connected to STM32 microcontrollers and WIFI modules and are scheduled in real time using free real time operating system(FreeRTOS). The visual and time series sensing data are transmitted to the server via WIFI in real time, and the user can monitor the system remotely by using the PYQT interface program on the PC. The system can also control home appliances by voice. The data interaction uses self-built WIFI module in AP mode for SOCKET communication. Through rigorous testing, the system demonstrates the capability of data communication, low-latency video streaming, and bi-directional control. The sensor network and real-time OS based architecture utilizes parallel execution to balance different temporal tasks and realize an agile cyber-physical system. This paper provides a reference for the underlying software infrastructure of intelligent buildings, embodying the integrated application of real-time scheduling, sensor networks and human-computer interaction.},
booktitle = {Proceedings of the 2023 12th International Conference on Networks, Communication and Computing},
pages = {127–132},
numpages = {6},
keywords = {Internet of Things, Real Time Operating System, STM32 data acquisition, Sensor networks, WIFI},
location = {Osaka, Japan},
series = {ICNCC '23}
}

@inproceedings{10.1145/3638837.3638862,
author = {Li, Lin and He, Zhili and Guan, Yuwei and Zhang, Hongguo},
title = {A Monitoring System for Complex Forest Environment Based on Wireless Sensor Network},
year = {2024},
isbn = {9798400709265},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3638837.3638862},
doi = {10.1145/3638837.3638862},
abstract = {In response to the problems of high energy consumption, short communication distance, and unstable network topology of wireless sensor networks in complex forest environments, this paper proposes a monitoring system for complex forest environments. The proposed system utilizes LoRa technology to design a wireless sensor network that enables low power consumption and long-distance transmission. In addition, a self-organizing network protocol is employed to ensure stable and reliable data transmission in the forest area. Meanwhile, a cloud platform is developed to receive, analyze, and visualize forest monitoring data in real-time, as well as to provide early warning information. The field test results show that the system can effectively capture real-time changes in environmental factor parameters within the forest area. The technical features of the proposed system, such as low power consumption, self-organizing network, stable and reliable communication, and long transmission distance, make it suitable for forest fire monitoring in harsh environments.},
booktitle = {Proceedings of the 2023 12th International Conference on Networks, Communication and Computing},
pages = {149–154},
numpages = {6},
keywords = {Environmental monitoring in forest regions, Low power consumption, Reliable networking, Wireless sensor networks},
location = {Osaka, Japan},
series = {ICNCC '23}
}

@inproceedings{10.1145/3638837.3638859,
author = {Zhu, Shilin and Lin, Fanqiang},
title = {Intelligent Agricultural Water and Fertilizer Irrigation System based on ZigBee Technology and STM32},
year = {2024},
isbn = {9798400709265},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3638837.3638859},
doi = {10.1145/3638837.3638859},
abstract = {With the continuous development of China's Internet of Things technology, the application of this technology in agriculture is becoming more and more extensive. China's agricultural irrigation has shown a trend of automation, but the current automatic irrigation system cannot automatically control the amount of water irrigation, and it is not intelligent enough. The irrigation water closely related to the development of modern green agriculture is far from meeting the development requirements of China 's agriculture. When the irrigation amount is too large, it will cause serious waste of water resources, and when the irrigation amount is too small, it will affect the growth of crops. Based on this situation, this paper designs an intelligent agricultural irrigation system, which combines the communication module with the single-chip microcomputer, and monitors the data of the crop growth environment in real time with the help of ZigBee wireless communication and sensors. According to different crop growth models and soil nutrient content and the characteristics and laws of fertilizers needed by crops, an intelligent irrigation system platform model for real-time monitoring of crop growth environment information based on the Internet of Things is constructed. After testing, the model can predict the amount of water and fertilizer required in the process of crop growth, so as to make timely and appropriate irrigation decisions scientifically, so as to improve the level of irrigation management. The system can greatly alleviate the problem of waste of water resources and soil compaction. It can not only realize water saving and energy saving, but also promote agricultural production and income increase. It provides a technical basis and support platform for the follow-up development of intelligent agriculture.},
booktitle = {Proceedings of the 2023 12th International Conference on Networks, Communication and Computing},
pages = {144–148},
numpages = {5},
keywords = {DHT11, ZigBee technology, intelligent water and fertilizer irrigation},
location = {Osaka, Japan},
series = {ICNCC '23}
}

@article{10.1145/3643555,
author = {Bian, Sizhen and Liu, Mengxi and Zhou, Bo and Lukowicz, Paul and Magno, Michele},
title = {Body-Area Capacitive or Electric Field Sensing for Human Activity Recognition and Human-Computer Interaction: A Comprehensive Survey},
year = {2024},
issue_date = {March 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {8},
number = {1},
url = {https://doi.org/10.1145/3643555},
doi = {10.1145/3643555},
abstract = {Due to the fact that roughly sixty percent of the human body is essentially composed of water, the human body is inherently a conductive object, being able to, firstly, form an inherent electric field from the body to the surroundings and secondly, deform the distribution of an existing electric field near the body. Body-area capacitive sensing, also called body-area electric field sensing, is becoming a promising alternative for wearable devices to accomplish certain tasks in human activity recognition (HAR) and human-computer interaction (HCI). Over the last decade, researchers have explored plentiful novel sensing systems backed by the body-area electric field, like the ring-form smart devices for sign language recognition, the room-size capacitive grid for indoor positioning, etc. On the other hand, despite the pervasive exploration of the body-area electric field, a comprehensive survey does not exist for an enlightening guideline. Moreover, the various hardware implementations, applied algorithms, and targeted applications result in a challenging task to achieve a systematic overview of the subject. This paper aims to fill in the gap by comprehensively summarizing the existing works on body-area capacitive sensing so that researchers can have a better view of the current exploration status. To this end, we first sorted the explorations into three domains according to the involved body forms: body-part electric field, whole-body electric field, and body-to-body electric field, and enumerated the state-of-art works in the domains with a detailed survey of the backed sensing tricks and targeted applications. We then summarized the three types of sensing frontends in circuit design, which is the most critical part in body-area capacitive sensing, and analyzed the data processing pipeline categorized into three kinds of approaches. The outcome will benefit researchers for further body-area electric field explorations. Finally, we described the challenges and outlooks of body-area electric sensing, followed by a conclusion, aiming to encourage researchers to further investigations considering the pervasive and promising usage scenarios backed by body-area capacitive sensing.},
journal = {Proc. ACM Interact. Mob. Wearable Ubiquitous Technol.},
month = mar,
articleno = {4},
numpages = {49},
keywords = {Electric field sensing, body-area network, body-area sensing, capacitive sensing, human activity recognition, human machine interaction, wearable}
}

@article{10.1145/3643499,
author = {Ley-Flores, Judith and Vidal, Laia Turmo and Segura, Elena M\'{a}rquez and Singh, Aneesha and Bevilacqua, Frederic and Cuadrado, Francisco and Dur\'{a}n, Joaqu\'{\i}n Roberto D\'{\i}az and Valdiviezo-Hern\'{a}ndez, Omar and S\'{a}nchez-Martin, Milagrosa and Tajadura-Jim\'{e}nez, Ana},
title = {Co-Designing Sensory Feedback for Wearables to Support Physical Activity through Body Sensations},
year = {2024},
issue_date = {March 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {8},
number = {1},
url = {https://doi.org/10.1145/3643499},
doi = {10.1145/3643499},
abstract = {Many technologies for promoting physical activity (PA) give limited importance to critical variables for engagement in PA, such as negative body perceptions. Here, we aim to address this gap by incorporating barriers and experienced body sensations into the design process for wearables and body-based devices thus expanding the design space for such technologies. We first report four co-design workshops with physically inactive participants (n=9); in these workshops, we explored tangible tools (i) to sensitize people to body sensations experienced when facing barriers to PA and (ii) to ideate how haptic and auditory feedback could transform body sensations to increase body-awareness and engagement in PA; results show several interactive sensorial patterns with potential to inform the design of body transformation wearables. These were validated through a follow-up workshop (n=13 participants) and reflections based on insights from a literature review. Our findings are significant for the design of ubiquitous technology to support and initiate PA in everyday contexts through a novel approach of transforming body perceptions/ sensations related to PA barriers. We contribute design inspirations and cards for identifying barriers to PA and to empower designers and researchers to integrate them early in the design process.},
journal = {Proc. ACM Interact. Mob. Wearable Ubiquitous Technol.},
month = mar,
articleno = {40},
numpages = {31},
keywords = {embodied design methods, physical activity, sensory feedback, wearables}
}

@article{10.1145/3643551,
author = {Xu, Chongzhi and Zheng, Xiaolong and Ren, Zhiyuan and Liu, Liang and Ma, Huadong},
title = {UHead: Driver Attention Monitoring System Using UWB Radar},
year = {2024},
issue_date = {March 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {8},
number = {1},
url = {https://doi.org/10.1145/3643551},
doi = {10.1145/3643551},
abstract = {The focus of Advanced driver-assistance systems (ADAS) is extending from the vehicle and road conditions to the driver because the driver's attention is critical to driving safety. Although existing sensor and camera based methods can monitor driver attention, they rely on specialised hardware and environmental conditions. In this paper, we aim to develop an effective and easy-to-use driver attention monitoring system based on UWB radar. We exploit the strong association between head motions and driver attention and propose UHead that infers driver attention by monitoring the direction and angle of the driver's head rotation. The core idea is to extract rotational time-frequency representation from reflected signals and to estimate head rotation angles from complex head reflections. To eliminate the dynamic noise generated by other body parts, UHead leverages the large magnitude and high velocity of head rotation to extract head motion information from the dynamically coupled information. UHead uses a bilinear joint time-frequency representation to avoid the loss of time and frequency resolution caused by windowing of traditional methods. We also design a head structure-based rotation angle estimation algorithm to accurately estimate the rotation angle from the time-varying rotation information of multiple reflection points in the head. Experimental results show that we achieve 12.96° median error of 3D head rotation angle estimation in real vehicle scenes.},
journal = {Proc. ACM Interact. Mob. Wearable Ubiquitous Technol.},
month = mar,
articleno = {25},
numpages = {28},
keywords = {Driver Attention Monitoring, Head Rotation, Ultra-Wideband, Wireless Sensing}
}

@article{10.1145/3643508,
author = {Khalid, Maryam and Klerman, Elizabeth B. and McHill, Andrew W. and Phillips, Andrew J. K. and Sano, Akane},
title = {SleepNet: Attention-Enhanced Robust Sleep Prediction using Dynamic Social Networks},
year = {2024},
issue_date = {March 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {8},
number = {1},
url = {https://doi.org/10.1145/3643508},
doi = {10.1145/3643508},
abstract = {Sleep behavior significantly impacts health and acts as an indicator of physical and mental well-being. Monitoring and predicting sleep behavior with ubiquitous sensors may therefore assist in both sleep management and tracking of related health conditions. While sleep behavior depends on, and is reflected in the physiology of a person, it is also impacted by external factors such as digital media usage, social network contagion, and the surrounding weather. In this work, we propose SleepNet, a system that exploits social contagion in sleep behavior through graph networks and integrates it with physiological and phone data extracted from ubiquitous mobile and wearable devices for predicting next-day sleep labels about sleep duration. Our architecture overcomes the limitations of large-scale graphs containing connections irrelevant to sleep behavior by devising an attention mechanism. The extensive experimental evaluation highlights the improvement provided by incorporating social networks in the model. Additionally, we conduct robustness analysis to demonstrate the system's performance in real-life conditions. The outcomes affirm the stability of SleepNet against perturbations in input data. Further analyses emphasize the significance of network topology in prediction performance revealing that users with higher eigenvalue centrality are more vulnerable to data perturbations.},
journal = {Proc. ACM Interact. Mob. Wearable Ubiquitous Technol.},
month = mar,
articleno = {37},
numpages = {34},
keywords = {Graph convolution, contagion, graph neural networks, mobile computing, multimodal sensing, sleep, social network, wearable sensing, well-being prediction}
}

@article{10.1145/3643515,
author = {Wang, Zi and Wang, Yilin and Yang, Jie},
title = {EarSlide: a Secure Ear Wearables Biometric Authentication Based on Acoustic Fingerprint},
year = {2024},
issue_date = {March 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {8},
number = {1},
url = {https://doi.org/10.1145/3643515},
doi = {10.1145/3643515},
abstract = {Ear wearables (earables) are emerging platforms that are broadly adopted in various applications. There is an increasing demand for robust earables authentication because of the growing amount of sensitive information and the IoT devices that the earable could access. Traditional authentication methods become less feasible due to the limited input interface of earables. Nevertheless, the rich head-related sensing capabilities of earables can be exploited to capture human biometrics. In this paper, we propose EarSlide, an earable biometric authentication system utilizing the advanced sensing capacities of earables and the distinctive features of acoustic fingerprints when users slide their fingers on the face. It utilizes the inward-facing microphone of the earables and the face-ear channel of the ear canal to reliably capture the acoustic fingerprint. In particular, we study the theory of friction sound and categorize the characteristics of the acoustic fingerprints into three representative classes, pattern-class, ridge-groove-class, and coupling-class. Different from traditional fingerprint authentication only utilizes 2D patterns, we incorporate the 3D information in acoustic fingerprint and indirectly sense the fingerprint for authentication. We then design representative sliding gestures that carry rich information about the acoustic fingerprint while being easy to perform. It then extracts multi-class acoustic fingerprint features to reflect the inherent acoustic fingerprint characteristic for authentication. We also adopt an adaptable authentication model and a user behavior mitigation strategy to effectively authenticate legit users from adversaries. The key advantages of EarSlide are that it is resistant to spoofing attacks and its wide acceptability. Our evaluation of EarSlide in diverse real-world environments with intervals over one year shows that EarSlide achieves an average balanced accuracy rate of 98.37\% with only one sliding gesture.},
journal = {Proc. ACM Interact. Mob. Wearable Ubiquitous Technol.},
month = mar,
articleno = {24},
numpages = {29},
keywords = {Biometrics, Earable, Fingerprint, Friction, User Authentication}
}

@article{10.1145/3643547,
author = {Chen, Wenqiang and Lin, Shupei and Peng, Zhencan and Parizi, Farshid Salemi and Heo, Seongkook and Patel, Shwetak and Matusik, Wojciech and Zhao, Wei and Stankovic, John},
title = {ViObject: Harness Passive Vibrations for Daily Object Recognition with Commodity Smartwatches},
year = {2024},
issue_date = {March 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {8},
number = {1},
url = {https://doi.org/10.1145/3643547},
doi = {10.1145/3643547},
abstract = {Knowing the object grabbed by a hand can offer essential contextual information for interaction between the human and the physical world. This paper presents a novel system, ViObject, for passive object recognition that uses accelerometer and gyroscope sensor data from commodity smartwatches to identify untagged everyday objects. The system relies on the vibrations caused by grabbing objects and does not require additional hardware or human effort. ViObject's ability to recognize objects passively can have important implications for a wide range of applications, from smart home automation to healthcare and assistive technologies. In this paper, we present the design and implementation of ViObject, to address challenges such as motion interference, different object-touching positions, different grasp speeds/pressure, and model customization to new users and new objects. We evaluate the system's performance using a dataset of 20 objects from 20 participants and show that ViObject achieves an average accuracy of 86.4\%. We also customize models for new users and new objects, achieving an average accuracy of 90.1\%. Overall, ViObject demonstrates a novel technology concept of passive object recognition using commodity smartwatches and opens up new avenues for research and innovation in this area.},
journal = {Proc. ACM Interact. Mob. Wearable Ubiquitous Technol.},
month = mar,
articleno = {5},
numpages = {26},
keywords = {Object Recognition, Tangible Interaction, Vibration Sensing, Wearable Sensing}
}

@article{10.1145/3643516,
author = {Hu, Zhizhang and Radmehr, Amirmohammad and Zhang, Yue and Pan, Shijia and Nguyen, Phuc},
title = {IOTeeth: Intra-Oral Teeth Sensing System for Dental Occlusal Diseases Recognition},
year = {2024},
issue_date = {March 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {8},
number = {1},
url = {https://doi.org/10.1145/3643516},
doi = {10.1145/3643516},
abstract = {While occlusal diseases - the main cause of tooth loss -- significantly impact patients' teeth and well-being, they are the most underdiagnosed dental diseases nowadays. Experiencing occlusal diseases could result in difficulties in eating, speaking, and chronicle headaches, ultimately impacting patients' quality of life. Although attempts have been made to develop sensing systems for teeth activity monitoring, solutions that support sufficient sensing resolution for occlusal monitoring are missing. To fill that gap, this paper presents IOTeeth, a cost-effective and automated intra-oral sensing system for continuous and fine-grained monitoring of occlusal diseases. The IOTeeth system includes an intra-oral piezoelectric-based sensing array integrated into a dental retainer platform to support reliable occlusal disease recognition. IOTeeth focuses on biting and grinding activities from the canines and front teeth, which contain essential information of occlusion. IOTeeth's intra-oral wearable collects signals from the sensors and fetches them into a lightweight and robust deep learning model called Physioaware Attention Network (PAN Net) for occlusal disease recognition. We evaluate IOTeeth with 12 articulator teeth models from dental clinic patients. Evaluation results show an F1 score of 0.97 for activity recognition with leave-one-out validation and an average F1 score of 0.92 for dental disease recognition for different activities with leave-one-out validation.},
journal = {Proc. ACM Interact. Mob. Wearable Ubiquitous Technol.},
month = mar,
articleno = {7},
numpages = {29},
keywords = {Intra-oral Sensing, Occlusal Disease Recognition}
}

@article{10.1145/3643541,
author = {Alchieri, Leonardo and Abdalazim, Nouran and Alecci, Lidia and Gashi, Shkurta and Gjoreski, Martin and Santini, Silvia},
title = {Lateralization Effects in Electrodermal Activity Data Collected Using Wearable Devices},
year = {2024},
issue_date = {March 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {8},
number = {1},
url = {https://doi.org/10.1145/3643541},
doi = {10.1145/3643541},
abstract = {Electrodermal activity (EDA) is a physiological signal that can be used to infer humans' affective states and stress levels. EDA can nowadays be monitored using unobtrusive wearable devices, such as smartwatches, and leveraged in personal informatics systems. A still largely uncharted issue concerning EDA is the impact on real applications of potential differences observable on signals measured concurrently on the left and right side of the human body. This phenomenon, called lateralization, originates from the distinct functions that the brain's left and right hemispheres exert on EDA. In this work, we address this issue by examining the impact of EDA lateralization in two classification tasks: a cognitive load recognition task executed in the lab and a sleep monitoring task in a real-world setting. We implement a machine learning pipeline to compare the performance obtained on both classification tasks using EDA data collected from the left and right sides of the body. Our results show that using EDA from the side that is not associated with the specific hemisphere activation leads to a significant decline in performance for the considered classification tasks. This finding highlights that researchers and practitioners relying on EDA data should consider possible EDA lateralization effects when deciding on sensor placement.},
journal = {Proc. ACM Interact. Mob. Wearable Ubiquitous Technol.},
month = mar,
articleno = {2},
numpages = {30},
keywords = {Electrodermal Activity, cognitive load, lateralization, machine learning, sleep monitoring, wearable sensing}
}

@inproceedings{10.1145/3638550.3641131,
author = {Malekzadeh, Mohammad and Kawsar, Fahim},
title = {Salted Inference: Enhancing Privacy while Maintaining Efficiency of Split Inference in Mobile Computing},
year = {2024},
isbn = {9798400704970},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3638550.3641131},
doi = {10.1145/3638550.3641131},
abstract = {In split inference, a deep neural network (DNN) is partitioned to run the early part of the DNN at the edge and the later part of the DNN in the cloud. This meets two key requirements for on-device machine learning: input privacy and computation efficiency. Still, an open question in split inference is output privacy, given that the outputs of the DNN are observable in the cloud. While encrypted computing can protect output privacy too, homomorphic encryption requires substantial computation and communication resources from both edge and cloud devices.In this paper, we introduce Salted DNNs: a novel approach that enables clients at the edge, who run the early part of the DNN, to control the semantic interpretation of the DNN's outputs at inference time. Our proposed Salted DNNs maintain classification accuracy and computation efficiency very close to the standard DNN counterparts. Experimental evaluations conducted on both images and wearable sensor data demonstrate that Salted DNNs attain classification accuracy very close to standard DNNs, particularly when the Salted Layer is positioned within the early part to meet the requirements of split inference. Our approach is general and can be applied to various types of DNNs. As a benchmark for future studies, we open-source our code at https://github.com/dr-bell/salted-dnns.},
booktitle = {Proceedings of the 25th International Workshop on Mobile Computing Systems and Applications},
pages = {14–20},
numpages = {7},
keywords = {edge computing, data privacy, split inference, deep neural networks},
location = {San Diego, CA, USA},
series = {HotMobile '24}
}

@inproceedings{10.1145/3638550.3641136,
author = {Romero, Julia and Ferlini, Andrea and Spathis, Dimitris and Dang, Ting and Farrahi, Katayoun and Kawsar, Fahim and Montanari, Alessandro},
title = {OptiBreathe: An Earable-based PPG System for Continuous Respiration Rate, Breathing Phase, and Tidal Volume Monitoring},
year = {2024},
isbn = {9798400704970},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3638550.3641136},
doi = {10.1145/3638550.3641136},
abstract = {In the continuous quest to push the boundaries of mobile healthcare and fitness tracking, monitoring respiratory biomarkers emerges as a pivotal frontier. In this paper, we present OptiBreathe, a lightweight on-device earable system designed to decode the respiratory modulations within photoplethysmography (PPG) signals. OptiBreathe computes three clinical respiratory biomarkers towards enabling continuous respiratory health monitoring with wearable devices. In our effort to bridge respiratory research and earable computing, we collected a first-of-its-kind dataset that empowers researchers to explore in-ear PPG alongside gold-standard spirometry-based ground truth in order to measure respiration rate, breathing phases, and tidal volume. OptiBreathe employs multiple algorithms to measure each respiratory parameter, achieving a best mean absolute error (MAE) of 1.96 breaths per minute on respiratory rate. When estimating breathing phases and tidal volume, OptiBreathe attains an MAE of 0.48 seconds on inspiratory time, 0.14 on inhalation-exhalation ratio (inhalation duration divided by exhalation duration), and a best mean absolute percentage error (MAPE) of 17\% on tidal volume (averaged across subjects). This work shows that the best performing algorithm depends on individuals' unique physiology, and that future research should investigate the relationship between physiological factors and algorithm performances. As we look forward, we highlight the challenges and nuances in harnessing PPG sensors for respiratory monitoring, inviting researchers to build upon our work.},
booktitle = {Proceedings of the 25th International Workshop on Mobile Computing Systems and Applications},
pages = {99–106},
numpages = {8},
keywords = {PPG, earables, breathing phases, tidal volume},
location = {San Diego, CA, USA},
series = {HotMobile '24}
}

@inproceedings{10.1145/3632047.3632068,
author = {Bartalucci, Lorenzo and Brogi, Chiara and Bucci, Alessandro and Topini, Alberto and Della Valle, Andrea and Secciani, Nicola and Ridolfi, Alessandro and Allotta, Benedetto},
title = {A Kinaesthetic Hand Exoskeleton System Toward Robot-augmented Rehabilitation Therapies in the Health 4.0 era},
year = {2024},
isbn = {9798400708152},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3632047.3632068},
doi = {10.1145/3632047.3632068},
abstract = {In the new era of Industry 4.0, digitization and automation are the tipping points for addressing rapidly evolving challenges. The momentum of this movement has underscored the critical importance of developing new technologies to collect, understand and use the enormous amount of data created. This revolutionary wave has also taken root in the healthcare sector, giving rise to the so-called Health 4.0, based on smart machines to provide patients with better, more value-added and more efficient healthcare services. This scenario has contributed to making innovative robot-augmented therapies a hot research topic with potentially significant societal impact. In this context, the authors present the implementation of a new prototype of a kinaesthetic exoskeleton to enhance and recover sensorimotor skills to perform grasping and manipulation via force stimuli from serious rehabilitation games. The discussion includes an initial overview of the system's hardware, both from a mechanical and electronic point of view, motivating the choices made in the design phase. It continues by moving on to a description of the system's low-level and high-level software architecture, along with the control strategy applied to implement progressive resistant force therapy. Finally, an example of serious game was developed as an application case for evaluating the system's usability and extrapolating empirical parameters indicative of responsiveness and accuracy. The results showed that the proposed system can reproduce constant forces with an average error of 0.75 N and standard deviation of 0.3 N with an average reaction time of 0.5 s and standard deviation of 0.4 s.},
booktitle = {Proceedings of the 2023 10th International Conference on Bioinformatics Research and Applications},
pages = {135–142},
numpages = {8},
keywords = {Hand exoskeleton, Health 4.0, Rehabilitative robotics, Rehabilitative serious game, Robot-augmented therapy},
location = {Barcelona, Spain},
series = {ICBRA '23}
}

@inproceedings{10.1145/3629606.3629638,
author = {Zhang, He and Ananda, Robin and Fu, Xinyi and Sun, Zhe and Wang, Xiaoyu and Chen, Keqi and Carroll, John},
title = {Multi-channel Sensor Network Construction, Data Fusion and Challenges for Smart Home},
year = {2024},
isbn = {9798400716454},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3629606.3629638},
doi = {10.1145/3629606.3629638},
abstract = {Both sensor networks and data fusion are essential foundations for developing the smart home Internet of Things (IoT) and related fields. We proposed a multi-channel sensor network construction method involving hardware, acquisition, and synchronization in the smart home environment and a smart home data fusion method (SHDFM) for multi-modal data (position, gait, voice, pose, facial expression, temperature, and humidity) generated in the smart home environment to address the configuration of a multi-channel sensor network, improve the quality and efficiency of various human activities and environmental data collection, and reduce the difficulty of multi-modal data fusion in the smart home. SHDFM contains 5 levels, with inputs and outputs as criteria to provide recommendations for multi-modal data fusion strategies in the smart home. We built a real experimental environment using the proposed method in this paper. To validate our method, we created a real experimental environment — a physical setup in a home-like scenario where the multi-channel sensor network and data fusion techniques were deployed and evaluated. The acceptance and testing results show that the proposed construction and data fusion methods can be applied to the examples with high robustness, replicability, and scalability. Besides, we discuss how smart homes with multi-channel sensor networks can support digital twins.},
booktitle = {Proceedings of the Eleventh International Symposium of Chinese CHI},
pages = {344–351},
numpages = {8},
keywords = {data fusion, internet of things, sensor network, smart home, system},
location = {Denpasar, Bali, Indonesia},
series = {CHCHI '23}
}

@inproceedings{10.1145/3629606.3629645,
author = {Guo, Mengyao and Zhang, Xiaolin and Wang, Zhiyi and Gao, Ze},
title = {Exploring Emotions in Art: Innovations in Biometric Monitoring and Real-Time Visualization},
year = {2024},
isbn = {9798400716454},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3629606.3629645},
doi = {10.1145/3629606.3629645},
abstract = {This paper presents a study on Real-Time Visualizations that investigates the temporal dynamics of artists’ emotional states in the context of visible emotions. The research aims to enhance comprehension within artistic performances by enabling the audience to grasp the performer’s immediate emotions perceptibly. Integrating wearable devices, biometric sensing, emotion recognition algorithms, and real-time visual representations introduces a novel framework to dynamically capture and represent artists’ emotions through color, shape, and movement. The study analyzes data obtained from artists across various disciplines and reveals a strong correlation between emotional states and the visual characteristics of their artworks. The Real-Time Visualizations deepen the audience’s understanding of the performance and facilitate bridging language and cultural barriers. The findings provide insights into the temporal dynamics of emotions during the creative process and offer new approaches to understanding and supporting emotions in art. This research holds significant potential for informing the development of tools to enhance artists’ emotional awareness and expression.},
booktitle = {Proceedings of the Eleventh International Symposium of Chinese CHI},
pages = {404–410},
numpages = {7},
keywords = {Biometric Monitor, Emotion visualization, Physiological signals, Real-Time Visualization, Wearable Installation},
location = {Denpasar, Bali, Indonesia},
series = {CHCHI '23}
}

@article{10.1145/3627164,
author = {Jin, Yunshui and Ma, Minhua and Liu, Yun},
title = {Comparative Study of HMD-based Virtual and Augmented Realities for Immersive Museums: User Acceptance, Medium, and Learning},
year = {2024},
issue_date = {March 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {17},
number = {1},
issn = {1556-4673},
url = {https://doi.org/10.1145/3627164},
doi = {10.1145/3627164},
abstract = {Technologies like Head Mounted Display (HMD)-based Virtual Reality (VR) and Augmented Reality (AR) have made HMD-based immersive museums possible. To investigate the user acceptance, medium, and interaction experience for HMD-based immersive museums, an app entitled The Extended Journey has been designed, developed, and deployed on both VR headsets and AR headsets. Subsequently, a between-subjects design experiment with 62 participants was conducted to measure the user experience and learning outcome in HMD VR and HMD AR conditions. Quantitative results revealed that HMD VR museums had statistically significantly better immersion and empathy compared to HMD AR museums. Qualitative data indicated HMD-based immersive museums were embraced by most young participants while HMD VR had better user acceptance than HMD AR for immersive museums. The interview also demonstrated that the advantage of the HMD-based immersive museum over the traditional online museum is not only the sensory immersion from the medium itself but also the interactive narrative experience that the HMD medium facilitates, especially the natural interaction with the CG characters and the environment in the story.},
journal = {J. Comput. Cult. Herit.},
month = feb,
articleno = {13},
numpages = {17},
keywords = {Virtual Reality (VR), Augmented Reality (AR), Augmented Virtuality (AV), Head Mounted Display (HMD), immersive museum, interactive museum, interactive narrative, immersion, interaction experience, user acceptance}
}

@article{10.1145/3639825,
author = {Fan, Boyu and Su, Xiang and Tarkoma, Sasu and Hui, Pan},
title = {Behave Differently when Clustering: A Semi-asynchronous Federated Learning Approach for IoT},
year = {2024},
issue_date = {May 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {20},
number = {3},
issn = {1550-4859},
url = {https://doi.org/10.1145/3639825},
doi = {10.1145/3639825},
abstract = {The Internet of Things (IoT) has revolutionized the connectivity of diverse sensing devices, generating an enormous volume of data. However, applying machine learning algorithms to sensing devices presents substantial challenges due to resource constraints and privacy concerns. Federated learning (FL) emerges as a promising solution allowing for training models in a distributed manner while preserving data privacy on client devices. We contribute SAFI, a semi-asynchronous FL approach based on clustering to achieve a novel in-cluster synchronous and out-cluster asynchronous FL training mode. Specifically, we propose a three-tier architecture to enable IoT data processing on edge devices and design a clustering selection module to effectively group heterogeneous edge devices based on their processing capacities. The performance of SAFI has been extensively evaluated through experiments conducted on a real-world testbed. As the heterogeneity of edge devices increases, SAFI surpasses the baselines in terms of the convergence time, achieving a speedup of approximately \texttimes{} 3 when the heterogeneity ratio is 7:1. Moreover, SAFI demonstrates favorable performance in non-independent and identically distributed settings and requires lower communication cost compared to FedAsync. Notably, SAFI is the first Java-implemented FL approach and holds significant promise to serve as an efficient FL algorithm in IoT environments.},
journal = {ACM Trans. Sen. Netw.},
month = feb,
articleno = {51},
numpages = {28},
keywords = {Federated learning, smart sensing, edge computing, deep learning}
}

@inproceedings{10.1145/3640912.3640934,
author = {Zhu, Jinyu and Li, He and Duan, Shihui and Zhu, Youyang and Zhao, Chenglin and Deng, Haojiang},
title = {End-to-End Performance Verification of 5G-TSN Converged Network},
year = {2024},
isbn = {9798400716683},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3640912.3640934},
doi = {10.1145/3640912.3640934},
abstract = {With the rapid development of fifth generation (5G) technology, the industrial Internet has increasingly high requirements for 5G deterministic assurance capabilities. 5G deterministic networks (5G DN) include Flexible Ethernet (FlexE), Time-Sensitive Network (TSN), Deterministic Networking (DetNet) and other technologies. Among them, 5G-TSN converged network technology has both the flexibility of 5G and the certainty of TSN technology, and has been written into the 3GPP standard, which has high research value. However, there is no actual measurement data on the end-to-end performance of 5G-TSN converged network at present, so we based on the 5G-TSN test environment. The end-to-end delay, packet loss rate and time synchronization accuracy were measured to verify the performance of 5G-TSN converged network.},
booktitle = {Proceedings of the 2023 International Conference on Communication Network and Machine Learning},
pages = {111–114},
numpages = {4},
location = {Zhengzhou, China},
series = {CNML '23}
}

@article{10.1145/3623615,
author = {Kargarmoakhar, Maral and Ross, Monique and Hazari, Zahra and Secules, Stephen and Weiss, Mark Allen and Georgiopoulos, Michael and Christensen, Kenneth and Solis, Tiana},
title = {The Impact of a Community of Practice Scholarship Program on Students’ Computing Identity},
year = {2024},
issue_date = {March 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {24},
number = {1},
url = {https://doi.org/10.1145/3623615},
doi = {10.1145/3623615},
abstract = {While computing programs in the U.S. are experiencing growth in enrollment trends, they are still grappling with matters related to retention and persistence of computing undergraduates. One construct identified by scholars as having an impact on persistence in computing is computing identity, which is shaped by constructs such as recognition, performance/competence beliefs, sense of belonging, and interest. Likewise, participation in what scholars call communities of practice (CoPs) can aid in the development of their computing identity. To help foster computing identity development, an initiative was designed at three large public universities named Flit-Path (Florida IT Pathways to Success). Flit-Path was established using the principles inherent to communities of practice with the goal of recruiting and retaining computing students. The Flit-Path program leveraged curricular and co-curricular support to engage academically talented students with financial need in computing disciplines (e.g., computer engineering, computer science, and information technology) and provided financial assistance via scholarships. The guiding research question for this study was, What is the impact of a computing community of practice (the Flit-Path program) on students’ computing identity, specifically the constructs of recognition, performance/competence, sense of belonging, and interest? In order to address this question, a validated survey instrument was used to compare 64 computing students who enrolled in the Flit-Path program with students from the same universities with matched years in college, computing GPA, race/ethnicity, gender, home/environment support, and work hours outside the home. For comparing the two groups, the research team used multivariate matching methods in R. The results of the study revealed that students in the Flit-Path program demonstrated substantially higher computing identities. Students who participated in the Flit-Path program experienced higher recognition, performance/competence, and sense of belonging in the computing field than their non-Flit-Path counterparts. There was also a borderline positive effect for interest. Together, the results indicate that well-designed CoP interventions in computing programs can have a significant effect on students’ identification with computing and ultimately their persistence.},
journal = {ACM Trans. Comput. Educ.},
month = feb,
articleno = {8},
numpages = {14},
keywords = {Communities of practice, computing identity, computing fields}
}

@inproceedings{10.1145/3637882.3637890,
author = {Erceg, Mirjana and Palamas, Georgios},
title = {Towards Harmonious Coexistence: A Bioacoustic-Driven Animal-Computer Interaction System for Preventing Ship Collisions with North Atlantic Right Whales},
year = {2024},
isbn = {9798400716560},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3637882.3637890},
doi = {10.1145/3637882.3637890},
abstract = {The North Atlantic Right Whale (NARW) population is currently teetering on the brink of extinction, with a mere approximate count of 350 individuals remaining. These animals have been protected under the Endangered Species Act since 1970. Today, the survival of right whales is imperiled primarily due to vessel collisions, net entanglements, and habitat degradation. This paper presents a novel system of animal-computer interaction founded on the identification of bioacoustic signatures. Initially, NARWs’ vocalizations were transformed into spectrograms, which were subsequently inputted into a Convolutional Neural Network (CNN). To enhance robustness against environmental noise, techniques such as time warping, frequency masking, and time masking were employed. The outcomes of our study indicate that the proposed system holds potential for establishing a closed-loop interaction framework between vessels and NARWs. This framework could enable vessels to adapt their speed or avoid routes frequented by NARWs. Furthermore, this article discusses the potential benefits of employing networked sensors, such as Internet of Things (IoT) devices, to augment NARW monitoring and data collection efforts.},
booktitle = {Proceedings of the Tenth International Conference on Animal-Computer Interaction},
articleno = {6},
numpages = {10},
keywords = {North Atlantic right whale, animal-computer interaction, aquatic mammal detection, bioacoustic signatures, bioacoustics, biodiversity conservation, internet of things, neural networks, passive acoustic monitoring, whale calls},
location = {Raleigh, NC, USA},
series = {ACI '23}
}

@inproceedings{10.1145/3637882.3637883,
author = {Wu, Yifan and Nichols, Colt and Foster, Marc and Martin, Devon and Dieffenderfer, James and Enomoto, Masataka and Lascelles, B. Duncan X. and Russenberger, Jane and Brenninkmeyer, Gerald and Bozkurt, Alper and Roberts, David L.},
title = {An Exploration of Machine Learning Methods for Gait Analysis of Potential Guide Dogs},
year = {2024},
isbn = {9798400716560},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3637882.3637883},
doi = {10.1145/3637882.3637883},
abstract = {Gait analysis is important for guide dog organizations, as ideal guide dogs have a smooth and efficient gait, where they can also easily shift between and maintain various gaits. Gait quality and natural traveling speed are two of the multiple factors important in matching a guide dog to its visually impaired handler. Gait evaluation typically includes subjective visual observation of the dog or objective assessments obtained from special-designed equipment. Guide dog organizations need a method to easily collect and analyze objective data of gait information. In this work, we explored how various machine learning models could learn and analyze gait patterns from inertial measurements data that were collected during two different data collection experiments using a wearable sensor device. We also evaluated how well each machine learning model could generalize behavior patterns from various dogs under different environments. Additionally, we compared how sensor placement locations could affect gait prediction performance by attaching the sensor device to the dog’s neck and back area respectively. The tested machine learning models were able to classify different gaits in the range of 42\% to 91\% in terms of accuracy, and predict various gait parameters with an error rate ranging from 14\% to 29\% depending on the setup. Furthermore, we also observed that using behavior data collected from the neck region contains more movement information than the back area. By performing a cross-dataset generalization test on the machine learning models, we found that even with performance drop, the models were able to learn gait-specific behavior patterns that are generalizable for different dogs. Although the results were preliminary, the proposed gait analysis exploration still showed promising potential for studying behavior patterns of candidate guide dogs.},
booktitle = {Proceedings of the Tenth International Conference on Animal-Computer Interaction},
articleno = {10},
numpages = {15},
keywords = {Canine Behavior Analysis, Canine Gait Analysis, Guide Dog, IMU, Machine Learning},
location = {Raleigh, NC, USA},
series = {ACI '23}
}

@inproceedings{10.1145/3635059.3635102,
author = {Xagoraris, Loukas and Kogias, Dimitrios and Karkazis, Panagiotis},
title = {A Review of Zero Trust Security Framework (ZTF) for Sustainable and Resilient Smart Cities},
year = {2024},
isbn = {9798400716263},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3635059.3635102},
doi = {10.1145/3635059.3635102},
abstract = {In recent years, cities as they adopt smart technology in an ever-evolving technological environment, face new complex threats and security challenges. Threats that affect the privacy of citizens but often impact critical infrastructure of a smart city, creating sustainability risks. Hence, the cyber security incidents have multiplied, allowing these threats to disrupt the functioning of a smart digitized ecosystem. In addition to these challenges, the smart cities have been developed like a technological complex puzzle with different interconnected sensors and software. This Internet of Things (IoT) – based infrastructure of a smart city includes different smart grid systems which will be studied. This paper highlights the vulnerabilities of a digital ecosystem in a smart city environment and addresses the security and privacy issues regarding the IoT-based infrastructure and cloud computing. We also present future trends on blockchain technology and we focus on the presentation of a zero trust blockchain-security framework (ZTF) which can be developed to mitigate the urban surface area of vulnerability exploitation and security risks.},
booktitle = {Proceedings of the 27th Pan-Hellenic Conference on Progress in Computing and Informatics},
pages = {269–273},
numpages = {5},
keywords = {Blockchain, IoT and Cloud Computing, Smart City Resilience, Smart City Sustainability},
location = {Lamia, Greece},
series = {PCI '23}
}

@inproceedings{10.1145/3635059.3635078,
author = {Psychogyios, Vasileios Periklis and Kapsalis, Vassilis},
title = {Mobile Network of Air Quality Monitoring Sensors},
year = {2024},
isbn = {9798400716263},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3635059.3635078},
doi = {10.1145/3635059.3635078},
abstract = {This paper presents the development of a network of mobile sensors for the real-time monitoring of the atmospheric air in order to calculate the Air Quality Index (AQI). As a proof of concept, a prototype of the sensor, a web application and a mobile application were implemented in order to manage the mobile sensors and process/view the data collected by them. The sensor, which can be installed in vehicles, collects and transmits environmental measurements wirelessly to a web application using proper APIs. These measurements are stored in a database and based on them, the Air Quality Index (AQI) is calculated. Following a publish-subscribe model, real-time data are forwarded to authorized users for monitoring purposes in the form of charts and tables. Historical data are used for analysis and study of the air quality over time and also used as an input to the Random Forest predictive algorithm implemented to predict air quality in locations without availability of real-time measurements. Monitoring air quality through mobile sensors constitutes a valuable tool towards the study of air pollution in large areas overcoming the limitations of fixed sensors. Furthermore, the immediate notifications of high-precision AQIs help people with respiratory problems to take timely protection measures.},
booktitle = {Proceedings of the 27th Pan-Hellenic Conference on Progress in Computing and Informatics},
pages = {123–129},
numpages = {7},
keywords = {AQI, Mobile air quality sensor, mobile application, monitoring, notifications, predictions},
location = {Lamia, Greece},
series = {PCI '23}
}

@inproceedings{10.1145/3632971.3633048,
author = {Laskowitz, Leonie and Huffstadt, Karsten},
title = {Between Reality and Fiction: Self-Representation as an Avatar and Its Effects on Self-Presence},
year = {2024},
isbn = {9798400707704},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3632971.3633048},
doi = {10.1145/3632971.3633048},
abstract = {Abstract. A self-confident appearance is a basic prerequisite for success in the world of work 4.0. Within a few seconds, people convey a first impression that usually lasts. Artificial intelligence is making it increasingly important how our virtual selves appear and communicate (nonverbally) in digital worlds such as the metaverse. In addition to the modified creation of an avatar, the field of photogrammetry is developing fast, creating exact likenesses of ourselves in virtual environments. Given the importance of self-representation in virtual space for future collaborations, it is important to investigate the impact of phenotype in virtual worlds and how an avatar type can profitably be used situationally. We analyzed the effect of self-similar versus desirable self-presentation as an avatar on one's self-awareness, considering various theoretical constructs in the area of self-awareness and stress stimuli. The avatars were arbitrarily created on the one hand and scanned on the other hand with the help of a lidar sensor, the state-of-the-art photogrammetry method. All subjects were exposed to the established Trier Social Stress Test. The results showed that especially insecure people prefer to create rather than be scanned when confronted with a stressful work situation. If they are in a casual work environment and a relaxed situation, they prefer a 3D photorealistic avatar that reflects them in detail. Confident people will give their avatar their true appearance in any situation, while insecure people would only do so for honesty and authenticity. The choice of avatar type has considerable impact on self-confidence in different situations.},
booktitle = {Proceedings of the 2023 International Joint Conference on Robotics and Artificial Intelligence},
pages = {193–203},
numpages = {11},
keywords = {Avatar, Trier Social Stress Test, metaverse, self-awareness, self-esteem, self-presentation, virtual identity, virtual reality},
location = {Shanghai, China},
series = {JCRAI '23}
}

@inproceedings{10.1145/3632971.3632990,
author = {Yue, Wenqiang and Chen, Li-an and Huang, Haiyan},
title = {Research on Machine Learning Algorithm-Based Approach for Detecting Abnormal Data from Environmental Sensors in Different Dimensions},
year = {2024},
isbn = {9798400707704},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3632971.3632990},
doi = {10.1145/3632971.3632990},
abstract = {With the development of environmental sensor technology, more and more environmental sensors are widely used in various fields, such as environmental monitoring, smart home, smart city and so on. However, due to the complexity and diversity of environmental sensor data, there are a high number of anomalous data in sensor data, which can lead to misjudgment and false positives, compromising data reliability and accuracy. Therefore, the detection method of abnormal data in different dimensions of environmental sensors based on machine learning algorithms were studied in this paper. Firstly, the environmental sensor data of IBRL (Intel Berkeley Research Lab) data set was preprocessed, including data cleaning, data normalization and feature extraction. Then, the simulation experiment was completed using the data set, and the data of different dimensions was detected using machine learning algorithms such as OneClass Support Vector Machine algorithm, Local Outlier Factor algorithm, and Isolation Forest algorithm. Finally, through experimental comparison and analysis of the application effects of the above three algorithms in anomaly detection of environmental data in different dimensions, the Isolation Forest algorithm with the best comprehensive detection effect was finally selected for practical engineering projects. In practical engineering projects, maintenance costs can be effectively reduced, project safety and reliability can be improved, and the purpose of improving project efficiency can ultimately be achieved by the proposed method.},
booktitle = {Proceedings of the 2023 International Joint Conference on Robotics and Artificial Intelligence},
pages = {26–33},
numpages = {8},
keywords = {Abnormal data detection, Environmental sensor, Machine learning algorithm},
location = {Shanghai, China},
series = {JCRAI '23}
}

@inproceedings{10.1145/3623509.3633378,
author = {Brombacher, Hans and Van Koningsbruggen, Rosa and Vos, Steven and Houben, Steven},
title = {SensorBricks: a Collaborative Tangible Sensor Toolkit to Support the Development of Data Literacy},
year = {2024},
isbn = {9798400704024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3623509.3633378},
doi = {10.1145/3623509.3633378},
abstract = {Data is often inaccessible for non-expert users, leading to a lack of data transparency and speculation in the understanding and interpretation of data, not providing personal value to individuals. The SensorBricks toolkit was evaluated during 5 workshops (N = 20) to learn how an IoT toolkit can support the development of data literacy. The SensorBricks toolkit introduced data to individuals in a fun, accessible and easy way, creating a low boundary for users to interact with data, sensors and output modalities. The toolkit helped individuals to reflect on the role of data in their environment. The collaborative aspect gave individuals the option to discuss the data and learn from each other’s experiences helping users to create a meaningful interpretation and shared understanding of sensor data. The combined digital and data physicalization data representation gives individuals both awareness and in-detail information, creating an understandable and informative way of presenting data.},
booktitle = {Proceedings of the Eighteenth International Conference on Tangible, Embedded, and Embodied Interaction},
articleno = {30},
numpages = {17},
keywords = {Data Literacy, Data Physicalization, IoT Toolkit, Sensor System, Tangibility},
location = {Cork, Ireland},
series = {TEI '24}
}

@inproceedings{10.1145/3623509.3633374,
author = {Li, Yangfangzheng and Zhou, Yi and Shen, Cheng and Stewart, Rebecca},
title = {E-textile Sleeve with Graphene Strain Sensors for Arm Gesture Classification of Mid-Air Interactions},
year = {2024},
isbn = {9798400704024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3623509.3633374},
doi = {10.1145/3623509.3633374},
abstract = {Arm gestures play a pivotal role in facilitating natural mid-air interactions. While computer vision techniques aim to detect these gestures, they encounter obstacles like obfuscation and lighting conditions. Alternatively, wearable devices have leveraged interactive textiles to recognize arm gestures. However, these methods predominantly emphasize textile deformation-based interactions, like twisting or grasping the sleeve, rather than tracking the natural body movement.This study bridges this gap by introducing an e-textile sleeve system that integrates multiple ultra-sensitive graphene e-textile strain sensors in an arrangement that captures bending and twisting along with an inertia measurement unit into a sports sleeve. This paper documents a comprehensive overview of the sensor design, fabrication process, seamless interconnection method, and detachable hardware implementation that allows for reconfiguring the processing unit to other body parts. A user study with ten participants demonstrated that the system could classify six different fundamental arm gestures with over 90\% accuracy.},
booktitle = {Proceedings of the Eighteenth International Conference on Tangible, Embedded, and Embodied Interaction},
articleno = {26},
numpages = {10},
keywords = {E-textiles, Gestural Interaction, Wearable devices},
location = {Cork, Ireland},
series = {TEI '24}
}

@inproceedings{10.1145/3623509.3633396,
author = {Postl, Valentin and Schwendtbauer, Wolfgang and Preindl, Thomas and Probst, Kathrin},
title = {Mold Printer: Creating Living Self-Revealing Artworks},
year = {2024},
isbn = {9798400704024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3623509.3633396},
doi = {10.1145/3623509.3633396},
abstract = {We present a method of creating living computer-aided drawings by depositing mold spores onto a growth medium using a modified 3D printer. Our approach combines the precision of computerized numerical control with the organic growth of fungi to yield an aesthetic and evolving viewing experience. The organic element of the drawing results in unique and unexpected artifacts driven by environmental factors and manufacturing inconsistencies. The microscopic spores, invisible to the naked eye, also allow for a sense of anticipation and surprise as a drawing slowly develops. Exploring the possibilities of mold-based media, we examined the color, growth pattern, and species interaction of two non-toxic fungal species. In this paper, we address the technical challenges of building a reliable mold printer, explore different methods of preservation, and conclude with a discussion regarding the artistic possibilities of creating living mold drawings.},
booktitle = {Proceedings of the Eighteenth International Conference on Tangible, Embedded, and Embodied Interaction},
articleno = {48},
numpages = {12},
location = {Cork, Ireland},
series = {TEI '24}
}

@inproceedings{10.1145/3623278.3624763,
author = {Ahmad, Adil and Ou, Botong and Liu, Congyu and Zhang, Xiaokuan and Fonseca, Pedro},
title = {Veil: A Protected Services Framework for Confidential Virtual Machines},
year = {2024},
isbn = {9798400703942},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3623278.3624763},
doi = {10.1145/3623278.3624763},
abstract = {Confidential virtual machines (CVMs) enabled by AMD SEV provide a protected environment for sensitive computations on an untrusted cloud. Unfortunately, CVMs are typically deployed with huge and vulnerable operating system kernels, exposing the CVMs to attacks that exploit kernel vulnerabilities. Veil is a versatile CVM framework that efficiently protects critical system services like shielding sensitive programs, which cannot be entrusted to the buggy kernel. Veil leverages a new hardware primitive, virtual machine privilege levels (VMPL), to install a privileged security monitor inside the CVM. We overcome several challenges in designing Veil, including (a) creating unlimited secure domains with a limited number of VMPLs, (b) establishing resource-efficient domain switches, and (c) maintaining commodity kernel backwards-compatibility with only minor changes. Our evaluation shows that Veil incurs no discernible performance slowdown during normal CVM execution while incurring a modest overhead (2 -- 64\%) when running its protected services across real-world use cases.},
booktitle = {Proceedings of the 28th ACM International Conference on Architectural Support for Programming Languages and Operating Systems, Volume 4},
pages = {378–393},
numpages = {16},
keywords = {confidential virtual machines, OS design, cloud security},
location = {Vancouver, BC, Canada},
series = {ASPLOS '23}
}

@inproceedings{10.1145/3628096.3629046,
author = {Anuyah, Oghenemaro and Wan, Ruyuan and Adejoro, Cornelius and Yeh, Tom and Metoyer, Ronald and Badillo-Urquiola, Karla},
title = {Cultural Considerations in AI Systems for the Global South: A Systematic Review},
year = {2024},
isbn = {9798400708879},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3628096.3629046},
doi = {10.1145/3628096.3629046},
abstract = {The field of Artificial Intelligence (AI) is leading transformative impacts across different sectors. However, these advancements are often developed with a Western-centric focus, neglecting the cultural diversity in regions such as the Global South. In this paper, we synthesize twelve research papers focusing on cultural considerations in designing AI systems for the Global South. Our findings revealed a significant focus on domains like healthcare and intelligent assistants and challenges, including usability, AI transparency, and data availability, that can hinder the design and deployment of culturally sensitive AI systems. Moreover, the results demonstrated the need to integrate cultural values to increase the acceptance and usefulness of AI systems for regions in the Global South. This paper guides future research towards developing culturally and contextually relevant AI systems for Africa, highlighting the need for increased visibility and representation of African researchers in HCI and AI domains.},
booktitle = {Proceedings of the 4th African Human Computer Interaction Conference},
pages = {125–134},
numpages = {10},
keywords = {Artificial Intelligence, Culture, Design Research, Global South, Systematic Review},
location = {East London, South Africa},
series = {AfriCHI '23}
}

@inproceedings{10.1145/3634875.3634877,
author = {Liao, Hung-Ju and Hsieh, Ya-Chu and Chiu, Shih-Wen and Lee, Meng-Rui and Tang, Kea-Tiong and Sun, Min},
title = {Shared Embedding of X-ray \&amp; Enose Networks for Lung Cancer Classification},
year = {2024},
isbn = {9798400716584},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3634875.3634877},
doi = {10.1145/3634875.3634877},
abstract = {Lung cancer is a significant cause of cancer-related deaths globally. X-ray image has been widely used for first-stage screening as it is affordable and widely available. Recently, with the development of the gas sensor IC chip, low-cost enose sensing exhaled breath from patients can potentially be used for the first-stage screening in the near future. We propose a share-embedding model combining x-ray images and enose sensory signals to diagnose lung cancer. Our model contains two branches: the image branch and the enose branch. Since the lack of the enose data, we try to use the pretrained image model to guide the enose branch to align toward the embedding space that the image model learned. Our share-embedding model is designed to be robust to domain shifts across devices and environments. To further improve performance, we use semi-supervised learning with instance weighting to transfer the model to the unlabeled target domain. To train and evaluate the performance, we collect the first paired X-ray images and enose data across multiple devices and clinical environments. In the experiments, our method outperforms each individual branch and a feature concatenation fusion method. In the cross-device setting, our method leveraging semi-supervised learning achieves the best performance.},
booktitle = {Proceedings of the 2023 8th International Conference on Biomedical Imaging, Signal Processing},
pages = {9–16},
numpages = {8},
keywords = {Lung cancer, across devices and environments, enose, share-embedding model, x-ray images},
location = {Singapore, Singapore},
series = {ICBSP '23}
}

@inproceedings{10.1145/3611315.3633266,
author = {Parvaresh, Amirhossein and Hosseinzadeh, Shima and Fey, Dietmar},
title = {Resilience and Precision Assessment of Natural Language Processing Algorithms in Analog In-Memory Computing: A Hardware-Aware Study},
year = {2024},
isbn = {9798400703256},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3611315.3633266},
doi = {10.1145/3611315.3633266},
abstract = {Natural Language Processing (NLP) serves as a cornerstone technology, facilitating complex human-computer interactions, enabling information retrieval, conducting sentiment analysis, and enhancing language comprehension. With the ever-growing use of NLPs, the conventional ’von Neumann’ computing paradigm is rapidly approaching its inherent limitations. In response, Analog In-Memory Computing (AIMC) emerges as a compelling alternative, albeit accompanied by inherent non-idealities when deploying neural networks on such platforms. In this paper, we have evaluated the precision and resilience of various NLP algorithms when executed within the AIMC framework, both with and without the application of hardware-aware training. Our analysis reveals noteworthy insights: Gated Recurrent Unit (GRU) neural networks exhibit enhanced resilience to noise, yielding an average test error of 3.97\% following hardware-aware training, as compared to their full precision counterparts. Conversely, Long Short-Term Memory (LSTM) networks demonstrate a slightly higher average test error of 5.67\%, indicating a relatively lower tolerance to non-idealities. In contrast, Convolutional Neural Networks (CNNs) manifest a heightened vulnerability, exhibiting an average relative test error of 13.34\%. Furthermore, we systematically investigate the sensitivity profiles of the selected neural networks in the presence of specific non-idealities, providing valuable insights into their robustness and susceptibility within the AIMC environment.},
booktitle = {Proceedings of the 18th ACM International Symposium on Nanoscale Architectures},
articleno = {28},
numpages = {6},
keywords = {AIMC, DNN, NLP, PCM},
location = {Dresden, Germany},
series = {NANOARCH '23}
}

@inproceedings{10.1145/3611315.3633249,
author = {Zhao, Haibin and Pal, Priyanjana and Hefenbrock, Michael and Beigl, Michael and Tahoori, Mehdi Baradaran},
title = {Towards Temporal Information Processing – Printed Neuromorphic Circuits with Learnable Filters},
year = {2024},
isbn = {9798400703256},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3611315.3633249},
doi = {10.1145/3611315.3633249},
abstract = {Many consumer products such as wearable and disposable electronics require flexibility, biocompatibility and ultra low-costs, which can hardly be matched by silicon electronics. Therefore, printed electronics (PE) becomes a competitive candidate thanks to its additive manufacturing. To address fundamental signal-processing tasks, printed neuromorphic circuits (pNCs) have received increasing attention, as they can achieve promising computational capabilities by assembling simple circuit primitives. However, many target domains of PE are based on processing temporal sensory data, which can not be reached by existing pNCs, since they lack components with time dependencies. This paper proposes a printed temporal processing block that combines existing pNCs with learnable filters. We model the proposed circuit and proposed the corresponding training objective to enable their bespoke design. Simulations on 15 benchmark time-series datasets reveal that, the proposed circuits can effectively process temporal data by using&nbsp;1.5 \texttimes{} and&nbsp;1.3 \texttimes{} &nbsp;of device counts and power respectively. The classification accuracy reaches 98\% of that from classic Elman recurrent neural networks.},
booktitle = {Proceedings of the 18th ACM International Symposium on Nanoscale Architectures},
articleno = {12},
numpages = {6},
keywords = {neuromorphic computing, printed electronics, recurrent neural network, temporal information processing},
location = {Dresden, Germany},
series = {NANOARCH '23}
}

@inproceedings{10.1145/3638067.3638081,
author = {Dos Santos, Paulo S\'{e}rgio Henrique and Oliveira, Alberto Dumont Alves and De Jesus, Thais Bonjorni Nobre and Aljedaani, Wajdi and Eler, Marcelo Medeiros},
title = {Evolution may come with a price: analyzing user reviews to understand the impact of updates on mobile apps accessibility},
year = {2024},
isbn = {9798400717154},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3638067.3638081},
doi = {10.1145/3638067.3638081},
abstract = {Mobile applications are constantly updated to adapt to evolving user and environment requirements. As changes are successively implemented to promote user satisfaction, the complexity of mobile apps increases, and overlooked quality aspects (e.g. privacy, security, power consumption) may decline if counter-measures are not adopted. In this paper, we analyzed accessibility reviews of mobile apps to show evidence that updates may introduce barriers that make the app less accessible than its previous version according to users’ perceptions. Our results show that accessibility barriers reported by users mostly include incompatibility with screen readers, the removal of accessibility features (e.g. color scheme or font customization), small font sizes and widgets, and incompatibility with the device’s accessibility configuration. The accessibility barriers impact the users considering different levels: i) perception: an inability or difficulty to see, read or distinguish interface elements due to their small size or color; ii) understanding: the inability or difficulty to navigate, access and interpret information; iii) operation: the inability of difficulty to perform tasks such as adding items to the cart, reading or sending messages, and booking a ride; iv) and physical reactions, such as eyestrain, vertigo, and headache. The sentiments expressed by users are generally negative, including frustration, disappointment, and sometimes a sense of discrimination against people with disabilities. The results of our study raise an alert to organizations and developers that they should implement measures to avoid introducing accessibility barriers while they add new features to their mobile apps.},
booktitle = {Proceedings of the XXII Brazilian Symposium on Human Factors in Computing Systems},
articleno = {52},
numpages = {11},
keywords = {Accessibility, app, evolution, mobile, update, user reviews},
location = {Macei\'{o}, Brazil},
series = {IHC '23}
}

@inproceedings{10.1145/3638067.3638114,
author = {Vasiljevic, Gabriel Alves Mendes and Cunha de Miranda, Leonardo},
title = {Model, Taxonomy and Methodology for Research Employing EEG-based Brain-Computer Interface Games},
year = {2024},
isbn = {9798400717154},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3638067.3638114},
doi = {10.1145/3638067.3638114},
abstract = {The rapid expansion of Brain-Computer Interface technology, aligned with the advancements on the fields of Human-Computer Interaction, Physiological Computing and Machine Learning, allowed for the recent development of applications outside of clinical environments, such as education, arts and games. Games controlled by electroencephalography (EEG), a specific case of BCI technology, benefit from both the fields of BCI and games, since they can be played by virtually any person regardless of physical condition, can be applied in numerous contexts, and are ludic by nature. Despite these recent advancements, there is still no solid theoretical foundation to aggregate the terminology and methods of these fields, since current models and classification schemes can represent characteristics of either BCI systems or games, but not both. In this sense, the thesis summarized in this work presents a model for representing EEG-based BCI games, a taxonomy for classifying and comparing studies of the field, and a methodology for conducting scientific studies using those games. The model is intended to describe and develop new EEG games by instantiating its components. The CoDIS taxonomy considers four aspects of such games: concept, design, implementation and study, each with different dimensions to represent various of their characteristics. Based on the model and the taxonomy, the PIERSE methodology was developed for the planning, implementation, execution and reporting of scientific experiments using those games. The contributions of the thesis are detailed in various dimensions in this manuscript.},
booktitle = {Proceedings of the XXII Brazilian Symposium on Human Factors in Computing Systems},
articleno = {42},
numpages = {10},
keywords = {BCI, EEG, Games, HCI},
location = {Macei\'{o}, Brazil},
series = {IHC '23}
}

@inproceedings{10.1145/3638067.3638132,
author = {Espinoza Taype, Geovanna Evelyn and Dos Reis, Julio Cesar and Calani Baranauskas, Maria Cec\'{\i}Lia},
title = {A Socioenactive Perspective on Emotion Contagion and Senses: Analyzing the Phenomenon via EEG Signals},
year = {2024},
isbn = {9798400717154},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3638067.3638132},
doi = {10.1145/3638067.3638132},
abstract = {Emotion contagion is a phenomenon in which emotions are transmitted from one to another in social interactions. In this process, our senses are involved because our body perceives the environment through them. Many activities are triggered between our mind, body, and the space around us involving sensory-motor, perception, and cognition aspects. All the aforementioned aspects are studied by the Socioenactive perspective in the frame of relationships connecting the social, physical, and digital worlds. This research explores the Socioenactive perspective into the emotion contagion phenomenon in the interaction with computational systems. Our study used an EEG device to collect brain wave data from 21 participants in a scenario of potential emotional contagion. Our analysis adopted the Transform Fourier technique to get features in brain wavelets of happiness, fear, anger, and sadness emotional states. The brain waves analysis considering the amplitude and frequency allows for finding features associated with each kind of emotional state. A post-experiment questionnaire was used to gather self-reported emotional states from participants. We investigated the relations between emotional states data gathered by the self-report and by brain waves directly. The results shown through the self-report and brain waves indicate that 71\% of participants felt the happiness emotion; 38\% of participants felt the sadness emotion; the fear and anger emotion resulted in 24\% and 19\% of the cases, respectively.},
booktitle = {Proceedings of the XXII Brazilian Symposium on Human Factors in Computing Systems},
articleno = {9},
numpages = {11},
keywords = {EEG, Emotional Contagion, Socioenactive, brain-waves, perception, senses},
location = {Macei\'{o}, Brazil},
series = {IHC '23}
}

@inproceedings{10.1145/3638067.3638134,
author = {Moreira, Francisco and Coutinho, Emanuel},
title = {Evaluating the User Experience of Type 1 Diabetes Control Applications},
year = {2024},
isbn = {9798400717154},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3638067.3638134},
doi = {10.1145/3638067.3638134},
abstract = {Type 1 diabetes is a chronic condition that affects millions of people around the world. For those, facing daily challenges is a reality, from constantly monitoring blood glucose levels to administering adequate doses of insulin. With the advances in E-Health technology and the improvement of ubiquitous applications and systems, new solutions are emerging to help people in their diabetes control, such as devices that send blood glucose levels via bluetooth to the control app, and subcutaneous sensors that are applied to the arm and monitor the blood glucose levels constantly. Despite the practicality that these systems present, their applications have scores below 3.5 stars on their respective platforms, showing dissatisfaction on part of its users. This article aims to evaluate the user experience of the apps G-Tech App and FreeStyle Libre. Both are ubiquitous applications for control of type 1 diabetes, although they have a different approach. For this, the extended MALTU evaluation was used and a bibliographical research was carried out. The evaluation consists of analyzing users’ spontaneous comments on social systems, such as Play Store and App Store. The results revealed problems that hinder the user’s interaction with the application, mainly regarding synchronization and functionalities.},
booktitle = {Proceedings of the XXII Brazilian Symposium on Human Factors in Computing Systems},
articleno = {17},
numpages = {11},
location = {Macei\'{o}, Brazil},
series = {IHC '23}
}

