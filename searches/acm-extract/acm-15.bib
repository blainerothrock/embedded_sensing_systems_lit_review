@inproceedings{10.1145/3636534.3696215,
author = {Hu, Tianyi and Yang, Fan and Scargill, Tim and Gorlatova, Maria},
title = {Apple v.s. Meta: A Comparative Study on Spatial Tracking in SOTA XR Headsets},
year = {2024},
isbn = {9798400704895},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3636534.3696215},
doi = {10.1145/3636534.3696215},
abstract = {Inaccurate spatial tracking in extended reality (XR) headsets can cause virtual object jitter, misalignment, and user discomfort, limiting the headsets' potential for immersive content and natural interactions. We develop a modular testbed to evaluate the tracking performance of commercial XR headsets, incorporating system calibration, tracking data acquisition, and result analysis, and allowing the integration of external cameras and IMU sensors for comparison with open-source VI-SLAM algorithms. Using this testbed, we quantitatively assessed spatial tracking accuracy under various user movements and environmental conditions for the latest XR headsets, Apple Vision Pro and Meta Quest 3. The Apple Vision Pro outperformed the Meta Quest 3, reducing relative pose error (RPE) and absolute pose error (APE) by 33.9\% and 14.6\%, respectively. While both headsets achieved subcentimeter APE in most cases, they exhibited APE exceeding 10 cm in challenging scenarios, highlighting the need for further improvements in reliability and accuracy.},
booktitle = {Proceedings of the 30th Annual International Conference on Mobile Computing and Networking},
pages = {2120–2127},
numpages = {8},
keywords = {extended reality, VI-SLAM, performance characterization},
location = {Washington D.C., DC, USA},
series = {ACM MobiCom '24}
}

@inproceedings{10.1145/3689236.3691494,
author = {Xu, Wenfang and Zhao, Shusheng},
title = {A Study of Data Leakage Prevention Techniques in Remote Collaborative Work Application},
year = {2024},
isbn = {9798400718137},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3689236.3691494},
doi = {10.1145/3689236.3691494},
abstract = {Under the wave of digital transformation, remote collaboration has become the new normal in the daily operation of enterprises. But at the same time, the risk of sensitive data leakage and the insufficiency of protection measures have increasingly become the focus of attention, posing a severe challenge to enterprise data security. To address this challenge, this paper proposes an innovative comprehensive data leakage prevention technical solution. This solution integrates cloud services and kernel technology and creates a set of data security protection systems for the remote collaboration working environment. This technical solution adopts a series of effective technical means, including asymmetric encryption, one-way data flow control, dynamic digital watermarking technology, injection attack defense, and program anti-hanging mechanism, significantly enhancing the security of data in the collaborative office system. The constructed framework includes multiple modules such as user management, service support, kernel driver, and user terminal. This technical solution can be integrated with enterprise remote collaboration office software, providing a higher level of security guarantee for the remote office environment, effectively curbing the risk of sensitive data leakage, and also providing solid technical support for the healthy and stable development of remote collaboration work.},
booktitle = {Proceedings of the 2024 9th International Conference on Cyber Security and Information Engineering},
pages = {193–197},
numpages = {5},
keywords = {Cloud service, Data leakage prevention, Encryption algorithm, Kernel technology, Remote collaborative work},
location = {
},
series = {ICCSIE '24}
}

@inproceedings{10.1145/3680528.3687620,
author = {Gao, Haichen and Cai, Shaoyu and Wu, Yuhong and Zhu, Kening},
title = {ThermOuch: A Wearable Thermo-Haptic Device for Inducing Pain Sensation in Virtual Reality through Thermal Grill Illusion},
year = {2024},
isbn = {9798400711312},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3680528.3687620},
doi = {10.1145/3680528.3687620},
abstract = {Existing research showed that unpleasant haptic feedback, such as pain, could enhance the user experience and performance in various scenarios (e.g. entertainment and training). This paper introduces ThermOuch, a wearable thermo-haptic device that leverages the thermal grill illusion (TGI) to simulate pain sensations in virtual reality (VR) without causing actual invasive/non-invasive harm. Our results of the user-perception experiments revealed that higher temperature-changing rates, particularly with increased warming, were associated with more intense pain perceived by the participants through our system. Furthermore, a higher ratio of warm-to-cool temperature transitions reduced the sensation of coldness prior to pain. Our experiments also showed that introducing an additional stimulus unit potentially heightened pain perception, and altering the spacing between stimulus units modified the perceived pain area. Lastly, the user study in VR demonstrated that ThermOuch significantly enhanced the sense of presence and body ownership for the participants, as well as elevated their biosignal-indicated arousal levels.},
booktitle = {SIGGRAPH Asia 2024 Conference Papers},
articleno = {138},
numpages = {12},
keywords = {Virtual reality, Haptic devices, Thermal, Pain sensation, Thermal Grill Illusion},
location = {Tokyo, Japan},
series = {SA '24}
}

@inproceedings{10.1145/3689236.3696037,
author = {Gou, Tingting},
title = {Design and Implementation of an IoT-Based Exercise Physiological Data Monitoring and Intelligent Evaluation System},
year = {2024},
isbn = {9798400718137},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3689236.3696037},
doi = {10.1145/3689236.3696037},
abstract = {To enable users to achieve a personalized and intelligent exercise experience in real-time, this paper designs and implements an exercise physiological data monitoring and intelligent evaluation system based on Internet of Things (IoT) technology. The main functions of the system are to provide users with real-time monitoring of exercise physiological parameters, evaluate exercise load, and implement intelligent warning functions based on the analysis of these parameters. The system adopts an IoT architecture and is designed with multiple layers: the perception layer, network layer, and application layer. The perception layer uses various types of sensor devices to collect key physiological parameters such as heart rate and blood oxygen saturation in real time. The network layer utilizes the ZigBee protocol to achieve local data transmission, while combining with the TCP/IP protocol for remote data communication. The application layer is mainly responsible for data processing; it analyzes the processed data to provide visual displays, generate personalized exercise prescriptions, and promptly provide intelligent warnings for exercise risks based on the analyzed database. Experimental results show that the system can effectively collect exercise physiological parameters with high accuracy, providing technical support for personalized health management and scientific training. This system offers technical references for intelligent applications in areas such as fitness, professional training, and smart elderly care.},
booktitle = {Proceedings of the 2024 9th International Conference on Cyber Security and Information Engineering},
pages = {858–864},
numpages = {7},
keywords = {Exercise load warning, Exercise monitoring, Exercise physiological data monitoring, Intelligent evaluation, IoT technology},
location = {
},
series = {ICCSIE '24}
}

@inproceedings{10.1145/3689236.3689271,
author = {Han, Lina and Shi, Haosu and Xiong, Dongdong},
title = {Design of Crop Environmental Monitoring System Based on ZigBee},
year = {2024},
isbn = {9798400718137},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3689236.3689271},
doi = {10.1145/3689236.3689271},
abstract = {With the development of Internet of things (iot) technology and and sensor technology, a crop Environmental monitoring system based on ZigBee was designed to improve the growing environment and yield of crops.The system uses two development boards, one as a host, and the other as a slave. various sensors and ZigBee to communicate with each other. The host is equipped with display screen, single-chip microcomputer, buzzer, key, etc. Its functions are to display the detected data, alarm for detecting abnormal information and threshold setting of soil moisture and light intensity. The slave is equipped with single-chip microcomputer, temperature and humidity sensors, soil humidity sensors, photoresistor and relays. Its functions are to achieve the collection of environmental data, the relay for controlling the water motor and lighting lamp. ZigBee module is used to realize the communication between microcontrollers.The system can collect and display real-time data of temperature and humidity, soil moisture and light intensity of crops, and according to the threshold set to achieve the automatic opening of the pump irrigation, automatic lighting and abnormal conditions alarm functions. The test results show that the system can effectively reduce the cost of crop Environmental monitoring and improve monitoring efficiency.In addition to the system can monitor the environment 24 hours a day, find the abnormal situation and carry on the early warning and the corresponding automatic treatment, improve the efficiency of crop production management. It also has strong expansibility.},
booktitle = {Proceedings of the 2024 9th International Conference on Cyber Security and Information Engineering},
pages = {454–460},
numpages = {7},
keywords = {Crop environmental Monitoring, Sensor Technology, ZigBee, intelligent agriculture, single-chip microcomputer technology},
location = {
},
series = {ICCSIE '24}
}

@inproceedings{10.1145/3702336.3702337,
author = {Nichols, Colt and Wu, Yifan and Gruen, Margaret and Roberts, David L. and Bozkurt, Alper},
title = {Wireless Tension Sensors for Characterizing Dog Frailty in Veterinary Settings},
year = {2024},
isbn = {9798400711756},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3702336.3702337},
doi = {10.1145/3702336.3702337},
abstract = {As a fundamental concept used in human gerontology, frailty refers to the gradual decline in physiological function with aging and the resulting vulnerability to adverse health outcomes. Assessment of frailty and using this for healthcare and resource management have garnered significant interest both to support the elderly and their caregivers. There have been substantial efforts to translate these concepts and outcomes into animal health. In this paper we present the preliminary effort towards a system to characterize functional muscle strength, an important component of frailty in dogs, using wireless and continuous electronic sensors. We have custom developed the front-end hardware with real time wireless data transfer capability with form and function specific for veterinary applications. In this system, frailty is investigated through continuous pulling force measurements collected on a leash-based device. The data can be monitored in real time over a smartphone and are also saved to the cloud for more complete offline analysis after the data collection session. We coupled the sensing system with a camera for synchronous recordings to further analyze the strength performance session footage. The next stages of this research will involve collecting data through a large cohort of dogs and using machine learning to fuse data and provide fragility assessment scores. This is our initial step towards a multimodal machine learning supported sensor system for both quantitative assessment and scoring of a component of frailty in dogs. The vision is to bring these measurements from veterinary environments to subjects homes for a more convenient and regular data collection.},
booktitle = {Proceedings of the International Conference on Animal-Computer Interaction},
articleno = {1},
numpages = {7},
keywords = {animal computer interaction, pulling force, wearable sensors, wireless, Bluetooth, frailty, muscle strength},
location = {
},
series = {ACI '24}
}

@inproceedings{10.1145/3700486.3700498,
author = {Song, Meihua and Yu, Shiyan and Mo, Zhong},
title = {Wearable sleep apnea detection device based on PVDF novel sensor},
year = {2024},
isbn = {9798400710063},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3700486.3700498},
doi = {10.1145/3700486.3700498},
abstract = {Purpose: Sleep Apnea Hypopnea Syndrome (SAHS) is a high incidence but little known functional disorder including central apnea sleep apnea syndrome and obstructive apnea sleep apnea hypopnea syndrome, its onset is often difficult to detect. If real-time sleep breathing monitoring can be carried out at home for patients, and an alarm can be issued when they have apnea to attract the attention of people around them, the tragedy can be prevented to the greatest extent. In order to realize real-time breathing monitoring at home, a wearable sleep breathing monitoring device was developed. Through the form of a belt embedded with dual sensors, continuous monitoring of sleep breathing signals can be achieved through normal wearing. Design signal regulation circuit charge conversion, filtering, amplification and other functions. The hardware circuit uses STM32 single chip microcomputer as the core controller to realize the signal analog-to-digital conversion. At the same time, the upper computer is designed by using LabVIEW software to realize the function of real-time display, storage and playback of signal waveform. An alarm is triggered when the breathing rate is abnormal or when the breathing is stopped for more than 10 seconds, and the host computer also has a function such as indicating the success of wearing.},
booktitle = {Proceedings of the 2024 International Conference on Biomedicine and Intelligent Technology},
pages = {75–80},
numpages = {6},
keywords = {A wearable device, Home health monitoring, Hypopnea syndrome, PVDF, Sleep apnea},
location = {
},
series = {ICBIT '24}
}

@inproceedings{10.1145/3702336.3702343,
author = {Mastali, Arianna and Mayo, Benjamin and Ramey, Charles and Elgart, Nate and Miller, Kirby and Jackson, Melody},
title = {Play That Trunky Music: Development of an Auditory Enrichment Device for Elephants in Zoos},
year = {2024},
isbn = {9798400711756},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3702336.3702343},
doi = {10.1145/3702336.3702343},
abstract = {Elephants are a quintessential animal for zoos and wildlife parks. These zoo-housed animals serve as ambassadors to educate the public about their respective species as well as wildlife more broadly. As with any zoo-housed animal, physical and cognitive engagement and exercise are crucially important to the well-being of zoo-housed elephants. A key component of cognitive stimulation for elephants is a complex and variable environment. We designed and deployed an instrumented enrichment device for African elephants (Loxodonta africana) at Zoo Atlanta, augmenting their existing food-based environmental enrichment with audio cognitive enrichment. To gauge elephant interest in our device, we compared usage of the existing food-based enrichment before and after augmentation with audio. The device was installed for 7 days and 10 hours and had a positive impact on frequency and retention time with the existing enrichment, increasing frequency of usage by 81 instances and retention time by 3 hours, 28 minutes, and 23 seconds. While our audio enrichment device was successful at collecting data with 88.14\% accuracy, improvements could be made to the sensing methods to reduce the rate of false actuations. Overall, the study is an example of successfully collecting longitudinal data with elephants and showed that these elephants responded positively to sound enrichment.},
booktitle = {Proceedings of the International Conference on Animal-Computer Interaction},
articleno = {7},
numpages = {14},
keywords = {animal computer interaction, zoo enrichment, elephant enrichment},
location = {
},
series = {ACI '24}
}

@inproceedings{10.1145/3696271.3696285,
author = {Zhao, Zhuqing and Shehada, Halah and Ha, Dong and Dos Reis, Barbara and White, Robin and Shin, Sook},
title = {Machine Learning-Driven Optimization of Livestock Management: Classification of Cattle Behaviors for Enhanced Monitoring Efficiency},
year = {2024},
isbn = {9798400717833},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3696271.3696285},
doi = {10.1145/3696271.3696285},
abstract = {Monitoring cattle health in remote and expansive pastures poses significant challenges that necessitate automated, continuous, and real-time behavior monitoring. This paper investigates the effectiveness and reliability sensor-based cattle behavior classification for such monitoring, emphasizing the impact of intelligent feature selection in enhancing classification performance. To achieve this, we developed Wireless Sensor Nodes (WSN) affixed to individual cattle, enabling the capture of 3-axis acceleration data from five cows across varying seasons, spanning from summer to winter. Initially, we extracted a comprehensive set of 52 features, representing a broad spectrum of cow behaviors alongside statistical attributes. To enhance computational efficiency, we employed the Recursive Feature Elimination (RFE) method to distill 30 critical features by discarding redundant or less significant ones. Subsequently, these optimized features were utilized to train four machine learning (ML) models: Support Vector Machine (SVM), k-Nearest Neighbors (k-NN), Random Forest (RF), and Histogram-based Gradient Boosted Decision Trees (HGBDT). Notably, the HGBDT model demonstrated superior performance, achieving remarkable F1-scores of 99.01\% for 'grazing', 98.74\% for 'ruminating', 89.62\% for 'lying', 84.06\% for 'standing', and 91.87\% for 'walking'. These findings underscore the potential of our approach to serve as a robust framework for precision livestock farming, offering valuable insights into enhancing cattle health monitoring in remote environments.},
booktitle = {Proceedings of the 2024 7th International Conference on Machine Learning and Machine Intelligence (MLMI)},
pages = {85–91},
numpages = {7},
keywords = {HGBDT, RF, RFE, SVM},
location = {
},
series = {MLMI '24}
}

@inproceedings{10.1145/3696271.3696310,
author = {Rahin, Saima Ahmed and Hui, Bo and Li, Wanwan},
title = {Visualizing and Analyzing Human Activity Patterns through Graph-Based Methods},
year = {2024},
isbn = {9798400717833},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3696271.3696310},
doi = {10.1145/3696271.3696310},
abstract = {In recent years, the proliferation of wearable sensors and mobile devices has enabled the collection of large-scale spatiotemporal data, providing unprecedented opportunities to analyze human activity patterns. This study presents a novel approach to visualize and analyze human activity patterns using graph-based methods. Utilizing a dataset comprising timestamped geographical coordinates and labeled activity data, we construct a graph where nodes represent individual data points, and edges denote temporal proximity. By employing Graph Neural Networks (GNNs), we effectively capture the intricate spatiotemporal relationships inherent in the data. Later, we compared three other models GCN, GAN, and GraphSAGE, and found that GCN performs better for cluster separation and GAT shows best in terms of training loss.},
booktitle = {Proceedings of the 2024 7th International Conference on Machine Learning and Machine Intelligence (MLMI)},
pages = {247–259},
numpages = {13},
keywords = {Activity Recognition, Graph Neural Networks (GNNs), Spatiotemporal Data, Temporal Sequences, Wearable Sensors},
location = {
},
series = {MLMI '24}
}

@inproceedings{10.1145/3686397.3686405,
author = {Ko, Chih-Hsiang},
title = {User Acceptance and Quality Requirements of Digital Twins},
year = {2024},
isbn = {9798400717345},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3686397.3686405},
doi = {10.1145/3686397.3686405},
abstract = {Digital twins provide conditions for cyber-physical integration, as a bridge connecting the physical world and the cyber world, providing a new way for the manufacturing industry to conduct smart production and precise management. Data from the real world is transmitted to the virtual model through sensors to complete simulation, verification, dynamic adjustment and feedback. By improving designers’ ability to extract knowledge from large and complex data, digital twins can speed up design and development. Therefore, it is necessary to have a deep understanding of how to provide data to designers and how they interact with data. The quality of digital twins would determine their usability and efficiency. This study emphasized on the benefits that digital twins could provide to designers in data processing and integration for the realization of design innovation through the interactive design model of virtual reality. The results of this study could help enhance designers’ ability to control data and strengthen the way designers interact with data. Based on the integrated data environment, designers could conduct interactive analysis, respond to changes in the physical world, improve the design process and add product values.},
booktitle = {Proceedings of the 2024 8th International Conference on Information System and Data Mining},
pages = {44–49},
numpages = {6},
keywords = {digital twin, quality requirement, virtual reality},
location = {
},
series = {ICISDM '24}
}

@article{10.1145/3696405,
author = {Ghosh, Ushasi and Chiejina, Azuka and Stephenson, Nathan and Shah, Vijay K and Shakkottai, Srinivas and Bharadia, Dinesh},
title = {SPARC: Spatio-Temporal Adaptive Resource Control for Multi-site Spectrum Management in NextG Cellular Networks},
year = {2024},
issue_date = {December 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {2},
number = {CoNEXT4},
url = {https://doi.org/10.1145/3696405},
doi = {10.1145/3696405},
abstract = {This work presents SPARC (Spatio-Temporal Adaptive Resource Control), a novel approach for multi-site spectrum management in NextG cellular networks. SPARC addresses the challenge of limited licensed spectrum in dynamic environments. We leverage the O-RAN architecture to develop a multi-timescale RAN Intelligent Controller (RIC) framework, featuring an xApp for near-real-time interference detection and localization, and a xApp for real-time intelligent resource allocation. By utilizing base stations as spectrum sensors, SPARC enables efficient and fine-grained dynamic resource allocation across multiple sites, enhancing signal-to-noise ratio (SNR) by up to 7dB, spectral efficiency by up to 15\%, and overall system throughput by up to 20\%. Comprehensive evaluations, including emulations and over-the-air experiments, demonstrate the significant performance gains achieved through SPARC, showcasing it as a promising solution for optimizing resource efficiency and network performance in NextG cellular networks.},
journal = {Proc. ACM Netw.},
month = nov,
articleno = {35},
numpages = {18},
keywords = {interference detection, ran intelligent control, traffic}
}

@article{10.1145/3695769,
author = {Cattai, Tiziana and Colonnese, Stefania and Garlisi, Domenico and Pagano, Antonino and Cuomo, Francesca},
title = {GraphSmart: A Method for Green and Accurate IoT Water Monitoring},
year = {2024},
issue_date = {November 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {20},
number = {6},
issn = {1550-4859},
url = {https://doi.org/10.1145/3695769},
doi = {10.1145/3695769},
abstract = {Water scarcity is nowadays a critical global concern and an efficient management of water resources is paramount. This paper presents an original approach for monitoring Water Distribution Systems (WDSs) through Internet of Things (IoT) that involves the integration of multiple sensors placed across the distribution network to accurately measure water flow. To enhance energy efficiency for green monitoring and communication process, we harness the power of graph theory and graph signal processing to represent in a tunable and accurate way the water flow and simultaneously minimize the number of IoT sensors communicating those measurements. We propose a graph model where water flow is represented as signal on graph and we introduce an algorithm, named GraphSmart, designed to reconstruct the graph signal when certain measurements are unknown or missing. Our framework is applied on a synthetic realistic environment within the context of LoRaWAN (Long Range Wide Area Network), an infrastructure and protocol designed for ultra-low-power IoT devices. Our findings show that GraphSmart significantly reduces energy consumption while ensuring precise flow estimation. Our research demonstrates high potential for energy-efficient and accurate water flow monitoring, paving the way to improve the management of WDSs and enabling water operators to address water scarcity challenges.},
journal = {ACM Trans. Sen. Netw.},
month = nov,
articleno = {130},
numpages = {32},
keywords = {Graph network, smart water distribution networks, IoT, flow reconstruction, wireless sensors, LoRaWAN, energy efficiency}
}

@article{10.1145/3696420,
author = {Cai, Xinjun and Xu, Jingao and Deng, Kuntian and Lan, Hongbo and Wu, Yue and Zhuge, Xiangwen and Yang, Zheng},
title = {TrinitySLAM: On-board Real-time Event-image Fusion SLAM System for Drones},
year = {2024},
issue_date = {November 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {20},
number = {6},
issn = {1550-4859},
url = {https://doi.org/10.1145/3696420},
doi = {10.1145/3696420},
abstract = {Drones have witnessed extensive popularity among diverse smart applications, and visual Simultaneous Localization and Mapping (SLAM) technology is commonly used to estimate the six-degrees-of-freedom pose for drone flight control systems. However, traditional image-based SLAM cannot ensure the flight safety of drones, especially in challenging environments such as high-speed flight and high dynamic range scenarios. The event camera, a new vision sensor, holds the potential to enable drones to overcome these challenging scenarios if fused with the image-based SLAM. Unfortunately, the computational demands of event-image fusion SLAM have grown manifold compared with image-based SLAM. Existing research on visual SLAM acceleration cannot achieve real-time operation of event-image fusion SLAM on on-board computing platforms for drones. To fill this gap, we present TrinitySLAM, a high-accuracy, real-time, low-energy consumption event-image fusion SLAM acceleration framework utilizing Xilinx Zynq, an on-board heterogeneous computing platform. The key innovations of TrinitySLAM&nbsp; include a fine-grained computation allocation strategy, several novel hardware–software co-acceleration designs, and an efficient data exchange mechanism. We fully implement TrinitySLAM&nbsp; on the latest Zynq UltraScale+ platform and evaluate its performance on one custom-made drone dataset and four official datasets covering various scenarios. Comprehensive experiments show that TrinitySLAM&nbsp; improves the pose estimation accuracy by 28\% with half end-to-end latency and 1.2\texttimes{} energy consumption reduction compared with the most comparable state-of-the-art heterogeneous computing platform acceleration baseline.},
journal = {ACM Trans. Sen. Netw.},
month = nov,
articleno = {121},
numpages = {22},
keywords = {Drone, pose estimation, event camera, SLAM, software–hardware co-design}
}

@article{10.1145/3699773,
author = {Gao, Yang and Zhang, Wenbo and Ren, Junbin and Zheng, Ruihao and Jin, Yingcheng and Wu, Di and Shu, Lin and Xu, Xiangmin and Jin, Zhanpeng},
title = {PressInPose: Integrating Pressure and Inertial Sensors for Full-Body Pose Estimation in Activities},
year = {2024},
issue_date = {December 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {8},
number = {4},
url = {https://doi.org/10.1145/3699773},
doi = {10.1145/3699773},
abstract = {The accurate assessment of human body posture through wearable technology has significant implications for sports science, clinical diagnostics, rehabilitation, and VR interaction. Traditional methods often require complex setups or are limited by the environment's constraints. In response to these challenges, this paper presents an innovative approach to human posture estimation under complex motion scenarios through the development of an advanced shoe insole embedded with pressure sensors and an Inertial Measurement Unit (IMU). Coupled with a single wrist-mounted IMU, our system facilitates a comprehensive analysis of human biomechanics by integrating physical kinematics modeling based on pressure data with a multi-region human posture estimation network. To enhance the robustness of our system model, we employed large language models to generate virtual human motion sequences. These sequences were utilized to create synthetic IMU data for data augmentation purposes, addressing the challenge of limited real-world data availability and variability. Our approach uniquely combines physical modeling with data-driven techniques to improve the accuracy and reliability of posture estimation. Experimental results demonstrate that our integrated system significantly advances wearable technology for motion analysis. The Mean Per Joint Position Error (MPJPE) was reduced to 7.75 cm, highlighting the effectiveness of our multi-modal modeling and virtual data augmentation in refining posture estimation.},
journal = {Proc. ACM Interact. Mob. Wearable Ubiquitous Technol.},
month = nov,
articleno = {197},
numpages = {28},
keywords = {IMU, body pose estimation, pressure sensing, smart shoe}
}

@inproceedings{10.1145/3689942.3694748,
author = {Nuguri, Sai Shreya and Karthik, Karan and Pusapati, Vamsi and Kambhampati, Anirudh and Bhamidipati, Subrahmanya Chandra and Calyam, Aneesh and Alarcon, Mauro Lemus and Calyam, Prasad},
title = {Zeus: IoT-based Healthcare Data Management Security Framework for Remote Patient Monitoring},
year = {2024},
isbn = {9798400712388},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3689942.3694748},
doi = {10.1145/3689942.3694748},
abstract = {The Internet of things (IoT) is transforming healthcare by enabling the remote capture of patient data for diagnostic and treatment purposes. IoT sensors with edge computing for data analysis and storage in the cloud for remote patient monitoring presents a promising avenue for personalized healthcare. However, this integration poses challenges, which require a comprehensive approach to address concerns related to data security, privacy, and scalability. In this paper, we propose an IoT-based healthcare data management security framework viz., ''Zeus'' to address the challenges in remote patient monitoring. Specifically, using an wearable edema monitor healthcare use case, we present a Zeus reference architecture to develop a secure edge-cloud application leveraging real-world IoT sensors data processing involving data transfer mechanisms via gateways, cloud-based storage, and an end-user analysis/visualization user interface. Our Zeus approach transforms traditional practices by embedding security considerations at every stage of the application data lifecycle, from collection, storage to analysis/visualization. By conducting a thorough risk assessment, we identify and mitigate potential vulnerabilities proactively and foster an iterative design that ensures meeting end-user requirements in a secure, and privacy-preserving manner. Lastly, we conduct a scalability test on the data pipeline to validate the application elasticity in terms of concurrently processing multiple data streams from IoT sensors integrated for edge-cloud computing.},
booktitle = {Proceedings of the 2024 Workshop on Cybersecurity in Healthcare},
pages = {93–100},
numpages = {8},
keywords = {data security and privacy, iot-based healthcare, risk assessment},
location = {Salt Lake City, UT, USA},
series = {HealthSec '24}
}

@article{10.1145/3699768,
author = {Yang, Baichen and Zhang, Xinyi and Zhang, Jiaxi and Huang, Zirui and Lu, Qiqi and Zhang, Jin and Hu, Hai and Zhang, Qian},
title = {KneeGuard: A Calibration-free Wearable Monitoring System for Knee Osteoarthritis Gait Re-training via Effortless Wearing},
year = {2024},
issue_date = {December 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {8},
number = {4},
url = {https://doi.org/10.1145/3699768},
doi = {10.1145/3699768},
abstract = {Gait re-training is an effective approach to slow disease progression and alleviate pain in knee osteoarthritis (KOA) patients. Personalized gait re-training strategies, based on knee loading and muscle forces, have shown promise in improving rehabilitation outcomes. Laboratory systems to monitor these metrics are unsuitable for daily use owing to the complicated setup and high-cost. Recently proposed wearable solutions try to fill this gap, but their in-lab calibration requirement still hinders practical usage. This paper introduces KneeGuard, a calibration-free gait re-training monitoring system that can estimate knee loading and muscle forces via effortless wearing. We identify the main issue of current calibration-needed systems is insufficient biomechanical information retrieval and modeling. To address this, we propose a user-friendly wearable prototype incorporating inertial measurement unit (IMU) and surface electromyography (sEMG) to obtain comprehensive biomechanical information including body geometrical changes and muscle contractions. For modeling, we design a biomechanic-inspired fusion framework based on multi-task learning and cross-modality attention to capture inter-modality biomechanical correlations. Additionally, since precise sensor placement required by current sEMG-based solutions is difficult to locate, we develop a circular sEMG array and propose a spatial-aware feature extraction module, achieving effective biomechanical feature extraction under effortless wearing. We collaborate with a medical center and collect a dataset from 21 KOA patients and 17 healthy subjects at different speeds. Notably, our dataset includes six gait types for KOA gait re-training, making it the first gait dataset with comprehensive re-training strategies. Evaluation demonstrates that KneeGuard achieves an average normalized root-mean-square error (NRMSE) of 9.95\% in knee loading estimation and an average NRMSE of 8.75\% in the estimation of muscle forces, comparable to the with-calibration results in existing works. We have open-sourced the code and a sample dataset in https://github.com/KneeGuard/KneeGuard.},
journal = {Proc. ACM Interact. Mob. Wearable Ubiquitous Technol.},
month = nov,
articleno = {151},
numpages = {29}
}

@article{10.1145/3699749,
author = {Monarca, Ivonne and Cibrian, Franceli L. and Hurtado, Isabel L\'{o}pez and Tentori, Monica},
title = {Smartphone Haptics Can Uncover Differences in Touch Interactions Between ASD and Neurotypicals},
year = {2024},
issue_date = {December 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {8},
number = {4},
url = {https://doi.org/10.1145/3699749},
doi = {10.1145/3699749},
abstract = {Utilizing touch interactions from smartphones for gathering data and identifying digital markers for screening and monitoring neurological disorders, such as Autism Spectrum Disorder (ASD), is an emerging area of research. Smartphones provide multiple benefits for this kind of study, including unobtrusive data collection via built-in sensors, integrated haptic feedback systems, and the capability to create specialized applications. Acknowledging the significant yet understudied presence of tactile processing differences in individuals with ASD, we designed and developed Feel and Touch, a mobile game that leverages the haptic capabilities of smartphones. This game provides vibrotactile feedback in response to touch interactions and collects data on these interactions. We conducted a deployment study with 83 Mexican children who played Feel and Touch to capture their interactions with the game. Our analysis, comparing touch interactions between children with ASD and neurotypical (NT) peers, uncovered three digital markers based on phone tilt and touch patterns that distinguish the two groups. Additionally, we demonstrated the ability of a machine learning model to accurately classify these interactions between ASD and NT children. Our findings discuss the implications in terms of accessibility and ubiquity, as well as the possibilities for the development of digital markers and their application in pervasive computing for healthcare.},
journal = {Proc. ACM Interact. Mob. Wearable Ubiquitous Technol.},
month = nov,
articleno = {164},
numpages = {34},
keywords = {Autism Spectrum Disorder, Digital Markers, Vibrotactile Pattern}
}

@article{10.1145/3699780,
author = {He, Zhixiang and Chen, Jing and Wu, Cong and He, Kun and Du, Ruiying and Jia, Ju and Gu, Yangyang and Sun, Xiping},
title = {HCR-Auth: Reliable Bone Conduction Earphone Authentication with Head Contact Response},
year = {2024},
issue_date = {December 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {8},
number = {4},
url = {https://doi.org/10.1145/3699780},
doi = {10.1145/3699780},
abstract = {Earables, or ear wearables, are increasingly being used for a variety of personal applications, prompting the development of authentication schemes to safeguard user privacy. Existing authentications are designed for traditional in-ear earphones, relying on a closed ear canal environment, which is not suited for bone conduction earphones that feature an open-ear design. In this paper, we propose HCR-Auth, a new authentication approach for bone conduction earphones based on head biometrics. It employs a modulated chirp signal, emitted by the earphone speaker, to actively sense the user's head structure, and captures the response through the earphone's accelerometer. It operates implicitly, eliminating additional efforts from the user to perform authentication. Through extensive experiments involving 60 subjects, we determine that HCR-Auth achieves a commendable balanced accuracy of 96.55\% using only 10 registration samples, proving its efficacy and resilience against potential threats. Our dataset and source codes are available at https://anonymous.4open.science/r/HCR-Auth-D43B/.},
journal = {Proc. ACM Interact. Mob. Wearable Ubiquitous Technol.},
month = nov,
articleno = {208},
numpages = {27},
keywords = {Biometrics, Earable, User Authentication}
}

@inproceedings{10.1145/3689943.3695042,
author = {Siriwardana, Rathu I. P. B. B. and Shen, Yu and Roos, Stefanie},
title = {Secure Communication in Dolphin: Integrating Trusted Execution Environments for Enhanced Caller Privacy},
year = {2024},
isbn = {9798400712395},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3689943.3695042},
doi = {10.1145/3689943.3695042},
abstract = {Censorship remains a critical global issue, with authorities frequently restricting internet access to control information dissemination. Dolphin has enabled data transmission via cellular voice channels during internet shutdowns but raises privacy concerns due to its reliance on the callee's trustworthiness.This paper proposes enhancing Dolphin with Trusted Execution Environments (TEEs) on the callee's side. All crucial operations are executed within a TEE, hiding sensitive information such as login credentials from the callee. As a consequence, we only rely on the callee for availability but not confidentiality and integrity, which are guaranteed by the TEE.We present a security analysis to show that indeed we achieve our confidentiality and integrity goals under the assumption that the hardware is indeed trusted. We implement our design using AWS Nitro Enclaves and our performance evaluation shows that the additional latency induced by our design is in the order of 1-2 seconds while the overall delay of Dolphin is in the order of minutes.},
booktitle = {Proceedings of the 23rd Workshop on Privacy in the Electronic Society},
pages = {47–58},
numpages = {12},
keywords = {AWS nitro enclaves, censorship resistance, internet blackouts, trusted execution environments},
location = {Salt Lake City, UT, USA},
series = {WPES '24}
}

@article{10.1145/3699756,
author = {Huang, Kunpeng and Iravantchi, Yasha and Chen, Dongyao and Sample, Alanson P.},
title = {MagDesk: Interactive Tabletop Workspace Based on Passive Magnetic Tracking},
year = {2024},
issue_date = {December 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {8},
number = {4},
url = {https://doi.org/10.1145/3699756},
doi = {10.1145/3699756},
abstract = {Accurate and responsive 3D tracking enables interactive and context-aware workspaces, including mixed reality 3D interfaces and collaborative tangible interactions. However, limitations of current tracking mechanisms - line-of-sight occlusion, drifting errors, small working volumes, or instrumentation that requires maintenance - ultimately restrict their adoption. This paper introduces MagDesk, an interactive tabletop workspace capable of real-time 3D tracking of passive magnets embedded in objects. Using a sensing array of 112 low-cost magnetometers underneath a table, our custom-designed signal processing and localization engine enables simultaneous tracking of multiple magnets in 5 degrees of freedom with millimeter accuracy. MagDesk can continuously and robustly track magnets at a maximum height of 600 mm over a 1750 mm (L) \texttimes{} 950 mm (W) table, while achieving an average positional and orientational error of 2.49 mm and 0.72 ° near the table surface and 14.40 mm and 2.25° across the entire sensing range. To demonstrate MagDesk's object-tracking capabilities, this work presents a series of magnetic widgets for tangible interactions and explores two applications - a 3D drawing interface and augmented-reality tabletop games. By instrumenting a regular table surface, MagDesk presents a low-cost and accurate approach to 3D tracking passive objects for home and office environments.},
journal = {Proc. ACM Interact. Mob. Wearable Ubiquitous Technol.},
month = nov,
articleno = {170},
numpages = {31},
keywords = {Interactive Workspace, Magnetic Sensing, Object Tracking}
}

@article{10.1145/3699771,
author = {Bian, Haoyu and Guo, Bin and Liu, Sicong and Ding, Yasan and Gao, Shanshan and Yu, Zhiwen},
title = {UbiHR: Resource-efficient Long-range Heart Rate Sensing on Ubiquitous Devices},
year = {2024},
issue_date = {December 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {8},
number = {4},
url = {https://doi.org/10.1145/3699771},
doi = {10.1145/3699771},
abstract = {Ubiquitous on-device heart rate sensing is vital for high-stress individuals and chronic patients. Non-contact sensing, compared to contact-based tools, allows for natural user monitoring, potentially enabling more accurate and holistic data collection. However, in open and uncontrolled mobile environments, user movement and lighting introduce noises. Existing methods, such as curve-based or short-range deep learning recognition based on adjacent frames, strike the optimal balance between real-time performance and accuracy, especially under limited device resources. In this paper, we present UbiHR, a ubiquitous device-based heart rate sensing system. Key to UbiHR is a real-time long-range spatio-temporal model enabling noise-independent heart rate recognition and display on commodity mobile devices, along with a set of mechanisms for prompt and energy-efficient sampling and preprocessing. Diverse experiments and user studies involving four devices, four tasks, and 80 participants demonstrate UbiHR's superior performance, enhancing accuracy by up to 74.2\% and reducing latency by 51.2\%.},
journal = {Proc. ACM Interact. Mob. Wearable Ubiquitous Technol.},
month = nov,
articleno = {163},
numpages = {26},
keywords = {Long-range Spatio-temporal Sensing}
}

@inproceedings{10.1145/3689942.3694747,
author = {Rahmani, Zahra and Shahini, Nahal and Gat, Nadav and Yun, Zebin and Jiang, Yuzhou and Farchy, Ofir and Harel, Yaniv and Chaudhary, Vipin and Ayday, Erman and Sharif, Mahmood},
title = {Privacy-Preserving Collaborative Genomic Research: A Real-Life Deployment and Vision},
year = {2024},
isbn = {9798400712388},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3689942.3694747},
doi = {10.1145/3689942.3694747},
abstract = {The data revolution holds a significant promise for the health sector. Vast amounts of data collected and measured from individuals will be transformed into knowledge, AI models, predictive systems, and digital best practices. One area of health that stands to benefit greatly from this advancement is the genomic domain. The advancement of AI, machine learning, and data science has opened new opportunities for genomic research, promising breakthroughs in personalized medicine. However, the increasing awareness of privacy and cyber security necessitates robust solutions to protect sensitive data in collaborative research. This paper presents a practical deployment of a privacy-preserving framework for genomic research, developed in collaboration with Lynx.MD, a platform designed for secure health data collaboration. The framework addresses critical cyber security and privacy challenges, enabling the privacy-preserving sharing and analysis of genomic data while mitigating risks associated with data breaches. By integrating advanced privacy-preserving algorithms, the solution ensures the protection of individual privacy without compromising data utility. A unique feature of the system is its ability to balance the trade-offs between data sharing and privacy, providing stakeholders with tools to quantify privacy risks and make informed decisions. The implementation of the framework within Lynx.MD involves encoding genomic data into binary formats and applying noise through controlled perturbation techniques. This approach preserves essential statistical properties of the data, facilitating effective research and analysis. Additionally, the system incorporates real-time data monitoring and advanced visualization tools, enhancing user experience and decision-making capabilities. The paper highlights the need for tailored privacy attacks and defenses specific to genomic data, given its unique characteristics compared to other data types. By addressing these challenges, the proposed solution aims to foster global collaboration in genomic research, ultimately contributing to significant advancements in personalized medicine and public health.},
booktitle = {Proceedings of the 2024 Workshop on Cybersecurity in Healthcare},
pages = {85–91},
numpages = {7},
keywords = {data sharing, genomic privacy, usable privacy},
location = {Salt Lake City, UT, USA},
series = {HealthSec '24}
}

@article{10.1145/3699736,
author = {Miao, Shenghuan and Chen, Ling},
title = {GOAT: A Generalized Cross-Dataset Activity Recognition Framework with Natural Language Supervision},
year = {2024},
issue_date = {December 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {8},
number = {4},
url = {https://doi.org/10.1145/3699736},
doi = {10.1145/3699736},
abstract = {Wearable human activity recognition faces challenges in cross-dataset generalization due to variations in device configurations and activity types across datasets. We present GOAT, a Generalized crOss-dataset Activity recogniTion framework that leverages learning with natural language supervision to address these challenges. GOAT utilizes textual attributes from activity labels and device on-body positions to enable multimodal pre-training, aligning wearable activity representations with corresponding textual representations. This approach enables GOAT to adapt to diverse device configurations and activity label spaces in downstream tasks. Our method incorporates a novel device position encoding technique, a Transformer-based activity encoder, and a cosine similarity loss function to enhance feature extraction and generalization capabilities. Extensive evaluations demonstrate GOAT's effectiveness across various scenarios, including comparisons with state-of-the-art baselines, component analysis, and zero-shot activity recognition. GOAT shows promise for advancing cross-dataset activity recognition, offering a flexible and scalable solution for diverse wearable sensing applications.},
journal = {Proc. ACM Interact. Mob. Wearable Ubiquitous Technol.},
month = nov,
articleno = {184},
numpages = {28},
keywords = {human activity recognition, pre-trained model, representation learning, wearable sensors}
}

@article{10.1145/3699740,
author = {Kouaho, Whitney-Jocelyn and Epstein, Daniel A.},
title = {Investigating Perspectives of and Experiences with Low Cost Commercial Fitness Wearables},
year = {2024},
issue_date = {December 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {8},
number = {4},
url = {https://doi.org/10.1145/3699740},
doi = {10.1145/3699740},
abstract = {Consumer fitness wearables account for a growing body of personal mobile devices in the U.S. As a result, there has been increasing interest in Ubicomp in designing sensing devices which incorporate the needs of people of a broad range of backgrounds, especially of lower socioeconomic (SES) status. However, fitness trackers are expensive, and although low cost versions exist, there has not been much research on the viability of these devices for promoting their goals. To further the conversation of device use, we review a corpus of over 1,700 product reviews of 9 low cost consumer trackers, to determine perceptions and expectations of quality and general use. From this, we find that the low cost device is not currently necessarily increasing access, and that people have a wide range of expectations for what tracking will allow and represents at this price point, which colors how they describe their use experiences. We suggest that there is a need for a focused design effort for low cost devices which rectifies such discrepancies, and presents the low cost device as a counterpart to those of a higher consumer price, not an alternative.},
journal = {Proc. ACM Interact. Mob. Wearable Ubiquitous Technol.},
month = nov,
articleno = {193},
numpages = {22},
keywords = {device reviews, fitness trackers, low cost, personal informatics, physical activity, wearables}
}

@article{10.1145/3699765,
author = {Yang, Bufang and Jiang, Siyang and Xu, Lilin and Liu, Kaiwei and Li, Hai and Xing, Guoliang and Chen, Hongkai and Jiang, Xiaofan and Yan, Zhenyu},
title = {DrHouse: An LLM-empowered Diagnostic Reasoning System through Harnessing Outcomes from Sensor Data and Expert Knowledge},
year = {2024},
issue_date = {December 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {8},
number = {4},
url = {https://doi.org/10.1145/3699765},
doi = {10.1145/3699765},
abstract = {Large language models (LLMs) have the potential to transform digital healthcare, as evidenced by recent advances in LLM-based virtual doctors. However, current approaches rely on patient's subjective descriptions of symptoms, causing increased misdiagnosis. Recognizing the value of daily data from smart devices, we introduce a novel LLM-based multi-turn consultation virtual doctor system, DrHouse, which incorporates three significant contributions: 1) It utilizes sensor data from smart devices in the diagnosis process, enhancing accuracy and reliability. 2) DrHouse leverages continuously updating medical knowledge bases to ensure its model remains at diagnostic standard's forefront. 3) DrHouse introduces a novel diagnostic algorithm that concurrently evaluates potential diseases and their likelihood, facilitating more nuanced and informed medical assessments. Through multi-turn interactions, DrHouse determines the next steps, such as accessing daily data from smart devices or requesting in-lab tests, and progressively refines its diagnoses. Evaluations on three public datasets and our self-collected datasets show that DrHouse can achieve up to an 31.5\% increase in diagnosis accuracy over the state-of-the-art baselines. The results of a 32-participant user study show that 75\% medical experts and 91.7\% test subjects are willing to use DrHouse.},
journal = {Proc. ACM Interact. Mob. Wearable Ubiquitous Technol.},
month = nov,
articleno = {153},
numpages = {29},
keywords = {Diagnostic Reasoning Systems, Internet of Things, Knowledge Retrieval, LLMs, Proactive Conversational Systems, Sensor Data, Up-to-Date}
}

@article{10.1145/3695876,
author = {Stephanie, Veronika and Khalil, Ibrahim and Atiquzzaman, Mohammed},
title = {Weight-Based Privacy-Preserving Asynchronous SplitFed for Multimedia Healthcare Data},
year = {2024},
issue_date = {December 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {20},
number = {12},
issn = {1551-6857},
url = {https://doi.org/10.1145/3695876},
doi = {10.1145/3695876},
abstract = {Multimedia significantly enhances modern healthcare by facilitating the analysis and sharing of diverse data, including medical images, videos, and sensor data. Integrating AI for multimedia data classification shows promise in improving healthcare services, data analysis, and decision-making. However, ensuring privacy in AI-integrated healthcare systems remains a challenge, especially with data continuously transmitted over networks. Synchronous Federated Learning (FL) is designed to address these privacy concerns by allowing end devices to collaboratively train a machine learning model without sharing data. Nonetheless, FL alone does not fully resolve privacy issues and faces efficiency challenges, particularly with devices of varying computational capabilities. In this article, we introduce an Asynchronous Partial Privacy-preserving Split-Federated Learning (APP-SplitFed) approach for smart healthcare systems. This method reduces computational demands on resource-limited devices and uses a weight-based aggregation method to allow devices of differing computational power to contribute effectively, ensuring optimal model performance and rapid convergence. Additionally, we incorporate a secure aggregation method to prevent adversaries from identifying individual models owned by healthcare institutions.},
journal = {ACM Trans. Multimedia Comput. Commun. Appl.},
month = nov,
articleno = {377},
numpages = {24},
keywords = {Federated Learning, Split Learning, Internet-of-Medical Things, Deep Learning, Secure Aggregation, Secure Multi-Party Computation}
}

@inproceedings{10.1145/3689942.3694755,
author = {Tschider, Charlotte},
title = {Position Paper: Revealing the Limits of Cybersecurity Law for Healthcare AI},
year = {2024},
isbn = {9798400712388},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3689942.3694755},
doi = {10.1145/3689942.3694755},
abstract = {Healthcare technologies are responsible for critical health functions. From electronic health record databases to complex artificially intelligent medical devices, the future of human health is largely tethered to an internet connection. Healthcare technologies also collect, transfer, store, and retain some of the most sensitive personal information that can be created, from medical data to behavioral characteristics, biometric data, and genetic data. It is no surprise that most countries categorize health technologies as "critical infrastructure": their improper function can precipitate cataclysmic results.Despite the inherent risks in operating health technologies, cybersecurity legal requirements applicable to them are largely generic, reliant on administrative agency interpretation and application. These requirements differ depending on whether an organization is a Health Insurance Portability and Accountability Act (HIPAA) covered entity, a medical device manufacturer, or a consumer health device company. In all, very few cybersecurity legal requirements are applicable to AI.Federal administrative agencies like the U.S. Food and Drug Administration, the Office for Civil Rights, and the Federal Trade Commission have exercised discretion and substituted rulemaking in cybersecurity with guidance, studies, and enforcement actions to establish these requirements for the healthcare sector. However, following recent U.S. Supreme Court decisions impacting administrative decision-making and limiting the power of administrative agencies, the necessity of enforceable cybersecurity requirements in the healthcare sector may need to be re-examined.},
booktitle = {Proceedings of the 2024 Workshop on Cybersecurity in Healthcare},
pages = {125–134},
numpages = {10},
keywords = {artificial intelligence, cybersecurity, fda, health data, hipaa, law, medical device, privacy},
location = {Salt Lake City, UT, USA},
series = {HealthSec '24}
}

@article{10.1145/3699744,
author = {Dai, Gaole and Xu, Huatao and Yoon, Hyungjun and Li, Mo and Tan, Rui and Lee, Sung-Ju},
title = {ContrastSense: Domain-invariant Contrastive Learning for In-the-Wild Wearable Sensing},
year = {2024},
issue_date = {December 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {8},
number = {4},
url = {https://doi.org/10.1145/3699744},
doi = {10.1145/3699744},
abstract = {Existing wearable sensing models often struggle with domain shifts and class label scarcity. Contrastive learning is a promising technique to address class label scarcity, which however captures domain-related features and suffers from low-quality negatives. To address both problems, we propose ContrastSense, a domain-invariant contrastive learning scheme for a realistic wearable sensing scenario where domain shifts and class label scarcity are presented simultaneously. To capture domain-invariant information, ContrastSense exploits unlabeled data and domain labels specifying user IDs or devices to minimize the discrepancy across domains. To improve the quality of negatives, time and domain labels are leveraged to select samples and refine negatives. In addition, ContrastSense designs a parameter-wise penalty to preserve domaininvariant knowledge during fine-tuning to further maintain model robustness. Extensive experiments show that ContrastSense outperforms the state-of-the-art baselines by 8.9\% on human activity recognition with inertial measurement units and 5.6\% on gesture recognition with electromyography when presented with domain shifts across users. Besides, when presented with different kinds of domain shifts across devices, on-body positions, and datasets, ContrastSense achieves consistent improvements compared with the best baselines.},
journal = {Proc. ACM Interact. Mob. Wearable Ubiquitous Technol.},
month = nov,
articleno = {162},
numpages = {32},
keywords = {Contrastive Learning, Domain Generalization, Wearable Sensing}
}

@inproceedings{10.1145/3688459.3688462,
author = {El Zein, Yamane and Salehzadeh Niksirat, Kavous and Zufferey, No\'{e} and Humbert, Mathias and Huguenin, K\'{e}vin},
title = {Shadow Health-Related Data: Definition, Categorization, and User Perspectives},
year = {2024},
isbn = {9798400717963},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3688459.3688462},
doi = {10.1145/3688459.3688462},
abstract = {Health-related data (HRD) about individuals are increasingly generated and processed. The sources and volume of such data have grown larger over the past years, they include wearable devices, health-related mobile apps, and electronic health records. HRD are sensitive, have important privacy implications, hence hold a special status under existing privacy laws and regulations. In this work, we focus on shadow HRD: these HRD are generated and/or processed by individuals by using general-purpose digital tools outside of a professional healthcare information system. Some examples are health-related queries made by individuals on general-purpose search engines and LLM-based chatbots, or medical appointments and contact information of health professionals synced to the cloud. Such data, and the privacy risks stemming from them, are often overlooked when studying digital health. Using information from two focus group sessions (23 participants in total), we identified and categorized a broad variety of user behaviors that, including the aforementioned examples, lead to the creation of shadow HRD. Then, informed by this categorization, we designed a questionnaire and deployed it through an online survey (300 respondents) to assess the prevalence of such behaviors among the general public, as well as user awareness of (and concerns about) the privacy risks stemming from their shadow HRD. Our findings show that most respondents adopt numerous and diverse behaviors that create shadow HRD, and that very few resort to mechanisms to protect their privacy.},
booktitle = {Proceedings of the 2024 European Symposium on Usable Security},
pages = {58–76},
numpages = {19},
keywords = {health-related data, privacy, user study},
location = {
},
series = {EuroUSEC '24}
}

@inproceedings{10.1145/3689936.3694693,
author = {Monteuuis, Jean-Philippe and Petit, Jonathan and Chen, Cong and Das, Soumya and Nekoui, Mohammad and Yang, Seung},
title = {V2X Misbehavior in Decentralized Notification Basic Service: Considerations for Standardization},
year = {2024},
isbn = {9798400712326},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3689936.3694693},
doi = {10.1145/3689936.3694693},
abstract = {Connected and Automated Vehicles (CAV) use sensors and wireless communication to improve road safety and efficiency. However, attackers may target Vehicle-to-Everything (V2X) communication. Indeed, an attacker may send authenticated but wrong data to con- vey false location information, alert incorrect events, or report a bogus object, thereby endangering other CAVs' safety. Standardiza- tion Development Organizations (SDOs) are currently working on developing security standards against such attacks. Unfortunately, current standardization efforts do not yet include misbehavior spec- ifications for all V2X services such as Decentralized Environment Notification Basic Service (DENBS also commonly called DENM). The contributions of this work are the first security analysis for DENM (67 threats), the proposal of 103 misbehavior detectors for DENM, and inputs for consideration in existing standards1.},
booktitle = {Proceedings of the 2024 Cyber Security in CarS Workshop},
pages = {76–84},
numpages = {9},
keywords = {cav, decentralized notification, misbehavior, risk assessment, standards., threat analysis, v2x},
location = {Salt Lake City, UT, USA},
series = {CSCS '24}
}

@inproceedings{10.1145/3689930.3695207,
author = {Routray, Kasturi and Bera, Padmalochan},
title = {Lightweight and Decentralized Access Control for Cloud-Assisted Industrial Control Systems},
year = {2024},
isbn = {9798400712265},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3689930.3695207},
doi = {10.1145/3689930.3695207},
abstract = {Cloud-assisted industrial control systems (CA-ICS ) are increasingly adopted for their ability to enhance efficiency, scalability, and remote access to resources. These systems integrate IoT devices for real-time monitoring and automated control, with the cloud supporting improved functionality and operational effectiveness. While CA-ICS provide several benefits, they face various data security challenges, such as unauthorized access, tampering, and leakage of sensitive data in an untrusted and dynamic cloud environment. In this work, we propose a ciphertext-policy attribute-based encryption (CP-ABE) framework to ensure secure and fine-grained access control on industrial data stored in the cloud. Our approach improves efficiency by replacing computationally intensive bilinear pairing operations with lightweight elliptic curve cryptography (ECC) based scalar multiplication operations. Our scheme utilizes decentralized attribute authorities to independently generate and distribute user private keys, avoiding coordination and preventing key escrow attacks. It uses unique global identifiers to combine key components which are linked to their specific attribute set. and facilitates efficient attribute revocation. Furthermore, our scheme employs fog nodes for partial decryption of ciphertext, which reduces computational overhead and latency for resource-constrained devices, thereby enhancing overall performance and response time. Theoretical analysis validates our proposed CP-ABE scheme's effectiveness and usability in CA-ICS, enhancing both security and the efficiency of remote monitoring and data-driven decision-making.},
booktitle = {Proceedings of the 2024 Workshop on Re-Design Industrial Control Systems with Security},
pages = {71–78},
numpages = {8},
keywords = {cp-abe, decentralized, ecc, outsourced decryption, revocation},
location = {Salt Lake City, UT, USA},
series = {RICSS '24}
}

@inproceedings{10.1145/3680530.3695456,
author = {Wicaksono, Irmandy and Blanchard, Lancelot and Chin, Sam and Colon, Cristian and Paradiso, Joseph},
title = {KnitworkVR: Dual-reality Experience through Distributed Sensor-Actuator Networks in the Living Knitwork Pavilion},
year = {2024},
isbn = {9798400711336},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3680530.3695456},
doi = {10.1145/3680530.3695456},
abstract = {KnitworkVR integrates dual-reality and digital twin platforms to simulate the Living Knitwork Pavilion in a desert landscape, using real-time sensor data. The sensor network captures movements, interactions, and spatial positioning of occupants, linking electric field sensor data with VR positioning. This creates a sensor-driven immersive experience with dynamic lighting, live animations, and adaptive soundscapes, enabling telepresence and collaborative interaction in both digital and physical environments. This paper explores the functional textile design, sensing hardware, audiovisual system, and VR framework, highlighting the applications of immersive spaces with knitted electronic textiles and distributed physical-digital systems.},
booktitle = {SIGGRAPH Asia 2024 Art Papers},
articleno = {12},
numpages = {7},
keywords = {electronic textiles, distributed sensing, digital twin, virtual reality, immersive environments, telepresence, AI-generated music},
location = {
},
series = {SA '24}
}

@article{10.1145/3687991,
author = {Jang, Deok-Kyeong and Yang, Dongseok and Jang, Deok-Yun and Choi, Byeoli and Lee, Sung-Hee and Shin, Donghoon},
title = {ELMO: Enhanced Real-time LiDAR Motion Capture through Upsampling},
year = {2024},
issue_date = {December 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {43},
number = {6},
issn = {0730-0301},
url = {https://doi.org/10.1145/3687991},
doi = {10.1145/3687991},
abstract = {This paper introduces ELMO, a real-time upsampling motion capture framework designed for a single LiDAR sensor. Modeled as a conditional autoregressive transformer-based upsampling motion generator, ELMO achieves 60 fps motion capture from a 20 fps LiDAR point cloud sequence. The key feature of ELMO is the coupling of the self-attention mechanism with thoughtfully designed embedding modules for motion and point clouds, significantly elevating the motion quality. To facilitate accurate motion capture, we develop a one-time skeleton calibration model capable of predicting user skeleton off-sets from a single-frame point cloud. Additionally, we introduce a novel data augmentation technique utilizing a LiDAR simulator, which enhances global root tracking to improve environmental understanding. To demonstrate the effectiveness of our method, we compare ELMO with state-of-the-art methods in both image-based and point cloud-based motion capture. We further conduct an ablation study to validate our design principles. ELMO's fast inference time makes it well-suited for real-time applications, exemplified in our demo video featuring live streaming and interactive gaming scenarios. Furthermore, we contribute a high-quality LiDAR-mocap synchronized dataset comprising 20 different subjects performing a range of motions, which can serve as a valuable resource for future research. The dataset and evaluation code are available at https://movin3d.github.io/ELMO_SIGASIA2024/},
journal = {ACM Trans. Graph.},
month = nov,
articleno = {237},
numpages = {14},
keywords = {motion capture, motion synthesis, character animation, point cloud, deep learning}
}

@inproceedings{10.1145/3691555.3696827,
author = {Yang, Huan and Zhang, Deyu and Zhao, Yudong and Li, Yuanchun and Liu, Yunxin},
title = {A First Look At Efficient And Secure On-Device LLM Inference Against KV Leakage},
year = {2024},
isbn = {9798400712470},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3691555.3696827},
doi = {10.1145/3691555.3696827},
abstract = {Running LLMs on end devices has garnered significant attention recently due to their advantages in privacy preservation. With the advent of lightweight LLM models and specially designed GPUs, on-device LLM inference has achieved the necessary accuracy and performance metrics.However, we have identified that LLM inference on GPUs can leak privacy-sensitive intermediate information, specifically the KV pairs. An attacker could exploit these KV pairs to reconstruct the entire user conversation, leading to significant vulnerabilities. Existing solutions, such as Fully Homomorphic Encryption (FHE) and Trusted Execution Environments (TEE), are either too computation-intensive or resource-limited.To address these issues, we designed KV-Shield, which operates in two phases. In the initialization phase, it permutes the weight matrices so that all KV pairs are correspondingly permuted. During the runtime phase, the attention vector is inversely permuted to ensure the correctness of the layer output. All permutation-related operations are executed within the TEE, ensuring that insecure GPUs cannot access the original KV pairs, thus preventing conversation reconstruction. Finally, we theoretically analyze the correctness of KV-Shield, along with its advantages and overhead.},
booktitle = {Proceedings of the 19th Workshop on Mobility in the Evolving Internet Architecture},
pages = {13–18},
numpages = {6},
location = {Washington D.C., DC, USA},
series = {MobiArch '24}
}

@inproceedings{10.1145/3689944.3696162,
author = {Dietrich, Jens and White, Tim and Abdollahpour, Mohammad Mahdi and Wen, Elliott and Hassanshahi, Behnaz},
title = {BinEq - A Benchmark of Compiled Java Programs to Assess Alternative Builds},
year = {2024},
isbn = {9798400712401},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3689944.3696162},
doi = {10.1145/3689944.3696162},
abstract = {Incidents like xz and SolarWinds have led to an increased focus on software supply chain security. A particular concern is the detection and prevention of compromised builds. A common approach is to independently re-build projects, and compare the results. This leads to the availability of different binaries built from the same sources, and raises the question of how to compare the respective binaries (to confirm the integrity of builds, to detect compromised builds, etc). It is however not clear how to do this: naive bitwise comparison is often too strict, and establishing the behavioural equivalence of two binaries is undecidable. A pragmatic step towards a solution is to provision a benchmark that can be used to test and train equivalence relations. We present such a benchmark for Java bytecode, consisting of 622,029 pairs of binaries (compiled Java classes) labelled as to whether these classes are equivalent or not. We refer to these pairs as equivalence and non-equivalence oracles, respectively. We derive equivalence oracles from building 56 projects and project versions using 32 dockerised build environments (with different compilers, compiler versions and configurations). Non-equivalence oracles are derived from three different sources: (1) proven breaking API changes, (2) semantic code changes synthesised by means of bytecode mutations, and (3) code changes extracted from vulnerability patches. To illustrate how to use the benchmark, we describe an experiment using two equivalence relations based on locality-sensitive hashing.},
booktitle = {Proceedings of the 2024 Workshop on Software Supply Chain Offensive Research and Ecosystem Defenses},
pages = {15–25},
numpages = {11},
keywords = {build security, java, maven, reproducible builds, software supply chain security},
location = {Salt Lake City, UT, USA},
series = {SCORED '24}
}

@article{10.1145/3690389,
author = {Li, Yuqi and Zhao, Kehao and Zhao, Jieru and Wang, Qirui and Zhong, Shuda and Lalam, Nageswara and Wright, Ruishu and Zhou, Peipei and Chen, Kevin P.},
title = {FiberFlex: Real-time FPGA-based Intelligent and Distributed Fiber Sensor System for Pedestrian Recognition},
year = {2024},
issue_date = {December 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {17},
number = {4},
issn = {1936-7406},
url = {https://doi.org/10.1145/3690389},
doi = {10.1145/3690389},
abstract = {In recent years, security monitoring of public places and critical infrastructure has heavily relied on the widespread use of cameras, raising concerns about personal privacy violations. To balance the need for effective security monitoring with the protection of personal privacy, we explore the potential of optical fiber sensors for this application. This article proposes FiberFlex, an intelligent and distributed fiber sensor system. Ultizing Field Programmable Gate Arrays (FPGA) high-level synthesis (HLS) acceleration, FiberFlex offers real-time pedestrian detection by co-designing the entire pipeline of optical signal acquisition, processing, and recognition networks based on the principles of optical fiber sensing. As a promising alternative to traditional camera-based monitoring systems, FiberFlex achieves pedestrian detection by analyzing the vibration patterns caused by pedestrian footsteps, enabling security monitoring while preserving individual privacy. FiberFlex comprises three modules: First, fiber-optic sensing system: A fiber-optic distributed acoustic sensing (DAS) system is built and used to measure the ground vibration waves generated by people walking. Second, algorithms: We first collect the training data by measuring the ground vibration waves, label the data, and use the data to train the neural network models to perform pedestrian recognition. Third, hardware accelerators: We use HLS tools to design hardware modules on FPGA for data collection and pre-processing and integrate them with the downstream neural network accelerators to perform in-line real-time pedestrian detection. The final detection results are sent back from FPGA to the host CPU. We implement our system FiberFlex with the in-house built DAS system and AMD/Xilinx Kintex7 FPGA KC705 board and verify the whole system using the real-world collected data. We conduct recognition tests on five test subjects of varying ages, heights, and weights in a fixed sensing area. Each subject experienced 20 real-time recognition tests using their daily walking habits, and the subjects were given adequate rest between tests. After 100 tests on five test subjects, the overall real-time recognition accuracy exceeded  (88.0\%) . The whole system uses 55 W of power, 33 W in the optical DAS system and 22 W in the FPGA. Relying on its end-to-end interdisciplinary design, FiberFlex seamlessly combines fiber-optic sensors with FPGA accelerators to enable low-power real-time security monitoring without compromising privacy, making it a valuable addition to the existing security monitoring network. According to FiberFlex, more valuable research can be conducted in the future, such as fall monitoring for the elderly, migration of identification networks between different application scenarios, and improvement of anti-interference performance in more complex environments. In future perception networks, where the “eyes” are not feasible, let’s use fiber optic touch instead.},
journal = {ACM Trans. Reconfigurable Technol. Syst.},
month = nov,
articleno = {57},
numpages = {30},
keywords = {FPGA architecture, Recognition, Fiber-optic, Distributed}
}

@inproceedings{10.1145/3687123.3698297,
author = {Chen, Theresa and Chiang, Yao-Yi},
title = {MiTREE: Multi-input Transformer Ecoregion Encoder for Species Distribution Modelling},
year = {2024},
isbn = {9798400711763},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3687123.3698297},
doi = {10.1145/3687123.3698297},
abstract = {Climate change poses an extreme threat to biodiversity, making it imperative to efficiently model species' habitats, movements, and ranges for effective conservation planning. The availability of large-scale remote sensing images and environmental data has facilitated the use of machine learning in Species Distribution Models (SDMs). The aim of SDMs is, for any spatial location of interest, to be able to predict the bird species that will be present. Previous models either do not leverage the relationship between environmental data and satellite imagery or do not account for differences in resolution between images from various sources. Additionally, location information and ecological characteristics at the location play a crucial role in predicting species distribution models, but these aspects have not yet been incorporated into state-of-the-art approaches. We introduce MiTREE: a multi-input vision-transformer-based model with an ecoregion encoder that embeds the ecological classification, and subsequently the location, of the region into the representation. We evaluate our model on the SatBird Summer and Winter datasets, in which the goal is to predict bird species encounter rates, and find that our approach improves upon state-of-the-art baselines.},
booktitle = {Proceedings of the 7th ACM SIGSPATIAL International Workshop on AI for Geographic Knowledge Discovery},
pages = {110–120},
numpages = {11},
keywords = {Multimodal machine learning, Spatial data, Species distribution modeling},
location = {Atlanta, GA, USA},
series = {GeoAI '24}
}

@inproceedings{10.1145/3697253.3697262,
author = {Lei, Demi and Saeed, Ahmed},
title = {Do We Need a Million Satellites in Orbit? Constellation-as-a-Service with Modular Satellites: Challenges and Opportunities},
year = {2024},
isbn = {9798400712807},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3697253.3697262},
doi = {10.1145/3697253.3697262},
abstract = {In this paper, we argue that deploying many mission-specific satellite mega-constellations incurs significant monetary and environmental costs. Instead, we propose launching a single or a small number of mega-constellations equipped with heterogeneous computing, communication, storage, and sensing capabilities, allowing them to offer a broad range of services to customers who no longer need to launch their own satellites. We argue that the hardware technology for building such platforms is already widely accessible. Thus, we highlight the algorithmic and systems challenges that the community needs to address to enable cost-efficient and secure constellation-as-a-service platforms. We also develop a simulator that allows for experimenting with different scheduling algorithms for constellation-as-a-service platforms.},
booktitle = {Proceedings of the 2nd International Workshop on LEO Networking and Communication},
pages = {61–66},
numpages = {6},
location = {Washington, DC, USA},
series = {LEO-NET '24}
}

@inproceedings{10.1145/3696348.3696861,
author = {Ma, Ruichun and Qiu, Lili and Hu, Wenjun},
title = {SurfOS: Towards an Operating System for Programmable Radio Environments},
year = {2024},
isbn = {9798400712722},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3696348.3696861},
doi = {10.1145/3696348.3696861},
abstract = {Programmable radio environments with metasurfaces introduce signal-level programmability to wireless networks, providing various services such as connectivity enhancement, coverage extension, sensing, security protection, and wireless powering. Next-generation wireless networks are set to widely deploy metasurfaces. However, the current one-system-per-use-case approach cannot scale with wide-ranging hardware designs and surface-aided applications. This paper presents a vision, SurfOS, a metasurface operating system for programmable radio environments. SurfOS aims to orchestrate heterogeneous surface hardware and provide diverse services for user-level applications. We discuss the challenges of building such a system, potential abstraction layers, and open research problems. Our early-stage implementation demonstrates the feasibility and benefits of this approach.},
booktitle = {Proceedings of the 23rd ACM Workshop on Hot Topics in Networks},
pages = {132–141},
numpages = {10},
keywords = {Metasurfaces, Operating System, Wireless Networks},
location = {Irvine, CA, USA},
series = {HotNets '24}
}

@article{10.1145/3701726,
author = {Yu, Keyang and Li, Qi and Chen, Dong and Hu, Liting},
title = {Safeguarding User-Centric Privacy in Smart Homes},
year = {2024},
issue_date = {November 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {24},
number = {4},
issn = {1533-5399},
url = {https://doi.org/10.1145/3701726},
doi = {10.1145/3701726},
abstract = {Internet of Things (IoT) devices have been increasingly deployed in smart homes to automatically monitor and control their environments. Unfortunately, extensive recent research has shown that on-path external adversaries can infer and further fingerprint people’s sensitive private information by analyzing IoT network traffic traces. In addition, most recent approaches that aim to defend against these malicious IoT traffic analytics cannot adequately protect user privacy with reasonable traffic overhead. In particular, these approaches often did not consider practical traffic reshaping limitations, user daily routine permitting, and user privacy protection preference in their design. To address these issues, we design a new low-cost, open source user-centric defense system—PrivacyGuard—that enables people to regain the privacy leakage control of their IoT devices while still permitting sophisticated IoT data analytics that is necessary for smart home automation. In essence, our approach employs intelligent deep convolutional generative adversarial network assisted IoT device traffic signature learning, long short-term memory based artificial traffic signature injection, and partial traffic reshaping to obfuscate private information that can be observed in IoT device traffic traces. We evaluate PrivacyGuard using IoT network traffic traces of 31 IoT devices from five smart homes and buildings. We find that PrivacyGuard can effectively prevent a wide range of state-of-the-art adversarial machine learning and deep learning based user in-home activity inference and fingerprinting attacks and help users achieve the balance between their IoT data utility and privacy preserving.},
journal = {ACM Trans. Internet Technol.},
month = nov,
articleno = {23},
numpages = {33},
keywords = {Security and privacy, data analytics, IoT sensors and devices, modeling and analysis}
}

@inproceedings{10.1145/3687488.3687554,
author = {Feng, Yuechun},
title = {Analysis and prediction of air quality based on mobile crowd perception based on machine learning},
year = {2024},
isbn = {9798400709937},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3687488.3687554},
doi = {10.1145/3687488.3687554},
abstract = {Air quality issues have attracted more and more public attention, and mobile crowd sensing uses the sensors of mobile devices such as smartphones to collect data, and through the participation of a large number of users, it can realize real-time monitoring of the urban environment with multi-dimensional and high spatiotemporal resolution. In this paper, a variety of machine learning models are used to process and analyze mobile crowd perception data. Data preprocessing, feature engineering is used to extract air quality-related features, and machine learning algorithms are used for training and testing. Experimental results show that mobile crowd sensing based on machine learning is an effective air quality analysis and prediction model, which can not only supplement the existing air quality monitoring network, but also provide more personalized and real-time air quality information for the public and decision-makers.},
booktitle = {Proceedings of the 2024 4th International Conference on Control and Intelligent Robotics},
pages = {372–376},
numpages = {5},
keywords = {air quality, machine learning, mobile crowd sensing, predictive models},
location = {
},
series = {ICCIR '24}
}

@inproceedings{10.1145/3698384.3699612,
author = {Williams, Harrison and Hicks, Matthew},
title = {A Survey of Prototyping Platforms for Intermittent Computing Research},
year = {2024},
isbn = {9798400712968},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3698384.3699612},
doi = {10.1145/3698384.3699612},
abstract = {Batteryless energy harvesting platforms are gaining popularity as a way to bring next-generation sensing and edge computing devices to deployments previously limited by their need for batteries. Energy harvesting enables perpetual, maintenance-free operation, but also introduces new challenges associated with unreliable environmental power as systems face common-case, yet unpredictable power failures. Software execution on these devices is an active area of research: intermittently executed software must correctly and efficiently handle arbitrary interruption, frequent state saving/restoration, and re-execution of certain code segments as part of a normal operation. The wide application range for batteryless systems combined with strict limitations on size and performance means there is little overlap in batteryless system prototypes---platforms are chosen for familiarity or specific features in a given application. Unfortunately, the effectiveness of different intermittent computing approaches varies widely across devices. As a result, intermittent computing research is at best hard to generalize across platforms and at worst contradictory across studies.This work explores several of the device-level differences that substantially affect intermittent system performance across eight low-power prototyping platforms. We examine system-level assumptions made by the major approaches to intermittent computing today and determine how compatible each approach is with each platform. The goal of this paper is to serve as a guide for researchers and practitioners developing intermittent systems to both understand the landscape of devices suitable for batteryless operation and to highlight how interactions between devices and the intermittent software running on them can profoundly affect both performance and high-level conclusions in intermittent systems research. We open source our device bring-up code and instructions to facilitate multi-board experiments for future approaches.},
booktitle = {Proceedings of the 12th International Workshop on Energy Harvesting and Energy-Neutral Sensing Systems},
pages = {8–14},
numpages = {7},
keywords = {Energy harvesting, intermittent computing, prototyping},
location = {Hangzhou, China},
series = {ENSsys '24}
}

@inproceedings{10.1145/3698384.3699613,
author = {Wu, Chenyang and Che, Lei and Jin, Siyu and Tian, Cheng and Wang, Gongwei and Liu, Siyang and Li, Xin and Hu, Guobiao and Tang, Lihua and Liang, Junrui},
title = {Attendance Tracking System using Many Battery-free Photovoltaic Bluetooth Beacon Badges},
year = {2024},
isbn = {9798400712968},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3698384.3699613},
doi = {10.1145/3698384.3699613},
abstract = {The concept of ambient IoT was introduced by 3GPP to describe low-cost, self-powered, or battery-free sensor nodes, which may reach up to 10 trillion units in the future. By replacing chemical batteries in many standalone IoT devices, we can achieve ubiquitous connectivity through environmentally friendly and maintenance-free solutions. This paper presents a systematic design of an attendance tracking system utilizing battery-free photovoltaic (PV) Bluetooth beacon badges, along with several stationary gateways. In particular, the experiences with real-world massive deployments of these battery-free Bluetooth badges are emphasized. Thanks to a customized power management design that experiences only nano-watt power leakage before activation, these beacon badges can operate in low-light environments by gradually accumulating energy from indoor lighting, functioning in conditions as low as 17 Lux. The design prioritizes cost-effectiveness, making these badges suitable for potential commercialization, with each compact badge measuring only 40 \texttimes{} 30 \texttimes{} 4 mm3 and a bill of materials (BOM) costing less than $1. In field tests, every attendee at an academic conference wore a souvenir battery-free PV badge, which broadcasted a packet once sufficient power was accumulated. Stationary gateways installed in various conference rooms collected attendance information, while a cloud-based program was developed to visualize the results.},
booktitle = {Proceedings of the 12th International Workshop on Energy Harvesting and Energy-Neutral Sensing Systems},
pages = {15–20},
numpages = {6},
keywords = {Attendance tracking, BLE beacon, ambient IoT, battery-free},
location = {Hangzhou, China},
series = {ENSsys '24}
}

@inproceedings{10.1145/3678884.3681874,
author = {Oguine, Ozioma Collins and Anuyah, Oghenemaro and Hughes, Emelia M. and Badillo-Urquiola, Karla},
title = {Examining Mainstream News Media Narratives on Youth Online Safety},
year = {2024},
isbn = {9798400711145},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3678884.3681874},
doi = {10.1145/3678884.3681874},
abstract = {People form their perspectives and opinions from their experiences and exposure to different information. Despite the growing literature on adolescent online safety, mainstream news media continues to be a large influence in shaping public perceptions of online safety. Understanding these narratives is essential for developing effective strategies to protect young internet users. This paper investigates the narratives surrounding youth online safety as depicted in mainstream news media. Through a systematic review of 157 news articles, we found three prevalent narratives: 1) a focus on negative youth risk experiences and heightened concerns regarding mental health issues, 2) an emphasis on restrictive practices as a primary intervention strategy, and 3) a lack of youth perspectives in online safety narratives. Our work highlights significant trends and discrepancies compared to current academic research on youth online safety. The insights from our findings offer important implications for media representation and the development of effective online safety strategies for youth. Content Warning: This paper discusses sensitive topics, such as emotional trauma, sexual exploitation, self-harm, and other adverse life events of children, which may be triggering. Reader discretion is advised.},
booktitle = {Companion Publication of the 2024 Conference on Computer-Supported Cooperative Work and Social Computing},
pages = {349–354},
numpages = {6},
keywords = {adolescent online safety, kids online safety act, kosa, mainstream news media, mental health, social media, youth online safety},
location = {San Jose, Costa Rica},
series = {CSCW Companion '24}
}

@inproceedings{10.1145/3678884.3681858,
author = {Aleem, Mahwish and Zahoor, Imama and Naseem, Mustafa},
title = {Towards Culturally Adaptive Large Language Models in Mental Health: Using ChatGPT as a Case Study},
year = {2024},
isbn = {9798400711145},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3678884.3681858},
doi = {10.1145/3678884.3681858},
abstract = {This paper explores the efficacy of ChatGPT as a multicultural therapist. Our study involves two rounds of prompt testing exercises: the first to assess general therapeutic skills and the second to identify multicultural counseling limitations. Our findings reveal significant limitations in memory, adaptability, listening, engagement depth, and cultural sensitivity. These limitations highlight the need for AI models to better adapt to diverse cultural contexts and exhibit increased empathy and responsiveness. We further discuss the integration of multicultural therapeutic practices, as well as the importance of culturally sensitive AI in mental health support. Our research contributes to Human Computer Interaction (HCI) literature by proposing design recommendations for future development and underscores the need for culturally nuanced therapeutic interactions in AI-driven mental health support},
booktitle = {Companion Publication of the 2024 Conference on Computer-Supported Cooperative Work and Social Computing},
pages = {240–247},
numpages = {8},
keywords = {chatgpt, cultural adaptivity, hci, inclusive design, large language models, mental health, multicultural therapy},
location = {San Jose, Costa Rica},
series = {CSCW Companion '24}
}

@inproceedings{10.1145/3695719.3695724,
author = {Yang, Haoran and Wang, Yunyu and Xia, Zongqiang and Guo, Xiu and Li, Yuxuan and Malamba Onanga, Ange Lucrecia and Liu, Mingtao and Zhang, Xin},
title = {LPRNet Improvement for License Plate Recognition in Complex Environments},
year = {2024},
isbn = {9798400716867},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3695719.3695724},
doi = {10.1145/3695719.3695724},
abstract = {LPRNet is a widely used lightweight license plate recognition model, but its recognition effect is poor when facing license plate images in complex environments. This paper finds that it can only achieve 79.0\% recognition accuracy by confirming it on the CCPD2019 complex environment dataset. In this paper, an improvement scheme is proposed to enhance the recognition effect of LPRNet when facing complex environments, which firstly incorporates a multi-scale feature extraction module to increase the network sensory field and extract features at different scales. After that, the attention mechanism is integrated so that the model in this paper can focus more on the most informative and discriminative part of the license plate image. The proposed network in this paper is verified using the CCPD2019 complex environment dataset, and the recognition accuracy reaches 86.0\%, which is an improvement of about 7.0\% compared with the original LPRNet, while the model size is only 2.4MB, which can satisfy the requirements of embedded devices. Through comparative experiments, this paper verifies the excellent performance of the proposed network in the face of complex recognition environments.},
booktitle = {Proceedings of the 2024 8th International Conference on Deep Learning Technologies},
pages = {29–33},
numpages = {5},
keywords = {LPRNet, Multiscale Feature Extraction, Complex environment license plate recognition},
location = {
},
series = {ICDLT '24}
}

@article{10.1145/3687044,
author = {Champion, Kaylea and Hill, Benjamin Mako},
title = {Life Histories of Taboo Knowledge Artifacts},
year = {2024},
issue_date = {November 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {8},
number = {CSCW2},
url = {https://doi.org/10.1145/3687044},
doi = {10.1145/3687044},
abstract = {Communicating about some vital topics---such as sexuality and health---is treated as taboo and subjected to censorship. How can we construct knowledge about these topics? Wikipedia is home to numerous high-quality knowledge artifacts about taboo topics like sexual organs and human reproduction. How did these artifacts come into being? How is their existence sustained? This mixed-methods comparative project builds on previous work on taboo topics in Wikipedia and draws from qualitative and quantitative approaches. We follow a sequential complementary design, developing a narrative articulation of the life of taboo articles, comparing them to nontaboo articles, and examining some of their quantifiable traits. We find that taboo knowledge artifacts develop through multiple successful collaboration styles and, unsurprisingly, that taboo subjects are the sites of conflict. We identify and describe six themes in the development of taboo knowledge artifacts. These artifacts need resilient leadership and engaged organizations to thrive under conditions of limited identifiability and disjointed sensemaking, while contributors simultaneously engage in emergent governance and imagining public audiences. Our observations have important implications for supporting public knowledge work on controversial subjects such as taboos and more generally.},
journal = {Proc. ACM Hum.-Comput. Interact.},
month = nov,
articleno = {505},
numpages = {32},
keywords = {anonymity, online communities, peer production, privacy, taboo, wikipedia}
}

@article{10.1145/3686977,
author = {Kim, Eunji and Jin, Seungwan and Han, Kyungsik},
title = {An Empirical Study on Social Anxiety in a Virtual Environment through Mediating Variables and Multiple Sensor Data},
year = {2024},
issue_date = {November 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {8},
number = {CSCW2},
url = {https://doi.org/10.1145/3686977},
doi = {10.1145/3686977},
abstract = {Social anxiety disorder is a psychological condition characterized by excessive nervousness in social situations, such as interpersonal interactions. Exposure therapy has shown benefits in its treatment, and virtual reality (VR) technology has gained much attention for reducing physical and psychological distance and providing additional quantitative evidence from the data generated by standard VR devices (e.g., head-mounted display). Clinical psychology studies have highlighted the importance of mediating variables of social anxiety; however, existing VR-based social anxiety studies have neglected such variables with respect to user experience and data analysis in the context of VR, although these variables could provide insights into the design and use of VR for the treatment of social anxiety. In this study, we focused on two representative mediating variables of social anxiety: (1) the gap between self-presentation motivation and expectancy, and (2) self-focused attention. We used sensor data (e.g., head movement, eye movement, eye gaze, and psychological signals) to investigate the impact of these variables on users' anxiety responses in VR. We developed &lt;u&gt;VR&lt;/u&gt;-based &lt;u&gt;S&lt;/u&gt;ocial Anxiety Support &lt;u&gt;T&lt;/u&gt;ool (VRST) that reflects the theoretical design elements of effective anxiety provocation. Based on the results of a user study with 30 participants, we confirmed that the mediating variables were associated with social anxiety in the VR environment. We also found that the mediating variables were associated with eye gaze, eye pupil, head movement, and body temperature. Our study results provide researchers, designers, and practitioners with empirical evidence and implications for the use of VR technology and sensor data in the mental health context.},
journal = {Proc. ACM Hum.-Comput. Interact.},
month = nov,
articleno = {438},
numpages = {24},
keywords = {interactive virtual reality design, social anxiety}
}

@article{10.1145/3687042,
author = {Gao, Zihan and Cranshaw, Justin and Thebault-Spieker, Jacob},
title = {Journeying Through Sense of Place with Mental Maps: Characterizing Changing Spatial Understanding and Sense of Place During Migration for Work},
year = {2024},
issue_date = {November 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {8},
number = {CSCW2},
url = {https://doi.org/10.1145/3687042},
doi = {10.1145/3687042},
abstract = {Millions of people move for work yearly, but this labor migration risks social and cultural challenges, hindering migrants' integration into new communities. Software tools could support this transition, but the design space around, and the mechanisms behind, how individuals develop spatial understanding and 'sense of place' is unclear. In our study, we leverage mental maps to explore migrants' 'sense of place'. We conduct a mixed- methods study with 12 participants, spanning two sessions - one before and one after their relocation, totaling 24 data sessions. We discover that post-relocation, mental maps not only widen coverage and generalization but also decrease in cartographic complexity and accuracy, reflecting a nuanced blend of personal narratives and spatial awareness. We also find that strategies for rebuilding and reshaping 'sense of place' span a complex set of dimensions spanning personal, social and environmental challenges, post-move. Our findings lay the groundwork, and underscore the need, for 'platial' (versus spatial) understanding and tools to rebuild sense of place, and foster better community cohesion. We highlight design opportunities for creating tools, especially those capturing personal nuances, to help migrants reestablish themselves and their sense of place.},
journal = {Proc. ACM Hum.-Comput. Interact.},
month = nov,
articleno = {503},
numpages = {31},
keywords = {mental map, migration, placemaking, relocation, sense of place, spatial understanding}
}

