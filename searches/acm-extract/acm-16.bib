@article{10.1145/3687015,
author = {Pfeil, Kevin and Badillo-Urquiola, Karla and LaViola, Joseph J., Jr. and Wisniewski, Pamela J.},
title = {"Like I was There:" A User Evaluation of an Interpersonal Telepresence System Developed through Value Sensitive Design},
year = {2024},
issue_date = {November 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {8},
number = {CSCW2},
url = {https://doi.org/10.1145/3687015},
doi = {10.1145/3687015},
abstract = {We developed and deployed an interpersonal telepresence prototype aimed at providing a positive one-to-one interaction between a Streamer and a Viewer. Our prototype uses four distributed, wearable cameras hidden from the public eye. It was designed to reduce the risk of Streamer self-consciousness while providing the Viewer with a greater sense of autonomy. We deployed our prototype with sixteen participants in dyads, who worked together to complete a scavenger hunt, and compared it the baseline of Skype. We found how our prototype better supported Streamer social well-being and physical comfort, and it also better supported Viewer autonomy. However, almost all participants desired a change to the design of the prototype, hinting that we need to provide better customization for future iterations of interpersonal telepresence devices.},
journal = {Proc. ACM Hum.-Comput. Interact.},
month = nov,
articleno = {476},
numpages = {18},
keywords = {qualitative methods, telepresence, user evaluation}
}

@article{10.1145/3686952,
author = {Wang, Zhiyuan and Hassan, Nusayer and LeBaron, Virginia and Flickinger, Tabor and Ling, David and Edwards, James and Wu, Congyu and Boukhechba, Mehdi and Barnes, Laura E.},
title = {CommSense: A Wearable Sensing Computational Framework for Evaluating Patient-Clinician Interactions},
year = {2024},
issue_date = {November 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {8},
number = {CSCW2},
url = {https://doi.org/10.1145/3686952},
doi = {10.1145/3686952},
abstract = {Quality patient-provider communication is critical to improve clinical care and patient outcomes. While progress has been made with communication skills training for clinicians, significant gaps exist in how to best monitor, measure, and evaluate the implementation of communication skills in the actual clinical setting. Advancements in ubiquitous technology and natural language processing make it possible to realize more objective, real-time assessment of clinical interactions and in turn provide more timely feedback to clinicians about their communication effectiveness. In this paper, we propose CommSense, a computational sensing framework that combines smartwatch audio and transcripts with natural language processing methods to measure selected "best-practice'' communication metrics captured by wearable devices in the context of palliative care interactions, including understanding, empathy, presence, emotion, and clarity. We conducted a pilot study involving N=40 clinician participants, to test the technical feasibility and acceptability of CommSense in a simulated clinical setting. Our findings demonstrate that CommSense effectively captures most communication metrics and is well-received by both practicing clinicians and student trainees. Our study also highlights the potential for digital technology to enhance communication skills training for healthcare providers and students, ultimately resulting in more equitable delivery of healthcare and accessible, lower cost tools for training with the potential to improve patient outcomes.},
journal = {Proc. ACM Hum.-Comput. Interact.},
month = nov,
articleno = {413},
numpages = {31},
keywords = {computational framework, natural language processing, patient-clinician communication, smartwatch}
}

@inproceedings{10.1145/3697467.3697654,
author = {Qin, Yilang and Wang, Meng and Zhang, Jie and Zhao, Qing and Zhao, Qiaoli and Li, Guoqiang},
title = {Design and application of smart agriculture IoT platform based on microservice architecture},
year = {2024},
isbn = {9798400710353},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3697467.3697654},
doi = {10.1145/3697467.3697654},
abstract = {This study aims to address the needs of smart agriculture for agricultural condition monitoring and agricultural production, and builds a multi-source data acquisition and perception technology system based on smart agriculture equipment such as agricultural condition weather stations, soil moisture stations, water and fertilizer integration machines, and pest monitoring equipment. It proposes real-time data quality monitoring and alarm strategies and multi-source data fusion methods. The smart agriculture IoT platform is designed based on the principle of scalability, microservice architecture, and modular development. It is deployed in the form of microservices through container technology, and includes core modules such as data collection, messaging engine, and time series data storage, as well as functional modules such as data display, data analysis, and spatial visualization display. Realize real-time display of sensor data, dynamic access of multi-source IoT devices, and control and management services for smart agricultural equipment. The system has been applied in 22 meteorological stations, 17 soil moisture stations, 2 pest monitoring stations, 4 water and fertilizer integration stations, and 1 potato storage environment monitoring in Henan Province, collecting more than 1 million pieces of monitoring data. It provides integrated information services and support for agricultural researchers, agricultural managers, agricultural operators, and ordinary consumers, from complex analysis to visual display of mobile APP.},
booktitle = {Proceedings of the 2024 4th  International Conference on Internet of Things and Machine Learning},
pages = {253–259},
numpages = {7},
keywords = {Deep learning, Integrated water and fertilizer management, Internet of Things, Microservices, Smart Agriculture, System design},
location = {
},
series = {IoTML '24}
}

@article{10.1145/3686940,
author = {Foriest, Jasmine C and Mittal, Shravika and Bray, Kirsten and Tran, Anh-Ton and De Choudhury, Munmun},
title = {A Cross Community Comparison of Muting in Conversations of Gendered Violence on Reddit},
year = {2024},
issue_date = {November 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {8},
number = {CSCW2},
url = {https://doi.org/10.1145/3686940},
doi = {10.1145/3686940},
abstract = {Gender-based violence (GBV) is an ongoing public health issue. Prevention practice and research on GBV contend with an incomplete understanding of its public health burden due to gender-exclusive definitions of GBV and inhibited survivor disclosure. Prior work in CSCW and HCI has explored sensitive disclosures and GBV conversations but excludes examination of conversation dynamics in surfacing knowledge of GBV. We used a mixed-methods approach to understand the phenomenon characterized by Muted Group Theory as a mechanism inhibiting disclosure in the context of GBV discussions on Reddit. Using an iterative process informed by literature of GBV research on cis-gender women, girls, trans, and non-binary populations, we developed comprehensive keywords to obtain, annotate, and analyze 298 posts and 10,369 comments about GBV across 7 subreddits. We found that muting faced by survivors offline, precluding reporting, is replicated on the Reddit platform. This study surfaced 5 categories of muting in discussions of GBV situated by variations in communication norms between dominant and non-dominant groups. These findings were supported by analysis of linguistic attributes that inform an Ensemble Classifier's detection of muting in conversations of GBV. The results offer that muting is a harmful occurrence in online disclosures of GBV that is mediated by existing moderation practices. This work contributes an expanded understanding of GBV conversations online, muting as a feature of those conversations, and an initial foray into detection to inform muting prevention.},
journal = {Proc. ACM Hum.-Comput. Interact.},
month = nov,
articleno = {401},
numpages = {29},
keywords = {gender-based violence, linguistic analysis, mixed-methods, muted group theory, reddit, social computing}
}

@article{10.1145/3686939,
author = {Hohendanner, Michel and Ullstein, Chiara and Miyamoto, Dohjin and Huffman, Emma F and Socher, Gudrun and Grossklags, Jens and Osawa, Hirotaka},
title = {Metaverse Perspectives from Japan: A Participatory Speculative Design Case Study},
year = {2024},
issue_date = {November 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {8},
number = {CSCW2},
url = {https://doi.org/10.1145/3686939},
doi = {10.1145/3686939},
abstract = {Currently, the development of the metaverse lies in the hands of industry. Citizens have little influence on this process. Instead, to do justice to the pluralism of (digital) societies, we should strive for an open discourse including many different perspectives on the metaverse and its core technologies such as AI. We utilize a participatory speculative design (PSD) approach to explore Japanese citizens' perspectives on future metaverse societies, as well as social and ethical implications. Our contributions are twofold. Firstly, we demonstrate the effectiveness of PSD in engaging citizens in critical discourse on emerging technologies like the metaverse by presenting our workshop framework and participants' processes. Secondly, we identify key themes from participants' perspectives, providing insights for culturally sensitive design and development of virtual environments. Our analysis shows that participants imagine the metaverse to have the potential to solve a variety of societal issues; for example, breaking down barriers of physical environments for communication, social interaction, crisis preparation, and political participation, or tackling identity-related issues. Regarding future metaverse societies, participants' imaginations raise critical questions about human-AI relations, technical solutionism, politics and technology, globalization and local cultures, and immersive technologies. We discuss implications and contribute to expanding conversations on metaverse developments.},
journal = {Proc. ACM Hum.-Comput. Interact.},
month = nov,
articleno = {400},
numpages = {51},
keywords = {design fiction, metaverse, participatory speculative design, research through design, sociotechnical systems}
}

@article{10.1145/3698195,
author = {Hussein, Dina and Belkhouja, Taha and Bhat, Ganapati and Doppa, Jana},
title = {Sensor-Aware Data Imputation for Time-Series Machine Learning on Low-Power Wearable Devices},
year = {2024},
issue_date = {January 2025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {30},
number = {1},
issn = {1084-4309},
url = {https://doi.org/10.1145/3698195},
doi = {10.1145/3698195},
abstract = {Wearable devices that have low-power sensors, processors, and communication capabilities are gaining wide adoption in several health applications. The machine learning algorithms on these devices assume that data from all sensors are available during runtime. However, data from one or more sensors may be unavailable due to energy or communication challenges. This loss of sensor data can result in accuracy degradation of the application. Prior approaches to handle missing data, such as generative models or training multiple classifiers for each combination of missing sensors are not suitable for low-energy wearable devices due to their high overhead at runtime. In contrast to prior approaches, we present an energy-efficient approach, referred to as Sensor-Aware iMputation&nbsp;(SAM), to accurately impute missing data at runtime and recover application accuracy. SAM first uses unsupervised clustering to obtain clusters of similar sensor data patterns. Next, it learns inter-relationship between clusters to obtain imputation patterns for each combination of clusters using a principled sensor-aware search algorithm. Using sensor data for clustering before choosing imputation patterns ensures that the imputation is aware of sensor data observations. Experiments on seven diverse wearable sensor-based time-series datasets demonstrate that SAM is able to maintain accuracy within 5\% of the baseline with no missing data when one sensor is missing. We also compare SAM against generative adversarial imputation networks&nbsp;(GAIN), transformers, and k-nearest neighbor methods. Results show that SAM outperforms all three approaches on average by more than&nbsp;25\% when two sensors are missing with negligible overhead compared to the baseline.},
journal = {ACM Trans. Des. Autom. Electron. Syst.},
month = nov,
articleno = {2},
numpages = {27},
keywords = {Human activity recognition, wearable electronics, missing data detection, data imputation, clustering, health monitoring}
}

@article{10.1145/3687006,
author = {Ghafouri, Vahid and Alatawi, Faisal and Karami, Mansooreh and Such, Jose and Suarez-Tangil, Guillermo},
title = {Transformer-Based Quantification of the Echo Chamber Effect in Online Communities},
year = {2024},
issue_date = {November 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {8},
number = {CSCW2},
url = {https://doi.org/10.1145/3687006},
doi = {10.1145/3687006},
abstract = {An Echo Chamber on social media refers to the environment where like-minded people hear the echo of each others' voices, opinions, or beliefs, which reinforce their own. Echo Chambers can turn social media platforms into collaborative venues that polarize and radicalize users rather than broadening their exposure to diverse information. Having a quantified metric for measuring the Echo Chamber effect can aid moderators and policymakers in tracking and mitigating online polarization and radicalization. Existing methods for Echo Chamber detection are either one-dimensional, only considering the network behavior of users while ignoring their semantic behavior, or require demanding supervised labeling, which is both expensive and less generalizable.This paper proposes a new metric to quantify the Echo Chamber effect using Transformer models for context-sensitive processing of natural language (NLP). Our metric quantifies (1) the effect of an Echo Chamber through the inverse effect of user diversity, and (2) polarization by means of user separability between two Echo Chambers in a topic. Leveraging this metric, we further propose an NLP-based embedding that represents the users' activity. Our model is simultaneously effective, computationally cheap, and unsupervised. As our method is unsupervised, it makes existing collaborative moderation efforts to thwart Echo Chamber effects more efficient by addressing the problem of identifying narrow information bases for algorithmic biases and misinformation detection. We run our analysis on three recent highly controversial political topics and a non-controversial topic: Russo-Ukrainian War, Abortion, Gun-Control, and SXSW music festival. Our results offer data-driven findings such as a higher Echo Chamber effect among Republicans over Democrats and diverse explicit support for Ukraine, especially among Democrats. We also observe a direct relationship between the Echo Chamber effect and polarization while observing that the low Echo Chamber effect for the Russo-Ukraine war is accompanied by a low polarization; and vice versa for Gun-Control.},
journal = {Proc. ACM Hum.-Comput. Interact.},
month = nov,
articleno = {467},
numpages = {27},
keywords = {NLP, echo chambers, polarization, sentence transformers, social networks}
}

@inproceedings{10.1145/3697467.3697679,
author = {Zheng, Yihao and Yuan, Zhaohui},
title = {A Multi-Channel Monitoring and Maintenance Platform for Unmanned Surveillance Station Network},
year = {2024},
isbn = {9798400710353},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3697467.3697679},
doi = {10.1145/3697467.3697679},
abstract = {In recent years, the demand for unmanned surveillance station networks across different fields has been steadily increasing. To address the challenges of operating and maintaining these stations, this study designs a multi-channel operation and maintenance platform for unmanned surveillance station network with private intranet. The platform comprises a hardware terminal system, a concurrent network relay system, and an operation and maintenance management system. The hardware terminal system utilizes an STM32 main control chip, integrating power supply, multi-sensor, and network modules to collect real-time data on station equipment status, power supply and distribution, network status, and environmental conditions. Data are transmitted via Ethernet or 4G network based on the TCP/IP protocol. The concurrent network relay system, based on the Linux operating system, employs epoll multiplexing IO technology and local and network sockets to achieve concurrent data processing and cross-network data transmission, paving the communication gaps between the private intranet and the internet. The operation and maintenance management system features a mobile app designed with a front-end and back-end separation architecture. The front end uses React Native and Ant Design mobile, while the back end is based on Node.js and Express, combined with a MySQL database. The system implements functions such as user management, data monitoring, fault analysis, and operation and maintenance management. A series of tests indicate that the platform operates stably, offers high real-time performance, and possesses strong processing capabilities. Through the platform, users can effectively conduct remote surveillance of stations, significantly improving operating and maintaining management efficiency.},
booktitle = {Proceedings of the 2024 4th  International Conference on Internet of Things and Machine Learning},
pages = {350–355},
numpages = {6},
keywords = {Liunx, Operation and maintenance management, STM32, Unmanned surveillance station network},
location = {
},
series = {IoTML '24}
}

@inproceedings{10.1145/3697467.3697667,
author = {Chen, Hailiang and Chu, Tianning and Yang, Lei and Wang, Zhijian and Xue, Liang},
title = {Digital Twin Warehouse Management Platform Developed Based on Unity3D},
year = {2024},
isbn = {9798400710353},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3697467.3697667},
doi = {10.1145/3697467.3697667},
abstract = {This study proposes a smart warehousing management system using digital twin and IoT technologies to tackle inventory inaccuracies and high labor costs. Unity3D engine constructs a virtual warehouse environment; machine learning predicts inventory usage time. Physical devices include Arduino UNO, DHT11 sensor, and MQ-2 smoke sensor for real-time data collection. ESP8266 module enables real-time data transmission. The system automates warehouse management, enhances efficiency and accuracy, and integrates virtual-real mapping, data collection, and analysis functions.},
booktitle = {Proceedings of the 2024 4th  International Conference on Internet of Things and Machine Learning},
pages = {303–310},
numpages = {8},
keywords = {Digital Twin, Internet of Things, Microcontroller, Real-time Monitoring, Unity3D, Warehouse Management},
location = {
},
series = {IoTML '24}
}

@inproceedings{10.1145/3649329.3658474,
author = {Zhao, Xin and Hu, Zhicheng and Guo, Zilong and Fan, Haodong and Yang, Xi and Zhou, Jing and Chang, Liang},
title = {A RRAM-based High Energy-efficient Accelerator Supporting Multimodal Tasks for Virtual Reality Wearable Devices},
year = {2024},
isbn = {9798400706011},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3649329.3658474},
doi = {10.1145/3649329.3658474},
abstract = {Virtual reality (VR) wearable devices can achieve immersive entertainment by fusing multi-modal tasks from various senses. However, constrained by the short battery life and limited hardware resources of the VR devices, running multiple tasks simultaneously with different modals is difficult. In this paper, we propose an energy-efficient accelerator that supports Multi-modal Tasks for VR devices, namely MTVR. We present a multi-task computing solution based on the flexible multi-task computing core design and efficient computing unit allocation strategy, which simultaneously achieves efficient work of multi-modal tasks. We design an early exit detector to skip invalid calculations, greatly saving energy. In addition, a fine-grained tiny value skip method at multiplier and adder levels is proposed to save energy further. We provide a hybrid RRAM and SRAM memory access scheme, reducing the external memory access (EMA). Through experimental evaluation, the multitask computing core achieves an average computational utilization of 95\%. When the invalid input ratio is 90\%, energy saving brought by the early exit detector can reach 88\%. The tiny value skip method further achieved 13\% energy saving. Hybrid memory access scheme obtains 98.9\% EMA reduction. We deployed the MTVR accelerator in FPGA and self-designed RRAM, achieving energy efficiency of 3.6 TOPS/W, higher than other single-task accelerators.},
booktitle = {Proceedings of the 61st ACM/IEEE Design Automation Conference},
articleno = {37},
numpages = {6},
location = {San Francisco, CA, USA},
series = {DAC '24}
}

@inproceedings{10.1145/3649329.3656514,
author = {Huijbregts, Lucas and Liu, Hsiao-Hsuan and Detterer, Paul and Hamdioui, Said and Yousefzadeh, Amirreza and Bishnoi, Rajendra},
title = {Energy-efficient SNN Architecture using 3nm FinFET Multiport SRAM-based CIM with Online Learning},
year = {2024},
isbn = {9798400706011},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3649329.3656514},
doi = {10.1145/3649329.3656514},
abstract = {Current Artificial Intelligence (AI) computation systems face challenges, primarily from the memory-wall issue, limiting overall system-level performance, especially for Edge devices with constrained battery budgets, such as smartphones, wearables, and Internet-of-Things sensor systems. In this paper, we propose a new SRAM-based Compute-In-Memory (CIM) accelerator optimized for Spiking Neural Networks (SNNs) Inference. Our proposed architecture employs a multiport SRAM design with multiple decoupled Read ports to enhance the throughput and Transposable Read-Write ports to facilitate online learning. Furthermore, we develop an Arbiter circuit for efficient data-processing and port allocations during the computation. Results for a 128\texttimes{}128 array in 3nm FinFET technology demonstrate a 3.1\texttimes{} improvement in speed and a 2.2\texttimes{} enhancement in energy efficiency with our proposed multiport SRAM design compared to the traditional single-port design. At system-level, a throughput of 44 MInf/s at 607 pJ/Inf and 29mW is achieved.},
booktitle = {Proceedings of the 61st ACM/IEEE Design Automation Conference},
articleno = {260},
numpages = {6},
location = {San Francisco, CA, USA},
series = {DAC '24}
}

@inproceedings{10.1145/3649329.3657339,
author = {Saffarpour, Mahya and Qian, Weitai and Vali, Kourosh and Kasap, Begum and Hedriana, Herman L. and Ghiasi, Soheil},
title = {Deep Harmonic Finesse: Signal Separation in Wearable Systems with Limited Data},
year = {2024},
isbn = {9798400706011},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3649329.3657339},
doi = {10.1145/3649329.3657339},
abstract = {We present a method, referred to as Deep Harmonic Finesse (DHF), for separation of non-stationary quasi-periodic signals when limited data is available. The problem frequently arises in wearable systems in which, a combination of quasi-periodic physiological phenomena give rise to the sensed signal, and excessive data collection is prohibitive. Our approach utilizes prior knowledge of time-frequency patterns in the signals to mask and in-paint spectrograms. This is achieved through an application-inspired deep harmonic neural network coupled with an integrated pattern alignment component. The network's structure embeds the implicit harmonic priors within the time-frequency domain, while the pattern-alignment method transforms the sensed signal, ensuring a strong alignment with the network. The effectiveness of the algorithm is demonstrated in the context of non-invasive fetal monitoring using both synthesized and in vivo data. When applied to the synthesized data, our method exhibits significant improvements in signal-to-distortion ratio (26\% on average) and mean squared error (80\% on average), compared to the best competing method. When applied to in vivo data captured in pregnant animal studies, our method improves the correlation error between estimated fetal blood oxygen saturation and the ground truth by 80.5\% compared to the state of the art.},
booktitle = {Proceedings of the 61st ACM/IEEE Design Automation Conference},
articleno = {312},
numpages = {6},
location = {San Francisco, CA, USA},
series = {DAC '24}
}

@inproceedings{10.1145/3698388.3699628,
author = {Huang, Yushan and Gong, Taesik and Jang, SiYoung and Kawsar, Fahim and Min, Chulhong},
title = {Energy Characterization of Tiny AI Accelerator-Equipped Microcontrollers},
year = {2024},
isbn = {9798400713002},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3698388.3699628},
doi = {10.1145/3698388.3699628},
abstract = {Tiny AI accelerators are seamlessly integrated into wearable devices due to their small form factor, enabling human sensing applications to run solely on wearables. However, despite this potential, the energy characterization of these tiny AI accelerators has been hardly studied, which is a key enabler for realizing such applications in our daily lives. In this paper, we present a comprehensive analysis of the energy characterization of ultra-low power microcontrollers using MAX78000 manufactured by Analog Device. We detailed the hardware components and their supported power configurations. We then conducted extensive benchmarks at micro and macro levels. For micro-level benchmarks, we evaluated the power/energy consumption under individual system configuration involved in each operation-sensing, AI inference, computation, memory I/O, and idle. For macro-level benchmarks, we analyzed the impact of system-wide configurations on overall energy consumption of end-to-end application pipelines. Our findings offer valuable insights into energy optimization for wearable systems with on-device and human-centered sensing technologies.},
booktitle = {Proceedings of the 2nd International Workshop on Human-Centered Sensing, Networking, and Multi-Device Systems},
pages = {1–6},
numpages = {6},
keywords = {Energy, Machine Learning, Microcontrollers, Tiny AI Accelerator},
location = {Hangzhou, China},
series = {HumanSys '24}
}

@inproceedings{10.1145/3678957.3685738,
author = {Prajod, Pooja and Mahesh, Bhargavi and Andr\'{e}, Elisabeth},
title = {Stressor Type Matters! --- Exploring Factors Influencing Cross-Dataset Generalizability of Physiological Stress Detection},
year = {2024},
isbn = {9798400704628},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3678957.3685738},
doi = {10.1145/3678957.3685738},
abstract = {Automatic stress detection using heart rate variability (HRV) features has gained significant traction as it utilizes unobtrusive wearable sensors measuring signals like electrocardiogram (ECG) or blood volume pulse (BVP). However, detecting stress through such physiological signals presents a considerable challenge owing to the variations in recorded signals influenced by factors, such as perceived stress intensity and measurement devices. Consequently, stress detection models developed on one dataset may perform poorly on unseen data collected under different conditions. To address this challenge, this study explores the generalizability of machine learning models trained on HRV features for binary stress detection. Our goal extends beyond evaluating generalization performance; we aim to identify the characteristics of datasets that have the most significant influence on generalizability. We leverage four publicly available stress datasets (WESAD, SWELL-KW, ForDigitStress, VerBIO) that vary in at least one of the characteristics such as stress elicitation techniques, stress intensity, and sensor devices. Employing a cross-dataset evaluation approach, we explore which of these characteristics strongly influence model generalizability. Our findings reveal a crucial factor affecting model generalizability: primary stressor. Models achieved good performance across datasets when the primary stressor (e.g., social evaluation in our case) remains consistent. Factors like stress intensity or brand of the measurement device had minimal impact on cross-dataset performance. Based on our findings, we recommend matching the primary stressor when deploying HRV-based stress models in new environments. Although previous works have performed cross-dataset evaluation of stress models, this is the first study to systematically investigate the factors influencing the cross-dataset applicability of HRV-based stress models. Our insights are crucial for scenarios with limited data, where techniques like domain generalization and domain adaptation may not be applicable.},
booktitle = {Proceedings of the 26th International Conference on Multimodal Interaction},
pages = {508–517},
numpages = {10},
keywords = {Cross-dataset, Electrocardiography, Generalizability, Heart rate variability, Machine learning, Photoplethysmography, Stress},
location = {San Jose, Costa Rica},
series = {ICMI '24}
}

@inproceedings{10.1145/3698576.3698765,
author = {Huang, Gongqi and Schuermann, Leon and Levy, Amit},
title = {Bridge: A Leak-Free Hardware-Software Architecture for Parallel Embedded Systems},
year = {2024},
isbn = {9798400713019},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3698576.3698765},
doi = {10.1145/3698576.3698765},
abstract = {Embedded and Internet of Things (IoT) devices are increasingly ubiquitous and process increasingly sensitive data. As a result, such devices must uphold security in addition to functional safety to avoid unintended information leaks. To react this change of environment, developers deploy conventional mechanisms such as memory isolation and priority scheduling to achieve aforementioned goals. While such techniques are resilient against attacks that endanger a device's functional safety, they are less effective in maintaining security as they ignore information leaks through timing channels, such as through scheduling policy and implicit microarchitectural state. Recent advances in timing-safe systems, in turn, limit themselves to time-shared systems without parallelism. This is problematic in the face of responsiveness and real-time constraints which are often found in embedded devices.This paper explores timing-safety in the space of parallel systems. We introduce Bridge, a new system architecture featuring multiple tasks with different security concerns that can execute in parallel without leaking information due to timing interference.},
booktitle = {Proceedings of the 2nd Workshop on Kernel Isolation, Safety and Verification},
pages = {16–22},
numpages = {7},
location = {Austin, TX, USA},
series = {KISV '24}
}

@inproceedings{10.1145/3698386.3699992,
author = {Zhao, Jumin and Wang, Wenjuan and Li, Dengao and Cheng, Jie and Li, Yajun and Hou, Yuchen},
title = {Channel alternating cooperative spectrum sensing scheme for mobile scenarios},
year = {2024},
isbn = {9798400712982},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3698386.3699992},
doi = {10.1145/3698386.3699992},
abstract = {With the widespread use of communication protocols such as LoRa, WIFI, Bluetooth, Zigbee, and the development of environmental backscattering techniques based on spectrum shifting, spectrum resources in the ISM bands will gradually become crowded and difficult to manage. The resulting interference between communication devices will limit the widespread deployment of communication devices and the further development of IoT technology. To avoid RF interference between devices and achieve better spectrum management, this paper proposes a channel alternating collaborative spectrum sensing scheme for mobile scenarios. Firstly, a neighbouring channel energy leakage model is constructed to address the problem that of secondary users with different spatial geographic locations are being affected by different degrees of perceived data. Then, an energy matrix generation scheme is proposed by designing the multi-timeslot alternate sensing, which can reduce the data computation. Finally, the CBAM-ConvLSTM model is built for the fusion center to deal with the problem of high latency of multi-user data perception, which achieves the efficient extraction of data and the light weight of the overall model. Simulation results show that the proposed algorithm is more accurate and robust to spectrum sensing in mobile scenarios.},
booktitle = {Proceedings of the First International Workshop on Radio Frequency (RF) Computing},
pages = {14–19},
numpages = {6},
keywords = {Cooperative spectrum sensing, Rf energy sensing, channel alternation, deep learning, mobile context},
location = {Hangzhou, China},
series = {RFCom '24}
}

@inproceedings{10.1145/3686215.3688383,
author = {Salari, Mohammadhossein and Bednarik, Roman},
title = {Investigating the Impact of Illumination Change on the Accuracy of Head-Mounted Eye Trackers: A Protocol and Initial Results},
year = {2024},
isbn = {9798400704635},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3686215.3688383},
doi = {10.1145/3686215.3688383},
abstract = {The advancement of eye tracking technology, including improved portability, usability, and affordability, has facilitated the transition of eye trackers from controlled laboratory settings to diverse real-world environments. One significant challenge in these real-world settings is the wide variation in illumination levels, potentially affecting eye tracking accuracy. Despite anecdotal evidence suggesting the sensitivity of head-mounted eye trackers to environmental light conditions, systematic research on this topic has been limited. This study introduces a standardized protocol for investigating the influence of lighting conditions on the accuracy of head-mounted eye trackers. We examined the performance of SMI Eye Tracking Glasses 2 Wireless under three distinct illumination levels: Low (Dark), Moderate (Normal), and High (Bright). Our experiment involved 9 participants performing accuracy tests under each lighting condition. We measured gaze accuracy while varying the illumination level during both the calibration and data recording phases. Results indicate that eye tracking accuracy is affected by the illumination level used during data collection. Best accuracy was achieved when data recording was performed under the same illumination level as the calibration. Notably, calibration under moderate illumination led to the most consistent performance across all lighting conditions. These findings provide valuable insights for researchers and practitioners using head-mounted eye trackers in varying lighting environments. The standardized protocol presented can be applied to evaluate other eye tracking systems, contributing to developing more robust mobile eye tracking techniques. Future research should investigate the generalizability of these results across different eye tracking technologies and explore potential software solutions to mitigate illumination-related accuracy issues.},
booktitle = {Companion Proceedings of the 26th International Conference on Multimodal Interaction},
pages = {204–210},
numpages = {7},
keywords = {Accuracy, Eye Tracking, Head-Mounted Eye Trackers, Illumination, Pupil Size},
location = {San Jose, Costa Rica},
series = {ICMI '24 Companion}
}

@inproceedings{10.1145/3698388.3699629,
author = {Thangarajan, Ashok Samraj and Kawsar, Fahim and Montanari, Alessandro},
title = {Hierarchical Demand Based Resource Allocation for On-Device Inference},
year = {2024},
isbn = {9798400713002},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3698388.3699629},
doi = {10.1145/3698388.3699629},
abstract = {The use of wearables such as smartwatches, earbuds, and smart rings is expanding rapidly. During the COVID-19 pandemic, individuals increasingly relied on continuous vital signs monitoring, such as oxygen saturation (SpO2) and heart rate (HR), provided by wearables to seek timely medical assistance. As individual sensors become more affordable and feature-rich, advanced sensing capabilities that were once exclusive to high-end wearables are becoming widespread. These vital signs are often aggregates, derived from processing large amounts of data, which can strain the low-power micro-controllers typically used in wearables. While recent advancements have led to the development of low-power microcontrollers with integrated multi-core processors and accelerators, efficiently utilizing these resources, along with the capabilities of the advanced sensors, remains challenging. In this position paper, we propose a hierarchical resource management strategy to optimize system performance, focusing on two key factors: (i) the guarantees needed for specific computations, and (ii) the resource demands these computations impose. By extending operating system primitives and introducing a modular middleware framework, we argue that this approach can facilitate the seamless integration of complex applications, leveraging the capabilities of a hierarchy of devices. This strategy, we contend, can significantly improve the efficiency and robustness of critical sensing systems, providing a more adaptable, privacy-preserving, and resilient solution.},
booktitle = {Proceedings of the 2nd International Workshop on Human-Centered Sensing, Networking, and Multi-Device Systems},
pages = {7–10},
numpages = {4},
keywords = {constrained systems, embedded systems, machine learning, resource allocation},
location = {Hangzhou, China},
series = {HumanSys '24}
}

@inproceedings{10.1145/3666025.3699339,
author = {Fang, Cheng and Liu, Sicong and Zhou, Zimu and Guo, Bin and Tang, Jiaqi and Ma, Ke and Yu, Zhiwen},
title = {AdaShadow: Responsive Test-time Model Adaptation in Non-stationary Mobile Environments},
year = {2024},
isbn = {9798400706974},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3666025.3699339},
doi = {10.1145/3666025.3699339},
abstract = {On-device adapting to continual, unpredictable domain shifts is essential for mobile applications like autonomous driving and augmented reality to deliver seamless user experiences in evolving environments. Test-time adaptation (TTA) emerges as a promising solution by tuning model parameters with unlabeled live data immediately before prediction. However, TTA's unique forward-backward-reforward pipeline notably increases the latency over standard inference, undermining the responsiveness in time-sensitive mobile applications. This paper presents AdaShadow, a responsive test-time adaptation framework for non-stationary mobile data distribution and resource dynamics via selective updates of adaptation-critical layers. Although the tactic is recognized in generic on-device training, TTA's unsupervised and online context presents unique challenges in estimating layer importance and latency, as well as scheduling the optimal layer update plan. AdaShadow addresses these challenges with a backpropagation-free assessor to rapidly identify critical layers, a unit-based runtime predictor to account for resource dynamics in latency estimation, and an online scheduler for prompt layer update planning. Also, AdaShadow incorporates a memory I/O-aware computation reuse scheme to further reduce latency in the reforwardpass. Results show that AdaShadow achieves the best accuracy-latency balance under continual shifts. At low memory and energy costs, Adashadow provides a 2x to 3.5x speedup (ms-level) over state-of-the-art TTA methods with comparable accuracy and a 14.8\% to 25.4\% accuracy boost over efficient supervised methods with similar latency.},
booktitle = {Proceedings of the 22nd ACM Conference on Embedded Networked Sensor Systems},
pages = {295–308},
numpages = {14},
keywords = {latency-efficient test-time adaptation, mobile environments},
location = {Hangzhou, China},
series = {SenSys '24}
}

@inproceedings{10.1145/3666025.3699361,
author = {Wu, Fengmin 中国大陆 and Liu, Sicong 中国大陆 and Zhu, Kehao 中国大陆 and Li, Xiaochen 中国大陆 and Guo, Bin 中国大陆 and Yu, Zhiwen 中国大陆 and Wen, Hongkai and Xu, Xiangrui 中国大陆 and Wang, Lehao 中国大陆 and Liu, Xiangyu 中国大陆},
title = {AdaFlow: Opportunistic Inference on Asynchronous Mobile Data with Generalized Affinity Control},
year = {2024},
isbn = {9798400706974},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3666025.3699361},
doi = {10.1145/3666025.3699361},
abstract = {The rise of mobile devices equipped with numerous sensors, such as LiDAR and cameras, has spurred the adoption of multi-modal deep intelligence for distributed sensing tasks, such as smart cabins and driving assistance. However, the arrival times of mobile sensory data vary due to modality size and network dynamics, which can lead to delays (if waiting for slower data) or accuracy decline (if inference proceeds without waiting). Moreover, the diversity and dynamic nature of mobile systems exacerbate this challenge. In response, we present a shift to opportunistic inference for asynchronous distributed multi-modal data, enabling inference as soon as partial data arrives. While existing methods focus on optimizing modality consistency and complementarity, known as modal affinity, they lack a computational approach to control this affinity in open-world mobile environments. AdaFlow pioneers the formulation of structured cross-modality affinity in mobile contexts using a hierarchical analysis-based normalized matrix. This approach accommodates the diversity and dynamics of modalities, generalizing across different types and numbers of inputs. Employing an affinity attention-based conditional GAN (ACGAN), AdaFlow facilitates flexible data imputation, adapting to various modalities and downstream tasks without retraining. Experiments show that AdaFlow significantly reduces inference latency by up to 79.9\% and enhances accuracy by up to 61.9\%, outperforming status quo approaches. Also, this method can enhance LLM performance to preprocess asynchronous data.},
booktitle = {Proceedings of the 22nd ACM Conference on Embedded Networked Sensor Systems},
pages = {606–618},
numpages = {13},
keywords = {distributed multi-modal system, non-blocking inference, mobile applications, affinity matrix},
location = {Hangzhou, China},
series = {SenSys '24}
}

@inproceedings{10.1145/3652620.3688264,
author = {Fakeye, Ireoluwa Akinlolu and Maas, Ellen Diana van Lutsenburg and Harris, Paul and Oulaid, Bader and Baker, Chris},
title = {Towards A Framework For Farm Scale Digital Twin},
year = {2024},
isbn = {9798400706226},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3652620.3688264},
doi = {10.1145/3652620.3688264},
abstract = {Enhancing agricultural productivity while maintaining ecological balance amidst climate change is a looming challenge. The future of resilient farming and food security will depend upon the effectiveness of collecting, interpreting, and acting on data. An agricultural digital twin (DT) can provide a feedback loop which improves both farm management and the computer system which informs it through integrating right-time sensor data, process-based models (PBMs), data-driven models (DDMs), and hybrid approaches. Three demonstrator DTs for farm ecosystems are currently under development, utilizing extensive datasets from three instrumented research farms at the North Wyke Farm Platform in Devon, UK to drive and evaluate the accuracy of models in simulating key agroecosystem processes, such as soil nutrient cycling, water balance, and crop performance. The implementation process involves data collection, processing, model integration, and visualization. Key measurements are gathered up to every 15 minutes. PBMs along with DDMs and hybrid models will be utilized in an ensemble to enhance predictive accuracy and robustness. The DT architecture consists of three tiers. A client tier focuses on creating a user-friendly web frontend and API. An analysis and retrieval tier will facilitate the orchestration of services by a container registry and Kubernetes master node. A simulation tier will handle intensive data processing and model simulations with Apache Spark and high-performance computing nodes. We expect the DTs to improve decision-making, enhance system resilience against biotic and abiotic stresses, and pave the way for sustainable agricultural innovation.},
booktitle = {Proceedings of the ACM/IEEE 27th International Conference on Model Driven Engineering Languages and Systems},
pages = {486–491},
numpages = {6},
keywords = {digital twin, information management framework, modelling, agriculture},
location = {Linz, Austria},
series = {MODELS Companion '24}
}

@inproceedings{10.1145/3652620.3688260,
author = {Protin, Lionel and Aggoune-Mtalaa, Wassila and Kavka, Carlos},
title = {Practical design and implementation of an augmented reality based digital twin},
year = {2024},
isbn = {9798400706226},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3652620.3688260},
doi = {10.1145/3652620.3688260},
abstract = {This paper presents a practical example of design and implementation of an augmented reality based digital twin of moving wheeled robots in an indoor environment. The architecture developed is based on the RAMI (Reference Architectural Model Industry 4.0) framework and integrates both the physical and the digital twins, allowing continuous data exchange and real-time feedback loops between the two twins. From the physical twin perspective, the use of augmented reality (AR) headsets and position sensors enables to track the movement of the wheeled robots. The interest of the chosen architecture is a seamless communication of the decision and user interfacing elements including the AR headsets and the fulfilment layers of the digital twin. The current developed modules are deployed at a laboratory scale. The perspective of this work is an upscale to larger rooms and more industrial robots.},
booktitle = {Proceedings of the ACM/IEEE 27th International Conference on Model Driven Engineering Languages and Systems},
pages = {459–463},
numpages = {5},
keywords = {digital twin, modular and extensible architecture, augmented reality, low code},
location = {Linz, Austria},
series = {MODELS Companion '24}
}

@inproceedings{10.1145/3671127.3698170,
author = {Codling, Jesse R. and Shulkin, Jeffrey D. and Chang, Yen-Cheng and Zhang, Jiale and Latapie, Hugo and Noh, Hae Young and Zhang, Pei and Dong, Yiwen},
title = {FloHR: Ubiquitous Heart Rate Measurement using Indirect Floor Vibration Sensing},
year = {2024},
isbn = {9798400707063},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3671127.3698170},
doi = {10.1145/3671127.3698170},
abstract = {Heart rate is one of the most critical metrics for human health. Most common methods for measuring human heart rate involve body contact, whether from wearable devices or manual measurement. However, such devices can cause discomfort to some patients. Past work for non-contact or remote heart rate measurement (e.g., camera or radio) is often limited by line-of-sight requirements that are not always possible in the real-world environment.This paper presents FloHR, an indirect heart rate monitoring system for human beings using heartbeat-induced floor vibrations. The key insight is that the human body generates a small wave of pressure and sound with each heartbeat. These are propagated as vibration through the structures the person is in contact with (e.g., a chair) and through the floor. FloHR then detects and interprets these small floor vibrations. We developed a highly sensitive vibration sensing system and heartbeat pattern modelling to identify these tiny vibrations among other body motions and ambient noise.We evaluated FloHR in a real home environment, demonstrating an average heart rate error similar to medical device standards on the floor near the subjects' chair, and on the order of 10 beats per minute (bpm) on the floor 2 meters away from the subject.},
booktitle = {Proceedings of the 11th ACM International Conference on Systems for Energy-Efficient Buildings, Cities, and Transportation},
pages = {44–54},
numpages = {11},
keywords = {heart rate, structural vibration, ubiquitous sensing},
location = {Hangzhou, China},
series = {BuildSys '24}
}

@inproceedings{10.1145/3671127.3699529,
author = {Lin, Cheyu and Doctorarastoo, Maral and Flanigan, Katherine},
title = {Your Actions Talk: Automated Sociometric Analysis Using Kinesics in Human Activities},
year = {2024},
isbn = {9798400707063},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3671127.3699529},
doi = {10.1145/3671127.3699529},
abstract = {Cyber-physical-social infrastructure systems (CPSIS) are an extension of cyber-physical systems (CPS). In addition to sensing, measuring, interpreting, and optimizing physical attributes of the built environment to improve infrastructure performance, CPSIS also takes into account human-centered---or social---objectives often overlooked by CPS. Although this paradigm shift aims to incorporate the social system supported by infrastructure into CPS, there is still a gap in measuring social objectives in line with the guiding principle of CPSIS. Specifically, the integration of sensing technologies and computation for assessing these social objectives remains largely unaddressed. As a salient example, sociometric tests used ubiquitously to capture the social structure and sociability embedded within a group of individuals still relies on subjects manually answering questionnaires to derive social connectivity. This data collection scheme is, among other things, subject to attribution bias, inefficient, and laborious. Here, reliance on manually-sourced data to inform sociometric tests falls short in leveraging the sensing and automation capabilities inherent in CPSIS. To overcome these challenges, we propose a human activity recognition (HAR) dataset and framework that can help to automate the procedure of sociometric assessment. The design of the dataset takes into account the limitations that hinders the development of the automated sociometric examination in state-of-the-art HAR techniques. The framework adopts a multidisciplinary approach, drawing upon HAR, kinesics, and sociology to efficiently distill the interpersonal relationships within social systems and provide a qualitative and quantitative interpretation of sociability for modeling and optimization in the context of CPSIS.},
booktitle = {Proceedings of the 11th ACM International Conference on Systems for Energy-Efficient Buildings, Cities, and Transportation},
pages = {271–278},
numpages = {8},
keywords = {Cyber-physical-social Infrastructure Systems, Human Activity Recognition, Social Networks, Sociometry},
location = {Hangzhou, China},
series = {BuildSys '24}
}

@inproceedings{10.1145/3615430.3615447,
author = {Bodon, Herminio and Kumar, Vishesh and Worsley, Marcelo},
title = {Constructing Sports Technologies and Understandings: Constructionist Pathways to Enrich Athletic Experiences},
year = {2024},
isbn = {9798400708961},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3615430.3615447},
doi = {10.1145/3615430.3615447},
abstract = {Sports spaces are being increasingly used for enabling a variety of computing education opportunities. This work often aims to support socially and disciplinarily minoritized communities, often children of color with specific cultural practices and identities around sports. In this work, we focus on how these experiences can be extended to support youth in developing lasting long term skills around computational making using athletic interest and participation as a jumping off point. We focus on how such a making process can enhance and augment learners’ sports understanding, and by extension sports performance; as well as how their sports interest helps them encounter and make sense of different computing concepts. In this paper, we discuss working with a student athlete, his journey of designing and bringing to life ideas around sports technologies, through physical computing and prototyping technologies. We employed a user-centered design approach for designing the learning experience, and emerging methods for assessing learning in making experiences. We blend data around his making experience with observations and interview data around his sports experiences. We find that the process of making augmented his ability to think more deeply about elements of his practice (e.g., strategies of play, ecosystem, and teamwork) and a deeper appreciation of science and technology in the real world. This work contributes an additional lens on how making can serve as a powerful process to realize new possibilities involving computing education in cultural-sustaining computing learning environments.},
booktitle = {Proceedings of FabLearn / Constructionism 2023: Full and Short Research Papers},
articleno = {9},
numpages = {8},
keywords = {basketball, computing education, culturally sustaining, identity, makecode, making, microbit, physical computing, puerto rico, sports, wearables},
location = {New York City, NY, USA},
series = {FLC '23}
}

@inproceedings{10.1145/3671127.3698167,
author = {Routh, Tushar and Saoda, Nurani and Nikseresht, Fateme and Billah, Md Fazlay Rabbi Masum and Gao, Jiechao and Rajan, Viswajith Govinda and Campbell, Bradford},
title = {ScreenSense: Screen Activity Detection in Real-World Environments with Indoor Light Sensors},
year = {2024},
isbn = {9798400707063},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3671127.3698167},
doi = {10.1145/3671127.3698167},
abstract = {Nowadays, light sensors are frequently utilized as wearables for assessing personal light exposure or installed in indoor environments for measuring ambient lighting at areas of interest. Interestingly, light emitted by computer screens records distinct patterns when such sensors are placed nearby. The phenomenon requires analysis for passive sensing and also raises critical privacy concerns. In this paper, we introduce ScreenSense, an innovative approach that leverages data from existing framework for detecting screen utilization. For that, we first collect a diversified dataset by placing a light sensor in close proximity to computer screen. We then classify captured dataset into five general categories: Mail, Social, Reading, Video, and No Activity. Our insight is that existing low-power, inexpensive light sensors can be an energy-efficient, low-cost alternative for collecting screen information over extended periods. However, we also observe that for to be effective in real-world, it needs to be robust against several practical factors, including the ambient room lighting where the user device is situated, transitioning between different activities, and examples from unfamiliar arrangements. To overcome these challenges, we propose dataset augmentation including realistic lighting conditions, transition filters, and time series-based augmentation. The system achieves a detection accuracy upto 91.25\% in real world testbed scenarios. ScreenSense also uncovers critical privacy issues inherent in simple IoT based light sensors deployed so commonly in smart buildings.},
booktitle = {Proceedings of the 11th ACM International Conference on Systems for Energy-Efficient Buildings, Cities, and Transportation},
pages = {22–32},
numpages = {11},
keywords = {Indoor Light Sensors, Passive Sensing, Screen Activity Detection},
location = {Hangzhou, China},
series = {BuildSys '24}
}

@article{10.1145/3678176,
author = {Tang, Zhangyong and Xu, Tianyang and Wu, Xiao-Jun and Kittler, Josef},
title = {Multi-Level Fusion for Robust RGBT Tracking via Enhanced Thermal Representation},
year = {2024},
issue_date = {October 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {20},
number = {10},
issn = {1551-6857},
url = {https://doi.org/10.1145/3678176},
doi = {10.1145/3678176},
abstract = {Due to the limitations of visible (RGB) sensors in challenging scenarios, such as nighttime and foggy environments, the thermal infrared (TIR) modality draws increasing attention as an auxiliary source for robust tracking systems. Currently, the existing methods extract both the RGB and TIR (RGBT) clues in a similar approach, i.e., utilising RGB-pretrained models with or without finetuning, and then aggregate the multi-modal information through a fusion block embedded in a single level. However, the different imaging principles of RGB and TIR data raise questions about the suitability of RGB-pretrained models for thermal data. In this article, it is argued that the modality gap is overlooked, and an alternative training paradigm is proposed for TIR data to ensure consistency between the training and test data, which is achieved by optimising the TIR feature extractor with only TIR data involved. Furthermore, with the goal of making better use of the enhanced thermal representations, a multi-level fusion strategy is inspired by the observation that various fusion strategies at different levels can contribute to a better performance. Specifically, fusion modules at both the feature and decision levels are derived for a comprehensive fusion procedure while the pixel-level fusion strategy is not considered due to the misalignment of multi-modal image pairs. The effectiveness of our method is demonstrated by extensive qualitative and quantitative experiments conducted on several challenging benchmarks. Code will be released at .},
journal = {ACM Trans. Multimedia Comput. Commun. Appl.},
month = oct,
articleno = {312},
numpages = {24},
keywords = {Visual object tracking, RGBT tracking, thermal enhancement, multi-modal multi-level fusion}
}

@inproceedings{10.1145/3675888.3676064,
author = {C, Chaitanya and Reddy, Yogananda A and Pasupuleti, Haribabu and Gvk, Sasirekha and Bapat, Jyotsna},
title = {Real-time Anomaly Detection at IoT-Edge Ingress Port using FPGA based ML Classifiers},
year = {2024},
isbn = {9798400709722},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3675888.3676064},
doi = {10.1145/3675888.3676064},
abstract = {Edge based architectures are being widely used for various Internet of Things (IoT) verticals like factories, transportation, healthcare, etc. Intelligent edges have the advantages of quick reaction time, lesser data bandwidth requirements for cloud connectivity, and privacy because of localization of data. Edge based IoT deployments make detection of anomalies in the ingress port which connects to the things, faster compared to the cloud based anomaly detectors. These anomalies can be due to security attacks, malfunction of equipment, degradation of sensor performance, or actual change in physical system. For example, in the case of smart healthcare with remote health monitoring, the anomalies can be due to variation in the patients’ vitals being monitored. It is very important to detect anomalies in real time with minimal latency as it dictates the response time for an appropriate action. Achieving low latencies in large scale IoT systems, wherein large number of sensors need to be monitored continuously, using only software, is challenging. In this paper a real-time anomaly detector architecture, based on a set of Logistic Regression (LR) Machine Learning (ML) classifiers in a Field Programmable Gate Array (FPGA) is proposed. This anomaly detector monitors the ingress traffic at the IoT edge, to predict the anomalies with minimal latency. Hardware-software partitioning used to achieve the real-time performance has been described. A novel LR twin based retraining mechanism, which updates the weights of the set of classifiers, with minimal disruption of real-time operation is discussed. The proposed system has been developed on PYNQ Z2 board for a set of 7 LRs. The system feasibility and timing analysis have been presented, highlighting the performance advantages as compared to pure software implementation.},
booktitle = {Proceedings of the 2024 Sixteenth International Conference on Contemporary Computing},
pages = {309–315},
numpages = {7},
location = {Noida, India},
series = {IC3-2024}
}

@inproceedings{10.1145/3641237.3691673,
author = {Trim, Michelle and Butler, Erin and Suttcliffe, Christina},
title = {Seeing How the Sausage is Made: Data Storytelling as Means and Method in a Computer Science Writing Course},
year = {2024},
isbn = {9798400705199},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3641237.3691673},
doi = {10.1145/3641237.3691673},
abstract = {As data corpus-driven tools and technologies increasingly push users to passively search for an answer, rather than search to understand, we believe that technical and computing disciplinary writing courses have a duty to teach the process of responsible data storytelling. While students can grasp that generative AI makes mistakes, hallucinates, and perpetuates bias, they can need help understanding the antecedent causes of those difficulties. All algorithmically driven decision-making or recommending software have in common a large data set that has been labeled, either by users or by the system itself. The origins of that data and the reasonable applications/deductions and conclusions possible for any given dataset have everything to do with why some tools help and some tools perpetuate harms. By starting at the very beginning and asking students to make sense of data, students can more easily see how purpose and audience impact analysis of any given collection of data. Once those opportunities for rhetorical choice making are known, students become ready to understand the connection between data and complex A.I. systems and some of the ways that bias and other kinds of harm can result if designers are not careful. Combining instruction in a technical coding environment with basic data literacy lessons such as ‘the seven data stories,’ [14] we developed and delivered a three-week writing unit designed around responsible data exploration and storytelling. In this experience report, we provide the assignment we used, and the scaffolded activities we employed to bring students through the process, remarking on what worked well and what we want to improve. We provide attendees with a link to an R-based notebook with a walk-through lesson on data exploration commands, and the rubric used to assess students’ texts, notebooks with code and commentary and results, all existing in a referential context. We provide the survey results of students’ perception of learning from this activity. Early findings demonstrate that students internalized lessons about the non-objective nature of data analysis and of specific responsible data storytelling practices required by anyone seeking to ethically represent answers within and limitations of any dataset.},
booktitle = {Proceedings of the 42nd ACM International Conference on Design of Communication},
pages = {217–222},
numpages = {6},
keywords = {Data Visualization, Data storytelling, Pedagogy, Technical communication},
location = {Fairfax, VA, USA},
series = {SIGDOC '24}
}

@inproceedings{10.1145/3675888.3676077,
author = {Bethu, Srikanth and Erukala, Suresh Babu},
title = {Abnormal activities identification using Deep Q Network from IoT Surveillance Systems},
year = {2024},
isbn = {9798400709722},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3675888.3676077},
doi = {10.1145/3675888.3676077},
abstract = {With the rapid proliferation of Internet of Things (IoT) devices, surveillance systems have become ubiquitous, providing crucial monitoring capabilities across various domains such as security, healthcare, and manufacturing. However, efficiently detecting abnormal activities within the vast streams of surveillance data remains a significant challenge. Traditional methods often struggle to adapt to dynamic environments and diverse anomalies, necessitating more sophisticated approaches. This paper proposes a novel framework for abnormal activity identification in IoT surveillance systems leveraging Deep Q Network (DQN) architecture. DQN, a form of reinforcement learning, has shown remarkable success in learning optimal strategies from high-dimensional sensory inputs. By integrating DQN into IoT surveillance systems, we aim to enhance their anomaly detection capabilities.},
booktitle = {Proceedings of the 2024 Sixteenth International Conference on Contemporary Computing},
pages = {398–406},
numpages = {9},
keywords = {Deep Learning, Deep Q Network (DQN), Internet of Things (IoT)},
location = {Noida, India},
series = {IC3-2024}
}

@inproceedings{10.1145/3664647.3681113,
author = {Qi, Zehao and Zhang, Ruixu and Hu, Xinyi and Liu, Wenxuan and Wang, Zheng},
title = {Predicting the Unseen: A Novel Dataset for Hidden Intention Localization in Pre-abnormal Analysis},
year = {2024},
isbn = {9798400706868},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3664647.3681113},
doi = {10.1145/3664647.3681113},
abstract = {Our paper introduces a novel video dataset specifically for Temporal Intention Localization (TIL), aimed at identifying hidden abnormal intention in densely populated and complex environments. Traditional Temporal Action Localization (TAL) frameworks, focusing on overt actions within constrained temporal intervals, often miss subtle pre-abnormal actions that unfold over extended periods. Our dataset comprises 228 videos with 5790 clips, each annotated to capture fine-grained actions within ambiguous temporal boundaries using the Joint-Linear-Assignment methodology. This approach enables detailed analysis of the evolution of abnormal intention over time. To detect subtle, hidden intention, we developed the Intention-Action Fusion module, an creative approach integrating dynamic feature fusion across 11 behavioral subcategories, significantly enhancing the model's ability to discern nuanced intention. This enhancement has led to performance improvements of up to 139\% in specific scenarios, dramatically boosting the model's sensitivity and interpretability, crucial for advancing proactive surveillance systems. By pushing the boundaries of technology, our dataset and methodologies foster proactive surveillance systems capable of preemptively identifying potential threats from nuanced behavioral patterns, encouraging further exploration into the complexities of intention beyond observable actions. The dataset is available at https://github.com/Zzz99999/Hidden_Abnormal_Intention.},
booktitle = {Proceedings of the 32nd ACM International Conference on Multimedia},
pages = {9690–9698},
numpages = {9},
keywords = {hidden intention, multimedia, pre-abnormal, temporal localization},
location = {Melbourne VIC, Australia},
series = {MM '24}
}

@inproceedings{10.1145/3675888.3676053,
author = {Choudhary, Utkarsh and Agarwal, Parul},
title = {Image Steganography Combined with Cryptography for Covert Communication},
year = {2024},
isbn = {9798400709722},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3675888.3676053},
doi = {10.1145/3675888.3676053},
abstract = {In today's digitally interconnected world, the need for secure communication has become paramount. Image steganography and cryptography emerge as two powerful tools in ensuring the confidentiality and integrity of transmitted data. From secure data transmission over public networks to covert communication in sensitive environments, the synergy of steganography and cryptography offers versatile solutions for ensuring information security. This paper presents an in-depth exploration of their combined application for covert communication. Image steganography involves embedding secret information within digital images without altering their perceptible appearance. By exploiting the redundancy of image data, covert messages can be hidden effectively. Cryptography, on the other hand, ensures the security of these hidden messages by employing encryption techniques, rendering them unreadable to unauthorized individuals. This study delves into the methodologies of integrating steganography and cryptography, addressing the challenges and considerations involved. Techniques such as LSB (Least Significant Bit) embedding, spread spectrum, and transformation-based methods are discussed alongside various cryptographic algorithms like AES (Advanced Encryption Standard) and RSA (Rivest–Shamir–Adleman). Overall, this research underscores the significance of image steganography combined with cryptography in bolstering covert communication channels. By providing enhanced confidentiality and integrity, this approach addresses the growing concerns surrounding data privacy and security in the digital age.},
booktitle = {Proceedings of the 2024 Sixteenth International Conference on Contemporary Computing},
pages = {207–212},
numpages = {6},
keywords = {Encryption technique, Rivest–Shamir–Adleman, Steganography, communication, cryptography},
location = {Noida, India},
series = {IC3-2024}
}

@inproceedings{10.1145/3689089.3689707,
author = {Deng, Zhiyuan and Zhao, Yanjuan and Qu, Bohan and Zhou, You and Wang, Jinjia and Xiong, Bo},
title = {A Hessian-Driven Convolutional Sparse Coding and Depth Awareness Algorithm for 3D Localization of Light Field Microscopy},
year = {2024},
isbn = {9798400712005},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3689089.3689707},
doi = {10.1145/3689089.3689707},
abstract = {Light-field microscopy (LFM), as an image acquisition device based on multi-sensor capturing of multi-view information, has gained widespread usage in the field of cell biology and neuroscience for the rapid and continuous recording of the spatial 3D distribution of cells and tissues. Presently, techniques utilizing deconvolution and deep learning are extensively employed for the analysis of data captured through LFM. Nevertheless, current deconvolution techniques continue to encounter constraints related to limited depth range, inadequate multi-source localization, and prolonged localization time, impeding their advancement. Moreover, deep learning methods are constrained in terms of their robustness and generalization ability. This paper introduces a novel approach to addressing the 3D localization challenge in LFM. This method is mainly based on a depth slice-based dictionary for more effective sparse coefficient solving and more accurate depth awareness. Specifically, a wave optics model is initially employed to create a slice-based dictionary comprising pre-constructed epipolar plane images (EPI) of the object at various depths. Subsequently, a convolutional sparse coding (CSC) approach is employed in conjunction with Hessian-driven damping to derive sparse coefficients for the EPI of the object within this dictionary. Then, a peak separation and clustering algorithm for energy aggregation is employed to separate and cluster multiple scenarios. Finally, an inversion verification algorithm is utilized to determine the optimal distribution of point sources. By evaluating our approach on simulated data and real-capture salina algae data, we have confirmed its efficacy in enhancing the depth range and localization accuracy, particularly for multi-point sources, while also decreasing the time required for localization in low signal-to-noise ratio (SNR) environments.},
booktitle = {Proceedings of the 2nd International Workshop on Methodologies for Multimedia},
pages = {10–18},
numpages = {9},
keywords = {convex optimization, convolutional sparse coding, depth detection, light field microscopy},
location = {Melbourne VIC, Australia},
series = {Meet4MM '24}
}

@article{10.1145/3680280,
author = {Khalighi, Moein and Benedetti, Giulio and Lahti, Leo},
title = {Algorithm 1047: FdeSolver, a Julia Package for Solving Fractional Differential Equations},
year = {2024},
issue_date = {September 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {50},
number = {3},
issn = {0098-3500},
url = {https://doi.org/10.1145/3680280},
doi = {10.1145/3680280},
abstract = {We introduce FdeSolver, an open-source Julia package designed to solve fractional-order differential equations efficiently. The available solutions are based on product-integration rules, predictor–corrector algorithms, and the Newton-Raphson method. The package covers solutions for one-dimensional equations with orders of positive real numbers. For higher-dimensional systems, it supports orders up to one. Incommensurate derivatives are allowed and defined in the Caputo sense. Here, we summarize the implementation for a representative class of problems and compare it with available alternatives in Julia and MATLAB. Moreover, FdeSolver leverages the power and flexibility of the Julia environment to offer enhanced computational performance, and our development emphasizes adherence to the best practices of open research software. To highlight its practical utility, we demonstrate its capability in simulating microbial community dynamics and modeling the spread of COVID-19. This latter application involves fitting the order of derivatives grounded on real-world epidemiological data. Overall, these results highlight the efficiency, reliability, and practicality of the FdeSolver Julia package.},
journal = {ACM Trans. Math. Softw.},
month = oct,
articleno = {22},
numpages = {23},
keywords = {Julia package, fractional differential equations, memory effects, numerical algorithms, predictor-corrector method, product-integration, Newton-Raphson method}
}

@article{10.1145/3688807,
author = {Demmel, Markus and G\"{o}bel, Thomas and Gon\c{c}alves, Patrik and Baier, Harald},
title = {Data Synthesis Is Going Mobile—On Community-Driven Dataset Generation for Android Devices},
year = {2024},
issue_date = {September 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {5},
number = {3},
url = {https://doi.org/10.1145/3688807},
doi = {10.1145/3688807},
abstract = {Personal electronic devices such as smartphones and smartwatches have become indispensable daily companions, collecting a multitude of personal and sensitive data. As a result, they are of paramount importance in digital forensic examinations. However, there is a lack of publicly available and ready-to-use digital forensic datasets, especially in mobile forensics. This work presents a concept and an open-source proof-of-concept implementation, which simplifies and automates the creation of mobile forensic datasets within the scope of the Android operating system. In contrast to previous approaches, which populate the most common databases of an Android device, our concept is based on community-driven playbooks and makes use of interaction with the actual smartphone GUI. Hence, we are able to generate coherent and realistic traces as they occur in real-world human usage. Our proof-of-concept implementation is based on the standard Android emulation environment and borrows tools from the user interface testing community. Our evaluation shows that our approach actually generates realistic Android datasets. For instance, we can generate traces that cannot be simulated by gestures (e.g., changing the GPS position or triggering incoming phone calls). Recording the actual data synthesis process allows users to either create and share their own playbooks (i.e., the exact instructions for the data synthesis process rather than having to share the full image) or reproduce Android images with different scenarios using playbooks previously created and shared by the community.},
journal = {Digital Threats},
month = oct,
articleno = {30},
numpages = {19},
keywords = {Mobile forensics, Android image, Forensic dataset, Digital corpora, Data synthesis, Data generation, Data synthesis framework, UI testing, Android Emulator, User simulation, Human interaction}
}

@inproceedings{10.1145/3674805.3686667,
author = {Lin\r{a}ker, Johan and Link, Georg and Lumbard, Kevin},
title = {Sustaining Maintenance Labor for Healthy Open Source Software Projects through Human Infrastructure: A Maintainer Perspective},
year = {2024},
isbn = {9798400710476},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3674805.3686667},
doi = {10.1145/3674805.3686667},
abstract = {Background: Open Source Software (OSS) fuels our global digital infrastructure but is commonly maintained by small groups of people whose time and labor represent a depletable resource. For the OSS projects to stay sustainable, i.e., viable and maintained over time without interruption or weakening, maintenance labor requires an underlying infrastructure to be supported and secured. Aims: Using the construct of human infrastructure, our study aims to investigate how maintenance labor can be supported and secured to enable the creation and maintenance of sustainable OSS projects, viewed from the maintainers’ perspective. Method: In our exploration, we interviewed ten maintainers from nine well-adopted OSS projects. We coded the data in two steps using investigator-triangulation. Results: We constructed a framework of infrastructure design that provide insight for OSS projects in the design of their human infrastructure. The framework specifically highlight the importance of human factors, e.g., securing a work-life balance and proactively managing social pressure, toxicity, and diversity. We also note both differences and overlaps in how the infrastructure needs to support and secure maintenance labor from maintainers and the wider OSS community, respectively. Funding is specifically highlighted as an important enabler for both types of resources. Conclusions: The study contributes to the qualitative understanding of the importance, sensitivity, and risk for depletion of the maintenance labor required to build and maintain healthy OSS projects. Human infrastructure is pivotal in ensuring that maintenance labor is sustainable, and by extension the OSS projects on which we all depend.},
booktitle = {Proceedings of the 18th ACM/IEEE International Symposium on Empirical Software Engineering and Measurement},
pages = {37–48},
numpages = {12},
keywords = {Community Health, Human Factors, Maintainers, Open Source Software, Project Health, Sustainability},
location = {Barcelona, Spain},
series = {ESEM '24}
}

@article{10.1145/3695881,
author = {Rathnayake, Darshana and Radhakrishnan, Meera and Hwang, Inseok and Misra, Archan},
title = {LILOC: Leveraging LiDARs for Accurate 3D Localization in Dynamic Indoor Environments},
year = {2024},
issue_date = {November 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {5},
number = {4},
url = {https://doi.org/10.1145/3695881},
doi = {10.1145/3695881},
abstract = {We present LiLoc, a system for precise 3D localization and tracking of mobile IoT devices (e.g., robots) in indoor environments using multi-perspective LiDAR sensing. LiLoc stands out with two key differentiators. First, unlike traditional localization approaches, our method remains robust in dynamically changing environments, adeptly handling varying crowd levels and object layout changes. Second, LiLoc is independent of pre-built static maps, employing dynamically updated point clouds from infrastructural-mounted LiDARs and LiDARs on individual IoT devices. For fine-grained, near real-time tracking, LiLoc intermittently utilizes complex 3D “global” registration between point clouds for robust spot location estimates. It further complements this with simpler “local” registrations, continuously updating IoT device trajectories. We demonstrate that LiLoc can (a) support accurate location tracking with location and pose estimation error being ≦7.4 cm and ≦3.2°, respectively, for 84\% of the time and the median error increasing only marginally (8\%), for correctly estimated trajectories, when the ambient environment is dynamic; (b) achieve a 36\% reduction in median location estimation error compared to an approach that uses only quasi-static global point cloud; and (c) obtain spot location estimates with a latency of only 973 msec. We also demonstrate how LiLoc efficiently integrates low-power inertial sensing, using a novel integration of inertial-based displacement to accelerate the local registration process, to enhance localization energy efficiency and latency.},
journal = {ACM Trans. Internet Things},
month = oct,
articleno = {23},
numpages = {33},
keywords = {LiDAR, 3D localization, pose estimation, trajectory tracking, dynamic indoor environments}
}

@inproceedings{10.1145/3690407.3690544,
author = {Hong, Zihan and Xi, Dongyang and Zhang, Kaixiang and Yan, Tingting},
title = {Research on the Water Level Optimization of the Great Lakes Based on Ford-Fulkerson Algorithm},
year = {2024},
isbn = {9798400710247},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3690407.3690544},
doi = {10.1145/3690407.3690544},
abstract = {Based on the intrinsic relationship between the data of the Great Lakes region and the geographical data, we developed a water flow network model and a hidden programming model to discuss how to apply the principles of graph theory and natural science to find the shortest path and the maximum flow. This model uses the Ford-Fulkerson algorithm and designs a differential equation model based on the dynamic relationship of water flow in the Great Lakes region. The study used available water level data, combined with detailed information on lakes and rivers, to create a graph-theoretical model. To maintain the ideal water level, the water level is converted into volume, and the result is obtained by whether the fluctuation range is exceeded. In addition, to evaluate the effectiveness and sensitivity of this method, we also designed a value analysis model to solve the optimization problem of the five lakes. This study not only demonstrates the application of graph theory and optimization theory in solving the Great Lakes problem, but also emphasizes the importance of considering environmental factors and conducting sensitivity analysis in model development and evaluation.},
booktitle = {Proceedings of the 2024 4th International Conference on Artificial Intelligence, Big Data and Algorithms},
pages = {824–828},
numpages = {5},
keywords = {Ford-Fulkerson algorithm, Great Lakes, analytic hierarchy process, graph-theoretical model, value analysis model},
location = {
},
series = {CAIBDA '24}
}

@inproceedings{10.1145/3690407.3690442,
author = {Yan, Xianghan and Guo, Weichao and Wang, Yanhong and Li, Shuofei},
title = {Application of Visual SLAM Technology in Military Intelligent Unmanned Systems},
year = {2024},
isbn = {9798400710247},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3690407.3690442},
doi = {10.1145/3690407.3690442},
abstract = {Vision-based Simultaneous Localization and Mapping (SLAM) technology provides environment perception, positioning, and navigation functions for unmanned systems, which is one of the key technologies for the intelligence of military unmanned systems. After over a decade of development, visual SLAM technology has formed a classic technical framework, including sensor data, visual odometry, back-end optimization, loop closure detection, and mapping. It has broad application prospects in the military, mainly in the autonomous navigation and control of intelligent unmanned systems, intelligence collection and surveillance, multi-aircraft collaborative operations, soldier simulation training, and enhanced battlefield perception. Currently, visual SLAM technology has been successfully applied to various military drones, mobile robots, and visual enhancement equipment systems. Despite challenges in robustness, accuracy, and real-time performance, with the development and breakthroughs in multi-sensor fusion and the introduction of deep learning, the military application level of visual SLAM technology will be better improved.},
booktitle = {Proceedings of the 2024 4th International Conference on Artificial Intelligence, Big Data and Algorithms},
pages = {206–211},
numpages = {6},
keywords = {Intelligent military, Intelligent unmanned systems, Simultaneous positioning and mapping, Visual SLAM},
location = {
},
series = {CAIBDA '24}
}

@article{10.1145/3701701.3701709,
author = {Chan, Justin and Glenn, Antonio and Itani, Malek and Mancl, Lisa R. and Gallagher, Emily R.},
title = {No Ear Left Behind: Wireless Earbuds for Low-Cost Hearing Screening},
year = {2024},
issue_date = {September 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {28},
number = {3},
issn = {2375-0529},
url = {https://doi.org/10.1145/3701701.3701709},
doi = {10.1145/3701701.3701709},
abstract = {Hearing loss is particularly harmful for language acquisition and neuro-development if it is left undetected in early childhood. Newborn hearing screening technologies using otoacoustic emissions (OAE) rely on detecting soft sounds generated by a healthy cochlea. High-income countries like the United States frequently implement hearing screening programs for every child at birth. However, such universal hearing screening is significantly less common in low- and middle-income countries, partly due to the conventional wisdom that the test requires sensitive and expensive acoustic hardware that costs thousands of dollars.In our MobiSys paper[1], we present the first wireless earbud design for low-cost hearing screening. Our hardware-software system reliably performs hearing screening using low-cost acoustic hardware, while being in the form-factor of a wireless earbud (Figure. 1a,b). The earbud hardware is designed to work across a large age range from newborns to adults. By developing low-cost and open-source wearable technology, our work may help address global health inequities in hearing screening by democratizing these medical devices.},
journal = {GetMobile: Mobile Comp. and Comm.},
month = oct,
pages = {20–24},
numpages = {5}
}

@inproceedings{10.1145/3686169.3686202,
author = {Wu, Kuan-Ju and Sareen, Harpreet and Kakehi, Yasuaki},
title = {The Ways of Water: A Guiding Metaphor for Designing Calm Technologies},
year = {2024},
isbn = {9798400710421},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3686169.3686202},
doi = {10.1145/3686169.3686202},
abstract = {This paper explores "The Ways of Water: Embody, Encalm, and Enliven" as a guiding metaphor for designing technologies that emphasize embodiment, mindfulness, and ecological awareness. By adapting Ursula K. Le Guin’s “the way of water” essay, Astrida Neimanis’s "Bodies of Water" feminist post-human phenomenology, Paul Dourish’s Embodied Interaction principles, and Weiser and Brown’s Calm Technology signs, we develop a framework for describing technologies that emphasize these qualities. Aligning with Astrida Neimanis’s notion of embodied experiences to think as a body of water, this paper advocates for a more reflective approach to design, recognizing the sensibility, fluidity, and interconnectedness of humans and those of others. Through the creation of three technologically mediated water containers driven from the metaphor—a Water Tank Display, an Interactive Dish for Tea Tasting, and a Water Plant Terrarium—and their corresponding narratives, we speculate on the potential of these interfaces to engage users in rich sensory experiences, encouraging contemplation on the embodied meanings of the materials with which they interact with. This paper aims to inspire HCI researchers and designers to incorporate the principles of "The Ways of Water" into their work and leverage new technologies in service of enhancing embodiment, mindfulness, and ecological responsibility to ultimately contribute to a more harmonious and sustainable future.},
booktitle = {Proceedings of the Halfway to the Future Symposium},
articleno = {42},
numpages = {9},
keywords = {Calm Technology, Embodied Interaction, Water, Well-Being},
location = {Santa Cruz, CA, USA},
series = {HttF '24}
}

@inproceedings{10.1145/3688225.3688226,
author = {Blancaflor, Eric B. and Pulgar, John Rhyz B. and Chan, James Rodley S. and Ly, Morris Myles B.},
title = {BMAT (Baggage Management Against Theft): An Automated Baggage Management System Using IoT Sensors with QR Code Verification Against Theft},
year = {2024},
isbn = {9798400717000},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3688225.3688226},
doi = {10.1145/3688225.3688226},
abstract = {The growing use of IoT devices in retail highlights integrating multi-sensor IoT systems to enhance security in busy environments as the shift from manual to technology-based management systems. Studies have reported that the global retail market was said to reach $37.67 trillion by 2027 as the rate of advancement of Internet of Things (IoT) technology has spurred innovative solutions. Therefore, the BMAT system project aims to develop an automated baggage management system incorporating IoT technologies for security. Specifically, leveraging a combination of force detection sensors, passive infrared sensors, QR code verification, and servo motors to augment robust protection against theft and unauthorized access to the bag check service. With that, the effectiveness of the proposed baggage management system is designed to support both public and private usage. Figma and Tinkercad aided in designing and prototyping the system, enabling comprehensive visualization and simulation of its components and functionalities. The system's architecture encompasses a network of IoT sensors embedded within lockers, continuously monitoring their physical environment and relaying real-time data to a central server. Users can check locker availability, scan QR codes, and receive security notifications through a web application while administrators oversee locker usage and security alerts. The BMAT system employs Frequency Hopping Spread Spectrum (FHSS) and AES-128 encryption to secure wireless communication and color-coded QR codes, enhancing overall system integrity. This project addresses the pressing need for enhanced security measures in public spaces, offering a scalable and efficient solution to mitigate the theft risk and ensure customer satisfaction.},
booktitle = {Proceedings of the 2024 6th Blockchain and Internet of Things Conference},
pages = {1–8},
numpages = {8},
location = {Fukuoka, Japan},
series = {BIOTC '24}
}

@inproceedings{10.1145/3691521.3691528,
author = {Jin, Xiao huan and Chang, Si yu and Ling, Yun and Chen, Zhong lue and Ma, Ling yan and Ren, Kang and Feng, Tao and Zhao, Jin},
title = {Incorporating Prior-Driven and Data-Driven Feature Extraction Approaches for Parkinson's Automatic Tremor Detection},
year = {2024},
isbn = {9798400717970},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3691521.3691528},
doi = {10.1145/3691521.3691528},
abstract = {Tremor is a primary symptom of Parkinson’s disease, currently clinically assessed through visual inspection. Objective tremor detection methods are being explored with the advancements in wearable sensors and machine learning technologies. However, there is still a lack of unified and effective standards across centers due to insufficient and poor robustness feature representation. To address this limitation, this paper introduces a novel feature extraction approach incorporating prior-driven and data-driven paradigms. Unrestricted by expert prior knowledge, data-driven methods delve into the internal structure of data to extract the underlying representation of tremors. The integration of both can provide more comprehensive feature sets. The method is applied to IMU data from 59 PD patients. In addition, previous studies mainly focus on the upper limb but less on the lower limb. Our work not only encompasses the analysis of upper limb tremors but also extends to lower limb tremors, and we analyze the distinctions between these two tremors. Extensive experiments demonstrate that the proposed method outperforms existing methods on upper limb tremor datasets. This work provides important insights for developing and implementing automatic tremor detection models in Parkinson’s disease.},
booktitle = {Proceedings of the 2024 9th International Conference on Biomedical Signal and Image Processing},
pages = {1–8},
numpages = {8},
keywords = {hybrid feature extraction, machine Learning, parkinson’s disease, upper and lower limb tremor detection, wearable sensors},
location = {Suzhou, China},
series = {ICBIP '24}
}

@article{10.1145/3677085,
author = {\c{C}etin Er, Cansu and \"{O}zcan, Oguzhan},
title = {Learning from Users: Everyday Playful Interactions to Support Architectural Spatial Changes},
year = {2024},
issue_date = {October 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {8},
number = {CHI PLAY},
url = {https://doi.org/10.1145/3677085},
doi = {10.1145/3677085},
abstract = {While there's growing interest in eliciting situated playful interactions with technologies in different contexts, how these interactions might shape everyday spaces still needs to be fully explored. To address this gap, this article aims to guide the architectural spatial changes by exploring everyday playful interactions of technology-adopted users in domestic spaces. We present our contributions in a two-fold study: First, through an extensive diary study involving 13 technology-adopted residents in gated communities, where distinct boundaries offer increased opportunities for playful interactions, we identified four playful themes: (1) creating and expanding play-spaces, (2) balancing play and comfort, (3) intertwining imagination with spatial experience, and (4) gamifying household interactions. Secondly, by building on these themes, we outline three design implications to inform architectural design processes, aiming to translate everyday playful interactions into tangible spatial changes. These implications include adapting shape-changing and wearable technologies for playful flexibility, embedding new forms of communications within infrastructures, and turning homes into interactive entities with multi-sensory technologies. While these findings provide a starting point for exploring new architectural design possibilities in similar environments, further research with architects, policymakers, and design researchers in the Human-Computer Interaction (HCI) and Human-Building Interaction (HBI) fields is essential to actualizing these changes.},
journal = {Proc. ACM Hum.-Comput. Interact.},
month = oct,
articleno = {320},
numpages = {25},
keywords = {architectural change, home, human-building interaction, playful interaction, situated play design, spatial change}
}

@article{10.1145/3677094,
author = {Spors, Velvet and Kaufman, Imo},
title = {Players, Take (Self-)Care: Bringing Humanistic Psychology into a Game Jam about Mental Health},
year = {2024},
issue_date = {October 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {8},
number = {CHI PLAY},
url = {https://doi.org/10.1145/3677094},
doi = {10.1145/3677094},
abstract = {Game jams are collective events that bring people together to think about, make and play games. As collaborative encounters built on community, game jams create unique interpersonal possibilities. Tapping into this relational potential, we integrated elements of humanistic psychology and the person-centred approach into a game jam: We engaged 19 participants in the making of games for self-care and mental health, over the course of a week, as a remote event hosted by the National Videogame Museum, UK. We go on to thematically analyse our shared discussions to unpack the jam as a mutual sense-making activity between facilitators and participants, demonstrating how the jam functioned as a space in which the status quo of mental health could be negotiated; contributing to the jam's sense of community, and generation of caring, novel designs. Finally, we outline two design opportunities for game designers, developers and researchers that seek to engage with the experiential nature of game jams care-fully.},
journal = {Proc. ACM Hum.-Comput. Interact.},
month = oct,
articleno = {329},
numpages = {27},
keywords = {game jam, human flourishing, humanistic psychology, mental health, participatory design, person-centred approach, self-care, video games}
}

@article{10.1145/3689438,
author = {Verma, Rohit and Mitra, Bivas and Chakraborty, Sandip},
title = {On-the-Go Automated Break Recommendation for Stress Avoidance during Highway Driving},
year = {2024},
issue_date = {March 2025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {2},
number = {1},
url = {https://doi.org/10.1145/3689438},
doi = {10.1145/3689438},
abstract = {Continuous cab driving is considered a highly stressful job, although drivers often ignore the stress. Taking a break from manual driving or transferring the control to another driver to release the stress would be an easy, intuitive solution, although the challenge is to detect the driving stress while the trip is going on. As driving stress depends on multiple diverse environmental and affective features, we, in this article, develop a novel assistive system, SmartHalt, which continuously senses the driving environment (such as road type, congestion, driver’s driving pattern) and then utilizes a spatial time series model of the driving environment with a deep learning framework to predict whether the driver will be stressed while on the trip. The model also considers the personality traits of the drivers along with the spatio-temporal features to differentiate the impact of stress on the driving behavior for different drivers and recommends taking a break soon before the driving behavior drops below a critical level. A thorough analysis of the model over seven different drivers for a 10 month-long experiment over 204,871 km of driving data reveals that the proposed approach can significantly improve driving behavior by recommending a driving break at proper times. Following the recommendation by SmartHalt improves the driving score by ≈50\% and reduces the number of driving offenses by ≈50\%. SmartHalt can help develop advanced driving assisting system (ADAS) platforms that understand the affective states of the driver and thus can be helpful for semi-autonomous driving environments for effective driver-vehicle interactions.},
journal = {ACM J. Auton. Transport. Syst.},
month = oct,
articleno = {4},
numpages = {25},
keywords = {Stress, GAN, spatio-temporal driving data}
}

@inproceedings{10.1145/3665463.3678827,
author = {DSouza, Prajwal and Fern\'{a}ndez Galeote, Daniel and Legaki, Nikoletta-Zampeta and Hamari, Juho},
title = {Edutainment in the Context of Science Communication in Virtual Reality},
year = {2024},
isbn = {9798400706929},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3665463.3678827},
doi = {10.1145/3665463.3678827},
abstract = {As social media becomes increasingly integral to science communication, there is a rising interest in blending education with entertainment to captivate the public. This paper presents the design of a virtual reality (VR) experience that strategically employs engagement strategies such as anticipation, surprise, juiciness, and agency, aimed at enhancing learning within science education. Leveraging the immersive capabilities of VR, the virtual environment seeks to adapt these social media elements to examine their potential in boosting engagement and learning. The VR experience will be used in an experiment featuring a controlled design, varying levels of interaction and sensory feedback to evaluate their influence on participants’ understanding of scientific concepts. By integrating these engaging elements, the experiment anticipates enhancing the educational utility of VR, guiding the development of more effective VR educational tools and broadening the appeal and accessibility of science learning for diverse audiences.},
booktitle = {Companion Proceedings of the 2024 Annual Symposium on Computer-Human Interaction in Play},
pages = {359–364},
numpages = {6},
keywords = {Extended Reality, Learning, Public Understanding of Science, Virtual Reality},
location = {Tampere, Finland},
series = {CHI PLAY Companion '24}
}

@inproceedings{10.1145/3679318.3685500,
author = {Wagnerberger, Dorothea and Schott, Danny and Schwenderling, Lovis and Hansen, Christian and Schumacher, Dominik},
title = {Empowering Patients: Improve Gender-Sensitive Medical Knowledge Through Interactive Edutainment},
year = {2024},
isbn = {9798400709661},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3679318.3685500},
doi = {10.1145/3679318.3685500},
abstract = {Disregarding crucial gender-specific differences and potential risks in medicine leads to widespread gender inequalities. This paper introduces interactive edutainment concepts developed through a user-centered design approach to raise awareness of gender medicine. An interactive exhibition course and an accompanying deck of cards provide an engaging and sensitizing experience of medical gender inequalities. Qualitative feedback, self-assessment, and user experience and behavior were evaluated during a public display of the concepts (n=14). The results highlight the potential of our playful approach to raising awareness among the public as well as health-related professionals, paving new ways for communication and empowerment of patients of all genders. We believe these insights have broader applicability across various domains, supporting efforts to address all forms of inequality.},
booktitle = {Proceedings of the 13th Nordic Conference on Human-Computer Interaction},
articleno = {78},
numpages = {12},
keywords = {Gender in Healthcare, Health Communication, Interaction Design, Interactive Edutainment},
location = {Uppsala, Sweden},
series = {NordiCHI '24}
}

@inproceedings{10.1145/3678935.3678975,
author = {Debruin, Simon A. and Nguyen, Hoang N. and Koo, Jeong-Hoi and Yang, Tae-Heon and Kim, Young-Min},
title = {Generating Age-Dependent Radial Artery Pulses with a Pneumatic Pulse Simulator: A Feasibility Study},
year = {2024},
isbn = {9798400717628},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3678935.3678975},
doi = {10.1145/3678935.3678975},
abstract = {Radial pulse simulators can play an important role in the advancement of wearable healthcare devices and the modernization of pulse diagnosis methods, which are widely used in Oriental Medicine. They can be used to calibrate wrist-worn sensors and train medical professionals for pulse palpations. This study proposes a new, simple, and cost-effective pulse simulator capable of producing a wide range of blood pressure waveforms. It designed and constructed a prototype pulse simulator, consisting of two precision solenoid valves, an air compressor, a pneumatic pressure sensor, and control electronics. By controlling the opening and closing of the solenoid valves, the simulator regulates the pneumatic pressure to generate desired pulse waveforms. To assess the performance of the prototype, age-related radial pulses were considered, and the pulse waveforms generated by the prototype for representative three age groups (10, 50, and 90-year-olds), which show distinctly different pulse waveforms, are compared with pre-existing in-vivo data for the same age groups. The results show that the Root-Mean-Squared-Error (RMSE) between the experimentally obtained pulses and in-vivo pulses of approximately 6\% for all groups, indicating the feasibility of the proposed pulse simulator for creating a range of pulse waveforms.},
booktitle = {Proceedings of the 2024 14th International Conference on Biomedical Engineering and Technology},
pages = {164–169},
numpages = {6},
keywords = {pulse generation, pulse simulation, pulse waveform, radial pulses, solenoid valve},
location = {Seoul, Republic of Korea},
series = {ICBET '24}
}

@inproceedings{10.1145/3678935.3678979,
author = {Pabiania, Maribelle Dequilla and Salvador, Catherine Sagbigsal and Palupit, Carl Sherwin Parto and Barba, Benjimel Nino Dangaran and Yu, Abel Simon Daepo},
title = {Hands-Free Electrolarynx with Pitch Control},
year = {2024},
isbn = {9798400717628},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3678935.3678979},
doi = {10.1145/3678935.3678979},
abstract = {The electronic larynx, or electrolarynx for short, is used mostly by patients with difficulties making vocal speech. This device is used by patients who have undergone total laryngectomy or those who have throat-related health conditions that make speaking difficult. Previous studies had implemented pitch and loudness variation controls to the electrolarynx to take out the monotonous voice and make it more comprehensible and more recognizable to a human voice. The goal of this study is to implement an easy-to-use, hands-free, controlled pitch electrolarynx that can erase some of the negatives of its use. A design where the electrolarynx is mounted on a neck brace-like case where it can be mounted on the neck without having to be held by hand, and for the activation of the electrolarynx, we used EMG electrode sensors that detect muscle contractions of the neck muscles. The researchers conclude that it is possible to use sEMG (Surface Electromyography) to control an electrolarynx's pitch. The subjects have a statistically significant effect on the prototype electrolarynx and its ability to vocalize after taking the NFMRT test. They have a subject p-value of 0.0033 and a test p-value of 0.057 from an alpha level of 0.05. Although the study used thresholds to have a set frequency at specific thresholds, it is possible to use the raw processed value of the sEMG sensors, provided they are free of noise to prevent a “shaky” voice due to the sensitivity of the nature of sEMG.},
booktitle = {Proceedings of the 2024 14th International Conference on Biomedical Engineering and Technology},
pages = {187–190},
numpages = {4},
location = {Seoul, Republic of Korea},
series = {ICBET '24}
}

