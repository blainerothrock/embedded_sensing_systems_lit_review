@inproceedings{10.1145/3565995.3566038,
author = {Abrego-Ulloa, Edwin Ra\'{u}l and Aguilar-Lazcano, Carlos Alberto and P\'{e}rez-Espinosa, Humberto and Rodr\'{\i}guez-Vizzuett, Liliana and Hern\'{a}ndez-Luquin, Mar\'{\i}a Fernanda and Espinosa-Curiel, Ismael Edrein and Escalante, Hugo Jair},
title = {Towards a monitoring and emergency alarm system activated by the barking of assistant dogs},
year = {2023},
isbn = {9781450398305},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3565995.3566038},
doi = {10.1145/3565995.3566038},
abstract = {The quality of life of people who are susceptible to presenting a sudden medical emergency is reduced by constantly suffering from a mental state of insecurity and concern, both on the part of patients and their caregivers. This is the case for older adults, people who suffer epileptic seizures, and people with emotional crises, to name a few. Assistance dogs trained to live with such people play a significant role, as they can identify emergencies and carry out specific actions to help the patient. It has a positive impact on people’s sense of security and self-esteem. In this article, we present the design, implementation, and validation of an environmental audio monitoring system that recognizes barking and detects the marking bark pattern of trained dogs to notify emergencies. When the device detects the barking pattern, it sends out an alarm signal that can be received on a caregiver’s phone. We evaluated the automatic bark detection performance of the audio classifier using the F1-score accuracy metric obtaining an average of 94\% under ideal conditions, and 98\% in a house simulation environment using background noise. Regarding the evaluation of the alarm algorithm, the system obtained 85\% without background noise and 82\% with background noise. This project intends to create the technological foundations for a system that improves the quality of life for patients and caregivers by enhancing the capabilities and maximizing the talents of assistance dogs taking advantage of the impressive current advances of information and communication technologies.},
booktitle = {Proceedings of the Ninth International Conference on Animal-Computer Interaction},
articleno = {17},
numpages = {10},
keywords = {alert, bark acoustic analysis, dog-computer interaction},
location = {Newcastle-upon-Tyne, United Kingdom},
series = {ACI '22}
}

@article{10.1145/3580865,
author = {Boovaraghavan, Sudershan and Chen, Chen and Maravi, Anurag and Czapik, Mike and Zhang, Yang and Harrison, Chris and Agarwal, Yuvraj},
title = {Mites: Design and Deployment of a General-Purpose Sensing Infrastructure for Buildings},
year = {2023},
issue_date = {March 2023},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {7},
number = {1},
url = {https://doi.org/10.1145/3580865},
doi = {10.1145/3580865},
abstract = {There is increasing interest in deploying building-scale, general-purpose, and high-fidelity sensing to drive emerging smart building applications. However, the real-world deployment of such systems is challenging due to the lack of system and architectural support. Most existing sensing systems are purpose-built, consisting of hardware that senses a limited set of environmental facets, typically at low fidelity and for short-term deployment. Furthermore, prior systems with high-fidelity sensing and machine learning fail to scale effectively and have fewer primitives, if any, for privacy and security. For these reasons, IoT deployments in buildings are generally short-lived or done as a proof of concept. We present the design of Mites, a scalable end-to-end hardware-software system for supporting and managing distributed general-purpose sensors in buildings. Our design includes robust primitives for privacy and security, essential features for scalable data management, as well as machine learning to support diverse applications in buildings. We deployed our Mites system and 314 Mites devices in Tata Consultancy Services (TCS) Hall at Carnegie Mellon University (CMU), a fully occupied, five-story university building. We present a set of comprehensive evaluations of our system using a series of microbenchmarks and end-to-end evaluations to show how we achieved our stated design goals. We include five proof-of-concept applications to demonstrate the extensibility of the Mites system to support compelling IoT applications. Finally, we discuss the real-world challenges we faced and the lessons we learned over the five-year journey of our stack's iterative design, development, and deployment.},
journal = {Proc. ACM Interact. Mob. Wearable Ubiquitous Technol.},
month = mar,
articleno = {2},
numpages = {32},
keywords = {Distributed Sensor Network, Real-World Deployment, Sensing and Sensor Technologies}
}

@article{10.1145/3580845,
author = {Rahman, Wasifur and Hasan, Masum and Islam, Md Saiful and Olubajo, Titilayo and Thaker, Jeet and Abdelkader, Abdel-Rahman and Yang, Phillip and Paulson, Henry and Oz, Gulin and Durr, Alexandra and Klockgether, Thomas and Ashizawa, Tetsuo and Investigators, Readisca and Hoque, Ehsan},
title = {Auto-Gait: Automatic Ataxia Risk Assessment with Computer Vision from Gait Task Videos},
year = {2023},
issue_date = {March 2023},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {7},
number = {1},
url = {https://doi.org/10.1145/3580845},
doi = {10.1145/3580845},
abstract = {Many patients with neurological disorders, such as Ataxia, do not have easy access to neurologists, -especially those living in remote localities and developing/underdeveloped countries. Ataxia is a degenerative disease of the nervous system that surfaces as difficulty with motor control, such as walking imbalance. Previous studies have attempted automatic diagnosis of Ataxia with the help of wearable biomarkers, Kinect, and other sensors. These sensors, while accurate, do not scale efficiently well to naturalistic deployment settings. In this study, we propose a method for identifying ataxic symptoms by analyzing videos of participants walking down a hallway, captured with a standard monocular camera. In a collaboration with 11 medical sites located in 8 different states across the United States, we collected a dataset of 155 videos along with their severity rating from 89 participants (24 controls and 65 diagnosed with or are pre-manifest spinocerebellar ataxias). The participants performed the gait task of the Scale for the Assessment and Rating of Ataxia (SARA). We develop a computer vision pipeline to detect, track, and separate the participants from their surroundings and construct several features from their body pose coordinates to capture gait characteristics such as step width, step length, swing, stability, speed, etc. Our system is able to identify and track a patient in complex scenarios. For example, if there are multiple people present in the video or an interruption from a passerby. Our Ataxia risk-prediction model achieves 83.06\% accuracy and an 80.23\% F1 score. Similarly, our Ataxia severity-assessment model achieves a mean absolute error (MAE) score of 0.6225 and a Pearson's correlation coefficient score of 0.7268. Our model competitively performed when evaluated on data from medical sites not used during training. Through feature importance analysis, we found that our models associate wider steps, decreased walking speed, and increased instability with greater Ataxia severity, which is consistent with previously established clinical knowledge. Furthermore, we are releasing the models and the body-pose coordinate dataset to the research community - the largest dataset on ataxic gait (to our knowledge). Our models could contribute to improving health access by enabling remote Ataxia assessment in non-clinical settings without requiring any sensors or special cameras. Our dataset will help the computer science community to analyze different characteristics of Ataxia and to develop better algorithms for diagnosing other movement disorders.},
journal = {Proc. ACM Interact. Mob. Wearable Ubiquitous Technol.},
month = mar,
articleno = {26},
numpages = {19},
keywords = {ataxia, computer vision, datasets, gait, pose estimation}
}

@article{10.1145/3580878,
author = {Wang, Yanxiang and Hu, Jiawei and Jia, Hong and Hu, Wen and Hassan, Mahbub and Uddin, Ashraf and Kusy, Brano and Youssef, Moustafa},
title = {Spectral-Loc: Indoor Localization Using Light Spectral Information},
year = {2023},
issue_date = {March 2023},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {7},
number = {1},
url = {https://doi.org/10.1145/3580878},
doi = {10.1145/3580878},
abstract = {For indoor settings, we investigate the impact of location on the spectral distribution of the received light, i.e., the intensity of light for different wavelengths. Our investigations confirm that even under the same light source, different locations exhibit slightly different spectral distribution due to reflections from their localised environment containing different materials or colours. By exploiting this observation, we propose Spectral-Loc, a novel indoor localization system that uses light spectral information to identify the location of the device. With spectral sensors finding their way into the latest products and applications, such as white balancing in smartphone photography, Spectral-Loc can be readily deployed without requiring any additional hardware or infrastructure. We prototype Spectral-Loc using a commercial-off-the-shelf light spectral sensor, AS7265x, which can measure light intensity over 18 different wavelength sub-bands. We benchmark the localization accuracy of Spectral-Loc against the conventional light intensity sensors that provide only a single intensity value. Our evaluations over two different indoor spaces, a meeting room, and a large office space, demonstrate that the use of light spectral information significantly reduces the localization error for the different percentiles.},
journal = {Proc. ACM Interact. Mob. Wearable Ubiquitous Technol.},
month = mar,
articleno = {37},
numpages = {26},
keywords = {Ambient light, Indoor localization, Spectral information}
}

@article{10.1145/3580832,
author = {Chen, Xiaowei and Jiang, Xiao and Fang, Jiawei and Guo, Shihui and Lin, Juncong and Liao, Minghong and Luo, Guoliang and Fu, Hongbo},
title = {DisPad: Flexible On-Body Displacement of Fabric Sensors for Robust Joint-Motion Tracking},
year = {2023},
issue_date = {March 2023},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {7},
number = {1},
url = {https://doi.org/10.1145/3580832},
doi = {10.1145/3580832},
abstract = {The last few decades have witnessed an emerging trend of wearable soft sensors; however, there are important signal-processing challenges for soft sensors that still limit their practical deployment. They are error-prone when displaced, resulting in significant deviations from their ideal sensor output. In this work, we propose a novel prototype that integrates an elbow pad with a sparse network of soft sensors. Our prototype is fully bio-compatible, stretchable, and wearable. We develop a learning-based method to predict the elbow orientation angle and achieve an average tracking error of 9.82 degrees for single-user multi-motion experiments. With transfer learning, our method achieves the average tracking errors of 10.98 degrees and 11.81 degrees across different motion types and users, respectively. Our core contributions lie in a solution that realizes robust and stable human joint motion tracking across different device displacements.},
journal = {Proc. ACM Interact. Mob. Wearable Ubiquitous Technol.},
month = mar,
articleno = {5},
numpages = {27},
keywords = {domain adaption, fuzzy entropy, long short-term memory, motion tracking, robust signal processing, soft sensors, textile sensors, transfer learning}
}

@article{10.1145/3580859,
author = {Wang, Xuan and Liu, Tong and Feng, Chao and Fang, Dingyi and Chen, Xiaojiang},
title = {RF-CM: Cross-Modal Framework for RF-enabled Few-Shot Human Activity Recognition},
year = {2023},
issue_date = {March 2023},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {7},
number = {1},
url = {https://doi.org/10.1145/3580859},
doi = {10.1145/3580859},
abstract = {Radio-Frequency (RF) based human activity recognition (HAR) enables many attractive applications such as smart home, health monitoring, and virtual reality (VR). Among multiple RF sensors, mmWave radar is emerging as a new trend due to its fine-grained sensing capability. However, laborious data collection and labeling processes are required when employing a radar-based sensing system in a new environment. To this end, we propose RF-CM, a general cross-modal human activity recognition framework. The key enabler is to leverage the knowledge learned from a massive WiFi dataset to build a radar-based HAR system with limited radar samples. It can significantly reduce the overhead of training data collection. In addition, RF-CM can work well regardless of the deployment setups of WiFi and mmWave radar, such as performing environments, users' characteristics, and device deployment. RF-CM achieves this by first capturing the activity-related variation patterns through data processing schemes. It then employs a convolution neural network-based feature extraction module to extract the high-dimensional features to be fed into the activity recognition module. Finally, RF-CM takes the generalization knowledge from WiFi networks as guide labels to supervise the training of the radar model, thus enabling a few-shot radar-based HAR system. We evaluate RF-CM by applying it to two HAR applications, fine-grained American sign language recognition (WiFi-cross-radar) and coarse-grained gesture recognition (WiFi-cross-RFID). The accuracy improvement of over 10\% in both applications demonstrates the effectiveness of RF-CM. This cross-modal ability allows RF-CM to support more cross-modal applications.},
journal = {Proc. ACM Interact. Mob. Wearable Ubiquitous Technol.},
month = mar,
articleno = {35},
numpages = {28},
keywords = {Cross-modal, Human Activity Recognition, Knowledge Transfer}
}

@article{10.1145/3580854,
author = {Dasari, Mallesham and Sheshadri, Ramanujan K. and Sundaresan, Karthikeyan and Das, Samir R.},
title = {RoVaR: Robust Multi-agent Tracking through Dual-layer Diversity in Visual and RF Sensing},
year = {2023},
issue_date = {March 2023},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {7},
number = {1},
url = {https://doi.org/10.1145/3580854},
doi = {10.1145/3580854},
abstract = {The plethora of sensors in our commodity devices provides a rich substrate for sensor-fused tracking. Yet, today's solutions are unable to deliver robust and high tracking accuracies across multiple agents in practical, everyday environments - a feature central to the future of immersive and collaborative applications. This can be attributed to the limited scope of diversity leveraged by these fusion solutions, preventing them from catering to the multiple dimensions of accuracy, robustness (diverse environmental conditions) and scalability (multiple agents) simultaneously.In this work, we take an important step towards this goal by introducing the notion of dual-layer diversity to the problem of sensor fusion in multi-agent tracking. We demonstrate that the fusion of complementary tracking modalities, - passive/relative (e.g. visual odometry) and active/absolute tracking (e.g.infrastructure-assisted RF localization) offer a key first layer of diversity that brings scalability while the second layer of diversity lies in the methodology of fusion, where we bring together the complementary strengths of algorithmic (for robustness) and data-driven (for accuracy) approaches. ROVAR is an embodiment of such a dual-layer diversity approach that intelligently attends to cross-modal information using algorithmic and data-driven techniques that jointly share the burden of accurately tracking multiple agents in the wild. Extensive evaluations reveal ROVAR'S multi-dimensional benefits in terms of tracking accuracy, scalability and robustness to enable practical multi-agent immersive applications in everyday environments.},
journal = {Proc. ACM Interact. Mob. Wearable Ubiquitous Technol.},
month = mar,
articleno = {8},
numpages = {25},
keywords = {Localization, Machine Learning, Sensor Fusion, Tracking}
}

@article{10.1145/3580784,
author = {Nakamura, Yugo and Nakaoka, Rei and Matsuda, Yuki and Yasumoto, Keiichi},
title = {eat2pic: An Eating-Painting Interactive System to Nudge Users into Making Healthier Diet Choices},
year = {2023},
issue_date = {March 2023},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {7},
number = {1},
url = {https://doi.org/10.1145/3580784},
doi = {10.1145/3580784},
abstract = {Given the complexity of human eating behaviors, developing interactions to change the way users eat or their choice of meals is challenging. In this study, we propose an interactive system called eat2pic designed to encourage healthy eating habits such as adopting a balanced diet and eating more slowly, by refraining the task of selecting meals into that of adding color to landscape pictures. The eat2pic system comprises a sensor-equipped chopstick (one of a pair) and two types of digital canvases. It provides fast feedback by recognizing a user's eating behavior in real time and displaying the result on a small canvas called "one-meal eat2pic." Moreover, it also provides slow feedback by displaying the number of colors of foods that the user consumed on a large canvas called "one-week eat2pic." The former was designed and implemented as a guide to help people eat more slowly, and the latter to encourage people to select more balanced menus. Through two user studies, we explored the experience of interaction with eat2pic, in which users' daily eating behavior was reflected in a series of "paintings," that is, images produced by the automated system. The experimental results suggest that eat2pic may provide an opportunity for reflection in meal selection and while eating, as well as assist users in becoming more aware of how they are eating and how balanced their daily meals are. We expect this system to inspire users' curiosity about different diets and ways of eating. This research also contributes to expanding the design space for products and services related to dietary support.},
journal = {Proc. ACM Interact. Mob. Wearable Ubiquitous Technol.},
month = mar,
articleno = {24},
numpages = {23},
keywords = {Aesthetic feedback, Behavior change, Dietary monitoring, Digital nudge, Human-food interaction, Well-being}
}

@article{10.1145/3580779,
author = {Wang, Shuai and Cao, Dongjiang and Liu, Ruofeng and Jiang, Wenchao and Yao, Tianshun and Lu, Chris Xiaoxuan},
title = {Human Parsing with Joint Learning for Dynamic mmWave Radar Point Cloud},
year = {2023},
issue_date = {March 2023},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {7},
number = {1},
url = {https://doi.org/10.1145/3580779},
doi = {10.1145/3580779},
abstract = {Human sensing and understanding is a key requirement for many intelligent systems, such as smart monitoring, human-computer interaction, and activity analysis, etc. In this paper, we present mmParse, the first human parsing design for dynamic point cloud from commercial millimeter-wave radar devices. mmParse proposes an end-to-end neural network design that addresses the inherent challenges in parsing mmWave point cloud (e.g., sparsity and specular reflection). First, we design a novel multi-task learning approach, in which an auxiliary task can guide the network to understand human structural features. Secondly, we introduce a multi-task feature fusion method that incorporates both intra-task and inter-task attention to aggregate spatio-temporal features of the subject from a global view. Through extensive experiments in both indoor and outdoor environments, we demonstrate that our proposed system is able to achieve ~ 92\% accuracy and ~ 84\% IoU accuracy. We also show that the predicted semantic labels can increase the performance of two downstream tasks (pose estimation and action recognition) by ~ 18\% and ~ 6\% respectively.},
journal = {Proc. ACM Interact. Mob. Wearable Ubiquitous Technol.},
month = mar,
articleno = {34},
numpages = {22},
keywords = {Human Parsing, Joint Learning, Millimeter Wave Sensing, Pose Estimation}
}

@inproceedings{10.1145/3581641.3584071,
author = {Jin, Yincheng and Choi, Seokmin and Gao, Yang and Li, Jiyang and Li, Zhengxiong and Jin, Zhanpeng},
title = {TransASL: A Smart Glass based Comprehensive ASL Recognizer in Daily Life},
year = {2023},
isbn = {9798400701061},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3581641.3584071},
doi = {10.1145/3581641.3584071},
abstract = {Sign language is a primary language used by deaf and hard-of-hearing (DHH) communities. However, existing sign language translation solutions primarily focus on recognizing manual markers. The non-manual markers, such as negative head shaking, question markers, and mouthing, are critical grammatical and semantic components of sign language for better usability and generalizability. Considering the significant role of non-manual markers, we propose the TransASL, a real-time, end-to-end system for sign language recognition and translation. TransASL extracts feature from both manual markers and non-manual markers via a customized eyeglasses-style wearable device with two parallel sensing modalities. Manual marker information is collected by two pairs of outward-facing microphones and speakers mounted to the legs of the eyeglasses. In contrast, non-manual marker information is acquired from a pair of inward-facing microphones and speakers connected to the eyeglasses. Both manual and non-manual marker features undergo a multi-modal, multi-channel fusion network and are eventually recognized as comprehensible ASL content. We evaluate the recognition performance of various sign language expressions at both the word and sentence levels. Given 80 frequently used ASL words and 40 meaningful sentences consisting of manual and non-manual markers, TransASL can achieve the WER of 8.3\% and 7.1\%, respectively. Our proposed work reveals a great potential for convenient ASL recognition in daily communications between ASL signers and hearing people.},
booktitle = {Proceedings of the 28th International Conference on Intelligent User Interfaces},
pages = {802–818},
numpages = {17},
keywords = {ASL recognition, Acoustic sensing, manual markers, non-manual markers, smart glasses},
location = {Sydney, NSW, Australia},
series = {IUI '23}
}

@article{10.1145/3532095,
author = {Lin, Chi and Wang, Pengfei and Ji, Chuanying and Obaidat, Mohammad S. and Wang, Lei and Wu, Guowei and Zhang, Qiang},
title = {A Contactless Authentication System Based on WiFi CSI},
year = {2023},
issue_date = {May 2023},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {19},
number = {2},
issn = {1550-4859},
url = {https://doi.org/10.1145/3532095},
doi = {10.1145/3532095},
abstract = {The ubiquitous and fine-grained features of WiFi signals make it promising for realizing contactless authentication. Existing methods, though yielding reasonably good performance in certain cases, are suffering from two major drawbacks: sensitivity to environmental dynamics and over-dependence on certain activities. Thus, the challenge of solving such issues is how to validate human identities under different environments, even with different activities. Toward this goal, in this article, we develop WiTL, a transfer learning–based contactless authentication system, which works by simultaneously detecting unique human features and removing the environment dynamics contained in the signal data under different environments. To correctly detect human features (i.e., human heights used in this article), we design a Height EStimation (HES) algorithm based on Angle of Arrival&nbsp;(AoA). Furthermore, a transfer learning technology combined with the Residual Network&nbsp;(ResNet) and the adversarial network is devised to extract activity features and learn environmental independent representations. Finally, experiments through multi-activities and under multi-scenes are conducted to validate the performance of WiTL. Compared with the state-of-the-art contactless authentication systems, WiTL achieves a great accuracy over 93\% and 97\% in multi-scenes and multi-activities identity recognition, respectively.},
journal = {ACM Trans. Sen. Netw.},
month = mar,
articleno = {29},
numpages = {20},
keywords = {Wireless sensing, identity recognition, WiFi CSI}
}

@inproceedings{10.1145/3572647.3572677,
author = {Zhang, Jinmeng and Zhang, Runtong},
title = {How does Basic Psychological Need Satisfaction Affect Knowledge Sharing Behavior in Online Health Communities: An Empirical Study},
year = {2023},
isbn = {9781450398640},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3572647.3572677},
doi = {10.1145/3572647.3572677},
abstract = {Online health communities (OHCs), a special type of virtual community, have emerged with the rapid growth of the Internet in which people can interact with others and receive other members’ treatment experiences. However, sustainable development of the OHCs require continuous knowledge contributions from members, thus it is vital to explore the factors that impact knowledge sharing behavior from different angles. Confirmatory factor analysis (CFA) and structural equation modelling (SEM) were used to test the hypotheses. We distributed the questionnaire via an online platform. There are 340 valid responses were collected and the questionnaire validity rate was 89.0\% (340/382). The results indicated that basic psychological need satisfaction has a positive effect on trust and sense of self-worth; trust has a positive effect on knowledge sharing behavior; sense of self-worth has a positive effect on knowledge sharing behavior. Furthermore, the research examined how to improve knowledge sharing behavior based on the findings of the empirical study.},
booktitle = {Proceedings of the 2022 6th International Conference on E-Business and Internet},
pages = {199–204},
numpages = {6},
keywords = {Basic psychological need satisfaction, Knowledge sharing behavior, Online health communities (OHCs), Self-determination theory, Sense of self-worth, Trust},
location = {Singapore, Singapore},
series = {ICEBI '22}
}

@article{10.1145/3564752,
author = {Thieme, Anja and Hanratty, Maryann and Lyons, Maria and Palacios, Jorge and Marques, Rita Faia and Morrison, Cecily and Doherty, Gavin},
title = {Designing Human-centered AI for Mental Health: Developing Clinically Relevant Applications for Online CBT Treatment},
year = {2023},
issue_date = {April 2023},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {30},
number = {2},
issn = {1073-0516},
url = {https://doi.org/10.1145/3564752},
doi = {10.1145/3564752},
abstract = {Recent advances in AI and machine learning (ML) promise significant transformations in the future delivery of healthcare. Despite a surge in research and development, few works have moved beyond demonstrations of technical feasibility and algorithmic performance. However, to realize many of the ambitious visions for how AI can contribute to clinical impact requires the closer design and study of AI tools or interventions within specific health and care contexts. This article outlines our collaborative, human-centered approach to developing an AI application that predicts treatment outcomes for patients who are receiving human-supported, internet-delivered Cognitive Behavioral Therapy (iCBT) for symptoms of depression and anxiety. Intersecting the fields of HCI, AI, and healthcare, we describe how we addressed the specific challenges of (1) identifying clinically relevant AI applications; and (2) designing AI applications for sensitive use contexts like mental health. Aiming to better assist the work practices of iCBT supporters, we share how learnings from an interview study with 15 iCBT supporters surfaced their practices and information needs and revealed new opportunities for the use of AI. Combined with insights from the clinical literature and technical feasibility constraints, this led to the development of two clinical outcome prediction models. To clarify their potential utility for use in practice, we conducted 13 design sessions with iCBT supporters that utilized interface mock-ups to concretize the AI output and derive additional design requirements. Our findings demonstrate how design choices can impact interpretations of the AI predictions as well as supporter motivation and sense of agency. We detail how this analysis and the design principles derived from it enabled the integration of the prediction models into a production interface. Reporting on identified risks of over-reliance on AI outputs and needs for balanced information assessment and preservation of a focus on individualized care, we discuss and reflect on what constitutes a responsible, human-centered approach to AI design in this healthcare context.},
journal = {ACM Trans. Comput.-Hum. Interact.},
month = mar,
articleno = {27},
numpages = {50},
keywords = {Human-centered AI, human-centered machine learning, mental health, machine learning, decision-support systems, human-AI partnership, real-world implementation of AI, user research, IxD, responsible AI, ethics}
}

@article{10.1145/3569892,
author = {Bossen, Claus and Pine, Kathleen H.},
title = {Batman and Robin in Healthcare Knowledge Work: Human-AI Collaboration by Clinical Documentation Integrity Specialists},
year = {2023},
issue_date = {April 2023},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {30},
number = {2},
issn = {1073-0516},
url = {https://doi.org/10.1145/3569892},
doi = {10.1145/3569892},
abstract = {This article describes the successful collaboration “in the wild” between Clinical Documentation Integrity Specialists (CDIS) and an Artificial Intelligence (AI)-embedded software to conduct knowledge work. CDIS review patient charts in near real-time to improve clinicians’ documentation, with the goal to make medical documentation more accurate, consistent and complete. CDIS collaborate with an AI-embedded “Computer Assisted Coding” (CAC) system that scans records from the Electronic Healthcare Record and auto-suggests codes based on natural language processing. CDIS find the CAC's suggestions are often inaccurate—often humorously so. Still, they find the CAC to be a useful helper, like Robin is to Batman. This human-AI collaboration is contingent on several factors: the flexible integration of the AI into the workflow similar to the notion of unremarkable AI; supporting the CDIS’ sensemaking; the CDIS’ knowledge about the CAC being predictably unreliable, an experience by the CDIS of the AI's value; humans remaining in control; and ability to experiment with the AI, which spurs reflection and learning for these knowledge workers.},
journal = {ACM Trans. Comput.-Hum. Interact.},
month = mar,
articleno = {26},
numpages = {29},
keywords = {Artificial Intelligence, clinical documentation, data work, ethnography, healthcare, in the wild, knowledge work}
}

@article{10.1145/3575801,
author = {Dar, Farooq and Liyanage, Mohan and Radeta, Marko and Yin, Zhigang and Zuniga, Agustin and Kosta, Sokol and Tarkoma, Sasu and Nurmi, Petteri and Flores, Huber},
title = {Upscaling Fog Computing in Oceans for Underwater Pervasive Data Science Using Low-Cost Micro-Clouds},
year = {2023},
issue_date = {May 2023},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {4},
number = {2},
url = {https://doi.org/10.1145/3575801},
doi = {10.1145/3575801},
abstract = {Underwater environments are emerging as a new frontier for data science thanks to an increase in deployments of underwater sensor technology. Challenges in operating computing underwater combined with a lack of high-speed communication technology covering most aquatic areas means that there is a significant delay between the collection and analysis of data. This in turn limits the scale and complexity of the applications that can operate based on these data. In this article, we develop underwater fog computing support using low-cost micro-clouds and demonstrate how they can be used to deliver cost-effective support for data-heavy underwater applications. We develop a proof-of-concept micro-cloud prototype and use it to perform extensive benchmarks that evaluate the suitability of underwater micro-clouds for diverse underwater data science scenarios. We conduct rigorous tests in both controlled and field deployments, using river and sea waters. We also address technical challenges in enabling underwater fogs, evaluating the performance of different communication interfaces and demonstrating how accelerometers can be used to detect the likelihood of communication failures and determine which communication interface to use. Our work offers a cost-effective way to increase the scale and complexity of underwater data science applications, and demonstrates how off-the-shelf devices can be adopted for this purpose.},
journal = {ACM Trans. Internet Things},
month = mar,
articleno = {9},
numpages = {29},
keywords = {Cloudlets, edge computing, cloud computing, aquatic environments, computation offloading}
}

@inproceedings{10.1145/3573428.3573640,
author = {Qin, Jilin},
title = {Research on A Convenient Home Care System for Gravida Based on Sensing Data Analysis},
year = {2023},
isbn = {9781450397148},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3573428.3573640},
doi = {10.1145/3573428.3573640},
abstract = {With the development of the times, more and more urban women are getting married late because of their emphasis on study and work. The proportion of older pregnant women is rising rapidly. The birth risks such as premature birth, abortion, gestational diabetes and hypertension are greatly increased, which brings new challenges to the quality of birth and the health of pregnant women. In particular, the incidence of premature infants increased year by year. Premature infants not only have a low survival rate, but also are likely to have intellectual problems. It is urgent to pay attention to the care of pregnant women and improve the birth quality of babies. This paper studies and designs a home convenient pregnant women care system based on sensor data analysis which involved Arduino board, relevant sensors and the software system. The system has the advantages of convenient use, multi-function, low cost and customizable. It can detect the ambient temperature and humidity, user's heart rhythm, harmful gas leakage, blood oxygen saturation, etc. The system also has some additional functions, such as first-aid skills for pregnant women, psychological counseling for pregnant women, fetal education music, and recipes for pregnant women, which are designed to reduce the burden and worry of pregnant women.},
booktitle = {Proceedings of the 2022 6th International Conference on Electronic Information Technology and Computer Engineering},
pages = {1185–1189},
numpages = {5},
keywords = {Gravida, MAX30102, MQ-2, Sensing Data, Uno R3},
location = {Xiamen, China},
series = {EITCE '22}
}

@inproceedings{10.1145/3573428.3573498,
author = {Shang, Zhiwei and Qi, Suiping and Ma, Ran and Li, Yunzhou},
title = {Design of wind sensor measurement and control system for extreme cold environment ∗},
year = {2023},
isbn = {9781450397148},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3573428.3573498},
doi = {10.1145/3573428.3573498},
abstract = {With the development of meteorological observation refinement, the polar regions and other extremely cold regions also need to carry out real-time wind observation, but the existing various types of wind measurement sensors are difficult to adapt to such extremely cold environment. In this paper, we developed a wind measurement and control system based on the principle of ultrasonic wind measurement with time difference method for extremely cold environment, and designed the basic circuit consisting of STM32 microcontroller minimum system, transducer driving circuit, echo signal receiving and conditioning circuit, etc. Based on this, we designed a fuzzy PID temperature control circuit to protect the sensitive element transducer at constant temperature, and also carried out the thermal insulation and protection design for the measurement and control part of the shell. And through the software simulation of the designed PID temperature control mode to select the verification. The wind sensor measurement and control circuit designed in this paper is applicable to the extremely cold environment, which has a guaranteed role in the development of wind measurement sensors applicable to the extremely cold environment and is of great significance for the acquisition of wind element information in the polar region.},
booktitle = {Proceedings of the 2022 6th International Conference on Electronic Information Technology and Computer Engineering},
pages = {406–410},
numpages = {5},
keywords = {measurement and control circuit, sonic wind measurement, wind measurement sensor},
location = {Xiamen, China},
series = {EITCE '22}
}

@inproceedings{10.1145/3574198.3574223,
author = {Fu, Qi and Qin, Haibo and Meng, Long and Zhang, Anjing and Chen, Chen and Chen, Wei},
title = {An unobtrusive upper-limb activity recognition system based on deep neural network fusion for stroke survivors},
year = {2023},
isbn = {9781450397223},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3574198.3574223},
doi = {10.1145/3574198.3574223},
abstract = {Stroke is a cerebrovascular disease that may cause long-term paralysis. Stroke survivors can recover more quickly with personalized treatment, which often requires the identification and evaluation of daily activities. Most of the existing methods for stroke activity recognition use wearable devices to collect motion and/or electrophysiology signals. However, as most survivors are elderly, the wearing process and operation methods are inevitably inconvenient for them. In this paper, we proposed an unobtrusive upper-limb movement recognition system for stroke survivors based on model fusion via combining three deep neural networks. Specifically, we recruited 16 stroke survivors with different impairment levels. Considering fine and dexterous movements of the upper limbs and hands take an important part in our daily life, fine-grained hand activities are more difficult to recognize. We conducted seventeen hand gesture recognition using video data collected by an Azure Kinect sensor. We compared the performance of three state-of-the-art deep neural networks, namely TSN, I3D, and Slowfast. Moreover, we fused the three models using soft voting. The top1 mean accuracy of our fusion model is 93.45\% on our dataset. With our method, it is expected to assist rehabilitation physicians, to formulate the corresponding treatment plan, and make better-personalized treatment for stroke survivors.},
booktitle = {Proceedings of the 2022 9th International Conference on Biomedical and Bioinformatics Engineering},
pages = {160–164},
numpages = {5},
keywords = {Deep neural network, Hand gesture recognition, Stroke},
location = {Kyoto, Japan},
series = {ICBBE '22}
}

@inproceedings{10.1145/3573428.3573459,
author = {Yang, Hui and Zhang, Yifei and Bi, Kaibo},
title = {Design of a Radar and Laser Compound Altimeter for Ground Detection},
year = {2023},
isbn = {9781450397148},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3573428.3573459},
doi = {10.1145/3573428.3573459},
abstract = {Radar altimeters and laser altimeters are two kinds of altitude detection devices with different performances. The laser altimeter has the advantages of high detection accuracy and strong anti-electromagnetic interference ability, while the radar altimeter is not affected by weather and environment, so it can be used in all weather. Therefore, the compound detection combined the radar altimeter and the laser altimeter is beneficial to improve the detection accuracy and enhance the anti-jamming capability of the system. According to the advantages and disadvantages of the two kinds of altimeters, a radar and laser compound altimeter is designed, the overall composition of the compound altimeter is studied, and the filtering and fusion algorithm of the two kinds of altimeters is proposed. The digital simulation result shows that the accuracy of the altitude detection based on multi-sensors fusion is higher than that of a single sensor, and the stability and reliability of the compound system are stronger. It shows that the compound altitude detection system combined radar and laser altimeter is feasible.},
booktitle = {Proceedings of the 2022 6th International Conference on Electronic Information Technology and Computer Engineering},
pages = {179–184},
numpages = {6},
keywords = {Compound altimeter, Laser altimeter, Radar altimeter, Signal fusion},
location = {Xiamen, China},
series = {EITCE '22}
}

@inproceedings{10.1145/3573428.3573585,
author = {Li, Qian and Sui, Huajie},
title = {Application of the perspective based on virtual reality technology to relieve anxiety in practice},
year = {2023},
isbn = {9781450397148},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3573428.3573585},
doi = {10.1145/3573428.3573585},
abstract = {Virtual reality technology is a new comprehensive technology with computer technology as the core. It makes comprehensive use of computer 3D graphics technology, simulation technology, sensing technology and display technology to generate almost real visual, auditory, tactile and sensory 3D models. The goal is to create a highly immersive and highly immersive non-realistic environment. With the help of computer programming, virtual reality technology can produce virtual scenes and related stimuli needed to relieve anxiety, with immersive, interactive and present-thinking ability. It can break through the limitation of traditional anxiety treatment and make the treatment process operable. This paper reviews the application of virtual reality technology in anxiety relief, chatbot generation model based on Seq2seq, equipment requirements and mechanisms. It has unique advantages over traditional therapies, but it also has some limitations. Future developments should consider technological innovation and standardization of treatment options.},
booktitle = {Proceedings of the 2022 6th International Conference on Electronic Information Technology and Computer Engineering},
pages = {870–874},
numpages = {5},
keywords = {Anxiety relief, Practical Psychology, Seq2seq, Virtual reality exposure therapy, Virtual reality technology},
location = {Xiamen, China},
series = {EITCE '22}
}

@article{10.1145/3569093,
author = {Meklati, Safia and Boussora, Kenza and Abdi, Mohamed El Hafedh and Berrani, Sid-Ahmed},
title = {Surface Damage Identification for Heritage Site Protection: A Mobile Crowd-sensing Solution Based on Deep Learning},
year = {2023},
issue_date = {June 2023},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {16},
number = {2},
issn = {1556-4673},
url = {https://doi.org/10.1145/3569093},
doi = {10.1145/3569093},
abstract = {This article addresses the general problem of built heritage protection against both deterioration and loss. To continuously monitor and update the structural health status, a crowd-sensing solution based on powerful and automatic deep learning technique is proposed. The aim of this solution is to get rid of the limitations of manual and visual damage detection methods that are costly and time-consuming. Instead, automatic visual inspection for damage detection on walls is efficiently and effectively performed using an embedded Convolutional Neural Network (CNN). This CNN detects the most frequent types of surface damage on wall photos. The study has been conducted in the Kasbah of Algiers where the four following types of damages have been considered: Efflorescence, spall, crack, and mold. The CNN is designed and trained to be integrated into a mobile application for a participatory crowd-sensing solution. The application should be widely and freely deployed, so any user can take a picture of a suspected damaged wall and get an instant and automatic diagnosis through the embedded CNN. In this context, we have chosen MobileNetV2 with a transfer learning approach. A set of real images have been collected and manually annotated and have been used for training, validation, and test. Extensive experiments have been conducted to assess the efficiency and the effectiveness of the proposed solution, using a 5-fold cross-validation procedure. Obtained results show in particular a mean weighted average precision of 0.868 ± 0.00862 (with a 99\% of confidence level) and a mean weighted average recall of 0.84 ± 0.00729 (with a 99\% of confidence level). To evaluate the performance of MobileNetV2 as a feature extractor, we conducted a comparative study with other small backbones. Further analysis of CNN activation using Grad-Cam has also been done. Obtained results show that our method remains effective even when using a small network and medium- to low-resolution images. MobileNetV2-based CNN size is smaller, and computational cost better, compared to the other CNNs, with similar performance results. Finally, detected surface damages have also been plotted on a geographic map, giving a global view of their distribution.},
journal = {J. Comput. Cult. Herit.},
month = mar,
articleno = {25},
numpages = {24},
keywords = {Built heritage, surface damage classification, structural health monitoring, deep learning, CNN, data augmentation, small dataset, multi-label classification, K-fold cross-validation, crowd-sensing, GRAD-CAM, geographic mapping}
}

@article{10.1145/3530694,
author = {Jiang, Yicheng and Zheng, Xia and Feng, Chao},
title = {Toward Multi-area Contactless Museum Visitor Counting with Commodity WiFi},
year = {2023},
issue_date = {March 2023},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {16},
number = {1},
issn = {1556-4673},
url = {https://doi.org/10.1145/3530694},
doi = {10.1145/3530694},
abstract = {Multi-area visitor counting plays a critical role in museum management, which can help administrative staff better study visitor flows and hotspots, so that they can ensure the quality and safety of visits. Internet of Things&nbsp;(IoT) techniques facilitate efficient recording and understanding of visitors’ spatial and temporal distribution in museums, and traditional visitor tracking applications use surveillance cameras or wireless connections with portable smart devices. However, these methods either involve privacy concerns or face the obstacle of getting natural behavioral data of all visitors. This article explores an IoT monitoring methodology in the field of museum studies, proposing a commodity WiFi-based head-counting framework that does not need the visitor to connect with any device. Our system analyzes the Channel State Information amplitude fluctuations at the fixed receiver caused when visitors cross the line-of-sight link. It enables multi-area visitor counting by achieving In-and-Out traffic detection at different sites with a convolutional neural network algorithm. The method also allows for a rough classification of visitor types based on body size, and an extra transfer module is presented to reduce training time for increasing sensing scenarios. Over 2,300 samples at five different sites were collected to test the usability. Experiment 1 implemented in three environments/deployments demonstrated that the proposed approach can be potentially implemented in variable sites of museums. It achieved high up to 95\% and 99\% accuracies for identifying the number and direction of people crossing, respectively. Experiment 2 sampled adults, children, and adult-child groups at a science museum and achieved approximately 89\% classification accuracy of visitor types. Experiment 3 collected data for all cases in which up to three targets entered and exited simultaneously, and reached a recognition accuracy of around 88\% for nine different cases. The potential and limitations for the practical application of wireless contactless sensing to cultural spaces are discussed.},
journal = {J. Comput. Cult. Herit.},
month = mar,
articleno = {8},
numpages = {26},
keywords = {Commodity WiFi, neural network, flow counting, visitor study}
}

@inproceedings{10.1145/3579109.3579127,
author = {Ding, Yueran and Zou, Junhong and Fan, Yixuan and Wang, Shengjin and Liao, Qingmin},
title = {A Digital Twin-based Testing and Data Collection System for Autonomous Driving in Extreme Traffic Scenarios},
year = {2023},
isbn = {9781450397568},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3579109.3579127},
doi = {10.1145/3579109.3579127},
abstract = {Autonomous driving systems need to undergo rigorous testing in complex scenarios including a variety of extreme operating conditions before they can be put into use. In this process, digital twin technology can migrate the scenes in the physical world to computer simulation software, so that engineers can comprehensively and safely conduct large-scale test experiments, get well prepared for vehicle tests on real road. The existing related systems in academia are still lacking in the authenticity, diversity and complexity of the scene. To solve the above problems, we propose a digital twin-based test and data acquisition system for autonomous driving under extreme traffic scenes. Based on UE4 engine and CARLA simulation platform, the system includes a Chinese urban style map with a total area of 10.8 square kilometers and 232 multi-site test routes including 29 possible events, 4 sets of environmental parameters, 2 sets of location parameters, and all weather condition. At the same time, a large amount of sensor data can also be collected in the system, which fills the insufficiency of collecting extreme working scene data in the real world. We give a perception-oriented autonomous driving data collection scheme, which can store sensor output while running simulation events, and automatically generate corresponding annotations, which can collect data in emergency situations. We also propose a new evaluation metric of autonomous driving system based on research on accident hazard. This test system covers a variety of extreme working conditions that are not involved in the existing systems, and puts forward higher requirements for the perception and decision-making algorithms related to autonomous driving.},
booktitle = {Proceedings of the 2022 6th International Conference on Video and Image Processing},
pages = {101–109},
numpages = {9},
keywords = {Autonomous Driving, Benchmark, Datasets, Scenarios Simulation},
location = {Shanghai, China},
series = {ICVIP '22}
}

@inproceedings{10.1145/3582700.3582713,
author = {Saito, Taiga and Hamazaki, Takumi and Kaneko, Seitaro and Kajimoto, Hiroyuki},
title = {Coldness Presentation to Ventral Forearm using Electrical Stimulation with Elastic Gel and Anesthetic Cream},
year = {2023},
isbn = {9781450399845},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3582700.3582713},
doi = {10.1145/3582700.3582713},
abstract = {To augment and enhance VR experience, various devices have been proposed to provide thermal sensations. In particular, Peltier devices are commonly used to induce cold sensations. However, these devices are unsuitable for long-term use due to high energy consumption. This study investigates the use of electrical stimulation to generate thermal sensation in the arm for future wearable applications. Due to its small size and low power requirements, electrical stimulation is unlikely to interfere with body movement or disrupt immersion. Furthermore, providing thermal sensation to the arm is expected to enhance immersion in VR content without interfering with hand movements. In addition, tactile sensation can also be presented by the electrical stimulation. However, electrical stimulation to the arm normally cannot provide a stable temperature sensation because pain threshold is too close to tactile and temperature threshold. We tackled this issue by two ways; one is by applying a gel layer to the arm to suppress the pain sensation by diffusing the current, and the other is by using local anesthetic cream. As a result, we found that electrical stimulation to the arm generated a cold sensation at several points out of 61 electrodes in both cases. The results of the evaluation experiments revealed that stimulation pulse width and polarity of electrical stimulation gave little effect, while there seems to be a trend that anodic stimulation using the gel tended to generate a cold sensation at relatively high intensity, and cathodic stimulation using either the gel and local anesthetic cream tended to have cold sensation over a wider area.},
booktitle = {Proceedings of the Augmented Humans International Conference 2023},
pages = {46–54},
numpages = {9},
keywords = {Cold Sensation, Electrical Stimulation, Forearm},
location = {Glasgow, United Kingdom},
series = {AHs '23}
}

@inproceedings{10.1145/3579375.3579396,
author = {Draper, Corban and Cheung, Joe Ee and Wuensche, Burkhard and Sanders, Philip J.},
title = {Development of a Virtual Reality Treatment for Tinnitus - A User Study},
year = {2023},
isbn = {9798400700057},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3579375.3579396},
doi = {10.1145/3579375.3579396},
abstract = {Tinnitus is the perception of sound when no external sound source exists. There is currently no cure for tinnitus. Existing treatments aim to mitigate tinnitus through Cognitive Behavioural Therapy and Sound Therapy. Virtual Reality (VR) has been adopted in certain medical fields due to its ability to combine visual and audial stimuli, and create immersive, controlled environments. The purpose of this research was to develop a novel tinnitus treatment, combining VR with existing tinnitus sound therapy, and assess its usability. A user study with 18 healthy participants was conducted. Quantitative and qualitative analyses garnered largely positive results. Participants found the application enjoyable, relaxing, and not stressful. The combination of audial and visual elements inside the virtual environment delivered a unified audio-visual stimulus and a sense of control of the location of the auditory stimulus that would serve as a masker sound in future tinnitus masking paradigms. More elaborate environments (beach and forest) were perceived as more enjoyable and realistic than a scene with minimal content for functionality. The beach scene was perceived as the most relaxing set-up, but the forest scene was preferred overall. Our results suggest the VR application can be developed into a multisensory tinnitus treatment and that future testing of the application in a sample of patients with bothersome tinnitus is justified. We provide guidelines for future researchers looking to create their own VR tinnitus tools.},
booktitle = {Proceedings of the 2023 Australasian Computer Science Week},
pages = {160–169},
numpages = {10},
keywords = {digital therapeutic, masking, multisensory integration, tinnitus, ventriloquist effect, virtual reality},
location = {Melbourne, VIC, Australia},
series = {ACSW '23}
}

@inproceedings{10.1145/3568162.3578630,
author = {Ranganeni, Vinitha and Sinclair, Mike and Ofek, Eyal and Miller, Amos and Campbell, Jonathan and Kolobov, Andrey and Cutrell, Edward},
title = {Exploring Levels of Control for a Navigation Assistant for Blind Travelers},
year = {2023},
isbn = {9781450399647},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3568162.3578630},
doi = {10.1145/3568162.3578630},
abstract = {Only a small percentage of blind and low-vision people use traditional mobility aids such as a cane or a guide dog. Various assistive technologies have been proposed to address the limitations of traditional mobility aids. These devices often give either the user or the device majority of the control. In this work, we explore how varying levels of control affect the users' sense of agency, trust in the device, confidence, and successful navigation. We present Glide, a novel mobility aid with two modes for control: Glide-directed and User-directed. We employ Glide in a study (N=9) in which blind or low-vision participants used both modes to navigate through an indoor environment. Overall, participants found that Glide was easy to use and learn. Most participants trusted Glide despite its current limitations, and their confidence and performance increased as they continued to use Glide. Users' control mode preferences varied in different situations; no single mode "won" in all situations.},
booktitle = {Proceedings of the 2023 ACM/IEEE International Conference on Human-Robot Interaction},
pages = {4–12},
numpages = {9},
keywords = {assistive navigation, robotics, user study},
location = {Stockholm, Sweden},
series = {HRI '23}
}

@inproceedings{10.1145/3579375.3579383,
author = {Xu, Leilei and Liu, Xiao and Jiang, Frank and Xu, Yi and Yao, Aiting and Xu, Jia and Li, Xuejun},
title = {Multi-Featured Anomaly Detection for Mobile Edge Computing Based UAV Delivery Systems},
year = {2023},
isbn = {9798400700057},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3579375.3579383},
doi = {10.1145/3579375.3579383},
abstract = {With the rapid development of communication infrastructure and the widespread of IoT computing facilities such as Mobile Edge Computing (MEC), the application of Unmanned Aerial Vehicles (UAVs) are increasingly growing especially in last-mile deliveries in smart logistics. However, the anomaly detection in the MEC environment is still one yet unresolved issue. In recent years, the methods of UAV anomaly detection mainly focus on detections of specific types of UAVs or a certain feature of UAVs, and it is not as certain to achieve efficient and reliable results, in other words, there is currently a lack of better ways to address security issues in UAV networks. In this paper, we propose a Multi-Featured Anomaly Detection (MFAD) method for MEC-based UAV delivery systems to detect malicious attacks in the network through the abnormal state of UAV. Firstly, we develop deep learning model to recognize the correct UAV behaviors using several common UAV data in normal states, including altitude and speed. Secondly, we apply attacks in the data to simulate anomalous UAV behaviors under cyberattacks. Thirdly, the abnormal data is merged into the selected normal behavior model to detect the Normalized Root Mean Square Error (NRMSE) between the input data and the data provided by the normal behavior model. Finally, experiments with UAV sensor data demonstrate that our method is effective in detecting anomalies, but also reduce the vital energy consumption in UAV delivery systems.},
booktitle = {Proceedings of the 2023 Australasian Computer Science Week},
pages = {58–65},
numpages = {8},
keywords = {Abnormal Detection, Deep Learning, Delivery System, Mobile Edge Computing, UAV},
location = {Melbourne, VIC, Australia},
series = {ACSW '23}
}

@article{10.1145/3576935,
author = {Afzal, Shehzad and Ghani, Sohaib and Hittawe, Mohamad Mazen and Rashid, Sheikh Faisal and Knio, Omar M. and Hadwiger, Markus and Hoteit, Ibrahim},
title = {Visualization and Visual Analytics Approaches for Image and Video Datasets: A Survey},
year = {2023},
issue_date = {March 2023},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {13},
number = {1},
issn = {2160-6455},
url = {https://doi.org/10.1145/3576935},
doi = {10.1145/3576935},
abstract = {Image and video data analysis has become an increasingly important research area with applications in different domains such as security surveillance, healthcare, augmented and virtual reality, video and image editing, activity analysis and recognition, synthetic content generation, distance education, telepresence, remote sensing, sports analytics, art, non-photorealistic rendering, search engines, and social media. Recent advances in Artificial Intelligence (AI) and particularly deep learning have sparked new research challenges and led to significant advancements, especially in image and video analysis. These advancements have also resulted in significant research and development in other areas such as visualization and visual analytics, and have created new opportunities for future lines of research. In this survey article, we present the current state of the art at the intersection of visualization and visual analytics, and image and video data analysis. We categorize the visualization articles included in our survey based on different taxonomies used in visualization and visual analytics research. We review these articles in terms of task requirements, tools, datasets, and application areas. We also discuss insights based on our survey results, trends and patterns, the current focus of visualization research, and opportunities for future research.},
journal = {ACM Trans. Interact. Intell. Syst.},
month = mar,
articleno = {5},
numpages = {41},
keywords = {Survey, image and video datasets, visual analytics, computer vision}
}

@inproceedings{10.1145/3578741.3578765,
author = {Sheng, Jie and Xia, Congdong and Feng, Lulu and Liu, Yuanhang},
title = {Perception Method of Abnormal Events in Rail Transit based on Multi-source Point Cloud Information},
year = {2023},
isbn = {9781450399067},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3578741.3578765},
doi = {10.1145/3578741.3578765},
abstract = {With the development of the rail transportation business, the perception of abnormal events in rail transportation has become particularly important. It is necessary to explore and innovate the technology by acquiring point cloud information through a new perception method - LiDAR(Light Detection and Ranging). In this paper, we propose a method of rail transit abnormal event sensing based on multi-source point cloud information. It can sense rail transit abnormal events in different areas of rail transit station lobby scenes. We use Matlab-based statistical filtering, plane fitting, and point cloud rotation to complete the pre-processing, and extract the valid point cloud data contained in the original point cloud. Then we use the voxel-centered difference method to perceive the dynamic targets in the rail transit environment. And we use the model of human characteristics and the deep learning method based on PointNet to complete the perception of human point cloud data in the dynamic targets. Finally, the human behavior patterns are discriminated based on the enclosing frame and skeleton extraction methods. The experimental results show that the proposed method can effectively sense the dynamic human targets in the station lobby scenes and provide data support for subsequent abnormal event detection.},
booktitle = {Proceedings of the 2022 5th International Conference on Machine Learning and Natural Language Processing},
pages = {119–124},
numpages = {6},
keywords = {Abnormal Events, Point Cloud, Rail Transit, Solid State Lidar, Statistical Filtering},
location = {Sanya, China},
series = {MLNLP '22}
}

@inproceedings{10.1145/3545945.3569876,
author = {Cowit, Noah Q. and Barker, Lecia},
title = {How do Teaching Practices and Use of Software Features Relate to Computer Science Student Belonging in Synchronous Remote Learning Environments?},
year = {2023},
isbn = {9781450394314},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3545945.3569876},
doi = {10.1145/3545945.3569876},
abstract = {When faculty behaviors foster students' sense of belonging in class, students report better learning experiences and are more likely to remain in the major. Sense of belonging is the feeling of being a valued and legitimate member of a community. Understanding teacher immediacy behaviors that cultivate belonging in postsecondary synchronous remote classrooms is important for retaining students in computing, where remote coursework is increasingly used to address increases in enrollment. This paper reports on an exploratory, survey-based study on the relationship between instructor immediacy behaviors and use of conferencing software features (e.g., chat, breakout rooms) with student sense of belonging in synchronous remote learning environments. Responses from 125 computing students from approximately 53 courses across the US show that students feel a moderate sense of belonging in their courses, with no differences found across demographic groups. Belonging was found to have a strong relationship with students' overall opinions of their courses and their likelihood of completing the major. Students' camera preferences and instructor camera requirements had no effect on belonging. A regression analysis showed that no tool use variables predicted student sense of belonging. However, two teacher immediacy behaviors, setting aside class time to talk about upcoming course content and use of humor, were significantly associated with an increase in sense of belonging.},
booktitle = {Proceedings of the 54th ACM Technical Symposium on Computer Science Education V. 1},
pages = {771–777},
numpages = {7},
keywords = {belonging, synchronous remote learning, undergraduate computing education},
location = {Toronto ON, Canada},
series = {SIGCSE 2023}
}

@article{10.1145/3499426,
author = {Gao, Honghao and Zhou, Lin and Kim, Jung Yoon and Li, Ying and Huang, Wanqiu},
title = {Applying Probabilistic Model Checking to the Behavior Guidance and Abnormality Detection for A-MCI Patients under Wireless Sensor Network},
year = {2023},
issue_date = {August 2023},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {19},
number = {3},
issn = {1550-4859},
url = {https://doi.org/10.1145/3499426},
doi = {10.1145/3499426},
abstract = {With the development of the Internet of Medical Things (IoMT), indoor wireless sensor networks (WSNs) have been used to monitor Alzheimer's disease patients daily and guide their behaviors. Alzheimer's disease may seriously impact patients’ memory, and thoughts of “what should I do” can unexpectedly form in their mind. This cognitive impairment can affect patients’ independence and well-being. As a basic infrastructure for future healthcare systems, WSN can collect patient behaviors, such as their positions and states, to support safety and health analyses. Therefore, this paper proposes a probabilistic model checking-based method to predict patient behaviors and detect abnormal behaviors related to mild cognitive impairment to help patients rebuild their confidence and perception. First, the layout of the home environment is abstracted as a formal grid, and a user activity model (UAM) is proposed in the form of discrete-time Markov chain (DTMC) to describe patients’ activity based on data collected by sensors. Second, because Alzheimer's patients with mild cognitive impairment (A-MCI) often forget their next daily activities, we classify and describe their daily behaviors as verification requirements in the form of probabilistic computational tree logic (PCTL). Then, the UAM is input into a probabilistic model checking tool and compared against the verification property PCTL to calculate the probability values and assess temporal behaviors. As result, the activity with the largest probability is selected for behavior guidance. Third, we demonstrate the process of detecting abnormalities, including activities with abnormal temporal behaviors and activities with normal temporal behaviors but unexpected probabilities that may be repeated more than twice. The key states are extracted from the UAM to specify the verification properties for abnormality detection. Finally, a case study is presented to demonstrate the usability and feasibility of our proposed method.},
journal = {ACM Trans. Sen. Netw.},
month = mar,
articleno = {48},
numpages = {24},
keywords = {Alzheimer's disease, Internet of Medical Things (IoMT), Wireless Sensor Network (WSN), probabilistic model checking, mild cognitive impairment, behavior guidance, abnormality detection}
}

@article{10.1145/3565483,
author = {Li, Jinxi and Guo, Deke and Xie, Junjie and Chen, Sheng},
title = {Availability-aware Provision of Service Function Chains in Mobile Edge Computing},
year = {2023},
issue_date = {August 2023},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {19},
number = {3},
issn = {1550-4859},
url = {https://doi.org/10.1145/3565483},
doi = {10.1145/3565483},
abstract = {With the advent of Network Function Virtualization (NFV) and Mobile Edge Computing (MEC), outsourcing network functions (NFs) to the MEC is becoming popular among network service providers (NSPs), since it brings the scalability and flexibility for NF deployment and maintenance. Each user’s request will go through a service function chain (SFC), which consists of several virtual network functions (VNFs, software substitutions for traditional hardware-based middleboxes) in a specific order, and then get a response. Unlike conventional hardware-based middleboxes, VNFs are not very reliable due to potential software faults and host malfunctions. Thus, a sensible way is to add redundancy for the primary VNFs of an SFC to enhance its availability. Nevertheless, which MEC node to place each VNF, and how many backup instances are enough to ensure the availability requirement of each SFC? These issues have not yet been resolved.In this article, we present the availability-aware provision of SFC (APoS) in the MEC environment with the primary goal of maximizing the number of served requests while meeting the requirements and reliability expectations of SFCs. For the APoS, we have primarily addressed the following two fundamental challenges: (i) First, how to efficiently map these primary and backup VNFs to meet the availability requirements of SFCs? At this point, we formulate it as an integer nonlinear programming (INLP) under the limitation of each MEC node’s resources. This issue is NP-hard, and a novel binary N-back search method is proposed to derive the optimal solution for the primary and backup VNFs mapping; (ii) Second, how can we reduce the latency for users to access their desired SFCs? Then, we investigate how to minimize the average delay for all requests in each time slot. To solve this problem, we design an online service switching (OSS) method, which jointly considers the queuing delay, communication delay, and switching delay. It achieves the optimal solution with a theoretical guarantee. Finally, we evaluate the proposed methods with real-world datasets. The results demonstrate that, compared with the benchmarks, our practices can achieve approximately 20\% request acceptance gain and up to 30\% delay reduction, on average.},
journal = {ACM Trans. Sen. Netw.},
month = mar,
articleno = {57},
numpages = {28},
keywords = {Availability-aware, service function chain, mobile edge computing}
}

@article{10.1145/3560265,
author = {Jiang, Jielin and Guo, Jiajie and Khan, Maqbool and Cui, Yan and Lin, Wenmin},
title = {Energy-saving Service Offloading for the Internet of Medical Things Using Deep Reinforcement Learning},
year = {2023},
issue_date = {August 2023},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {19},
number = {3},
issn = {1550-4859},
url = {https://doi.org/10.1145/3560265},
doi = {10.1145/3560265},
abstract = {As a critical branch of the Internet of Things (IoT) in the medicine industry, the Internet of Medical Things (IoMT) significantly improves the quality of healthcare due to its real-time monitoring and low medical cost. Benefiting from edge and cloud computing, IoMT is provided with more computing and storage resources near the terminal to meet the low-delay requirements of computation-intensive services. However, the service offloading from health monitoring units (HMUs) to edge servers generates additional energy consumption. Fortunately, artificial intelligence (AI), which has developed rapidly in recent years, has proved effective in some resource allocation applications. Taking both energy consumption and delay into account, we propose an energy-aware service offloading algorithm under an end-edge-cloud collaborative IoMT system with Asynchronous Advantage Actor-critic (A3C), named ECAC. Technically, ECAC uses the structural similarity between the natural distributed IoMT system and A3C, whose parameters are asynchronously updated. Besides, due to the typical delay-sensitivity mechanism and time-energy correction, ECAC can adjust dynamically to the diverse service types and system requirements. Finally, the effectiveness of ECAC for IoMT is proved on real data.},
journal = {ACM Trans. Sen. Netw.},
month = mar,
articleno = {55},
numpages = {20},
keywords = {Service offloading, asynchronous advantage actor-critic, internet of medical things, deep reinforcement learning}
}

@inproceedings{10.1145/3575882.3575890,
author = {Firdaus, Muhammad Yusha and Wibowo, Dena Karunianto and Hamidah, Maratul and Utama, Ryan Prasetya and Dewi, Mustika Fitriana and Hamdani, Mohammad and Setianingrum, Lesti and Rahardjo, Sasono and Purwoadi, Michael Andreas and Purnomo, Edhi},
title = {The Effect of Fiber Bragg Grating (FBG) Sensors on Data Channel of Fiber Optic Communication (FOC) System},
year = {2023},
isbn = {9781450397902},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3575882.3575890},
doi = {10.1145/3575882.3575890},
abstract = {The advantages of optical fiber sensors, including fiber bragg grating (FBG) sensors, e.g. greater sensitivity, immunity to electromagnetic interference (EMI) and radio frequency interference (RFI), versatility, reliability, compatibility to optical communication and telemetry, reduced cost, reduced size, and reduced weight have been very well known. In particular, the FBG sensors have been widely utilized in many fields such as in structural health monitoring, oil and gas, civil industry, medical and space equipment. In this paper we develop a model of FBG sensors embedded fiber optic communication (FOC) system by using OptiSystem v.18. The bit error rate (BER) and Q-factor analysis as results of the effect of two FBG sensors on telecommunication channels, in which the sensors are integrated into a single fiber optic communication (FOC) with 80 km of fiber optic length. The results show that even with 2 sensors embedded in FOC system, the min BER and max Q factor of the system are still in good conditions with values of 4.35x 10-7 and 4.87 respectively.},
booktitle = {Proceedings of the 2022 International Conference on Computer, Control, Informatics and Its Applications},
pages = {40–43},
numpages = {4},
keywords = {Bit Error Rate (BER), Fiber Bragg Gratings (FBG), Fiber Optic Communication (FOC), Q factor},
location = {Virtual Event, Indonesia},
series = {IC3INA '22}
}

@article{10.1145/3563949,
author = {Afandizadeh Zargari, Amir Hosein and Aqajari, Seyed Amir Hossein and Khodabandeh, Hadi and Rahmani, Amir and Kurdahi, Fadi},
title = {An Accurate Non-accelerometer-based PPG Motion Artifact Removal Technique using CycleGAN},
year = {2023},
issue_date = {January 2023},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {4},
number = {1},
url = {https://doi.org/10.1145/3563949},
doi = {10.1145/3563949},
abstract = {A photoplethysmography (PPG) is an uncomplicated and inexpensive optical technique widely used in the healthcare domain to extract valuable health-related information, e.g., heart rate variability, blood pressure, and respiration rate. PPG signals can easily be collected continuously and remotely using portable wearable devices. However, these measuring devices are vulnerable to motion artifacts caused by daily life activities. The most common ways to eliminate motion artifacts use extra accelerometer sensors, which suffer from two limitations: (i) high power consumption, and (ii) the need to integrate an accelerometer sensor in a wearable device (which is not required in certain wearables). This paper proposes a low-power non-accelerometer-based PPG motion artifacts removal method outperforming the accuracy of the existing methods. We use Cycle Generative Adversarial Network to reconstruct clean PPG signals from noisy PPG signals. Our novel machine-learning-based technique achieves 9.5 times improvement in motion artifact removal compared to the state-of-the-art without using extra sensors such as an accelerometer, which leads to 45\% improvement in energy efficiency.},
journal = {ACM Trans. Comput. Healthcare},
month = feb,
articleno = {1},
numpages = {14},
keywords = {Machine learning, deep generative models, cycle GAN, PPG signals, motion artifacts removal, noise removal}
}

@inproceedings{10.1145/3569009.3572749,
author = {Kellermeyer, Jonas and Torpus, Jan and Kovacevic, Toni and Kellner, Sophie Stephanie and Spindler, Cedric Julian},
title = {To Touch or not to Touch? Differences in Affordance Resonating with Materialities. Hard and Soft Sensors embedded in an Artistic Research Setting},
year = {2023},
isbn = {9781450399777},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3569009.3572749},
doi = {10.1145/3569009.3572749},
abstract = {In this paper, we present theoretical basics, creative development processes, and partial evaluation results of human behavior and attitude in a dramaturgically staged interactive environment. The installation is set up in a media lab and the separate rooms are carefully designed to provoke emotional and cognitive human reactions. The corresponding installed sensor-actuator system includes different types of embedded sensors and tangible interfaces to create a fully embodied experience for participants walking through the artistic research facility. We evaluate and compare two opposite design approaches to investigate the impact of dramaturgy, design strategies, and furnishing on affective human-machine correlations and appropriation processes.},
booktitle = {Proceedings of the Seventeenth International Conference on Tangible, Embedded, and Embodied Interaction},
articleno = {18},
numpages = {13},
keywords = {aesthetics of electronics, artistic research, environmental psychology, haptic interfaces, interactive surfaces, responsive environment, sensor actor network, soft sensors, techno-social hybridity, ubiquitous computing, wearables},
location = {Warsaw, Poland},
series = {TEI '23}
}

@inproceedings{10.1145/3569009.3572805,
author = {Bell, Fiona and Chow, Derrek and Choi, Hyelin and Alistar, Mirela},
title = {SCOBY BREASTPLATE: SLOWLY GROWING A MICROBIAL INTERFACE},
year = {2023},
isbn = {9781450399777},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3569009.3572805},
doi = {10.1145/3569009.3572805},
abstract = {We present an interactive breastplate grown and fabricated from SCOBY (Symbiotic Culture Of Bacteria and Yeast) biofilm over the course of 13 weeks. Challenging the fail-fast and rapid prototyping trends that inhabit HCI research, we instead explore what it means to design at the pace of another living organism. To create our wearable, we combined DIY-Bio knowledge with digital fabrication methods and traditional crafting techniques in order to tune aspects of the SCOBY such as strength, flexibility, shape, color, and electrical conductivity. We then embedded sensors and LEDs within the SCOBY to create a wearable that visually signals based on touch interactions. We demonstrate the interactivity of the breastplate in an everyday context, where differing light responses result from the wearer being hugged, tapped, or brushed. Lastly, we analyze the biodegradability of the SCOBY breastplate and observe the limitations and opportunities of SCOBY as a grown microbial interface.},
booktitle = {Proceedings of the Seventeenth International Conference on Tangible, Embedded, and Embodied Interaction},
articleno = {34},
numpages = {15},
keywords = {Bio-HCI, Biodesign, Biomaterials, DIYBio, Microbial Cellulose, Slow Design, Sustainability, Tangible Interfaces, Wearables},
location = {Warsaw, Poland},
series = {TEI '23}
}

@inproceedings{10.1145/3572864.3580332,
author = {Hu, Changshuo and Ma, Xiao and Ma, Dong and Dang, Ting},
title = {Lightweight and Non-Invasive User Authentication on Earables},
year = {2023},
isbn = {9798400700170},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3572864.3580332},
doi = {10.1145/3572864.3580332},
abstract = {The widespread adoption of wireless earbuds has advanced the developments in earable-based sensing in various domains like entertainment, human-computer interaction, and health monitoring. Recently, researchers have shown an increased interest in user authentication using earables. Despite the successes witnessed in acoustic probing and speech based authentication systems, this paper proposed a lightweight and non-invasive ambient sound based user authentication scheme. It employs the difference between the in-ear and out-ear sounds to estimate the individual-specific occluded ear canal transfer function (OECTF). Specifically, the {out-ear, in-ear} scaling factors at different frequency bands are captured via linear regression and treated as the OECTF for user authentication. The proposed system is validated using 12 subjects under six different noisy environments and achieves a Balanced Error Rate (BER) of 4.84\%. The particularly lightweight system can be easily deployed in earbuds and paves the pathway for more personalized services.},
booktitle = {Proceedings of the 24th International Workshop on Mobile Computing Systems and Applications},
pages = {36–41},
numpages = {6},
location = {Newport Beach, California},
series = {HotMobile '23}
}

@inproceedings{10.1145/3572864.3580341,
author = {Balaji, Ananta Narayanan and Ferlini, Andrea and Kawsar, Fahim and Montanari, Alessandro},
title = {Stereo-BP: Non-Invasive Blood Pressure Sensing with Earables},
year = {2023},
isbn = {9798400700170},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3572864.3580341},
doi = {10.1145/3572864.3580341},
abstract = {Frequent blood pressure monitoring with earables has been increasingly explored owing to its importance in diagnosing cardiac health. While previous solutions for blood pressure estimation in earables are uncomfortable and less accurate, the objective of this study is to achieve non-invasive, accurate and cuff-less blood pressure monitoring with PPG sensors integrated into earphones. To this end, we investigated photoplethysmograph (PPG) signals from the left and right ears and found that blood arrives earlier in the left ear due to the closer distance from the heart. Based on our findings, we propose Stereo-BP --- an earable system leveraging the pulse time difference measured between PPG signals from our left and right ear-worn prototypes to estimate blood pressure. Our preliminary evaluation with 20 participants shows the feasibility of measuring systolic and diastolic blood pressure from the ears, with mean absolute errors of 3.97 mmHg and 3.83 mmHg, respectively, against ground truth blood pressure measurements from a clinical-grade cuff-based device. Our investigation shows the feasibility of Stereo-BP in providing frequent blood pressure estimation with future earables.},
booktitle = {Proceedings of the 24th International Workshop on Mobile Computing Systems and Applications},
pages = {96–102},
numpages = {7},
keywords = {PPG, blood pressure sensing, earables},
location = {Newport Beach, California},
series = {HotMobile '23}
}

@inproceedings{10.1145/3572864.3580340,
author = {Chhaglani, Bhawana and Acer, Utku G\"{u}nay and Jang, Si Young and Kawsar, Fahim and Min, Chulhong},
title = {Cocoon: On-Body Microphone Collaboration for Spatial Awareness},
year = {2023},
isbn = {9798400700170},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3572864.3580340},
doi = {10.1145/3572864.3580340},
abstract = {We are now surrounded by multiple microphones available on various devices around us including wearables. This opens unique opportunities for acoustic sensing applications to enhance the spatial resolution of audio signals on the body. However, state-of-the-art acoustic sensing applications still mostly utilize a single microphone or a microphone array on a single device. In this paper, we present Cocoon, a case study for on-body microphone collaboration for spatial awareness. Cocoon is a novel wearable system that automatically provides users with situational services based on their location. To this end, it combines spatial profiles from multiple on-body microphones on the fly and identifies a user's location by matching the profile against the pre-registered ones. Our experimental results show that Cocoon outperforms the existing single microphone-based methods, 10.0\% points and 21.5\% points accuracy increase in the controlled and real-world setup, respectively. Cocoon also improves the robustness to slight movements and orientation changes of the microphone, reducing the error rate by 17.5\% points.},
booktitle = {Proceedings of the 24th International Workshop on Mobile Computing Systems and Applications},
pages = {89–95},
numpages = {7},
keywords = {microphone, spatial sensing, wearable collaboration},
location = {Newport Beach, California},
series = {HotMobile '23}
}

@inproceedings{10.1145/3572864.3580336,
author = {Yin, Zhigang and Liyanage, Mohan and Zuniga, Agustin and Nurmi, Petteri and Flores, Huber},
title = {Hedgehog: Detecting Drink Spiking on Wearables},
year = {2023},
isbn = {9798400700170},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3572864.3580336},
doi = {10.1145/3572864.3580336},
abstract = {People increasingly carry wearables and the capabilities of these devices have reached a point where it is increasingly possible to harness the devices to support everyday interactions. We contribute a new use of wearables by demonstrating how they can be used to safeguard against drink spiking, the deliberate act of adding substances to another person's drink. We design Hedgehog, a pervasive sensing approach that re-purposes the optical sensors in off-the-shelf wearables to identify spiked drinks by analysing differences in light reflectivity resulting from small particles inside the drink. We present a wearable prototype inspired by a smart ring design and conduct rigorous experiments that show the Hedgehog reaches up to 89.71\% accuracy in detecting drinks that are tampered with. Our work demonstrates how pervasive sensing enables innovative applications and how smart wearables can be re-purposed to support personal safety.},
booktitle = {Proceedings of the 24th International Workshop on Mobile Computing Systems and Applications},
pages = {61–67},
numpages = {7},
keywords = {IoT, light sampling, liquid sensing, smart ring, wearable},
location = {Newport Beach, California},
series = {HotMobile '23}
}

@article{10.1145/3519302,
author = {Wu, Kaishun and Huang, Yandao and Qiu, Minghui and Peng, Zhenkan and Wang, Lu},
title = {Toward Device-free and User-independent Fall Detection Using Floor Vibration},
year = {2023},
issue_date = {February 2023},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {19},
number = {1},
issn = {1550-4859},
url = {https://doi.org/10.1145/3519302},
doi = {10.1145/3519302},
abstract = {The inevitable aging trend of the world’s population brings a lot of challenges to the health care for the elderly. For example, it is difficult to guarantee timely rescue for single-resided elders who fall at home. Under this circumstance, a reliable automatic fall detection machine is in great need for emergent rescue. However, the state-of-the-art fall detection systems are suffering from serious privacy concerns, having a high false alarm, or being cumbersome for users. In this article, we propose a device-free fall detection system, namely G-Fall, based on floor vibration collected by geophone sensors. We first decompose the falling mode and characterize it with time-dependent floor vibration features. By leveraging Hidden Markov Model (HMM), our system is able to detect the fall event precisely and achieve user-independent detection. It requires no training from the elderly but only an HMM template learned in advance through a small number of training samples. To reduce the false alarm rate, we propose a novel reconfirmation mechanism using Energy-of-Arrival (EoA) positioning to assist in detecting the human fall. Extensive experiments have been conducted on 24 human subjects. On average, G-Fall achieves a 95.74\% detection precision on the anti-static floor and 97.36\% on the concrete floor. Furthermore, with the assistance of EoA, the false alarm rate is reduced to nearly 0\%.},
journal = {ACM Trans. Sen. Netw.},
month = feb,
articleno = {5},
numpages = {20},
keywords = {Fall detection, floor vibration, geophone, device-free, user-independent}
}

@article{10.1145/3561513,
author = {Singh, KN and Singh, OP and Singh, Amit Kumar and Agrawal, Amrit Kumar},
title = {EiMOL: A Secure Medical Image Encryption Algorithm based on Optimization and the Lorenz System},
year = {2023},
issue_date = {April 2023},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {19},
number = {2s},
issn = {1551-6857},
url = {https://doi.org/10.1145/3561513},
doi = {10.1145/3561513},
abstract = {Nowadays, the demand for digital images from different intelligent devices and sensors has dramatically increased in smart healthcare. Due to advanced low-cost and easily available tools and software, manipulation of these images is an easy task. Thus, the security of digital images is a serious challenge for the content owners, healthcare communities, and researchers against illegal access and fraudulent usage. In this article, a secure medical image encryption algorithm, EiMOL, based on optimization and the Lorenz system, is proposed for smart healthcare applications. In the first stage, an optimized random sequence (ORS) is generated through directed weighted complex network particle swarm optimization using the genetic algorithm (GDWCN-PSO). This random number matrix and the Lorenz system are adopted to encrypt plain medical images, obtaining the cipher messages with a relationship to the plain images. According to our obtained results, the proposed EiMOL encryption algorithm is effective and resistant to the many attacks on benchmark Kaggle and Open-i datasets. Further, extensive experimental results demonstrate that the proposed algorithm outperforms the state-of-the-art approaches.},
journal = {ACM Trans. Multimedia Comput. Commun. Appl.},
month = feb,
articleno = {94},
numpages = {19},
keywords = {Healthcare system, medical image, encryption, optimization, security}
}

@article{10.1145/3498329,
author = {Kocaturk, Tuba and Mazza, Domenico and McKinnon, Malcolm and Kaljevic, Sofija},
title = {GDOM: An Immersive Experience of Intangible Heritage through Spatial Storytelling},
year = {2023},
issue_date = {December 2022},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {15},
number = {4},
issn = {1556-4673},
url = {https://doi.org/10.1145/3498329},
doi = {10.1145/3498329},
abstract = {This paper presents the design, development, and evaluation of GDOM (Geelong Digital Outdoor Museum) application that integrates intangible heritage stories into places of public significance through a 3D virtual immersive environment. The project makes an important contribution to community-centered intangible heritage, while bridging the gap between theory and practice of location-based, non-linear storytelling. Research by Design methodology has been adopted to integrate highly cross-disciplinary insights into the creation, reproduction, and evaluation of a tangible application. A web-based 360° panoramic image viewer platform has been utilised to design and curate an interactive heritage experience, by spatially linking stories (content) to specific locations. The key innovation is the location-based, non-linear and spatial storytelling inside a 3D immersive virtual space where users have the opportunity to interact with intangible heritage stories. GDOM application opened up new opportunities to connect people with intangible heritage to facilitate new forms of environmental knowing, spatial and cultural understanding, and the creation of a sense of place. An in-depth evaluation of GDOM, with both expert and non-expert user groups, confirmed the GDOM application as an effective tool to experience intangible heritage to facilitate better understanding of places compared to a physical experience of heritage in a museum. Potential context of application with immediate benefits have been reported as education and cultural tourism sectors.},
journal = {J. Comput. Cult. Herit.},
month = feb,
articleno = {59},
numpages = {18},
keywords = {Intangible heritage, spatial storytelling, location-based storytelling, community engagement, 360° scanning, immersive experience}
}

@inproceedings{10.1145/3572549.3572634,
author = {Wang, Xueqi and Sui, Jinxue},
title = {Electronic Engineering Academic Competition Training Based on CDIO: A Case of IOT Health Monitoring System Design},
year = {2023},
isbn = {9781450397766},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3572549.3572634},
doi = {10.1145/3572549.3572634},
abstract = {Innovative teaching is rationally integrated into laboratory activities based on CDIO engineering education concepts and academic competitions. The teaching mode of independent learning, course teaching and practice innovation is adopted, and differentiated and personalized practical training is carried out in different stages, levels and competitions, and teaching students in accordance with their aptitude. After engineering training, students are organized to participate in electronic design, Internet of Things (IOT) and robots and other academic competitions. The IoT health monitoring system for student entries has been used as a case to illustrate the teaching effect of CDIO. This design uses various sensors to monitor the life and health data during movement, and then transmits data to the back end of self-built server through IOT. From hardware to software, to overall system design and competition display, realize CDIO of Engineering Education. Through academic competition training, students engineering practice, innovation and comprehensive ability have been effectively improved},
booktitle = {Proceedings of the 14th International Conference on Education Technology and Computers},
pages = {533–537},
numpages = {5},
location = {Barcelona, Spain},
series = {ICETC '22}
}

@article{10.1145/3582011,
author = {Abu-Khadrah, Ahmed and Ali, Ali Mohd and Jarrah, Muath},
title = {An Amendable Multi-Function Control Method using Federated Learning for Smart Sensors in Agricultural Production Improvements},
year = {2023},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
issn = {1550-4859},
url = {https://doi.org/10.1145/3582011},
doi = {10.1145/3582011},
abstract = {Communications and Computer Engineering Department, Faculty of Engineering, Al-Ahliyya Amman University, Amman 19328, JordanSchool of Information Technology, Skyline University, Sharjah, 1797, UAESmart Sensors are used for monitoring, sensing, and actuating controls in small and large-scale agricultural plots. From soil features to crop health and climatic observations, the smart sensors integrate with sophisticated technologies such as the Internet of Things or cloud for decentralized processing and global actuation. Considering this integration, an Amendable Multi-Function Sensor Control (AMFSC) is introduced in this proposal. This proposed method focuses on sensor operations that aid agricultural production improvements. The agriculture hindering features from the soil, temperature, and crop infections are sensed and response is actuated based on controlled operations. The control operations are performed according to the sensor control validation and modified control acute sensor, which helps to maximize productivity. The sensor control and operations are determined using federated learning from the accumulated data in the previous sensing intervals. This learning validates the current sensor data with the optimal data stored for different crops and environmental factors in the past. Depending on the computed, sensed, and optimal (adaptable) data, the sensor operation for actuation is modified. This modification is recommended for crop and agriculture development to maximize agricultural productivity. In particular, the sensing and actuation operations of the smart sensors for different intervals are modified to maximize production and adaptability. The efficiency of the system was evaluated using different parameters and the system maximizes the analysis rate (12.52\%), control rate (7\%), adaptability (9.65\%) and minimizes the analysis time (7.12\%), and actuation lag (8.97\%)},
note = {Just Accepted},
journal = {ACM Trans. Sen. Netw.},
month = feb,
keywords = {Agricultural Production, Federation Learning, Multi-Function sensor, Sensor Control, Smart Sensors, Productivity Analysis, Modified Control}
}

@inproceedings{10.1145/3528227.3528569,
author = {Lakshman, Shashank Bangalore and Eisty, Nasir U.},
title = {Software engineering approaches for TinyML based IoT embedded vision: a systematic literature review},
year = {2023},
isbn = {9781450393324},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3528227.3528569},
doi = {10.1145/3528227.3528569},
abstract = {Internet of Things (IoT) has catapulted human ability to control our environments through ubiquitous sensing, communication, computation, and actuation. Over the past few years, IoT has joined forces with Machine Learning (ML) to embed deep intelligence at the far edge. TinyML (Tiny Machine Learning) has enabled the deployment of ML models for embedded vision on extremely lean edge hardware, bringing the power of IoT and ML together. However, TinyML powered embedded vision applications are still in a nascent stage, and they are just starting to scale to widespread real-world IoT deployment. To harness the true potential of IoT and ML, it is necessary to provide product developers with robust, easy-to-use software engineering (SE) frameworks and best practices that are customized for the unique challenges faced in TinyML engineering. Through this systematic literature review, we aggregated the key challenges reported by TinyML developers and identified state-of-art SE approaches in large-scale Computer Vision, Machine Learning, and Embedded Systems that can help address key challenges in TinyML based IoT embedded vision. In summary, our study draws synergies between SE expertise that embedded systems developers and ML developers have independently developed to help address the unique challenges in the engineering of TinyML based IoT embedded vision.},
booktitle = {Proceedings of the 4th International Workshop on Software Engineering Research and Practice for the IoT},
pages = {33–40},
numpages = {8},
keywords = {IoT, TinyML, embedded vision, software engineering, systematic literature review},
location = {Pittsburgh, Pennsylvania},
series = {SERP4IoT '22}
}

@article{10.1145/3561056,
author = {Cheng, Xia and Sha, Mo},
title = {Autonomous Traffic-Aware Scheduling for Industrial Wireless Sensor-Actuator Networks},
year = {2023},
issue_date = {May 2023},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {19},
number = {2},
issn = {1550-4859},
url = {https://doi.org/10.1145/3561056},
doi = {10.1145/3561056},
abstract = {Recent years have witnessed rapid adoption of low-power Wireless Sensor-Actuator Networks (WSANs) in process industries. To meet the critical demand for reliable and real-time communication in harsh industrial environments, the industrial WSAN standards make a set of specific design choices, such as employing the Time-Slotted Channel Hopping (TSCH) technique. Such design choices distinguish industrial WSANs from traditional Wireless Sensor Networks, which were designed for best-effort services. Recently, there has been increasing interest in developing new methods to enable autonomous transmission scheduling for industrial WSANs that run TSCH and the Routing Protocol for Low-Power and Lossy Networks (RPL). Our study shows that the current approaches fail to consider the traffic loads of different devices when assigning time slots and channels, which significantly compromises network performance when facing high data rates. In this article, we introduce a novel Autonomous Traffic-Aware transmission scheduling method for industrial WSANs. The device that runs ATRIA can detect its traffic load based on its local routing information and then schedule its transmissions accordingly without the need to exchange information with neighboring devices. Experimental results show that ATRIA provides significantly higher end-to-end network reliability and lower end-to-end latency without introducing additional overhead compared with a state-of-the-art baseline.},
journal = {ACM Trans. Sen. Netw.},
month = feb,
articleno = {38},
numpages = {25},
keywords = {Industrial wireless sensor-actuator networks, IEEE 802.15.4, transmission scheduling, TSCH, RPL}
}

@inproceedings{10.1145/3566097.3567938,
author = {Ma, Tianliang and Deng, Zhihui and Shao, Leilai},
title = {AutoFlex: Unified Evaluation and Design Framework for Flexible Hybrid Electronics},
year = {2023},
isbn = {9781450397834},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3566097.3567938},
doi = {10.1145/3566097.3567938},
abstract = {Flexible hybrid electronics (FHE), integrating high performance silicon chips with multi-functional sensors and actuators on flexible substrates, can be intimately attached onto irregular surfaces without compromising their functionalities, thus enabling more innovations in healthcare, internet of things (IoTs) and various human-machine interfaces (HMIs). Recent developments on compact models and process design kits (PDKs) of flexible electronics have made designs of small to medium flexible circuits feasible. However, the absence of a unified model and comprehensive evaluation benchmarks for flexible electronics makes it infeasible for a designer to fairly compare different flexible technologies and to explore potential design options for a heterogeneous FHE design. In this paper, we present AutoFlex, a unified evaluation and design framework for flexible hybrid electronics, where device parameters can be extracted automatically and performance can be evaluated comprehensively from device levels, digital blocks to large-scale digital circuits. Moreover, a ubiquitous FHE sensor acquisition system, including a flexible multi-functional sensor array, scan drivers, amplifiers and a silicon based analog-to-digital converter (ADC), is developed to reveal the design challenges of a representative FHE system.},
booktitle = {Proceedings of the 28th Asia and South Pacific Design Automation Conference},
pages = {757–762},
numpages = {6},
keywords = {design automation, flexible electronics, flexible hybrid electronics, hardware/software co-design, heterogeneous system design},
location = {Tokyo, Japan},
series = {ASPDAC '23}
}

@inproceedings{10.1145/3559009.3569675,
author = {Durvasula, Sankeerth and Kiguru, Raymond and Mathur, Samarth and Xu, Jenny and Lin, Jimmy and Vijaykumar, Nandita},
title = {VoxelCache: Accelerating Online Mapping in Robotics and 3D Reconstruction Tasks},
year = {2023},
isbn = {9781450398688},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3559009.3569675},
doi = {10.1145/3559009.3569675},
abstract = {Real-time 3D mapping is a critical component in many important applications today including robotics, AR/VR, and 3D visualization. 3D mapping involves continuously fusing depth maps obtained from depth sensors in phones, robots, and autonomous vehicles into a single 3D representative model of the scene. Many important applications, e.g., global path planning and trajectory generation in micro aerial vehicles, require the construction of large maps at high resolutions. In this work, we identify mapping, i.e., construction and updates of 3D maps to be a critical bottleneck in these applications. The memory required and access times of these maps limit the size of the environment and the resolution with which the environment can be feasibly mapped, especially in resource constrained environments such as autonomous robot platforms and portable devices. To address this challenge, we propose VoxelCache: a hardware-software technique to accelerate map data access times in 3D mapping applications. We observe that mapping applications typically access voxels in the map that are spatially co-located to each other. We leverage this temporal locality in voxel accesses to cache indices to blocks of voxels to enable quick lookup and avoid expensive access times. We evaluate VoxelCache on popularly used mapping and reconstruction applications on both GPUs and CPUs. We demonstrate an average speedup of 1.47X (up to 1.66X) and 1.79X (up to 1.91X) on CPUs and GPUs respectively.},
booktitle = {Proceedings of the International Conference on Parallel Architectures and Compilation Techniques},
pages = {239–251},
numpages = {13},
keywords = {SLAM, caching, hardware acceleration, mapping, reconstruction},
location = {Chicago, Illinois},
series = {PACT '22}
}

