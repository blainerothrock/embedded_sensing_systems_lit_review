@inproceedings{10.1145/3649902.3656354,
author = {Crafa, Daniele Maria and Di Giacomo, Susanna and Natali, Dario and Fiorini, Carlo Ettore and Carminati, Marco},
title = {Towards Invisible Eye Tracking with Lens-Coupled Lateral Photodetectors},
year = {2024},
isbn = {9798400706073},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3649902.3656354},
doi = {10.1145/3649902.3656354},
abstract = {A novel low-power and easy to integrate sensing configuration for wearable eye tracking is presented. Within the context of infrared oculography based on individual photosensors, we proposed to couple a set of photodetectors to the lateral edges of a standard lens, acting as waveguide for the IR light, instead of directing them towards the eyeball. This allows to embed the detectors in the rim, thus being fully hidden in the eyewear, invisible to the user and robustly integrated with the glasses. A preliminary setup with four photodiodes whose signals are processed by an agile two-layer neural network was realized and characterized. Here we demonstrate both experimentally and by means of simulations the feasibility of this patent-pending approach. Detected maps of light patterns respond to different impinging light orientations. An angular resolution of about 5° is achieved with only 4 individual photodetectors coupled to a thick rectangular glass lens. A larger number of detectors would provide better resolutions. The parameters of ray-tracing simulations were first adjusted to match the experimental data from a simplified geometry. Then, simulations were used to estimate the expected signals with an eye model, paving the way to a promising outlook. The combination of hardware and software solutions here presented aims at addressing the trade-off between power consumption and angular resolution in the estimation of the direction of gaze which is crucial for pervasive eye tracking.},
booktitle = {Proceedings of the 2024 Symposium on Eye Tracking Research and Applications},
articleno = {90},
numpages = {7},
keywords = {Pervasive eye tracking, infrared oculography, neural networks, optoelectronic sensing.},
location = {Glasgow, United Kingdom},
series = {ETRA '24}
}

@inproceedings{10.1145/3643832.3661863,
author = {Fu, Yongjian and Zhang, Yongzhao and Lu, Yu and Qiu, Lili and Chen, Yi-Chao and Wang, Yezhou and Wang, Mei and Li, Yijie and Ren, Ju and Zhang, Yaoxue},
title = {Adaptive Metasurface-Based Acoustic Imaging using Joint Optimization},
year = {2024},
isbn = {9798400705816},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3643832.3661863},
doi = {10.1145/3643832.3661863},
abstract = {Acoustic imaging is attractive due to its ability to work under occlusion, different lighting conditions, and privacy-sensitive environments. Existing acoustic imaging methods require large transceiver arrays or device movement, which makes it challenging to use in many scenarios. In this paper, we develop a novel acoustic imaging system for low-cost devices with few speakers and microphones without any device movement. To achieve this goal, we leverage a 3D-printed passive acoustic metasurface to significantly enhance the diversity of the measurement data, thereby improving the imaging quality. Specifically, we jointly design the transmission signal, transceivers' beamforming weights, metasurface, and imaging algorithm to minimize the imaging reconstruction error in an end-to-end manner. We further develop a scheme to dynamically adapt the imaging resolution based on the distance to the target. We implement a system prototype. Using extensive experiments, we show that our system yields high-quality images across a wide range of scenarios.},
booktitle = {Proceedings of the 22nd Annual International Conference on Mobile Systems, Applications and Services},
pages = {492–504},
numpages = {13},
keywords = {acoustic imaging, compressive sensing, joint optimization},
location = {Minato-ku, Tokyo, Japan},
series = {MOBISYS '24}
}

@inproceedings{10.1145/3643832.3661860,
author = {Duan, Di and Sun, Zehua and Ni, Tao and Li, Shuaicheng and Jia, Xiaohua and Xu, Weitao and Li, Tianxing},
title = {F2Key: Dynamically Converting Your Face into a Private Key Based on COTS Headphones for Reliable Voice Interaction},
year = {2024},
isbn = {9798400705816},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3643832.3661860},
doi = {10.1145/3643832.3661860},
abstract = {In this paper, we proposed F2Key, the first earable physical security system based on commercial off-the-shelf headphones. F2Key enables impactful applications, such as enhancing voiceprint-based authentication systems, reliable voice assistants, audio deepfake defense, and the legal validity of artifacts. The key idea of F2Key is to establish a stable acoustic sensing field across the user's face and embed the user's facial structures and articulatory habits into a user-specific generative model that serves as a private key. The private key can decrypt the Channel Impulse Response (CIR) profiles provided by the acoustic sensing field into an inferred spectrogram that can match the real one calculated from the corresponding speech, provided that the user's CIR-spectrogram mapping relationship is consistent with the one embedded in the generative model. Extensive experiments demonstrate that F2Key resists 99.9\%, 96.4\%, and 95.3\% of speech replay attacks, mimicry attacks, and hybrid attacks, respectively. We discussed and evaluated F2Key from different perspectives, such as the health consideration and identical twins study, to show the practicality and reliability.},
booktitle = {Proceedings of the 22nd Annual International Conference on Mobile Systems, Applications and Services},
pages = {127–140},
numpages = {14},
keywords = {acoustic sensing, deepfake detection, earable sensing, physical security system},
location = {Minato-ku, Tokyo, Japan},
series = {MOBISYS '24}
}

@inproceedings{10.1145/3631701.3631702,
author = {Ahmed, Muhammad Rausiddin and Myo, Thirein and Aseeri, Mohammed A and Marhaban, Mohammad Hamiruce B. and Al Baroomi, Badar and Kaiser, M Shamin},
title = {DBSCAN-Based Malicious Node Detection to Secure Wireless Sensor Networks},
year = {2024},
isbn = {9798400707537},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3631701.3631702},
doi = {10.1145/3631701.3631702},
abstract = {Wireless sensor networks (WSNs) is application driven technology. Technology is becoming increasingly popular among scientists and industrialists. Data is collected from various environmental phenomena using cost-effective and versatile sensor nodes in an unsupervised manner. Because WSNs are distributed and sensor nodes have specific characteristics, they are susceptible to different types of attacks. To ensure that WSNs work effectively, securing the network is important. Detecting malicious nodes and implementing effective mechanisms to secure WSNs allow accurate data collection for various applications. The DBSCAN algorithm has been applied in this research to detect malicious nodes and secure WSNs. We created WSN environments with varying numbers of nodes through Python simulations, ranging from 50 to 500. The simulations were based on real-world hypothetical data, including temperature and humidity readings from Canberra, Australia, derived from real-world measurements to aid in the simulations. The results of this study showed promising performance, with the detection accuracy reaching nearly 95\% for WSNs with 500 nodes and 100\% for smaller networks. Developing hybrid approaches in future work will enhance detection accuracy in large networks. In order for WSNs to be able to provide secure and reliable operation, it is vital that malicious nodes can be detected during their operation as effectively as possible, across a wide range of applications.},
booktitle = {Proceedings of the 2023 5th International Conference on Big Data Engineering and Technology},
pages = {1–7},
numpages = {7},
location = {Singapore, Singapore},
series = {BDET '23}
}

@inproceedings{10.1145/3643832.3661893,
author = {Imran, Abdullah and Bianchi, Antonio},
title = {Automated Detection of Cryptographic Inconsistencies in Android’s Keymaster Implementations},
year = {2024},
isbn = {9798400705816},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3643832.3661893},
doi = {10.1145/3643832.3661893},
abstract = {Android smartphones use a dedicated component, Keymaster, to perform all their cryptographic, security-sensitive operations (e.g., storing cryptographic material and performing signing operations). While all Android Keymaster implementations need to expose a specific interface, their internals are hard to analyze, since their source code is generally not available. Moreover, Android Keymasters' code normally runs in a Trusted Execution Environment (TEE), where typical debugging functionality is not available. For these reasons, Keymaster implementations cannot be analyzed using white-box or gray-box automated approaches.To address this issue, in this paper, we design, implement, and evaluate AKF (Android Keymaster Fuzzer), a device-agnostic, differential, black-box fuzzer. AKF uses a dynamic grammar to test, in parallel, multiple Keymaster implementations, comparing their behavior, looking for inconsistencies. AKF can operate on different Keymaster implementations at the same time, including Keymaster implementations running on different devices and in different TEEs (e.g., ARM TrustZone and Google's Titan-M).We evaluated AKF by running it on 6 different Android devices, where it correctly detected 87 implementation inconsistencies that are a cause for concern in terms of both security and usability of cryptographic operations, including a previously-known encryption bug affecting the Titan-M chip (CVE-2019-9465).},
booktitle = {Proceedings of the 22nd Annual International Conference on Mobile Systems, Applications and Services},
pages = {385–397},
numpages = {13},
keywords = {Android, keymaster, TEE, ARM trustzone, Titan-M, StrongBox},
location = {Minato-ku, Tokyo, Japan},
series = {MOBISYS '24}
}

@inproceedings{10.1145/3661813.3661817,
author = {Visotto, Matteo and Mottola, Luca},
title = {Enabling Location-aware Operation in Decentralized IoT Communications},
year = {2024},
isbn = {9798400706592},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3661813.3661817},
doi = {10.1145/3661813.3661817},
abstract = {We present an efficient design to enable location-aware operation in decentralized IoT communications. Large-scale IoT systems represent the backbone of a smart city functioning, allowing pervasive environmental sensing across devices and networks. However, existing IoT communication systems are largely driven by data types and miss out on embracing data location, which is fundamental in environment sensing. To address this issue, we demonstrate it is possible to efficiently embed a notion of location within the Zenoh protocol. We make it possible to steer message routing based on both data type and location, yet without altering the existing routing core and message forwarding, unlike most existing solutions. We also present three encoding techniques for location data, each of them representing a different trade-off between expressiveness and performance overhead. Our evaluation uses a virtualized environment and real-world packet traces of heterogeneous networks. We show, for example, that our design decreases the average message latency by more than 50\% when routing data also based on location, while increasing throughput, compared to two different baselines.},
booktitle = {Proceedings of the 2nd Workshop on Advances in Environmental Sensing Systems for Smart Cities},
pages = {13–18},
numpages = {6},
keywords = {location-awareness, IoT, pub/sub, req/resp, protocol, zenoh},
location = {Minato-ku, Tokyo, Japan},
series = {EnvSys '24}
}

@inproceedings{10.1145/3661813.3661816,
author = {Routh, Tushar K and Saoda, Nurani and Govinda Rajan, Viswajith and Campbell, Bradford},
title = {Data Efficient Sensing for Daylong Light Exposure Analysis},
year = {2024},
isbn = {9798400706592},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3661813.3661816},
doi = {10.1145/3661813.3661816},
abstract = {It's important to gather information regarding our daylong light exposure to understand how different artificial and natural light sources throughout the day physiologically and psychologically affect us. However, continuous transmission of surrounding lighting environment parameters for classifying the source is energy-expensive. Moreover, when such sensors need to function within strict energy constraints, an inefficient way of operation can significantly reduce their lifespan. In this paper, we argue that instead of naively transmitting every sensed value, indoor light sensors should recognize the importance of sample points to achieve reasonable detection accuracy and only responding to particular events of interest. However, identifying the event is challenging, as natural variations and real-world scenarios can often produce fluctuations resembling those of interest. To enhance the intelligence of indoor light sensors for accurately identifying relevant events and optimizing data usage, we first develop an algorithm to find important events in long recordings. Then we prioritize samples within timeframe and implement lossless compression methods to minimize the amount of information necessary for subsequent offline classification. Following the implementation of these methods, we examine their effectiveness in realistic testbed. Based on the result, reduced raw RGB information by up to 97.94\% in the testbed scenario without a significant decline in classification accuracy.},
booktitle = {Proceedings of the 2nd Workshop on Advances in Environmental Sensing Systems for Smart Cities},
pages = {7–12},
numpages = {6},
keywords = {smart light sensing, data efficient sensing},
location = {Minato-ku, Tokyo, Japan},
series = {EnvSys '24}
}

@inproceedings{10.1145/3660395.3660435,
author = {Li, Zhongyue and Zhang, Yanan and Jia, Xianfeng and Pan, Chenglong and Liu, Pingyi and Lu, Xu},
title = {Research on the security of automotive domain controller systems based on trusted execution environment},
year = {2024},
isbn = {9798400716362},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3660395.3660435},
doi = {10.1145/3660395.3660435},
abstract = {With the continuous development of automotive technology, the security issues of automotive systems have become increasingly prominent. Traditional automotive systems have many potential security risks, such as remote attacks, vehicle data leakage, and unauthorized access. To address these issues, researchers and car manufacturers have started focusing on the application of trusted execution environments. A trusted execution environment is a secure computing environment that provides hardware and software-level security protection, safeguarding sensitive data and performing critical tasks. Introducing trusted execution environments into automotive domain controllers can effectively enhance the security and reliability of the system. This study aims to explore the security of automotive domain controller systems based on trusted execution environments. We will investigate existing trusted execution environment technologies and analyze their application value in the automotive field, then we will explore the impact of trusted execution environments on the security of automotive domain controller systems as well. By conducting in-depth research on the application of trusted execution environments in the automotive field, we can provide guidance and recommendations to car manufacturers and researchers on how to improve the security of automotive domain controller systems. The ultimate goal is to build more security and more reliable automotive systems, protecting user privacy and data security.},
booktitle = {Proceedings of the 2023 3rd Guangdong-Hong Kong-Macao Greater Bay Area Artificial Intelligence and Big Data Forum},
pages = {229–235},
numpages = {7},
location = {Guangzhou, China},
series = {AIBDF '23}
}

@inproceedings{10.1145/3661638.3661692,
author = {Bao, Yichen and Wei, Lifei and Han, Dezhi},
title = {Efficient and Secure Multi-Party Private Set Operation Protocol Suitable for IoT Devices},
year = {2024},
isbn = {9798400716966},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3661638.3661692},
doi = {10.1145/3661638.3661692},
abstract = {In the IoT environment, a large amount of sensitive data are transmitted and processed by IoT devices, such as personal identity, location data and health data. To protect these sensitive data from leakage, multi-party private set operation (MPSO) has become one of the important multi-party secure computing techniques in the IoT domain, which allows the parties with private sets to perform secure intersection and union operations respectively without disclosing private information other than the results. It allows the exchange and share of IoT data effectively. Most of them use homomorphic encryption with expensive computational overhead or oblivious transfer with expensive communication costs, which can affect the performance of practical applications, especially for the IoT devices. A new multi-party multi-query set membership testing component is designed to allow multiple participants to compute the differences of their own datasets. In addition, a multi-party private set operation protocol is constructed based on this component to achieve minimal overhead for communication in a star network topology, and to designate the central party to obtain the final computation results. The intersection or union results is computed while obtaining the cardinality of the set intersection without revealing any additional information. The security of the constructed protocol is proved under a semi-honest model. The proposed framework is an efficient extension of the existing work mqRPMT. The experiment is using the elliptic curve curve25519 on ECDH key negotiation. In the multi-party private set intersection protocol, the proposed protocol has fewer communication rounds and higher computational efficiency than those of the existing work for small sets. In the multi-party private set union protocol, the proposed protocol runs in O(nlogn) time complexity and constant communication rounds, which is better than the existing work.},
booktitle = {Proceedings of the 2023 International Conference on Artificial Intelligence, Systems and Network Security},
pages = {283–290},
numpages = {8},
location = {Mianyang, China},
series = {AISNS '23}
}

@inproceedings{10.1145/3660395.3660397,
author = {Shi, Yao},
title = {Haptic Interaction and Force Feedback in Metaverse},
year = {2024},
isbn = {9798400716362},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3660395.3660397},
doi = {10.1145/3660395.3660397},
abstract = {In recent years, the emerging concept of "Metaverse" has attracted strong attention as soon as it was put forward. The metaverse contains technological achievements such as the information revolution, artificial intelligence revolution, virtual reality (VR) and augmented reality (AR), aiming to build a digital information universe parallel to the real world, in which people can reproduce social dynamics in real life. VR and AR technologies are the key to build the metaverse. Enhancing the user's immersion and simulating the user's feelings in the real world is the core of the metaverse. Realizing instant, real-life force feedback to users in the metaverse and enhancing their authenticity has become a concerning research topic in recent years. But so far, there is no haptic wearable devices that can be mass-produced and sold on the market. This paper discusses the technology of realizing haptic interaction and force feedback in the metaverse. Various research to realize haptic sensation, and their applications in communication, VR and AR, as well as the relevant research and progress are reviewed. The related challenges and technical problems of haptic interaction and force feedback technology are discussed.},
booktitle = {Proceedings of the 2023 3rd Guangdong-Hong Kong-Macao Greater Bay Area Artificial Intelligence and Big Data Forum},
pages = {5–9},
numpages = {5},
location = {Guangzhou, China},
series = {AIBDF '23}
}

@inproceedings{10.1145/3660043.3660218,
author = {Song, Wei and Bai, Yulong and Jin, Zean and Qin, Haoyu},
title = {Design of a Virtual Reality-Based Open-Source Hardware Platform for Virtual Experimentation},
year = {2024},
isbn = {9798400716157},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3660043.3660218},
doi = {10.1145/3660043.3660218},
abstract = {In the current wave of digital education, the convergence of Virtual Reality (VR) technology with open-source hardware presents revolutionary opportunities for experimental teaching. This study designs and implements an open-source hardware virtual experiment platform based on the Arduino Uno microcontroller. Utilizing the Unity3D engine and other auxiliary software tools, a desktop virtual experiment system has been constructed. This system encompasses 12 basic experiments ranging from simple circuit design to complex programming tasks and integrates two complex case scenarios: Smart Farming and Intelligent Transportation Systems. By simulating intelligent systems, this platform offers students an immersive learning environment with multi-sensory interaction, significantly boosting their enthusiasm and engagement. Furthermore, the platform's risk-free experimental environment and use of low-cost hardware render it an economically efficient teaching tool, particularly suitable for budget-constrained educational settings. The outcomes of this study highlight the immense potential of VR technology and open-source hardware in enhancing educational quality and promoting comprehensive student development, offering new perspectives for the evolution of educational technology.},
booktitle = {Proceedings of the 2023 International Conference on Information Education and Artificial Intelligence},
pages = {979–984},
numpages = {6},
location = {Xiamen, China},
series = {ICIEAI '23}
}

@inproceedings{10.1145/3651781.3651825,
author = {Wardana, Aulia Arif and Sukarno, Parman and Salman, Muhammad},
title = {Collaborative Botnet Detection in Heterogeneous Devices of Internet of Things using Federated Deep Learning},
year = {2024},
isbn = {9798400708329},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3651781.3651825},
doi = {10.1145/3651781.3651825},
abstract = {This research introduces a pioneering approach, termed Hierarchical Collaborative Botnet Detection, leveraging Federated Deep Learning to address the escalating security concerns within the Internet of Things (IoT) ecosystems characterized by heterogeneous devices. The proposed framework establishes a hierarchical structure facilitating efficient collaboration among devices at different levels, enabling scalable and distributed botnet detection. Federated Deep Learning ensures model training without centralizing sensitive data, respecting privacy constraints inherent in IoT environments. The methodology involves the development of a collaborative learning model capable of analyzing diverse data sources across the IoT landscape, utilizing the N-BaIoT dataset for comprehensive evaluation. Comprehensive simulations and experiments, conducted with the N-BaIoT dataset, showcase the robustness and efficiency of the proposed approach in detecting botnet activities across diverse IoT devices. Based on experimental results, the proposed method can identify botnets with an average accuracy of 98,97, precision of 98,75, recall of 99,41, and an F1-score of 99,11. The hierarchical and federated nature of the model contributes to a more resilient and scalable botnet detection system for large-scale IoT deployments, laying the foundation for a secure and collaborative IoT landscape in the face of evolving cyber threats.},
booktitle = {Proceedings of the 2024 13th International Conference on Software and Computer Applications},
pages = {287–291},
numpages = {5},
keywords = {IoT, deep learning, federated learning, heterogeneous devices, intrusion detection},
location = {Bali Island, Indonesia},
series = {ICSCA '24}
}

@inproceedings{10.1145/3651781.3651823,
author = {Truong, Tuyen Phong and Tran, Khai Quang and Diep, Dang Hai and Nguyen, Van-Muot},
title = {Design of a Blockchain-based IoT Data Storage and Sharing System},
year = {2024},
isbn = {9798400708329},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3651781.3651823},
doi = {10.1145/3651781.3651823},
abstract = {The Internet of Things (IoT) has been applied in many fields of science, technology, economy, and society, including agriculture, aquaculture, the environment, and smart city management. However, storing and sharing data in IoT applications face many challenges in ensuring data integrity and security. Because IoT data collection devices in a centralized model are frequently limited in their security capabilities and are vulnerable to attacks, blockchain technology is rapidly developing many key features to improve data security and sharing. This study aims to employ blockchain technology to enhance the security and data integrity of IoT applications. The system used a private blockchain network built on the GoQuorum platform. The Solidity programming language was used to develop the smart contracts in the blockchain network. Users interact with the smart contract via a web interface to create processes for collecting data from gateways in the sensor network. This blockchain-based system enhances the security of stored data queries and ensures the integrity of the shared data.},
booktitle = {Proceedings of the 2024 13th International Conference on Software and Computer Applications},
pages = {268–274},
numpages = {7},
keywords = {Internet of Things, blockchain, data storage and sharing, smart contract},
location = {Bali Island, Indonesia},
series = {ICSCA '24}
}

@inproceedings{10.1145/3651781.3651839,
author = {S B, Bore Gowda},
title = {Uneven clustering: An approach to maximize the lifetime of sensor nodes},
year = {2024},
isbn = {9798400708329},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3651781.3651839},
doi = {10.1145/3651781.3651839},
abstract = {Wireless sensor networks (WSNs) are made up of thousands of tiny electronic devices with the ability to monitor and communicate with one another. These tiny electronics devices are called as nodes normally placed in an operational environment with the purpose of sensing and gathering environmental data, like pollution levels, humidity, pressure, and temperature etc. The collected data can be sent to central place called base station or sink for further processing. The wireless sensor networks are characterised by certain constraints such as battery energy, storage space and computation ability due to the employment of midrange microprocessors/microcontrollers. The majority of the application involves the sensor nodes being placed haphazardly inside the targeted area, necessitating unsupervised operations. The typical design issue in the operation of WSN is the self-organization, since the WSNs are used in difficulty terrains in which human intervention is not possible. The basic function of sensor nodes is to sense, collect, process and forward the data to base station. These processes must be designed in such away that the energy consumption by the node must be very less, since the energy in the sensor node is limited. The majority of routing protocols work to extend the life of networks by lowering power usage. The literature review provides an evident that the clustering WSN for data forwarding is best way to maximize the lifetime of the networks. The purpose of this research paper is to maximize the lifetime of wireless nodes by proposing an energy-efficient uneven cluster-based routing protocol (UCR). In this protocol, the uneven clusters are created by dividing the network in such way that, the cluster size increases as we move away from the base station. The primary objective of the uneven clustering is that the load in terms of energy consumption is distributed almost uniformly among cluster heads (CHs). The proposed UCR take care of hot spot issues well with uneven cluster size. This approach pays significantly towards network longevity.},
booktitle = {Proceedings of the 2024 13th International Conference on Software and Computer Applications},
pages = {379–384},
numpages = {6},
keywords = {Energy, WSN, efficiency, lifespan, nodes, routing, uneven clusters},
location = {Bali Island, Indonesia},
series = {ICSCA '24}
}

@article{10.1145/3654941,
author = {Kozar, Anastasiia and Del Monte, Bonaventura and Zeuch, Steffen and Markl, Volker},
title = {Fault Tolerance Placement in the Internet of Things},
year = {2024},
issue_date = {June 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {2},
number = {3},
url = {https://doi.org/10.1145/3654941},
doi = {10.1145/3654941},
abstract = {Today's IoT applications exploit the capabilities of three different computation environments: sensors, edge, and cloud. Ensuring fault tolerance at the edge level presents unique challenges due to complex network hierarchies and the presence of resource-constrained computing devices. In contrast to the Cloud, the Edge lacks high availability standards and a persistent upstream backup. To ensure reliability, fault tolerance mechanisms have to be deployed on the edge devices along with processing operators competing for available resources. However, existing operator placement strategies are not aware of fault tolerance resource requirements, and existing fault tolerance approaches are not aware of available resources. This miscommunication in resource-constrained environments like the Edge leads to underprovisioning and failures. In this paper, we present a resource-aware fault-tolerance approach that takes the unique characteristics of the Edge into account to provide reliable stream processing. To this end, we model fault tolerance as an operator placement problem that uses multi-objective optimization to decide where to backup data. As opposed to existing approaches that treat operator placement and fault tolerance as two separate steps, we combine them and showcase that this is especially important for low-end edge devices. Overall, our approach effectively mitigates potential failures and outperforms state-of-the-art fault tolerance approaches by up to an order of magnitude in throughput.},
journal = {Proc. ACM Manag. Data},
month = may,
articleno = {138},
numpages = {29},
keywords = {data management, fault tolerance, stream processing}
}

@inproceedings{10.1145/3660043.3660215,
author = {Wang, Xueqin and Song, Yukun and Chen, Shiqiang},
title = {Construction and Assessment Analysis of Virtual Simulation Online Teaching Course for Children with Sensory Integration Disorder},
year = {2024},
isbn = {9798400716157},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3660043.3660215},
doi = {10.1145/3660043.3660215},
abstract = {Objective: With the development of virtual simulation online teaching, more and more courses have been built into virtual simulation courses. In order to improve course construction and assessment, this study analyzed the course materials and assessment models of virtual simulation online teaching for children with sensory integration disorders. Method: 60 students in 2020 physical education were selected as the experimental subjects, and the course data was analyzed using the calculation method of assessment scores and Pearson correlation. Result: (1) Design the steps, system architecture diagram, and operating environment of virtual simulation online learning for children with sensory integration disorders; (2) The experimental process has the highest evaluation score in the assessment project, and also accounts for a high proportion in the course evaluation. Secondly, the evaluation results have higher scores and evaluation values, while the evaluation value of the experimental preview is not high. (3) The scores of experimental preparation and experimental process are moderately correlated with the total score of the course, while the scores of evaluation results are highly correlated with the total score of the course. Conclusion: By analyzing the structure and assessment scores of virtual simulation experiment courses, theoretical and practical support is provided for the development of virtual simulation online courses, enriching the teaching mode of virtual simulation experiments.},
booktitle = {Proceedings of the 2023 International Conference on Information Education and Artificial Intelligence},
pages = {964–968},
numpages = {5},
location = {Xiamen, China},
series = {ICIEAI '23}
}

@inproceedings{10.1145/3651781.3651789,
author = {Yokoyama, Akihiko and Moriguchi, Sosuke and Watanabe, Takuo},
title = {Switching Mechanism for Update Timing of Time-Varying Values in an FRP Language for Small-Scale Embedded Systems},
year = {2024},
isbn = {9798400708329},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3651781.3651789},
doi = {10.1145/3651781.3651789},
abstract = {Emfrp, a functional reactive programming (FRP) language for small-scale embedded systems, is a DSL designed for execution in resource-constrained environments. The execution model of Emfrp provides a reactive behavior of the system through repeated actions such as waiting for inputs from sensors, updating all time-varying values, and outputting them to the actuators. Such polling-based execution consumes unnecessary energy due to frequent update processing. For this reason, the extended language EvEmfrp was proposed to reduce unnecessary update processing and improve energy consumption. EvEmfrp statically determines and schedules the update period of the whole system by annotating the timing of the time-varying value updates and the input interrupts. Since time-varying value updates are performed at periodic timing, the system is put into sleep mode when no update processing is required, thereby saving energy. However, because the timing annotations and the update intervals are set statically, executing a program that updates a specified time-varying value after a fixed time starting from an interrupt signal without unnecessary updates is impossible. This causes frequent wake-up from sleep mode and prevents power saving. We propose a mechanism for extending timing annotations and dynamically changing the update intervals to solve this problem. We also show the usefulness of the proposed mechanism through an example of debouncing for button presses.},
booktitle = {Proceedings of the 2024 13th International Conference on Software and Computer Applications},
pages = {45–54},
numpages = {10},
keywords = {embedded systems, functional reactive programming, power consumption},
location = {Bali Island, Indonesia},
series = {ICSCA '24}
}

@inproceedings{10.1145/3653924.3653925,
author = {Kang, Byungseok},
title = {Public cloud-base big alarm data analytics platform for large-scale physical security},
year = {2024},
isbn = {9798400716935},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3653924.3653925},
doi = {10.1145/3653924.3653925},
abstract = {Along with the development of ICT technology, physical and building security services are also evolved. State-of-the-art sensors detect the slightest changes in movement, heat, smoke, light, vibration, etc. Most of the on-premise servers were used to provide building care services in the existing village or small city-scale areas. In this environment, we were able to provide reliable services to customers without any problems. However, there is a problem in providing services for large cities or the entire country. There is a limit to storing and analyzing a big amount of alarm data in the on-premise server. Furthermore, the detection mechanism determines actual intrusion based on pre-defined rule without data analytics. This mechanism has high false alarm ratio and error rate. To solve this problem, this paper introduces a public cloud-based platform that provides security services by collecting, storing, and analyzing alarm data simultaneously generated across the entire country. The proposed platform improves the accuracy of false intrusion determination through machine learning in public cloud. Compared to previous rule-base algorithm, our model improves false alarm detection ratio around 20\%. It uses both structured and unstructured data sets to determine false alarms. This platform supports the security guard (commander) by visualizing the analysis results using Microsoft Power BI service. In addition, we provide statistical analysis results between alarm data and related weather conditions.},
booktitle = {Proceedings of the 2024 7th International Conference on Data Storage and Data Engineering},
pages = {1–5},
numpages = {5},
keywords = {Big data, Cloud computing, alarm service, physical security, security alarm, security service, smart sensors},
location = {Shanghai, China},
series = {DSDE '24}
}

@inproceedings{10.1145/3636534.3649358,
author = {Ren, Yidong and Sun, Wei and Du, Jialuo and Zeng, Huaili and Dong, Younsuk and Zhang, Mi and Chen, Shigang and Liu, Yunhao and Li, Tianxing and Cao, Zhichao},
title = {Demeter: Reliable Cross-soil LPWAN with Low-cost Signal Polarization Alignment},
year = {2024},
isbn = {9798400704895},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3636534.3649358},
doi = {10.1145/3636534.3649358},
abstract = {Soil monitoring plays an essential role in agricultural systems. Rather than deploying sensors' antennas above the ground, burying them in the soil is an attractive way to retain a non-intrusive aboveground space. Low Power Wide-Area Network (LPWAN) has shown its long-distance and low-power features for aboveground Internet-of-Things (IoT) communication, presenting a potential of extending to underground cross-soil communication over a wide area, which however has not been investigated before. The variation of soil conditions brings significant signal polarization misalignment, degrading communication reliability. In this paper, we propose Demeter, a low-cost low-power programmable antenna design to keep reliable cross-soil communication automatically. First, we propose a hardware architecture to enable polarization adjustment on commercial-off-the-shelf (COTS) single-RF-chain LoRa radio. Moreover, we develop a low-power programmable circuit to obtain polarization adjustment. We further design an energy-efficient heuristic calibration algorithm and an adaptive calibration scheduling method to keep signal polarization alignment automatically. We implement Demeter with a customized PCB circuit and COTS devices. Then, we evaluate its performance in various soil types and environmental conditions. The results show that Demeter can achieve up to 11.6 dB SNR gain indoors and 9.94 dB outdoors, 4\texttimes{} horizontal communication distance, at least 20 cm deeper underground deployment, and up to 82\% energy consumption reduction per day compared with the standard LoRa.},
booktitle = {Proceedings of the 30th Annual International Conference on Mobile Computing and Networking},
pages = {230–245},
numpages = {16},
keywords = {agricultural IoT, LPWAN, cross-soil communication},
location = {Washington D.C., DC, USA},
series = {ACM MobiCom '24}
}

@inproceedings{10.1145/3636534.3649370,
author = {Ouyang, Xiaomin and Shuai, Xian and Li, Yang and Pan, Li and Zhang, Xifan and Fu, Heming and Cheng, Sitong and Wang, Xinyan and Cao, Shihua and Xin, Jiang and Mok, Hazel and Yan, Zhenyu and Yu, Doris Sau Fung and Kwok, Timothy and Xing, Guoliang},
title = {ADMarker: A Multi-Modal Federated Learning System for Monitoring Digital Biomarkers of Alzheimer's Disease},
year = {2024},
isbn = {9798400704895},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3636534.3649370},
doi = {10.1145/3636534.3649370},
abstract = {Alzheimer's Disease (AD) and related dementia are a growing global health challenge due to the aging population. In this paper, we present ADMarker, the first end-to-end system that integrates multi-modal sensors and new federated learning algorithms for detecting multidimensional AD digital biomarkers in natural living environments. ADMarker features a novel three-stage multi-modal federated learning architecture that can accurately detect digital biomarkers in a privacy-preserving manner. Our approach collectively addresses several major real-world challenges, such as limited data labels, data heterogeneity, and limited computing resources. We built a compact multi-modality hardware system and deployed it in a four-week clinical trial involving 91 elderly participants. The results indicate that ADMarker can accurately detect a comprehensive set of digital biomarkers with up to 93.8\% accuracy and identify early AD with an average of 88.9\% accuracy. ADMarker offers a new platform that can allow AD clinicians to characterize and track the complex correlation between multidimensional interpretable digital biomarkers, demographic factors of patients, and AD diagnosis in a longitudinal manner.},
booktitle = {Proceedings of the 30th Annual International Conference on Mobile Computing and Networking},
pages = {404–419},
numpages = {16},
keywords = {digital biomarkers, behavior monitoring, multi-modal federated learning systems},
location = {Washington D.C., DC, USA},
series = {ACM MobiCom '24}
}

@inproceedings{10.1145/3636534.3649365,
author = {Sun, Xue and Xiong, Jie and Feng, Chao and Li, Xiaohui and Zhang, Jiayi and Li, Binghao and Fang, Dingyi and Chen, Xiaojiang},
title = {Gastag: A Gas Sensing Paradigm using Graphene-based Tags},
year = {2024},
isbn = {9798400704895},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3636534.3649365},
doi = {10.1145/3636534.3649365},
abstract = {Gas sensing plays a key role in detecting explosive/toxic gases and monitoring environmental pollution. Existing approaches usually require expensive hardware or high maintenance cost, and are thus ill-suited for large-scale long-term deployment. In this paper, we propose Gastag, a gas sensing paradigm based on passive tags. The heart of Gastag design is embedding a small piece of gas-sensitive material to a cheap RFID tag. When gas concentration varies, the conductivity of gas-sensitive materials changes, impacting the impedance of the tag and accordingly the received signal. To increase the sensing sensitivity and gas concentration range capable of sensing, we carefully select multiple materials and synthesize a new material that exhibits high sensitivity and high surface-to-weight ratio. To enable a long working range, we redesigned the tag antenna and carefully determined the location to place the gas-sensitive material in order to achieve impedance matching. Comprehensive experiments demonstrate the effectiveness of the proposed system. Gastag can achieve a median error of 6.7 ppm for CH4 concentration measurements, 12.6 ppm for CO2 concentration measurements, and 3 ppm for CO concentration measurements, outperforming a lot of commodity gas sensors on the market. The working range is successfully increased to 8.5 m, enabling the coverage of many tags with a single reader, laying the foundation for large-scale deployment.},
booktitle = {Proceedings of the 30th Annual International Conference on Mobile Computing and Networking},
pages = {342–356},
numpages = {15},
keywords = {gas sensing, RFID, backscatter, wireless sensing, internet of things (IoT), graphene antenna},
location = {Washington D.C., DC, USA},
series = {ACM MobiCom '24}
}

@inproceedings{10.1145/3636534.3649373,
author = {Johnson, Jacob and Palacios, Ashton and Arvonen, Cody and Lundrigan, Philip},
title = {Wireless Latency Shift Keying},
year = {2024},
isbn = {9798400704895},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3636534.3649373},
doi = {10.1145/3636534.3649373},
abstract = {IEEE 802.11 (WiFi) only has two modes of trust---complete trust or complete untrust. The lack of nuance leaves no room for sensors that a user does not fully trust but wants to connect to their network, such as a WiFi sensor. Solutions exist, but they require advanced knowledge of network administration. We solve this problem by introducing a new way of modulating data in the latency of the network, called Latency Shift Keying. We use specific characteristics of the WiFi protocol to carefully control the latency of just one device on the network. We build a transmitter, receiver, and modulation scheme that is designed to encode data in the latency of a network. We develop an application, Wicket, that solves the WiFi trust issue using Latency Shift Keying to create a new security association between an untrusted WiFi sensor and a wired device on the trusted network. We evaluate its performance and show that it works in many network conditions and environments.},
booktitle = {Proceedings of the 30th Annual International Conference on Mobile Computing and Networking},
pages = {452–466},
numpages = {15},
keywords = {wireless subprotocol, IoT, sensor networks, 802.11, wifi},
location = {Washington D.C., DC, USA},
series = {ACM MobiCom '24}
}

@inproceedings{10.1145/3654823.3654897,
author = {Zhang, Jiawen and Huang, Xiaoyan and Chen, Qian},
title = {Blood Glucose Monitoring Using Non-Invasive Features of Wearable Devices and Machine Learning},
year = {2024},
isbn = {9798400716416},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3654823.3654897},
doi = {10.1145/3654823.3654897},
abstract = {Abstract: With the increasing number of people with diabetes and the popularity of wearable devices, it becomes a novel research direction to use sensor data from wearable devices to monitor blood glucose in healthy people. There are many methods used for blood glucose prediction, such as using NIR and PPG for accurate blood glucose prediction, however, these data are usually not easy to acquire, and using data from wearable devices may be a potential direction. In this paper, two methods were proposed using the latest dataset released by Physiconet in 2023, 1-D CNN and tsfresh, for feature extraction of sensor data, and then construct a GRU network to predict blood glucose values, comparing the effectiveness of the two methods. Besides, the effects of different sensor features on the prediction results are explored. The study shows that the features extracted by tsfresh can follow the trend of blood glucose changes well, but it is still far from predicting specific blood glucose value. A larger dataset is needed to make a conclusion on the feasibility of the study.},
booktitle = {Proceedings of the 2024 3rd Asia Conference on Algorithms, Computing and Machine Learning},
pages = {409–413},
numpages = {5},
keywords = {blood glucose monitoring,1D-CNN, non-invasive features,machine learning},
location = {Shanghai, China},
series = {CACML '24}
}

@inproceedings{10.1145/3636534.3649386,
author = {Zhang, Xinran and Zhu, Hanqi and Duan, Yifan and Zhang, Wuyang and Shangguan, Longfei and Zhang, Yu and Ji, Jianmin and Zhang, Yanyong},
title = {Map++: Towards User-Participatory Visual SLAM Systems with Efficient Map Expansion and Sharing},
year = {2024},
isbn = {9798400704895},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3636534.3649386},
doi = {10.1145/3636534.3649386},
abstract = {Constructing precise 3D maps is crucial for the development of future map-based systems such as self-driving and navigation. However, generating these maps in complex environments, such as multi-level parking garages or shopping malls, remains a formidable challenge. In this paper, we introduce a participatory sensing approach that delegates map-building tasks to map users, thereby enabling cost-effective and continuous data collection. The proposed method harnesses the collective efforts of users, facilitating the expansion and ongoing update of the maps as the environment evolves.We realized this approach by developing Map++, an efficient system that functions as a plug-and-play extension, supporting participatory map-building based on existing SLAM algorithms. Map++ addresses a plethora of scalability issues in this participatory map-building system by proposing a set of lightweight, application-layer protocols. We evaluated Map++ in four representative settings: an indoor garage, an outdoor plaza, a public SLAM benchmark, and a simulated environment. The results demonstrate that Map++ can reduce traffic volume by approximately 46\% with negligible degradation in mapping accuracy, i.e., less than 0.03m compared to the baseline system. It can support approximately 2\texttimes{} as many concurrent users as the baseline under the same network bandwidth. Additionally, for users who travel on already-mapped trajectories, they can directly utilize the existing maps for localization and save 47\% of the CPU usage.},
booktitle = {Proceedings of the 30th Annual International Conference on Mobile Computing and Networking},
pages = {633–647},
numpages = {15},
keywords = {user-participatory, SLAM, map sharing, map expansion},
location = {Washington D.C., DC, USA},
series = {ACM MobiCom '24}
}

@inproceedings{10.1145/3659211.3659232,
author = {Xie, Li and Shi, Fengshuo and Wang, Yuqing and Li, Shengzhou and Kang, Xiaoguan and Deng, Yanfen},
title = {Research on the Design of Color Emotional Preferences in Products for Children with Autism Spectrum Disorder Based on Physiological Measurements and Random Forests},
year = {2024},
isbn = {9798400716669},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3659211.3659232},
doi = {10.1145/3659211.3659232},
abstract = {This study explores whether professionals engaged in Autism Spectrum Disorder (ASD) rehabilitation work develop similar color preferences through prolonged interactions with ASD children. The aim is to utilize these preferences for conducting color emotion research with ASD children, thereby mitigating challenges and limitations posed by ASD children in experiments. Physiological measurements, including Electrodermal Activity (EDA) and Electrocardiogram (ECG), were obtained from ASD rehabilitation teachers during specific color stimuli. The study aimed to reveal whether there are emotional tendencies similar to ASD children in color emotions. Industrial design undergraduate students were invited to participate in the evaluation, utilizing their physiological signals and a random forest model to establish a dual-layer correlation structure of "physiological signals - wearable color distance perception" for emotional image evaluation. The model was compared with GBDT, Adaboost, Xgboost, and RF algorithm models. Experimental results indicate (1) ASD rehabilitation teachers exhibit color preferences similar to ASD children; (2) the dual-modal (EDA + ECG) product color emotion image evaluation model based on random forests achieves a prediction accuracy of 85.35\%; (3) wearable products (bracelets) based on the yellow + green combination provide a deeper sense of affinity.},
booktitle = {Proceedings of the 2023 4th International Conference on Big Data Economy and Information Management},
pages = {114–123},
numpages = {10},
location = {Zhengzhou, China},
series = {BDEIM '23}
}

@inproceedings{10.1145/3654823.3654885,
author = {Xiao, Zili and Liu, Ke and Hu, Miao and Wu, Di},
title = {DeepCTS: A Deep Reinforcement Learning Approach for AI Container Task Scheduling},
year = {2024},
isbn = {9798400716416},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3654823.3654885},
doi = {10.1145/3654823.3654885},
abstract = {Container technology is a new paradigm of virtualization technology that has developed very rapidly in recent years. In view of container clusters for AI tasks, tasks can be divided into training tasks and inference tasks. Among them, the scheduling delay sensitivity of training tasks is low and the execution time is long, while the scheduling delay sensitivity of inference tasks is high and the execution time is short. However, prior works have rarely considered the characteristics of training and inference tasks, leading to excessive completion latency for latency-sensitive inference tasks and insufficient resources for resource-sensitive training tasks. There are also imbalanced resource usage within nodes and imbalanced resource usage among nodes in container clusters due to lack of consideration of the characteristics of AI tasks.In addition, an online learning algorithm is needed to adaptively make decisions based on the dynamics of task arrival. Therefore, this paper proposes an AI container cloud resource scheduling algorithm named DeepCTS based on reinforcement learning based on the characteristics of different latency sensitivities of training tasks and inference tasks in AI container clusters. DeepCTS takes the resource usage status of cluster nodes and container tasks characteristics as input, and from the perspective of different types of tasks with different delay sensitivity, in order to reduce tasks waiting time and balance cluster resource load. And through action mask filtering, it guides reinforcement learning agents to prioritize inference tasks in the process of interacting with the environment to reduce the waiting time of inference tasks, and at the same time make full use of the idle resources in the cluster when tasks resource requests are low. Compared with the existing scheduling algorithm based, the experimental results show that the average waiting time of tasks is reduced by 35.1\% and the reduction of resource imbalance between nodes and the degree of resource imbalance within nodes are improved by 14.2\% and 1.4\% respectively.},
booktitle = {Proceedings of the 2024 3rd Asia Conference on Algorithms, Computing and Machine Learning},
pages = {342–347},
numpages = {6},
keywords = {Cloud Computing, Container, Deep Reinforcement Learning, Kubernetes, Resource Scheduling},
location = {Shanghai, China},
series = {CACML '24}
}

@article{10.1145/3655614,
author = {\c{C}ak\i{}r, Mehtap and Huckauf, Anke},
title = {What Eyeblinks Reveal: Interpersonal Synchronization in Dyadic Interaction},
year = {2024},
issue_date = {May 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {8},
number = {ETRA},
url = {https://doi.org/10.1145/3655614},
doi = {10.1145/3655614},
abstract = {This study examines eyeblink synchronization in interactions characterized by mutual gaze without task-related or conversational elements that can trigger similarities in visual, auditory, or cognitive processing. We developed a study design capable of isolating the role of gaze in human-human interaction and observed the blinking behavior of dyads with mobile eye tracking glasses under three conditions: face-to-face mutual gaze, mediated mutual gaze through a mirror, and self-directed gaze in a mirror. The results revealed that when the interaction was through direct mutual gaze, eyeblink synchronization increased concurrently with a more structured temporal pattern. Also, the sense of connection between partners mimicked the synchronization. These findings suggest that even minor deviations caused by mediated interaction lead to reduced synchronization and a weakened sense of connection among partners. The paper also discusses the need for methodologies to enhance the efficacy and authenticity of online environments and human-robot interaction.},
journal = {Proc. ACM Hum.-Comput. Interact.},
month = may,
articleno = {240},
numpages = {15},
keywords = {eye tracking, eyeblink, human-computer interaction, mutual gaze, synchronization}
}

@inproceedings{10.1145/3643833.3656127,
author = {He, Yaqi and Zeng, Kai and Jiao, Long and Mark, Brian L. and Khasawneh, Khaled N.},
title = {Swipe2Pair: Secure and Fast In-Band Wireless Device Pairing},
year = {2024},
isbn = {9798400705823},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3643833.3656127},
doi = {10.1145/3643833.3656127},
abstract = {Wireless device pairing is a critical security mechanism to bootstrap the secure communication between two devices without a pre-shared secret. It has been widely used in many Internet of Things (IoT) applications, such as smarthome and smarthealth. Most existing device pairing mechanisms are based on out-of-band channels, e.g., extra sensors or hardware, to validate the location proximity of pairing devices. However, out-of-band channels are not universal on all wireless devices, thus this type of scheme is limited to certain application scenarios or conditions. On the other hand, in-band channel-based device pairing aims at universal applicability by only relying on wireless interfaces. Existing in-band channel-based pairing schemes either require multiple antennas separated in a good distance on one pairing devices which is not applicable in certain scenarios, or require users to repeat multiple sweeps which is not optimal in terms of usability. Therefore, an in-band wireless device pairing scheme providing high security while maintaining good usability (simple pairing process and user interaction) is highly desired. In this work, we propose an easy-to-use mutual authentication device pairing scheme, named Swipe2Pair, based on location proximity of pairing devices and wireless transmission power randomization. We conduct extensive security analysis and collect considerable experimental data under various settings in different environments. Experimental results show that Swipe2Pair achieves high security and usability. It only takes less than one second to complete the pairing process with a simple swipe of one device in front of the other.},
booktitle = {Proceedings of the 17th ACM Conference on Security and Privacy in Wireless and Mobile Networks},
pages = {196–206},
numpages = {11},
keywords = {authentication, in-band device pairing, security protocol, wireless communication system},
location = {Seoul, Republic of Korea},
series = {WiSec '24}
}

@inproceedings{10.1145/3643833.3656132,
author = {Sunar, Shiva and Shirani, Paria and Majumdar, Suryadipta and Brown, J. David},
title = {On Continuously Verifying Device-level Functional Integrity by Monitoring Correlated Smart Home Devices},
year = {2024},
isbn = {9798400705823},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3643833.3656132},
doi = {10.1145/3643833.3656132},
abstract = {The correct functionality (can also be called as functional integrity) from a smart device is essential towards ensuring their safe and secure operations. The functional integrity of a device can be defined based on its correctness in sensing and actuating on the physical environment as well as in reporting to the users. As evident from several practical threats (e.g., event spoofing attacks, event masking attacks, sensor failure, vulnerabilities, and misconfigurations), this functional integrity of a device are often breached to cause severe security and safety impacts to their users. To make things worse, such integrity breaches might stay stealthy (due to their non-existence at the user-side) as well as be caused from both devices and apps (due to their vulnerability and misconfiguratons at both physical and cyber spaces). Existing works mainly focus on detecting specific attacks without aiming at verifying functional integrity as a security property. In this paper, we bridge this gap by proposing a continuous approach for smart homes to verify functional integrity at the device-level while monitoring correlated devices. Specifically, our main idea is to learn the correlations among various sensors and actuators in a smart environment, and continuously monitor all the correlated devices to verify functional integrity breaches against various real-world attacks, including spoofing, masking, sensor failure, and device misconfigurations/vulnerabilities. We implement our approach in the context of smart home and evaluate its effectiveness (e.g., for sensors, R2 score of 0.98, and for actuators, accuracy up to 100\%) using a public dataset.},
booktitle = {Proceedings of the 17th ACM Conference on Security and Privacy in Wireless and Mobile Networks},
pages = {219–230},
numpages = {12},
keywords = {IoT security, correlated device, functional integrity, smart home},
location = {Seoul, Republic of Korea},
series = {WiSec '24}
}

@inproceedings{10.1145/3643833.3656124,
author = {Fu, Chenglong and Du, Xiaojiang and Zeng, Qiang and Zhao, Zhenyu and Zuo, Fei and Di, Jia},
title = {Seeing Is Believing: Extracting Semantic Information from Video for Verifying IoT Events},
year = {2024},
isbn = {9798400705823},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3643833.3656124},
doi = {10.1145/3643833.3656124},
abstract = {Along with the increasing popularity of smart home IoT devices, more users are turning to smart home automation platforms to control and automate their IoT devices. However, IoT automation is vulnerable to spoofed event attacks. Given that IoT devices are intricately linked with the physical environment and operate autonomously, event-based attacks can pose serious safety and security challenges. Our observations show that many IoT events are accompanied by visual modifications in objects such as shape alterations (for example, contact sensor events correspond with door movement) or changes in color/brightness (for example, a functioning microwave oven with the internal light switched on). These alterations can be detected by the commonly deployed smart cameras, providing a visually rich but challenging to manipulate channel for verifying IoT events. We introduce IoTSentry, the first system of its kind to extract high-level semantic information from streaming video data and pixels for IoT event verification. We have designed a Siamese deep neural network to identify variations in the appearance of IoT devices and interior objects. These are used as the yardstick for verifying IoT events received at IoT automation platforms. Upon assessing IoTSentry with 21 IoT devices (8 types), the results demonstrate that IoTSentry can be trained within 120 seconds, yielding an accuracy rate of over 96.7\% in recognizing device states. We have deployed the 21 IoT devices and IoTSentry on two real-world smart home test sites. Over the course of our one-week evaluation, IoTSentry consistently achieved an average detection rate of 99.24\% in identifying attack instances. Moreover, it triggered no more than 2 false alarms per day on each test site.},
booktitle = {Proceedings of the 17th ACM Conference on Security and Privacy in Wireless and Mobile Networks},
pages = {101–112},
numpages = {12},
keywords = {internet of things, security, smart home},
location = {Seoul, Republic of Korea},
series = {WiSec '24}
}

@inproceedings{10.1145/3643833.3656135,
author = {Sabra, Mohd and Vinayaga-Sureshkanth, Nisha and Sharma, Ari and Maiti, Anindya and Jadliwala, Murtuza},
title = {De-anonymizing VR Avatars using Non-VR Motion Side-channels},
year = {2024},
isbn = {9798400705823},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3643833.3656135},
doi = {10.1145/3643833.3656135},
abstract = {Virtual Reality (VR) technology offers an immersive audio-visual experience to users through which they can interact with a digitally represented 3D space (i.e., a virtual world) using a headset device. By (visually) transporting users from their physical world to realistic virtual spaces, VR systems enable interactive and true-to-life versions of traditional applications such as gaming, remote conferencing and virtual tourism. However, VR applications also present significant user-privacy challenges. This paper studies a new type of privacy threat targeting VR users which attempts to connect their activities visible in the virtual world to their physical state sensed in the real world. Specifically, this paper analyzes the feasibility of carrying out a de-anonymization or identification attack on VR users by correlating visually observed movements of users' avatars in the virtual world with some auxiliary data (e.g., motion sensor data from mobile/wearable devices) representing their context/state in the physical world. To enable this attack, the paper proposes a novel framework which first employs a learning-based activity classification approach to translate the disparate visual movement data and motion sensor data into an activity-vector to ease comparison, followed by a filtering and identity ranking phase outputting an ordered list of potential identities corresponding to the target visual movement data. A comprehensive empirical evaluation of the proposed framework is conducted to study the feasibility of such a de-anonymization attack.},
booktitle = {Proceedings of the 17th ACM Conference on Security and Privacy in Wireless and Mobile Networks},
pages = {54–65},
numpages = {12},
keywords = {de-anonymization, motion, side channel, virtual reality},
location = {Seoul, Republic of Korea},
series = {WiSec '24}
}

@inproceedings{10.1145/3652628.3652767,
author = {Zhang, Jiawei and Wang, Long and Chen, Xinzhu and Jiang, Yaotong and Tian, Ziwei},
title = {Artificial Intelligence-Based Education Platform Course Recommendation System},
year = {2024},
isbn = {9798400708831},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3652628.3652767},
doi = {10.1145/3652628.3652767},
abstract = {The rapid development of artificial intelligence technology has brought many conveniences to people, and at the same time has had a huge impact on the traditional education model. Interactive learning platforms have become mainstream in the context of the big data era. This article takes an online course in a university as an example to explore user interest points, demand characteristics and knowledge acquisition rules in an artificial intelligence system environment. After processing and analyzing students' browsing behavior in different scenarios, the corresponding results are returned to the database to better grasp the user's preference information and provide more services for teaching. At the same time, through the application of machine intelligence algorithms and AI technology, the personalized recommendation capabilities of the learning platform can be improved to meet students' personalized learning needs. This article tests the algorithm of the system. The test results show that the content-based recommendation algorithm performs medium to high in accuracy, but its coverage is low and is not affected by data sparsity. The collaborative filtering recommendation algorithm performs generally highest in terms of accuracy and coverage, with an accuracy rate of 96\%, and is sensitive to sparse data. The hybrid recommendation algorithm has high accuracy and coverage, and factors such as data sparsity have a medium to high impact on it. Recommendation algorithms based on deep learning show high levels of accuracy and coverage, and their impact on factors such as data sparsity is also moderate to high. However, although artificial intelligence technology has broad prospects for application in the field of education, it also faces some challenges, such as privacy protection and compliance with data use. Therefore, in the process of promoting and applying artificial intelligence technology, it is necessary to strengthen compliance with relevant laws and regulations to ensure that students' information security and privacy rights are effectively protected.},
booktitle = {Proceedings of the 4th International Conference on Artificial Intelligence and Computer Engineering},
pages = {835–841},
numpages = {7},
location = {Dalian, China},
series = {ICAICE '23}
}

@inproceedings{10.1145/3652628.3652807,
author = {Zheng, Xuemei and Liu, Jichao and Yuan, Tianmin and Liu, Chengpan},
title = {Sustainable Role of AI Robots for EFL Learners: Strengths, Weaknesses and Proposals},
year = {2024},
isbn = {9798400708831},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3652628.3652807},
doi = {10.1145/3652628.3652807},
abstract = {The aim of this research is to examine how AI EFL (English as a foreign language) learning robots affected learners by analyzing the functions and user experience. For this purpose, data were collected from positive, medium and negative views of five selected robots with EFL learning functions of over 5000 reviews on JD.com. Findings mainly indicated three points. First, the AI robots for EFL learning mainly focus on children, and few ones are targeted at adults. Second, the most frequently mentioned key words/phrase by at least 10\% of users of the five robots are appearance, picture book, sound effect, operation, sensitivity, function, freedom, workshop, and quality. Next, the main advantages of the product for English learning can be non-linguistic aspects such as learning interest motivation and visual health protection and opinions vary on the shortcomings. This study showed that the improvements need to be made mainly in four aspects, that is, combining the latest big data and voice technology to enhance interaction capabilities; increasing the breadth of users age, profession, etc. to meet the learning needs of different people; developing unique learning strategies and plans for individual users; and meeting the learning needs of different scenarios such as travelling, professional fields, language exams, etc. These results of the study have implications for the research and development of AI EFL learning robot and sustainable development of EFL learners.},
booktitle = {Proceedings of the 4th International Conference on Artificial Intelligence and Computer Engineering},
pages = {1088–1095},
numpages = {8},
location = {Dalian, China},
series = {ICAICE '23}
}

@inproceedings{10.1145/3652628.3652638,
author = {Wang, Licai and Liu, Bo and Wang, Butang and Wang, Lei},
title = {Enhancing Coal Mine Safety Monitoring Algorithm using Graph Computing Techniques},
year = {2024},
isbn = {9798400708831},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3652628.3652638},
doi = {10.1145/3652628.3652638},
abstract = {Coal mines are one of the pillars of industrial development, and their production safety issues have an important impact on social economy. Due to the complexity of industrial big data, the processing and prediction of coal mine safety monitoring data have always been highly challenging. For example, coal mine safety is generally related to multiple environmental variables such as temperature, methane concentration, and wind speed, and these data are usually distributed in multiple sensors monitoring data. Researchers need to deeply analyze the relationship between the data and model accordingly. Therefore, this paper proposes a coal mine safety monitoring algorithm based on graph computing. This algorithm abstracts sensors and the relationships between them into nodes and edges, and then converts sensor data into graph data. On this basis, the algorithm processes data through a heterogeneous graph neural network and achieves prediction of sensor monitoring values. Through this algorithm, coal mine safety practitioners can accurately predict sensor monitoring values and respond promptly, thereby improving coal mine production safety.},
booktitle = {Proceedings of the 4th International Conference on Artificial Intelligence and Computer Engineering},
pages = {59–64},
numpages = {6},
location = {Dalian, China},
series = {ICAICE '23}
}

@inproceedings{10.1145/3652628.3652814,
author = {Li, Peng and Tian, Ye and Chen, Yaojie},
title = {Active Wave Compensation Control Method for Shipborne Lifting Robot Arm},
year = {2024},
isbn = {9798400708831},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3652628.3652814},
doi = {10.1145/3652628.3652814},
abstract = {When the shipborne robotic arm transfers goods at sea, the position of the lifted object at the end of the arm will undergo drastic changes due to the influence of sea waves and other marine environments. The safety and efficiency of lifting goods cannot be guaranteed. A kinematic model based active wave compensation control method for shipborne lifting robotic arms is proposed to address this issue. Firstly, establish a global coordinate system, calculate the initial position of the lifted object, and calculate the offset position of the lifted object based on the ship attitude information measured by the sensor. Then establish a kinematic model to calculate the compensation angle of the robotic arm and the compensation length of the end rope, and synchronize the control of the robotic arm based on the compensation amount. Finally, a simulation experimental platform with a shipborne robotic arm equipped with a lifting rope device was used in the laboratory for the experiment. The experimental results showed that the position compensation rate of the end object after compensation can reach 93\%, verifying the effectiveness of the compensation algorithm, improving the efficiency of offshore operations while also ensuring the safety of lifting goods.},
booktitle = {Proceedings of the 4th International Conference on Artificial Intelligence and Computer Engineering},
pages = {1134–1139},
numpages = {6},
location = {Dalian, China},
series = {ICAICE '23}
}

@inproceedings{10.1145/3652628.3652699,
author = {Lian, Xinan and Wu, Zhenglong},
title = {Research on Image Processing and Application of Air-to-Ground Platforms},
year = {2024},
isbn = {9798400708831},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3652628.3652699},
doi = {10.1145/3652628.3652699},
abstract = {With the widespread application of aerial platforms such as unmanned aerial vehicles and remote sensing satellites in economic, social, and defense fields, the acquisition and processing of aerial images play an increasingly important role. However, there is currently no literature that systematically and comprehensively studies the image processing of aerial platforms, and the characteristics and relationships of image processing on different platforms still need to be explored. Due to the inherent variations in imaging characteristics across different platforms, as well as the diverse requirements for platform usage, a standardized classification for ground-based image processing remains elusive. In this study, we propose a novel approach that analyzes the internal and external environmental mechanisms of platform imaging from an algorithmic application perspective. Our objective is to delve into the current state of ground-based image processing and its applications. Finally, three key issues and development directions are pointed out regarding image processing for aerial platforms, including imaging characteristic processing, algorithm transplantation and application, and multisource information fusion.},
booktitle = {Proceedings of the 4th International Conference on Artificial Intelligence and Computer Engineering},
pages = {428–437},
numpages = {10},
location = {Dalian, China},
series = {ICAICE '23}
}

@inproceedings{10.1145/3658271.3658295,
author = {Osias, Ana Clara Fraga and Schaefer, Mariana Albuquerque Reynaud and Veloso, Gustavo Vieira and Oliveira, Hugo and Reis, Julio},
title = {Interpretable Approaches for Land Use and Land Cover Classification},
year = {2024},
isbn = {9798400709968},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3658271.3658295},
doi = {10.1145/3658271.3658295},
abstract = {Context: The Land Use Land Cover (LULC) undergoes various changes over time. Monitoring these changes is important for environmental disaster management, and agricultural land monitoring, among other applications. Focusing on the effects caused by environmental disasters, the Quadril\'{a}tero Ferr\'{\i}fero Region in Minas Gerais, Brazil, was chosen as the study area. This region has experienced dam breaks over the years, leading to an increased number of studies investigating the use of machine learning in this context. Problem: In the context of environmental disasters, making quick and effective decisions is essential, and the use of automated LULC classification systems plays a crucial role in this process. Proposed Solution: This study developed a map for the mentioned study area and presented a detailed methodology for creating a LULC classifier using machine learning techniques and discussing model interpretability in this context. SI Theory: This work is associated with Computational Learning Theory, focusing on defining and exploring automated classification methods. Method: Remote Sensing data were used to segment the area of interest, calculating indices from information obtained from different satellite bands and the digital elevation map. The models were trained with labeled samples after feature selection. Results: The tested models (Random Forest, Support Vector Machine, and K-Nearest Neighbours) demonstrated performance with no statistical difference, achieving F1-scores ranging from 0.89290 to 0.92994. Contribution: Considering the increasing research in this area, this work provides a detailed methodology that can contribute to and promote promising machine learning solutions for this field.},
booktitle = {Proceedings of the 20th Brazilian Symposium on Information Systems},
articleno = {24},
numpages = {9},
keywords = {LULC, machine learning, model interpretability, remote sensing},
location = {Juiz de Fora, Brazil},
series = {SBSI '24}
}

@inproceedings{10.1145/3638682.3638684,
author = {Shen, Jiaming and Bai, Lin and Wang, Haijuan and Ji, Bo and Cheng, Wenming and Zhang, Guocai},
title = {A Lightweight Anchor-Free Detector Using Cross-Dimensional Interactive Feature Balance for SAR Ship Detection},
year = {2024},
isbn = {9798400709272},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3638682.3638684},
doi = {10.1145/3638682.3638684},
abstract = {In recent years, the deep convolutional neural network (CNN) model has rapidly developed, and it is widely used in SAR remote sensing target detection. Many methods utilize preset anchor boxes for target classification and boundary box coordinate regression. However, these methods encounter challenges when deployed to edge devices. Firstly, in SAR images, ships are sparsely and unevenly distributed, rendering most anchor boxes redundant. Secondly, the target detection model relying on anchor boxes demands extensive computation during anchor box generation, typically running on hardware-rich environments. Nevertheless, edge devices lack the necessary hardware environment to meet the deployment requirements of the CNN model. To address these issues, this paper proposes a lightweight anchor-free detector called Cross-Dimensional Interactive Feature Balance (CDIFB-Net). We adopt a key point strategy to predict the bounding box, eliminating the reliance on anchors. CDIFB-Net employs a partial convolution (PConv) based model as a lightweight feature extraction network to tackle the model's lightweight problem. Additionally, considering the characteristics of large target scale differences and unbalanced target distribution in SAR ship images, and to reduce the precision decline problem caused by lightweight, this paper introduces a cross-dimensional interactive feature balance pyramid (CDI-FBP), which balances semantic information of different levels through feature pyramid aggregation and averaging. The cross-dimensional interaction module (CDIM) establishes the relationship between the ship target and the background. Experiments conducted on the SAR Ship dataset (SSDD) and High-resolution SAR Image dataset (HRSID), along with inference experiments in different hardware environments, validate the effectiveness of the network for SAR ship detection. The experimental results demonstrate that the proposed CDIFB-Net maintains fast reasoning, low delay, and excellent detection accuracy across various hardware environments.},
booktitle = {Proceedings of the 2023 5th International Conference on Video, Signal and Image Processing},
pages = {9–15},
numpages = {7},
keywords = {CDI-FBP, Convolutional neural network, lightweight, ship detection},
location = {Harbin, China},
series = {VSIP '23}
}

@inproceedings{10.1145/3638682.3638692,
author = {Luo, Xinhua and Wang, Qingyan and Liang, Xintao and Zhang, Zhen},
title = {Research on hyperspectral image classification based on improved deep cross-domain few-shot learning},
year = {2024},
isbn = {9798400709272},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3638682.3638692},
doi = {10.1145/3638682.3638692},
abstract = {In this study, an enhanced method and system for hyperspectral image classification are presented, based on deep cross-scene few-shot learning. This pertains to the domain of remote sensing image processing technology and addresses the prevalent issues of inadequate classification performance in existing techniques for hyperspectral image categorization. The core aspects of this invention encompass the following: utilization of two mapping layers to standardize the input dimensions between the source and target domains; the deployment of an embedded feature extractor to incorporate the image cubes from both the source and target domains into a space-spectral embedding environment simultaneously, ensuring that like samples are closely aligned and dissimilar ones are distanced. Through gauging the distances between each class of unlabeled and labeled samples in this space-spectral embedding zone, learning with a few number of examples in both the source and target domains is achieved. Furthermore, a conditional domain discriminator is employed to mitigate domain shifts between domains, thus solidifying the domain stability of the extracted spatial-spectral embedding features. This innovative approach allows for high-precision hyperspectral data categorization, even when only a few examples are available.},
booktitle = {Proceedings of the 2023 5th International Conference on Video, Signal and Image Processing},
pages = {64–71},
numpages = {8},
keywords = {Hyperspectral image, cross-scene, few-shot learning},
location = {Harbin, China},
series = {VSIP '23}
}

@inproceedings{10.1145/3605098.3635994,
author = {Yuhala, Peterson and M\'{e}n\'{e}trey, J\"{a}mes and Felber, Pascal and Pasin, Marcelo and Schiavoni, Valerio},
title = {Fortress: Securing IoT Peripherals with Trusted Execution Environments},
year = {2024},
isbn = {9798400702433},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3605098.3635994},
doi = {10.1145/3605098.3635994},
abstract = {With the increasing popularity of Internet of Things (IoT) devices, securing sensitive user data has emerged as a major challenge. These devices often collect confidential information, such as audio and visual data, through peripheral inputs like microphones and cameras. Such sensitive information is then exposed to potential threats, either from malicious software with high-level access rights or transmitted (sometimes inadvertently) to untrusted cloud services. In this paper, we propose a generic design to enhance the privacy in IoT-based systems by isolating peripheral I/O memory regions in a secure kernel space of a trusted execution environment (TEE). Only a minimal set of peripheral driver code, resident within the secure kernel, can access this protected memory area.This design effectively restricts any unauthorised access by system software, including the operating system and hypervisor. The sensitive peripheral data is then securely transferred to a user-space TEE, where obfuscation mechanisms can be applied before it is relayed to third parties, e.g., the cloud. To validate our architectural approach, we provide a proof-of-concept implementation of our design by securing an audio peripheral based on inter-IC sound (I2S), a serial bus to interconnect audio devices. The experimental results show that our design offers a robust security solution with an acceptable computational overhead.},
booktitle = {Proceedings of the 39th ACM/SIGAPP Symposium on Applied Computing},
pages = {243–250},
numpages = {8},
keywords = {confidential computing, trusted execution environments, ARM TrustZone, OP-TEE, kernel drivers, IoT, secure peripherals, edge computing},
location = {Avila, Spain},
series = {SAC '24}
}

@inproceedings{10.1145/3605098.3636045,
author = {L\'{o}pez, V\'{\i}ctor and Fontenla-Romero, Oscar and Hern\'{a}ndez-Pereira, Elena and Guijarro-Berdi\~{n}as, Bertha and Blanco-Seijo, Carlos and Fernandez-Paz, Samuel},
title = {RUL Prediction of Lithium-ion Batteries using a Federated and Homomorphically Encrypted Learning Method},
year = {2024},
isbn = {9798400702433},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3605098.3636045},
doi = {10.1145/3605098.3636045},
abstract = {The increasing demand for lithium-ion batteries (LIB) across various industries has accentuated the importance of accurately predicting the Remaining Useful Life (RUL) of these energy storage devices. This article introduces a novel approach to RUL prediction by leveraging a federated learning (FL) and homomorphic encryption (HE) model, called FedHEONN. Traditional RUL prediction models often face challenges not only related to the accuracy and reliability of estimations but also to data privacy and security when dealing with sensitive information in Internet of Things (IoT) environments. In response, our approach employs FL, allowing multiple distributed nodes to collaboratively train a predictive model without sharing private data. This ensures data privacy and security while harnessing the collective knowledge from diverse edge computing devices. Furthermore, to address the issue of secure computation over encrypted data, FedHEONN has the capacity to incorporate HE into the learning process. This enables the model to operate directly on encrypted data, providing an additional layer of protection to that of the federated model itself.Our experimental results test the efficacy of this FL method in accurately predicting the RUL of LIB real data against benchmark models, including linear regression with regularisation techniques such as Lasso, Ridge and Elastic-net, and non-linear models such as multilayer perceptron and support vector machine for regression. The experiment demonstrates the preservation of prediction outcomes, upholding an additional level of data safety through encrypted transmission of model information.},
booktitle = {Proceedings of the 39th ACM/SIGAPP Symposium on Applied Computing},
pages = {565–571},
numpages = {7},
keywords = {lithium-ion batteries, remaining useful life, federated learning, homomorphic encryption},
location = {Avila, Spain},
series = {SAC '24}
}

@inproceedings{10.1145/3639856.3639859,
author = {Saha, Bidyut and Samanta, Riya and Ghosh, Soumya Kanti and Roy, Ram Babu},
title = {TinyML-Driven On-Device Personalized Human Activity Recognition and Auto-Deployment to Smart Bands},
year = {2024},
isbn = {9798400716492},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3639856.3639859},
doi = {10.1145/3639856.3639859},
abstract = {Human activity recognition has revolutionized health and fitness monitoring, although significant hindrances still exist. One such difficulty is making a system that considers each person’s unique physical activity features, routines, and preferences to provide personalized outcomes. Another challenge is implementing on-device computing models that balance latency, energy use, performance, and accuracy. To bridge this research gap, in this paper, BandX 2.0, a wrist-worn, customized human activity recognition smart band, is presented. BandX 2.0 utilizes IMU sensors, along with a TinyML-driven on-device computing paradigm. It has preloaded activity classes that can be customized based on an individual’s unique movement style. Users can add any number of activity classes by performing and recording the activities for a short duration, thus incorporating minimal calibration and intervention. For personalised human activity recognition, a lightweight 1D Convolutional Neural Network is constructed by employing a transfer learning strategy, along with fine-tuning, using a small dataset gathered from the user’s environment. This approach led to a 37\% increase in the accuracy of human activity recognition compared to generalized models. The evaluation of BandX 2.0’s performance was conducted by leveraging three benchmark datasets: WISDM, PAMAP2, and the BandX dataset. Furthermore, this work proposed a cloud-supported framework for the automatic wireless deployment of the TinyML model to remote wearables. The framework facilitates model customization in a cloud environment and enables on-device inference, even when limited target data is available.},
booktitle = {Proceedings of the Third International Conference on AI-ML Systems},
articleno = {3},
numpages = {9},
keywords = {Auto-deployment, Cloud, Human Activity Recognition, On-device Machine Learning, Personalization},
location = {Bangalore, India},
series = {AIMLSystems '23}
}

@article{10.1145/3650040,
author = {Bano, Saira and Tonellotto, Nicola and Cassar\`{a}, Pietro and Gotta, Alberto},
title = {FedCMD: A Federated Cross-modal Knowledge Distillation for Drivers’ Emotion Recognition},
year = {2024},
issue_date = {June 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {15},
number = {3},
issn = {2157-6904},
url = {https://doi.org/10.1145/3650040},
doi = {10.1145/3650040},
abstract = {Emotion recognition has attracted a lot of interest in recent years in various application areas such as healthcare and autonomous driving. Existing approaches to emotion recognition are based on visual, speech, or psychophysiological signals. However, recent studies are looking at multimodal techniques that combine different modalities for emotion recognition. In this work, we address the problem of recognizing the user’s emotion as a driver from unlabeled videos using multimodal techniques. We propose a collaborative training method based on cross-modal distillation, i.e., “FedCMD” (Federated Cross-Modal Distillation). Federated Learning (FL) is an emerging collaborative decentralized learning technique that allows each participant to train their model locally to build a better generalized global model without sharing their data. The main advantage of FL is that only local data is used for training, thus maintaining privacy and providing a secure and efficient emotion recognition system. The local model in FL is trained for each vehicle device with unlabeled video data by using sensor data as a proxy. Specifically, for each local model, we show how driver emotional annotations can be transferred from the sensor domain to the visual domain by using cross-modal distillation. The key idea is based on the observation that a driver’s emotional state indicated by a sensor correlates with facial expressions shown in videos. The proposed “FedCMD” approach is tested on the multimodal dataset “BioVid Emo DB” and achieves state-of-the-art performance. Experimental results show that our approach is robust to non-identically distributed data, achieving 96.67\% and 90.83\% accuracy in classifying five different emotions with IID (independently and identically distributed) and non-IID data, respectively. Moreover, our model is much more robust to overfitting, resulting in better generalization than the other existing methods.},
journal = {ACM Trans. Intell. Syst. Technol.},
month = may,
articleno = {57},
numpages = {27},
keywords = {Emotion recognition, cross-modal distillation, federated learning, transfer learning}
}

@inproceedings{10.1145/3653666.3656108,
author = {Martin, Nicole D. and Antoine, Allen and Wilson Vazquez, Andrea and Black, Cydny},
title = {Training Effective Facilitators to Scale Equity-Focused Computer Science Professional Learning},
year = {2024},
isbn = {9798400706264},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3653666.3656108},
doi = {10.1145/3653666.3656108},
abstract = {Creating computer science (CS) classrooms in which all students - especially those historically excluded in CS - feel a sense of belonging is critical to equitably expanding CS education. Providing professional learning that prepares teachers to cultivate inclusive and culturally responsive environments at the scale needed to address inequities in CS education is a major challenge. This paper explores our experience scaling inclusive CS teaching through the development of a professional learning course for teachers and accompanying facilitator training. We describe key design decisions made over several iterations of the teacher-facing course and facilitator training. Our approach has aimed to balance the need for building community and safe spaces to converse about sensitive topics with the capacity to reach teachers at scale. We discuss findings from recent facilitator trainings and discuss best practices we have learned for scaling equity-based professional learning in CS.},
booktitle = {Proceedings of the 2024 on RESPECT Annual Conference},
pages = {270–277},
numpages = {8},
keywords = {K-12 teachers, broadening participation in computing, equity, professional development},
location = {Atlanta, GA, USA},
series = {RESPECT 2024}
}

@article{10.1145/3659603,
author = {Su, Yuchen and Huang, Shiyue and Liu, Hongbo and Chen, Yuefeng and Du, Yicong and Wang, Yan and Ren, Yanzhi and Chen, Yingying},
title = {PPG-Hear: A Practical Eavesdropping Attack with Photoplethysmography Sensors},
year = {2024},
issue_date = {June 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {8},
number = {2},
url = {https://doi.org/10.1145/3659603},
doi = {10.1145/3659603},
abstract = {Photoplethysmography (PPG) sensors have become integral components of wearable and portable health devices in the current technological landscape. These sensors offer easy access to heart rate and blood oxygenation, facilitating continuous long-term health monitoring in clinic and non-clinic environments. While people understand that health-related information provided by PPG is private, no existing research has demonstrated that PPG sensors are dangerous devices capable of obtaining sensitive information other than health-related data. This work introduces PPG-Hear, a novel side-channel attack that exploits PPG sensors to intercept nearby audio information covertly. Specifically, PPG-Hear exploits low-frequency PPG measurements to discern and reconstruct human speech emitted from proximate speakers. This technology allows attackers to eavesdrop on sensitive conversations (e.g., audio passwords, business decisions, or intellectual properties) without being noticed. To achieve this non-trivial attack on commodity PPG-enabled devices, we employ differentiation and filtering techniques to mitigate the impact of temperature drift and user-specific gestures. We develop the first PPG-based speech reconstructor, which can identify speech patterns in the PPG spectrogram and establish the correlation between PPG and speech spectrograms. By integrating a MiniRocket-based classifier with a PixelGAN model, PPG-Hear can reconstruct human speech using low-sampling-rate PPG measurements. Through an array of real-world experiments, encompassing common eavesdropping scenarios such as surrounding speakers and the device's own speakers, we show that PPG-Hear can achieve remarkable accuracy of 90\% for recognizing human speech, surpassing the current state-of-the-art side-channel eavesdropping attacks using motion sensors operating at equivalent sampling rates (i.e., 50Hz to 500Hz).},
journal = {Proc. ACM Interact. Mob. Wearable Ubiquitous Technol.},
month = may,
articleno = {82},
numpages = {28},
keywords = {Eavesdropping attack, PPG, Side-channel}
}

@article{10.1145/3659604,
author = {Englhardt, Zachary and Ma, Chengqian and Morris, Margaret E. and Chang, Chun-Cheng and Xu, Xuhai "Orson" and Qin, Lianhui and McDuff, Daniel and Liu, Xin and Patel, Shwetak and Iyer, Vikram},
title = {From Classification to Clinical Insights: Towards Analyzing and Reasoning About Mobile and Behavioral Health Data With Large Language Models},
year = {2024},
issue_date = {June 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {8},
number = {2},
url = {https://doi.org/10.1145/3659604},
doi = {10.1145/3659604},
abstract = {Passively collected behavioral health data from ubiquitous sensors could provide mental health professionals valuable insights into patient's daily lives, but such efforts are impeded by disparate metrics, lack of interoperability, and unclear correlations between the measured signals and an individual's mental health. To address these challenges, we pioneer the exploration of large language models (LLMs) to synthesize clinically relevant insights from multi-sensor data. We develop chain-of-thought prompting methods to generate LLM reasoning on how data pertaining to activity, sleep and social interaction relate to conditions such as depression and anxiety. We then prompt the LLM to perform binary classification, achieving accuracies of 61.1\%, exceeding the state of the art. We find models like GPT-4 correctly reference numerical data 75\% of the time.While we began our investigation by developing methods to use LLMs to output binary classifications for conditions like depression, we find instead that their greatest potential value to clinicians lies not in diagnostic classification, but rather in rigorous analysis of diverse self-tracking data to generate natural language summaries that synthesize multiple data streams and identify potential concerns. Clinicians envisioned using these insights in a variety of ways, principally for fostering collaborative investigation with patients to strengthen the therapeutic alliance and guide treatment. We describe this collaborative engagement, additional envisioned uses, and associated concerns that must be addressed before adoption in real-world contexts.},
journal = {Proc. ACM Interact. Mob. Wearable Ubiquitous Technol.},
month = may,
articleno = {56},
numpages = {25},
keywords = {Passive sensing, clinical insights, large-language-models, mental health}
}

@article{10.1145/3659628,
author = {Xu, Ziqi and Zhang, Jingwen and Greenberg, Jacob and Frumkin, Madelyn and Javeed, Saad and Zhang, Justin K. and Benedict, Braeden and Botterbush, Kathleen and Rodebaugh, Thomas L. and Ray, Wilson Z. and Lu, Chenyang},
title = {Predicting Multi-dimensional Surgical Outcomes with Multi-modal Mobile Sensing: A Case Study with Patients Undergoing Lumbar Spine Surgery},
year = {2024},
issue_date = {June 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {8},
number = {2},
url = {https://doi.org/10.1145/3659628},
doi = {10.1145/3659628},
abstract = {Pre-operative prediction of post-surgical recovery for patients is vital for clinical decision-making and personalized treatments, especially with lumbar spine surgery, where patients exhibit highly heterogeneous outcomes. Existing predictive tools mainly rely on traditional Patient-Reported Outcome Measures (PROMs), which fail to capture the long-term dynamics of patient conditions before the surgery. Moreover, existing studies focus on predicting a single surgical outcome. However, recovery from spine surgery is multi-dimensional, including multiple distinctive but interrelated outcomes, such as pain interference, physical function, and quality of recovery. In recent years, the emergence of smartphones and wearable devices has presented new opportunities to capture longitudinal and dynamic information regarding patients' conditions outside the hospital. This paper proposes a novel machine learning approach, Multi-Modal Multi-Task Learning (M3TL), using smartphones and wristbands to predict multiple surgical outcomes after lumbar spine surgeries. We formulate the prediction of pain interference, physical function, and quality of recovery as a multi-task learning (MTL) problem. We leverage multi-modal data to capture the static and dynamic characteristics of patients, including (1) traditional features from PROMs and Electronic Health Records (EHR), (2) Ecological Momentary Assessment (EMA) collected from smartphones, and (3) sensing data from wristbands. Moreover, we introduce new features derived from the correlation of EMA and wearable features measured within the same time frame, effectively enhancing predictive performance by capturing the interdependencies between the two data modalities. Our model interpretation uncovers the complementary nature of the different data modalities and their distinctive contributions toward multiple surgical outcomes. Furthermore, through individualized decision analysis, our model identifies personal high risk factors to aid clinical decision making and approach personalized treatments. In a clinical study involving 122 patients undergoing lumbar spine surgery, our M3TL model outperforms a diverse set of baseline methods in predictive performance, demonstrating the value of integrating multi-modal data and learning from multiple surgical outcomes. This work contributes to advancing personalized peri-operative care with accurate pre-operative predictions of multi-dimensional outcomes.},
journal = {Proc. ACM Interact. Mob. Wearable Ubiquitous Technol.},
month = may,
articleno = {81},
numpages = {30},
keywords = {EMA, Multi-task Learning, Post-surgical Prediction, Wearables}
}

@article{10.1145/3659605,
author = {Liao, Zimo and Jin, Meng and An, Shun and Niu, Chaoyue and Wu, Fan and Deng, Tao and Chen, Guihai},
title = {Waving Hand as Infrared Source for Ubiquitous Gas Sensing},
year = {2024},
issue_date = {June 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {8},
number = {2},
url = {https://doi.org/10.1145/3659605},
doi = {10.1145/3659605},
abstract = {Gases in the environment can significantly affect our health and safety. As mobile devices gain popularity, we consider to explore a human-centered gas detection system that can be integrated into commercial mobile devices to realize ubiquitous gas detection. However, existing gas sensors either have too long response delays or are too cumbersome. This paper shows the feasibility of performing gas sensing by shining infrared (IR) signals emitted from our hands through the gas, allowing the system to rely on a single IR detector. The core opportunity arises from the fact that the human hand can provide stable, broadband, and omnidirectional IR radiation. Considering that IR signals experience distinct attenuation when passing through different gases or gases with different concentrations, we can integrate the human hand into the gas sensing system to enable extremely low-power and sustainable gas sensing. Yet, it is challenging to build up a robust system directly utilizing the hand's IR radiation. Practical issues include low IR radiation from the hand, unstable optical path, impact of environmental factors such as ambient temperature, etc. To tackle these issues, we on one hand modulate the IR radiation from the hand leveraging the controllability of the human hand, which improves the hand's IR radiation. On the other hand, we provide a dual-channel IR detector design to filter out the impact of environmental factors and gases in the environment. Extensive experiments show that our system can realize ethanol, gaseous water, and CO2 detection with 96.7\%, 92.1\% and 94.2\%, respectively.},
journal = {Proc. ACM Interact. Mob. Wearable Ubiquitous Technol.},
month = may,
articleno = {69},
numpages = {26},
keywords = {Gas detection, mid-infrared signal, mobile sensing, pyroelectric infrared detector}
}

@article{10.1145/3659597,
author = {Hong, Zhiqing and Li, Zelong and Zhong, Shuxin and Lyu, Wenjun and Wang, Haotian and Ding, Yi and He, Tian and Zhang, Desheng},
title = {CrossHAR: Generalizing Cross-dataset Human Activity Recognition via Hierarchical Self-Supervised Pretraining},
year = {2024},
issue_date = {June 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {8},
number = {2},
url = {https://doi.org/10.1145/3659597},
doi = {10.1145/3659597},
abstract = {The increasing availability of low-cost wearable devices and smartphones has significantly advanced the field of sensor-based human activity recognition (HAR), attracting considerable research interest. One of the major challenges in HAR is the domain shift problem in cross-dataset activity recognition, which occurs due to variations in users, device types, and sensor placements between the source dataset and the target dataset. Although domain adaptation methods have shown promise, they typically require access to the target dataset during the training process, which might not be practical in some scenarios. To address these issues, we introduce CrossHAR, a new HAR model designed to improve model performance on unseen target datasets. CrossHAR involves three main steps: (i) CrossHAR explores the sensor data generation principle to diversify the data distribution and augment the raw sensor data. (ii) CrossHAR then employs a hierarchical self-supervised pretraining approach with the augmented data to develop a generalizable representation. (iii) Finally, CrossHAR fine-tunes the pretrained model with a small set of labeled data in the source dataset, enhancing its performance in cross-dataset HAR. Our extensive experiments across multiple real-world HAR datasets demonstrate that CrossHAR outperforms current state-of-the-art methods by 10.83\% in accuracy, demonstrating its effectiveness in generalizing to unseen target datasets.},
journal = {Proc. ACM Interact. Mob. Wearable Ubiquitous Technol.},
month = may,
articleno = {64},
numpages = {26},
keywords = {Cross-dataset, Cross-domain, Human activity recognition, Self-supervised learning}
}

@article{10.1145/3659598,
author = {Zhang, Qian and Liu, Ke and Wang, Dong},
title = {Sensing to Hear through Memory: Ultrasound Speech Enhancement without Real Ultrasound Signals},
year = {2024},
issue_date = {June 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {8},
number = {2},
url = {https://doi.org/10.1145/3659598},
doi = {10.1145/3659598},
abstract = {Speech enhancement on mobile devices is a very challenging task due to the complex environmental noises. Recent works using lip-induced ultrasound signals for speech enhancement open up new possibilities to solve such a problem. However, these multi-modal methods cannot be used in many scenarios where ultrasound-based lip sensing is unreliable or completely absent. In this paper, we propose a novel paradigm that can exploit the prior learned ultrasound knowledge for multi-modal speech enhancement only with the audio input and an additional pre-enrollment speaker embedding. We design a memory network to store the ultrasound memory and learn the interrelationship between the audio and ultrasound modality. During inference, the memory network is able to recall the ultrasound representations from audio input to achieve multi-modal speech enhancement without needing real ultrasound signals. Moreover, we introduce a speaker embedding module to further boost the enhancement performance as well as avoid the degradation of the recalling when the noise level is high. We adopt an end-to-end multi-task manner to train the proposed framework and perform extensive evaluations on the collected dataset. The results show that our method yields comparable performance with audio-ultrasound methods and significantly outperforms the audio-only methods.},
journal = {Proc. ACM Interact. Mob. Wearable Ubiquitous Technol.},
month = may,
articleno = {68},
numpages = {31},
keywords = {acoustic sensing, deep learning, lip movement, ultrasound speech enhancement}
}

