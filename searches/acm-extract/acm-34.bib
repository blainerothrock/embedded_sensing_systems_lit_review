@inproceedings{10.1145/3569192.3569218,
author = {Barbosa, Luis C. N. and Moreira, Antonio H. J. and Carvalho, Vitor and Vila\c{c}a, Jo\~{a}o L. and Morais, Pedro},
title = {Biosignal Databases for Training of Artificial Intelligent Systems},
year = {2023},
isbn = {9781450396868},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3569192.3569218},
doi = {10.1145/3569192.3569218},
abstract = {Coronavirus disease (COVID-19) is an infectious disease caused by the SARS-CoV-2 virus. Most people infected with the virus will have mild to moderate respiratory diseases, however, the elderly population is the most vulnerable, becoming seriously ill, requiring continuous medical follow-up. In this sense, technologies were developed that allow continuous and individual monitoring of patients, in a home environment, namely through wearable devices, thus avoiding continuous hospitalization. Thus, these devices allow great improvements in data analysis methods since they can continuously acquire the physiological signals of an individual and process them in real-time through artificial intelligence (AI) methods. However, training of AI methods is not straightforward, requiring a large amount of data. In this study, we review the most common biosignal databases available in the literature. A total of thirteen databases were selected. Most of the databases (9 databases) were related to ECG signal, as well as 4 databases containing signals from SPO2, Heart Rate, Blood Pressure, etc. Characteristics were described, namely: the population of the databases, data resolution, sampling rates, sample time, number of signal samples, annotated classes, data acquisition conditions, among other aspects. Overall, this study summarizes and described the public biosignals databases available in the literature, which may be important in the implementation of intelligent classification methods.},
booktitle = {Proceedings of the 9th International Conference on Bioinformatics Research and Applications},
pages = {74–81},
numpages = {8},
keywords = {Wearable Devices, ECG Databases, Biosignals Databases, Artificial Intelligence},
location = {Berlin, Germany},
series = {ICBRA '22}
}

@inproceedings{10.1145/3524614.3528630,
author = {Trieflinger, Stefan and M\"{u}nch, J\"{u}rgen and Weiss, Lukas and Roling, Bastian and Lang, Dominic},
title = {Transformation towards a product-led company: case studies from industry},
year = {2023},
isbn = {9781450393027},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3524614.3528630},
doi = {10.1145/3524614.3528630},
abstract = {Context: Today, companies face increasing market dynamics, rapidly evolving technologies, and rapid changes in customer behavior. Traditional approaches to product development typically fail in such environments and require companies to transform their often feature-driven mindset into a product-led mindset. A promising first step on the way to a product-led company is a better understanding of how product planning can be adapted to the requirements of an increasingly dynamic and uncertain market environment in the sense of product roadmapping. The authors developed the DEEP product roadmap assessment tool to help companies evaluate their current product roadmap practices and identify appropriate actions to transition to a more product-led company. Objective: The goal of this paper is to gain insight into the applicability and usefulness of version 1.1 of the DEEP model. In addition, the benefits, and implications of using the DEEP model in corporate contexts will be explored. Method: We conducted a multiple case study in which participants were observed using the DEEP model. We then interviewed each participant to understand their perceptions of the DEEP model. In addition, we conducted interviews with each company's product management department to learn how the application of the DEEP model influenced their attitudes toward product roadmapping. Results: The study showed that by applying the DEEP model, participants better understood which artifacts and methods were critical to product roadmapping success in a dynamic and uncertain market environment. In addition, the application of the DEEP model helped convince management and other stakeholders of the need to change current product roadmapping practices. The application also proved to be a suitable starting point for the transformation in the participating companies.},
booktitle = {Proceedings of the 5th International Workshop on Software-Intensive Business: Towards Sustainable Software Business},
pages = {9–16},
numpages = {8},
keywords = {agile development, change management, innovation, product management, product roadmap, product strategy, roadmapping},
location = {Pittsburgh, Pennsylvania},
series = {IWSiB '22}
}

@inproceedings{10.1145/3569192.3569213,
author = {Ngueleu, Armelle-Myriane and Batcho, Charles Sebiyo and Otis, Martin J.-D.},
title = {Comparison and validation of pressure and acceleration time-domain waveform models of a smart insole for accurate step count in healthy people},
year = {2023},
isbn = {9781450396868},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3569192.3569213},
doi = {10.1145/3569192.3569213},
abstract = {Several studies have shown good accuracies for step count based on pressure signals of smart insoles in people walking at different speeds. Although smart insoles are often equipped with pressure sensors and accelerometer, no study has focused on comparing the accuracy of step count separately based on pressure and acceleration signals in healthy people. The objectives of this study were to design a waveform model of accelerometer and pressure sensors, and then compare with commercially well-known step count devices and validate these models using manual step counter for step count. Eight healthy participants (age: 39.8±17.56 years old) wore a pair of smart insoles, a GaitUp, and a StepWatchTM and performed the six-minute walking test at walking speeds from 1.62 to 2.22 m/s. Four pressure and one acceleration waveform models were designed and used for the detection of 341 to 412 steps. Accuracies ranged from 99.80\%±0.60\% to 99.97\%±1.38\% for right side, and from 99.67\%±0.63\% to 99.90\%±0.05\% for left side with pressure waveform models. In addition, the acceleration waveform model provided accuracies of 99.87\%±2.49\% and 99.84\%±4.77\% for right and left sides respectively. Step count accuracies using the GaitUp were 99.51\%±2.06\% for right side, and 99.51\%±4.32\% for left side. Finally, the StepWatchTM yielded step count accuracies of 99.31\%±15.95\% and 98.52\%±28.06\% for right and left sides respectively. These results suggested the smart insole with pressure and acceleration waveform models as more accurate than the StepWatchTM and the GaitUp for step count.},
booktitle = {Proceedings of the 9th International Conference on Bioinformatics Research and Applications},
pages = {129–134},
numpages = {6},
keywords = {Waveform models, Validity, Step count, Smart insole, Comparison},
location = {Berlin, Germany},
series = {ICBRA '22}
}

@inproceedings{10.1145/3568834.3568888,
author = {Jacinto, Mariela and Rivera, Melissa and Viacava, Gino},
title = {Lean Service and BPM to Increase the Efficiency of an Operational Process in the Insurance Sector},
year = {2023},
isbn = {9781450397582},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3568834.3568888},
doi = {10.1145/3568834.3568888},
abstract = {One of the pillars of the world economy is the service sector, since in developed and developing countries it contributes 70\% and 45\% of GDP, respectively. For this reason, companies in this sector seek to innovate their processes, become more efficient and competitive. In this sense, Lean Service and BPM stand out for generating efficiency and competitiveness in Back Office processes, through a focus on optimizing the value of processes, eliminating activities and reducing waste. In this case study, the aim is to increase the efficiency of the process of issuing electronic receipts in a Peruvian Banking and Insurance company, through the implementation of Lean and BPM tools such as: electronic 5s, digital Poka Yoke, load balancing and BPMN. Our proposal model includes the aforementioned Lean Service and BPM tools, which together achieve the reduction of rework, reduction of time in operation and reduction of overtime, which translates into increased process efficiency. Although more and more companies are applying Lean tools in the Services sector, there are still few precedents for their application in the Banking and Insurance sector. In this sense, the novelty of our proposal is the application of a model that combines Lean and BPM tools, such as Poka Yoke and electronic 5s in a digital work environment, obtaining favorable results. For this reason, this research will contribute to the scientific community a new model to increase efficiency in companies in the insurance sector in Latin America.},
booktitle = {Proceedings of the 8th International Conference on Industrial and Business Engineering},
pages = {218–222},
numpages = {5},
keywords = {• Lean Service, BPM, Banking, Information Management, Insurance, Poka Yoke, Process redesign},
location = {Macau, China},
series = {ICIBE '22}
}

@inproceedings{10.1145/3560905.3568101,
author = {Sutton, Felix},
title = {The Design of a Battery-Less Wireless Condition Monitoring System for Industrial Circuit Breakers},
year = {2023},
isbn = {9781450398862},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3560905.3568101},
doi = {10.1145/3560905.3568101},
abstract = {Circuit breakers are a fundamental safety device in all residential and industrial electrical distribution installations. The harsh environmental conditions of industrial circuit breakers can lead to unwanted resistance, i.e., due to the build-up of dirt, between the circuit breaker terminals and the conducting metal bars that supply power from the grid. This can lead to excessive heat through the circuit breaker mechanics, which over time, may degrade the lifetime of the circuit breaker. In order to mitigate this, a monitoring system is needed to remotely monitor the temperature of the circuit breaker contact terminals, thus improving scheduled maintenance and minimizing downtime.We present the system design of a battery-less wireless temperature sensor for industrial circuit breakers. We follow well established embedded system design principles, and advocate a refinement to existing design methodologies specific to low-power energy harvesting wireless embedded systems. In this work, we detail each step in the proposed design methodology and present an evaluation of the system prototype in an industrial environment.},
booktitle = {Proceedings of the 20th ACM Conference on Embedded Networked Sensor Systems},
pages = {865–870},
numpages = {6},
location = {Boston, Massachusetts},
series = {SenSys '22}
}

@inproceedings{10.1145/3560905.3568561,
author = {Bakar, Abu and Goel, Rishabh and de Winkel, Jasper and Huang, Jason and Ahmed, Saad and Islam, Bashima and Pawe\l{}czak, Przemys\l{}aw and Y\i{}ld\i{}r\i{}m, Kas\i{}m Sinan and Hester, Josiah},
title = {Protean: An Energy-Efficient and Heterogeneous Platform for Adaptive and Hardware-Accelerated Battery-Free Computing},
year = {2023},
isbn = {9781450398862},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3560905.3568561},
doi = {10.1145/3560905.3568561},
abstract = {Battery-free and intermittently powered devices offer long lifetimes and enable deployment in new applications and environments. Unfortunately, developing sophisticated inference-capable applications is still challenging due to the lack of platform support for more advanced (32-bit) microprocessors and specialized accelerators---which can execute data-intensive machine learning tasks, but add complexity across the stack when dealing with intermittent power. We present Protean to bridge the platform gap for inference-capable battery-free sensors. Designed for runtime scalability, meeting the dynamic range of energy harvesters with matching heterogeneous processing elements like neural network accelerators. We develop a modular "plug-and-play" hardware platform, SuperSensor, with a reconfigurable energy storage circuit that powers a 32-bit ARM-based microcontroller with a convolutional neural network accelerator. An adaptive task-based runtime system, Chameleon, provides intermittency-proof execution of machine learning tasks across heterogeneous processing elements. The runtime automatically scales and dispatches these tasks based on incoming energy, current state, and programmer annotations. A code generator, Metamorph, automates conversion of ML models to intermittent safe execution across heterogeneous compute elements. We evaluate Protean with audio and image workloads and demonstrate up to 666x improvement in inference energy efficiency by enabling usage of modern computational elements within intermittent computing. Further, Protean provides up to 166\% higher throughput compared to non-adaptive baselines.},
booktitle = {Proceedings of the 20th ACM Conference on Embedded Networked Sensor Systems},
pages = {207–221},
numpages = {15},
keywords = {energy harvesting platform, intermittent computing, protean},
location = {Boston, Massachusetts},
series = {SenSys '22}
}

@inproceedings{10.1145/3560905.3568300,
author = {Moss, Arthur and Lee, Hyunjong and Xun, Lei and Min, Chulhong and Kawsar, Fahim and Montanari, Alessandro},
title = {Ultra-Low Power DNN Accelerators for IoT: Resource Characterization of the MAX78000},
year = {2023},
isbn = {9781450398862},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3560905.3568300},
doi = {10.1145/3560905.3568300},
abstract = {The development of edge devices with dedicated hardware accelerators has pushed the deployment and inference of Deep Neural Network (DNN) models closer to users and real-world sensory systems than ever before (e.g., wearables, IoT). Recently, a further subset of these devices has emerged: ultra-low power DNN accelerators. These microcontrollers possess a dedicated hardware accelerator and are able to operate with only μJ's of energy in milliseconds of time. With their small form-factor, such devices could be used for battery-powered machine learning (ML) applications. In this work, we take a close look at one such device: the MAX78000 by Maxim Integrated. We characterize the device's performance by running five DNN models of various sizes and architectures, and analyze its operational latency, power consumption, and memory footprint. To better understand the performance characteristics, we take a step further and investigate how different layer types (operation type, kernel size, number of input and output channels) and the selection of accelerator processors affect the execution time.},
booktitle = {Proceedings of the 20th ACM Conference on Embedded Networked Sensor Systems},
pages = {934–940},
numpages = {7},
keywords = {edge accelerators, neural networks, resource characterisation},
location = {Boston, Massachusetts},
series = {SenSys '22}
}

@inproceedings{10.1145/3560905.3578264,
author = {Chung, Ming-Kuang and Ching, Fu-Shiang and Chen, Ling-Jyh},
title = {From Participatory Sensing to Public-Private Partnership: The Development of AirBox Project in Taiwan},
year = {2023},
isbn = {9781450398862},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3560905.3578264},
doi = {10.1145/3560905.3578264},
abstract = {A complete sensor network should include sensors, data processing, and data services. However, to establish the legitimacy of sensor data for urban governance, sensor networks should go beyond simple deployment of sensors in the built environment and strive for deeper integration of data services within civil society. This paper presents the Taiwan AirBox Project as an exemplary case of practical deployment of a sensor network to discuss the topics of open data, value-added services, and joint calibration services; as well as how these services generate productive public-private partnerships.The AirBox project adopted a strategy of combining open-source hardware, flexible database API, multiple value-added data services, and open-joint calibration to gradually enhance the data quality. The results suggested that: 1. open hardware and open source software are keys to expanding the deployment of the sensor network; 2. open data and diverse value-added services enhance the public's environmental awareness and advocacy; 3. the open joint-calibration system helps connect government policy formulation with public environmental awareness.In addition, the AirBox project demonstrates the feasibility of a democratized deployment strategy. "Openness" serves as the foundation for mutual trust, communication, cooperation, and co-creation among stakeholders involved in the deployment process.},
booktitle = {Proceedings of the 20th ACM Conference on Embedded Networked Sensor Systems},
pages = {1000–1006},
numpages = {7},
keywords = {AirBox, open joint-calibration system, participatory sensing, sensor network deployment},
location = {Boston, Massachusetts},
series = {SenSys '22}
}

@inproceedings{10.1145/3560905.3568525,
author = {Feng, Yuda and Xie, Yaxiong and Ganesan, Deepak and Xiong, Jie},
title = {LTE-Based Low-Cost and Low-Power Soil Moisture Sensing},
year = {2023},
isbn = {9781450398862},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3560905.3568525},
doi = {10.1145/3560905.3568525},
abstract = {Soil moisture sensing is a basic function required by applications like precision irrigation. Recently, RF based soil moisture sensing solutions [10, 43] have been proposed, which, however, can hardly support large scale deployment in challenging outdoor environments, since they must have dedicated signal emitters and also require power supply for either the signal emitters (WiFi or RFID reader) or both the transceivers (WiFi AP and client). LTE signal provides a unique opportunity for soil moisture sensing as the ubiquitously deployed base stations are naturally always-on signal emitters, eliminating the need for deploying extra hardware. In this paper, we implement a low-cost LTE based soil moisture sensor using commercial off-the-shelf hardware. We also realize duty-cycled soil sensing by automatically self-calibrating the phase offset after powering on the devices, significantly reducing the overall power consumption of the sensor. Extensive experiments show that our low-cost sensor ($55) achieves a high accuracy (3.15\%) which is comparable to high-end soil moisture sensors ($850), wide coverage (2.4 km from the base station) and low power consumption (lasting 16 months using batteries).},
booktitle = {Proceedings of the 20th ACM Conference on Embedded Networked Sensor Systems},
pages = {421–434},
numpages = {14},
keywords = {LTE sensing, low-power and low-cost sensing, pervasive sensing, smart agriculture, soil moisture sensing},
location = {Boston, Massachusetts},
series = {SenSys '22}
}

@inproceedings{10.1145/3560905.3567769,
author = {Sun, Yifei and Liu, Yuxuan and Wang, Ziteng and Qu, Xiaolei and Zheng, Dezhi and Chen, Xinlei},
title = {C-RIDGE: Indoor CO2 Data Collection System for Large Venues Based on prior Knowledge},
year = {2023},
isbn = {9781450398862},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3560905.3567769},
doi = {10.1145/3560905.3567769},
abstract = {CO2 concentration data with high resolution in large venues is highly required during indoor sport events for in-time environment adjustment to guarantee the athlete performances and audience experience. However, the limited battery energy of the wireless sensors cannot support high data resolution and long time coverage simultaneously. Besides, there also lacks effective embedded methods to clean anomaly data caused by the human and environmental factors probably occurring in large venues. Thus, in this paper, we propose C-RIDGE, a low-power sensing system for high resolution CO2 data collection in large venues. Based on prior knowledge, firstly, an adaptive sampling rate adjustment policy is developed for lower energy consumption to extend the time coverage of data. Secondly, CO2 physical property (CPP) aided data cleaning algorithm is designed to improve data quality as well, using Pearson Correlation Coefficient (PCC) and standard deviation with sliding windows. C-RIDGE has been deployed in one venue during a world-class event. The experiments and collected data have shown the system power consumption can be reduced by 36.1\%, with measurement error less than 10.2\%. The outliers and anomaly trends can also be detected and calibrated effectively via CPP algorithm. The dataset is available at https://doi.org/10.5281/zenodo.7160830.},
booktitle = {Proceedings of the 20th ACM Conference on Embedded Networked Sensor Systems},
pages = {1077–1082},
numpages = {6},
keywords = {CO2 sensing, data analysis, data collection, low power system},
location = {Boston, Massachusetts},
series = {SenSys '22}
}

@inproceedings{10.1145/3560905.3568110,
author = {Madden, John and Marcano, Gabriel and Taylor, Stephen and Pannuto, Pat and Josephson, Colleen},
title = {Hardware to Enable Large-Scale Deployment and Observation of Soil Microbial Fuel Cells},
year = {2023},
isbn = {9781450398862},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3560905.3568110},
doi = {10.1145/3560905.3568110},
abstract = {Soil microbial fuel cells are a promising source of energy for outdoor sensor networks. These biological systems are sensitive to environmental conditions, therefore more data is needed on their behavior "in the wild" to enable the creation of an energy system capable of being widely deployed. Prior work on early characterization of microbial fuel cells relied on extremely accurate, but expensive, logging hardware. To scale up the number of deployment sites, we present custom logging hardware, specially designed to accurately monitor the behavior of microbial fuel cells at low cost. This paper describes the design and evaluation of the board, which is open source and freely available on GitHub.},
booktitle = {Proceedings of the 20th ACM Conference on Embedded Networked Sensor Systems},
pages = {906–912},
numpages = {7},
keywords = {microbial fuel cell, power harvesting, power monitoring, sensor networks},
location = {Boston, Massachusetts},
series = {SenSys '22}
}

@inproceedings{10.1145/3560905.3568528,
author = {Li, Dong and Liu, Jialin and Lee, Sunghoon Ivan and Xiong, Jie},
title = {Room-Scale Hand Gesture Recognition Using Smart Speakers},
year = {2023},
isbn = {9781450398862},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3560905.3568528},
doi = {10.1145/3560905.3568528},
abstract = {Acoustic signal has been recently adopted for contact-free hand gesture recognition due to its fine-grained sensing granularity and wide availability of microphone and speaker in consumer-grade electronic devices such as smartphones. However, a very limited sensing range constrains acoustic sensing to application scenarios where users interact with devices in close proximity. In this paper, we improve the range of acoustic sensing and demonstrate the feasibility of enabling room-scale hand gesture recognition using commodity smart speakers. We develop a series of novel signal processing techniques and implement our system on two commodity smart speaker prototypes with different numbers of microphones. Extensive evaluations are performed in three different environments with 1440 gestures collected from 16 participants. Experiment results show that our system can significantly increase the sensing range from 1 m to 4--5 m. In the challenging scenario where the user is 4 m away from the smart speaker and there is strong interference, the achieved gesture recognition accuracy is still higher than 90\%.},
booktitle = {Proceedings of the 20th ACM Conference on Embedded Networked Sensor Systems},
pages = {462–475},
numpages = {14},
keywords = {contact-free acoustic sensing, room-scale hand gesture recognition, smart speaker},
location = {Boston, Massachusetts},
series = {SenSys '22}
}

@inproceedings{10.1145/3560905.3567764,
author = {Katsidimas, Ioannis and Kotzakolios, Thanasis and Nikoletseas, Sotiris and Panagiotou, Stefanos H. and Timpilis, Konstantinos and Tsakonas, Constantinos},
title = {Impact Events for Structural Health Monitoring of a Plastic Thin Plate: Dataset},
year = {2023},
isbn = {9781450398862},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3560905.3567764},
doi = {10.1145/3560905.3567764},
abstract = {Nowadays, more and more datasets are published towards research and development of systems and models, enabling direct comparisons, continuous improvement of solutions, and researchers engagement with experimental, real life data. However, especially in the Structural Health Monitoring (SHM) domain, there are plenty of cases where new research projects have a unique combination of structure design and implementation, sensor selection and technological enablers that does not fit with the configuration of relevant individual studies in the literature. Thus, we share the data from our case study to the research community as we did not find any relevant repository available. More specifically, in this paper, we present a novel time-series dataset for impact detection and localization on a plastic thin-plate, towards Structural Health Monitoring applications, using ceramic piezoelectric transducers (PZTs) connected to an Internet of Things (IoT) device. The dataset was collected from an experimental procedure of low-velocity, low-energy impact events that includes at least 3 repetitions for each unique experiment, while the input measurements come from 4 PZT sensors placed at the corners of the plate. For each repetition and sensor, 5000 values are stored with 100 KHz sampling rate. The system is excited with a steel ball, and the height from which it is released varies from 10 cm to 20 cm. The dataset is available in GitHub (https://github.com/Smart-Objects/Impact-Events-Dataset).},
booktitle = {Proceedings of the 20th ACM Conference on Embedded Networked Sensor Systems},
pages = {1020–1025},
numpages = {6},
keywords = {PZT sensor data, dataset, impact events, microcontroller, structural health monitoring, thin plate},
location = {Boston, Massachusetts},
series = {SenSys '22}
}

@inproceedings{10.1145/3560905.3568529,
author = {Wang, Kailong and Shi, Cong and Cheng, Jerry and Wang, Yan and Xie, Minge and Chen, Yingying},
title = {Solving the WiFi Sensing Dilemma in Reality Leveraging Conformal Prediction},
year = {2023},
isbn = {9781450398862},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3560905.3568529},
doi = {10.1145/3560905.3568529},
abstract = {With the wide deployment of smart environments and IoT devices, WiFi sensing has demonstrated its great convenience and contactless sensing capabilities in supporting a broad array of applications. However, designing a ubiquitous WiFi sensing system for heterogeneous scenarios in practice is still a big dilemma as the system performs poorly when the testing data is significantly different from the training data caused by domain variations. To address this dilemma, existing studies involve extra efforts to develop new features or even to retrain the original model under environmental variations. However, none of them can resolve the dilemma completely. In this work, we conduct a comprehensive study on the domain variation problem to make WiFi sensing robust and accurate in reality. Our definition of domains is comprehensive and includes environments, surrounding settings, user differences, user's facing directions, user's positions relative to WiFi sensors, and user participating time frames. Our innovation is to achieve reliable WiFi sensing across all the domains based on the conformal prediction framework. Our approach quantifies the conformity (i.e., similarity) between the testing WiFi samples and the training samples, then labels the testing samples with the most probable class(es). We develop a novel cross-domain transformal prediction scheme based on the multivariate kernel density estimation to effectively assess and learn the conformity of each domain in the training data. To meet various application-specific requirements, we further develop two approaches to fuse the knowledge of conformity derived from the training domains to perform predictions. Extensive experiments with both self-collected and public datasets show that our framework can improve prediction accuracies from 30\% to 74\% improvements in three most representative WiFi-based applications across six types of domain variations.},
booktitle = {Proceedings of the 20th ACM Conference on Embedded Networked Sensor Systems},
pages = {407–420},
numpages = {14},
keywords = {conformal prediction, domain variations, wifi sensing},
location = {Boston, Massachusetts},
series = {SenSys '22}
}

@inproceedings{10.1145/3560905.3568435,
author = {Dong, Yiwen and Liu, Jingxiao and Noh, Hae Young},
title = {GaitVibe+: Enhancing Structural Vibration-Based Footstep Localization Using Temporary Cameras for in-Home Gait Analysis},
year = {2023},
isbn = {9781450398862},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3560905.3568435},
doi = {10.1145/3560905.3568435},
abstract = {In-home gait analysis is important for providing early diagnosis and adaptive treatments for individuals with gait disorders. Existing systems include wearables and pressure mats, but they have limited scalability due to dense deployment and device carrying/charging requirements. Recently, vision-based systems have been developed to enable scalable, accurate in-home gait analysis, but it faces privacy concerns due to the exposure of people's appearances and daily activities. To overcome these limitations, our prior work developed footstep-induced structural vibration sensing for in-home gait monitoring, which is device-free, wide-ranged, and perceived as more privacy-friendly. Although it has succeeded in temporal parameter estimation, it shows limited performance for spatial gait parameter estimation due to the low accuracy in footstep localization. In particular, the localization error mainly comes from the estimation error of the wave arrival time at the vibration sensors and its error propagation to wave velocity estimations. To this end, we present GaitVibe+, a vibration-based footstep localization method fused with temporarily installed cameras for in-home gait analysis. Our method has two stages: fusion and operating stages. In the fusion stage, both cameras and vibration sensors are installed to record only a few trials of the subject's footstep data, through which we characterize the uncertainty in wave arrival time and model the wave velocity profiles for the given structure. In the operating stage, we remove the camera to preserve privacy at home. The footstep localization is conducted by estimating the time difference of arrival (TDoA) over multiple vibration sensors, whose accuracy is improved through the reduced uncertainty and velocity modeling during the fusion stage. We evaluate GaitVibe+ through a real-world experiment with 50 walking trials. With only 3 trials of multi-modal fusion, our approach has an average localization error of 0.22 meters, which reduces the spatial gait parameter error by 4.1x (from 111.4\% to 27.1\%) compared to the existing work.},
booktitle = {Proceedings of the 20th ACM Conference on Embedded Networked Sensor Systems},
pages = {1168–1174},
numpages = {7},
keywords = {computer vision, in-home gait analysis, localization, multi-modal fusion, spatial gait parameter, vibration},
location = {Boston, Massachusetts},
series = {SenSys '22}
}

@inproceedings{10.1145/3560905.3568510,
author = {Luo, Wenjie and Song, Qun and Yan, Zhenyu and Tan, Rui and Lin, Guosheng},
title = {Indoor Smartphone SLAM with Learned Echoic Location Features},
year = {2023},
isbn = {9781450398862},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3560905.3568510},
doi = {10.1145/3560905.3568510},
abstract = {Indoor self-localization is a highly demanded system function for smartphones. The current solutions based on inertial, radio frequency, and geomagnetic sensing may have degraded performance when their limiting factors take effect. In this paper, we present a new indoor simultaneous localization and mapping (SLAM) system that utilizes the smartphone's built-in audio hardware and inertial measurement unit (IMU). Our system uses a smartphone's loud-speaker to emit near-inaudible chirps and then the microphone to record the acoustic echoes from the indoor environment. Our profiling measurements show that the echoes carry location information with sub-meter granularity. To enable SLAM, we apply contrastive learning to construct an echoic location feature (ELF) extractor, such that the loop closures on the smartphone's trajectory can be accurately detected from the associated ELF trace. The detection results effectively regulate the IMU-based trajectory reconstruction. Extensive experiments show that our ELF-based SLAM achieves median localization errors of 0.1 m, 0.53 m, and 0.4m on the reconstructed trajectories in a living room, an office, and a shopping mall, and outperforms the Wi-Fi and geomagnetic SLAM systems.},
booktitle = {Proceedings of the 20th ACM Conference on Embedded Networked Sensor Systems},
pages = {489–503},
numpages = {15},
keywords = {acoustic sensing, simultaneous localization and mapping},
location = {Boston, Massachusetts},
series = {SenSys '22}
}

@inproceedings{10.1145/3560905.3568530,
author = {Fu, Yongjian and Wang, Shuning and Zhong, Linghui and Chen, Lili and Ren, Ju and Zhang, Yaoxue},
title = {SVoice: Enabling Voice Communication in Silence via Acoustic Sensing on Commodity Devices},
year = {2023},
isbn = {9781450398862},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3560905.3568530},
doi = {10.1145/3560905.3568530},
abstract = {Silent Speech Interface (SSI) has been proposed as a means of reconstructing audible speech from silent articulatory gestures for covert voice communication in public and voice assistance for the aphasic. Prior arts of SSI, either relying on wearable devices or cameras, may lead to extended contact requirements or privacy leakage risks. The recent advances in acoustic sensing have brought new opportunities for sensing gestures, but their original intention is to infer speech content for classification instead of audible speech reconstruction, resulting in the loss of some important speech information (e.g., speech rate, intonation, and emotion). In this paper, we propose, the first system that supports accurate audible speech reconstruction by analyzing the disturbance of tiny articulatory gestures on the reflected ultrasound signal. The design of introduces a new model that provides the unique mapping relationship between ultrasound and speech signals, so that the audible speech can be successfully reconstructed from the silent speech. However, establishing the mapping relationship depends on plenty of training data. Instead of the time-consuming collection of massive amounts of data for training, we construct an inverse task that constitutes a dual form with the original task to generate virtual gestures from widely available audio (e.g., phone calls) for facilitating model training. Furthermore, we introduce a fine-tuning mechanism using unlabeled data for user adaptation. We implement using a portable smartphone and evaluate it in various environments. The evaluation results show that can reconstruct speech with a (Character Error Rate) CER as low as 7.62\%, and decrease the CER from 82.77\% to 9.42\% on new users with only 1 hour of ultrasound signals provided, which outperforms state-of-the-art acoustic-based approaches while preserving rich speech information.},
booktitle = {Proceedings of the 20th ACM Conference on Embedded Networked Sensor Systems},
pages = {622–636},
numpages = {15},
keywords = {acoustic sensing, cGAN, silent speech, transformer},
location = {Boston, Massachusetts},
series = {SenSys '22}
}

@inproceedings{10.1145/3560905.3568539,
author = {Zhang, Yan and Zhu, Yi and Liu, Zihao and Miao, Chenglin and Hajiaghajani, Foad and Su, Lu and Qiao, Chunming},
title = {Towards Backdoor Attacks against LiDAR Object Detection in Autonomous Driving},
year = {2023},
isbn = {9781450398862},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3560905.3568539},
doi = {10.1145/3560905.3568539},
abstract = {Due to the great advantage of LiDAR sensors in perceiving complex driving environments, LiDAR-based 3D object detection has recently drawn significant attention in autonomous driving. Although many advanced LiDAR object detection models have been developed, their designs are mainly based on deep learning approaches, which are usually data-hungry and expensive to train. Thus, it is common for some LiDAR perception system developers or self-driving car companies to collect training data from different sources (e.g., self-driving car users) or outsource the training work to a third party. However, these practices provide opportunities for backdoor attacks, where the attacker aims to inject a hidden trigger pattern into the victim detection model by poisoning its training set and let the model fail to detect objects when the trigger presents in the inference phase. Although backdoor attacks have posed serious security concerns, the vulnerability of LiDAR object detection to such attacks has not yet been studied. To fill the research gap, in this paper, we present the first study on backdoor attacks against LiDAR object detection in autonomous driving. Specifically, we propose a novel backdoor attack strategy based on which the attacker can achieve the attack goal by poisoning a small number of point cloud samples. In addition, the proposed attack strategy is physically realizable, and it allows the attacker to easily perform the attack using some common objects as the triggers. To make the poisoned samples difficult to be detected, we also design a stealthy attack strategy by creating some fake vehicle point clusters to hide the injected points in the point cloud. The desirable performance of our attacks is demonstrated through both simulation and real-world case study.},
booktitle = {Proceedings of the 20th ACM Conference on Embedded Networked Sensor Systems},
pages = {533–547},
numpages = {15},
keywords = {LiDAR object detection, autonomous driving, backdoor attack},
location = {Boston, Massachusetts},
series = {SenSys '22}
}

@inproceedings{10.1145/3560905.3568414,
author = {Boubin, Jayson and Zhang, Zichen and Chumley, John and Stewart, Christopher},
title = {Adaptive Deployment for Autonomous Agricultural UAV Swarms},
year = {2023},
isbn = {9781450398862},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3560905.3568414},
doi = {10.1145/3560905.3568414},
abstract = {Unmanned aerial vehicles (UAV) play a critical role in many edge computing deployments and applications. UAV are prized for their maneuverability, low cost, and sensing capacity, facilitating many applications that would otherwise be prohibitively expensive or dangerous without them. UAV are cheaper than alternative aerial analysis methods, but still incur costs from expensive human piloting and workloads which necessitate high-resolution coverage of large areas. Recently, autonomous UAV swarms have emerged to increase the speed of deployments, decrease the cost and scope of human piloting, and improve the quality of autonomous decision-making through data sharing. Autonomous UAV deployments, however, suffer from external factors. UAV are inherently power-constrained, with low onboard battery lives and limited ability to siphon power from the edge systems that support them. Certain environmental conditions, like inclement weather, wind, extreme heat, and low light also affect UAV power consumption, sensed data quality, and ultimately mission success. In this paper, we present an empirically based model for efficient autonomous swarm deployment. We built and deployed a real autonomous UAV swarm to map leaf defoliation in soybeans. Using this deployment, we determined environmental conditions which led to malfunctions, inefficient edge energy usage, and mispredictions. Using these findings, we developed a deployment model for UAV swarms that decreases malfunctions and data irregularities by 4.9X and decreases edge energy consumption by 45\%, while increasing deployment times by only 4\%.},
booktitle = {Proceedings of the 20th ACM Conference on Embedded Networked Sensor Systems},
pages = {1089–1095},
numpages = {7},
location = {Boston, Massachusetts},
series = {SenSys '22}
}

@inproceedings{10.1145/3560905.3568531,
author = {Jiang, Linshan and Song, Qun and Tan, Rui and Li, Mo},
title = {PriMask: Cascadable and Collusion-Resilient Data Masking for Mobile Cloud Inference},
year = {2023},
isbn = {9781450398862},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3560905.3568531},
doi = {10.1145/3560905.3568531},
abstract = {Mobile cloud offloading is indispensable for inference tasks based on large-scale deep models. However, transmitting privacy-rich inference data to the cloud incurs concerns. This paper presents the design of a system called PriMask, in which the mobile device uses a secret small-scale neural network called MaskNet to mask the data before transmission. PriMask significantly weakens the cloud's capability to recover the data or extract certain private attributes. The MaskNet is cascadable in that the mobile can opt in to or out of its use seamlessly without any modifications to the cloud's inference service. Moreover, the mobiles use different MaskNets, such that the collusion between the cloud and some mobiles does not weaken the protection for other mobiles. We devise a split adversarial learning method to train a neural network that generates a new MaskNet quickly (within two seconds) at run time. We apply PriMask to three mobile sensing applications with diverse modalities and complexities, i.e., human activity recognition, urban environment crowdsensing, and driver behavior recognition. Results show PriMask's effectiveness in all the three applications.},
booktitle = {Proceedings of the 20th ACM Conference on Embedded Networked Sensor Systems},
pages = {164–178},
numpages = {15},
keywords = {cloud inference, dynamic neural networks, privacy-preserving techniques},
location = {Boston, Massachusetts},
series = {SenSys '22}
}

@inproceedings{10.1145/3560905.3567768,
author = {Yuan, Shiji and Sun, Ying and Wang, Shuai and Chen, Xinlei and Ding, Ying and Zheng, Dezhi and Fan, Shangchun},
title = {Non-Acoustic Speech Sensing System Based on Flexible Piezoelectric},
year = {2023},
isbn = {9781450398862},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3560905.3567768},
doi = {10.1145/3560905.3567768},
abstract = {Speech is one of the most important biological signals to complement human-human and human-computer interaction. Traditional speech datasets were collected by air microphones, but using these datasets in noisy environments such as factories is practically challenging. Therefore, speech recognition in noisy environments poses higher requirements. The non-acoustic speech dataset plays a significant role in robust speech recognition under high background noise. Existing datasets suffered from dull sound, low intelligibility and poor recognition accuracy due to hardware and computer technology limitations. This paper presents a non-acoustic speech sensing system based on flexible piezoelectric. The system collected vibration signals from the jaws of six males and five females, and the corpus contained ten different control commands at 90 dB of background noise. The dataset is reliable with high intelligibility and capable of achieving 93.7\% recognition accuracy by calculation. With the aforementioned benefits, this dataset is an essential tool for studying human-computer interaction in high-noise environments, analyzing human acoustic properties, and aiding medical rehabilitation.},
booktitle = {Proceedings of the 20th ACM Conference on Embedded Networked Sensor Systems},
pages = {1055–1060},
numpages = {6},
keywords = {flexible piezoelectric sensor, non-acoustic speech, speech command data},
location = {Boston, Massachusetts},
series = {SenSys '22}
}

@inproceedings{10.1145/3560905.3568437,
author = {Yin, Xiangyu and Huang, Kai and Forno, Erick and Chen, Wei and Huang, Heng and Gao, Wei},
title = {Out-Clinic Pulmonary Disease Evaluation via Acoustic Sensing and Multi-Task Learning on Commodity Smartphones},
year = {2023},
isbn = {9781450398862},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3560905.3568437},
doi = {10.1145/3560905.3568437},
abstract = {Pulmonary diseases, such as asthma and Chronic Obstructive Pulmonary Disease (COPD), constitute a major public health challenge. The disease symptoms, including airway obstruction and inflammation, usually result in changes in airway mechanical properties, such as the caliber and impedance of the airway. To measure such airway properties for disease evaluation and diagnosis purposes, pulmonary function tests (PFT) has been widely adopted. However, most existing PFT systems require expensive and cumbersome hardware that are impossible to be used out of clinic. To allow out-clinic continuous pulmonary disease evaluation, in this paper we present AWARE, a new sensing and AI system that supports accurate and reliable PFT using commodity smartphones. AWARE uses a smartphone to transmit acoustic signals and reconstructs the profile of human airway based on the analysis of reflected acoustic waves captured from the smartphone's microphone. The subject's pulmonary condition is then evaluated by a multi-task learning model that integrates both the airway measurements and the subject's lung function records as the ground truth. Evaluations on 75 human subjects demonstrate that AWARE has the capability to achieve 80\% accuracy on distinguishing between humans with healthy pulmonary function and with asthma symptoms.},
booktitle = {Proceedings of the 20th ACM Conference on Embedded Networked Sensor Systems},
pages = {1182–1188},
numpages = {7},
keywords = {acoustic sensing, multitask learning, pulmonary disease evaluation, smartphone},
location = {Boston, Massachusetts},
series = {SenSys '22}
}

@inproceedings{10.1145/3560905.3568108,
author = {Brunner, Hannah and Boano, Carlo Alberto and R\"{o}mer, Kay},
title = {Leakage-Aware Lifetime Estimation of Battery-Free Sensor Nodes Powered by Supercapacitors},
year = {2023},
isbn = {9781450398862},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3560905.3568108},
doi = {10.1145/3560905.3568108},
abstract = {Battery-free sensor nodes rely solely on energy harvested from the environment and thus employ supercapacitors as energy storage to allow perpetual operation in absence of ambient energy. To guarantee that the sensor nodes can survive in periods where no harvested energy is available, it is crucial to accurately estimate the lifetime of these devices. However, as we show experimentally in this paper, an accurate lifetime estimation is non-trivial due to the supercapacitors' complex discharge characteristics (e.g., leakage currents) and large capacitance tolerances. After showing that empirical data capturing the supercapacitors' characteristics is essential towards an accurate estimation of the system's lifetime, we introduce an enhanced leakage model that is computationally lightweight and evaluate its accuracy experimentally.},
booktitle = {Proceedings of the 20th ACM Conference on Embedded Networked Sensor Systems},
pages = {892–898},
numpages = {7},
keywords = {battery-free systems, leakage, sensor nodes, supercapacitors},
location = {Boston, Massachusetts},
series = {SenSys '22}
}

@inproceedings{10.1145/3560905.3568420,
author = {Saffari, Ali and Iyer, Vikram and Kapetanovic, Zerina and Ranganathan, Vaishnavi},
title = {Smart Pallets: Toward Self-Powered Pallet-Level Environmental Sensors for Food Supply Chains},
year = {2023},
isbn = {9781450398862},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3560905.3568420},
doi = {10.1145/3560905.3568420},
abstract = {This work highlights the need for a low-cost and low-overhead solution to monitor pallet-level environment in the food supply chain to create traceability, accountability and reduce wastage. We identify post-harvest sensing through the supply chain as a key need to reduce food waste. Toward this end, we develop initial prototypes of two different wireless environmental sensing architectures. The first leverages an ultra-low power timer with a current consumption of 35 nA to power gate and periodically wake up the system. The second mode explores a sparse event driven sensing model leveraging the threshold detection features of low power sensors to log events of interest. We demonstrate a millimeter scale prototypes that can read and backscatter temperature and humidity data with as little as 3.2 μW of power.},
booktitle = {Proceedings of the 20th ACM Conference on Embedded Networked Sensor Systems},
pages = {1130–1135},
numpages = {6},
keywords = {RFID, WISP, backscatter, environmental sensors, food supply chain, smart agriculture, smart pallet, wireless sensors},
location = {Boston, Massachusetts},
series = {SenSys '22}
}

@inproceedings{10.1145/3560905.3568416,
author = {Dong, Yiwen and Codling, Jesse R and Rohrer, Gary and Miles, Jeremy and Sharma, Sudhendu and Brown-Brandl, Tami and Zhang, Pei and Noh, Hae Young},
title = {PigV2: Monitoring Pig Vital Signs through Ground Vibrations Induced by Heartbeat and Respiration},
year = {2023},
isbn = {9781450398862},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3560905.3568416},
doi = {10.1145/3560905.3568416},
abstract = {Pig vital sign monitoring (e.g., estimating the heart rate (HR) and respiratory rate (RR)) is essential to understand the stress level of the sow and detect the onset of parturition. It helps to maximize peri-natal survival and improve animal well-being in swine production. The existing approach mainly relies on manual measurement, which is labor-intensive and only provides a few points of information. Other sensing modalities such as wearables and cameras are developed to enable more continuous measurement, but are still limited due to animal discomfort, data transfer, and storage challenges. In this paper, we introduce PigV2, the first system to monitor pig heart rate and respiratory rate through ground vibrations. Our approach leverages the insight that both heartbeat and respiration generate ground vibrations when the sow is lying on the floor. We infer vital information by sensing and analyzing these vibrations. The main challenge in developing PigV2 is the overlap of vital- and non-vital-related information in the vibration signals, including pig movements, pig postures, pig-to-sensor distances, and so on. To address this issue, we first characterize their effects, extract their current status, and then reduce their impact by adaptively interpolating vital rates over multiple sensors. PigV2 is evaluated through a real-world deployment with 30 pigs. It has 3.4\% and 8.3\% average errors in monitoring the HR and RR of the sows, respectively.},
booktitle = {Proceedings of the 20th ACM Conference on Embedded Networked Sensor Systems},
pages = {1102–1108},
numpages = {7},
keywords = {heart rate, pig, precision livestock farming, respiratory rate, structural vibration, vital signs},
location = {Boston, Massachusetts},
series = {SenSys '22}
}

@article{10.1145/3517014,
author = {Wu, Yue and Li, Fan and Xie, Yadong and Wang, Yu and Yang, Zheng},
title = {SymListener: Detecting Respiratory Symptoms via Acoustic Sensing in Driving Environments},
year = {2023},
issue_date = {February 2023},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {19},
number = {1},
issn = {1550-4859},
url = {https://doi.org/10.1145/3517014},
doi = {10.1145/3517014},
abstract = {Sound-related respiratory symptoms are commonly observed in our daily lives. They are closely related to illnesses, infections, or allergies but ignored by the majority. Existing detection methods either depend on specific devices, which are inconvenient to wear, or are sensitive to noises and only work for indoor environment. Considering the lack of monitoring method for in-car environment, where there is high risk of spreading infectious diseases, we propose a smartphone-based system, named SymListener, to detect respiratory symptoms in driving environment. By continuously recording acoustic data through a built-in microphone, SymListener can detect the sounds of cough, sneeze, and sniffle. We design a modified ABSE-based method to remove the strong and changeable driving noises while saving energy of the smartphone. An LSTM network is adopted to classify the three types of symptoms according to the carefully designed acoustic features. We implement SymListener on different Android devices and evaluate its performance in real driving environment. The evaluation results show that SymListener can reliably detect target respiratory symptoms with an average accuracy of 92.19\% and an average precision of 90.91\%.},
journal = {ACM Trans. Sen. Netw.},
month = jan,
articleno = {3},
numpages = {21},
keywords = {smartphone application, acoustic sensing, Respiratory symptom detection}
}

@inproceedings{10.1145/3574131.3574439,
author = {Liu, Chaoyi and Shi, Rongkai and Xiang, Nan and Ma, Jieming and Liang, Hai-Ning},
title = {A Low-cost Efficient Approach to Synchronize Real-world and Virtual-world Objects in VR via In-built Cameras},
year = {2023},
isbn = {9798400700316},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3574131.3574439},
doi = {10.1145/3574131.3574439},
abstract = {Virtual reality (VR) technology has become a growing force in entertainment, education, science, and manufacturing due to the capability of providing users with immersive experiences and natural interaction. Although common input devices such as controllers, gamepads, and trackpads have been integrated into mainstream VR systems for user-content interaction, they cannot provide users with realistic haptic feedback. Some prior work tracks and maps the physical objects into the virtual space to allow users to interact with these objects directly, which improves users’ sense of reality in the virtual environment. However, most of them use additional hardware sensors, which inevitably increases the cost. In this research, a lightweight approach is proposed to synchronize the positions and motions between physical and digital objects without any extra costs. We use the real-time captured video data from in-built cameras on a VR headset and employ feature points based algorithms to generate projections of the physical objects in the virtual world. Our approach does not rely on additional sensors but just uses components available in a VR headset. Our approach allows users to interact with target objects with their hands directly without the need for specially designed trackers, markers, and other hardware devices as used in previous work. With our approach, users can get more realistic operational feedback when interacting with corresponding virtual objects.},
booktitle = {Proceedings of the 18th ACM SIGGRAPH International Conference on Virtual-Reality Continuum and Its Applications in Industry},
articleno = {32},
numpages = {8},
keywords = {Virtual Reality, Object Synchronization, Augmented Reality},
location = {Guangzhou, China},
series = {VRCAI '22}
}

@inproceedings{10.1145/3574131.3574456,
author = {Cui, Dixuan and Mousas, Christos},
title = {Evaluating the Sense of Embodiment through Out-of-Body Experience and Tactile Feedback},
year = {2023},
isbn = {9798400700316},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3574131.3574456},
doi = {10.1145/3574131.3574456},
abstract = {Out-of-body experience (OBE) is generated by sensory disintegration. In virtual reality (VR), we can provide OBE to people by switching the first-person perspective (1PP) to the third-person perspective (3PP). Generally, 1PP is the choice for high body ownership and presence. Moreover, tactile feedback that is experienced from the 1PP can provide a higher immersive experience. However, whether the combination of 3PP and tactile feedback could affect the sense of embodiment in immersive environments is underexplored. Thus, we conducted a 2 \texttimes{} 2 (OBE: 1PP vs. 3PP \texttimes{} Tactile Feedback [TF]: with vs. without tactile feedback) VR study to discover the effect of OBE in the presence of TF. In our study, we examined OBE and TF through the five dimensions of the sense of embodiment: body ownership, agency, tactile sensations, location of the body, and response to external stimuli. We developed an application to replicate the rubber hand illusion (RHI) study with partial body tracking. We found significant results for both OBE and TF in different dimensions of embodiment. Specifically, we revealed that 3PP decreased the body’s sense of body ownership, agency, and location. Moreover, enabling tactile feedback induced tactile sensations and responses to external stimuli. In the remainder of this paper, we discuss our findings and limitations and provide directions for future studies on OBE in VR.},
booktitle = {Proceedings of the 18th ACM SIGGRAPH International Conference on Virtual-Reality Continuum and Its Applications in Industry},
articleno = {23},
numpages = {7},
keywords = {virtual reality, tactile feedback, self-avatar, out-of-body experience, embodiment},
location = {Guangzhou, China},
series = {VRCAI '22}
}

@article{10.1145/3539659,
author = {Rizk, Hamada and Yamaguchi, Hirozumi and Youssef, Moustafa and Higashino, Teruo},
title = {Laser Range Scanners for Enabling Zero-overhead WiFi-based Indoor Localization System},
year = {2023},
issue_date = {March 2023},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {9},
number = {1},
issn = {2374-0353},
url = {https://doi.org/10.1145/3539659},
doi = {10.1145/3539659},
abstract = {Robust and accurate indoor localization has been the goal of several research efforts over the past decade. Toward achieving this goal, WiFi fingerprinting-based indoor localization systems have been proposed. However, fingerprinting involves significant effort—especially when done at high density—and needs to be repeated with any change in the deployment area. While a number of recent systems have been introduced to reduce the calibration effort, these still trade overhead with accuracy. This article presents LiPhi++, an accurate system for enabling fingerprinting-based indoor localization systems without the associated data collection overhead. This is achieved by leveraging the sensing capability of transportable laser range scanners to automatically label WiFi scans, which can subsequently be used to build (and maintain) a fingerprint database. As part of its design, LiPhi++ leverages this database to train a deep long short-term memory network utilizing the signal strength history from the detected access points. LiPhi++ also has provisions for handling practical deployment issues, including the noisy wireless environment, heterogeneous devices, among others. Evaluation of LiPhi++ using Android phones in two realistic testbeds shows that it can match the performance of manual fingerprinting techniques under the same deployment conditions without the overhead associated with the traditional fingerprinting process. In addition, LiPhi++ improves upon the median localization accuracy obtained from crowdsourcing-based and fingerprinting-based systems by 284\% and 418\%, respectively, when tested with data collected a few months later.},
journal = {ACM Trans. Spatial Algorithms Syst.},
month = jan,
articleno = {4},
numpages = {25},
keywords = {deep learning, laser range scanners, WiFi, fingerprinting, Indoor localization}
}

@article{10.1145/3571297,
author = {Amores, Judith},
title = {The Future of Technology for Cognitive Enhancement and Well-Being: Olfactory Wearables},
year = {2023},
issue_date = {Winter 2022},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {29},
number = {2},
issn = {1528-4972},
url = {https://doi.org/10.1145/3571297},
doi = {10.1145/3571297},
abstract = {The sense of smell, or olfaction, is probably the most underappreciated and the least understood and exploited in human-computer interaction. However, in the future, wearable devices will not only be able to sense and provide audio-visual cues but will also augment our sense of smell. How will this impact our interaction with technology? Does the future stink?},
journal = {XRDS},
month = jan,
pages = {18–23},
numpages = {6}
}

@article{10.1145/3569484,
author = {Zhao, Yiran and Tao, Yujie and Le, Grace and Maki, Rui and Adams, Alexander and Lopes, Pedro and Choudhury, Tanzeem},
title = {Affective Touch as Immediate and Passive Wearable Intervention},
year = {2023},
issue_date = {December 2022},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {6},
number = {4},
url = {https://doi.org/10.1145/3569484},
doi = {10.1145/3569484},
abstract = {We investigated affective touch as a new pathway to passively mitigate in-the-moment anxiety. While existing mobile interventions offer great promises for health and well-being, they typically focus on achieving long-term effects such as shifting behaviors. As such, most mobile interventions are not applicable to provide immediate help in acute conditions -- when a user experiences a high anxiety level during ongoing events (e.g., completing high-stake tasks or mitigating interpersonal conflicts). A few works have developed passive interventions that are effective in-the-moment by leveraging breathing regulations and biofeedback. In this paper, we drew on neuroscientific findings on affective touch, the slow stroking on hairy skin that can elicit innate pleasantness and evaluated affective touch as a mobile health intervention. To induce affective touch, we first engineered a wearable device that renders a soft stroking sensation on the user's forearm. Then, we conducted a between-group experiment, in which participants underwent high-stress situations with/without receiving affective touch and post-experiment interviews, with 24 participants. Our results showed that participants who received affective touch experienced lower state anxiety and the same physiological stress response level compared to the control group participants. We also found that affective touch facilitated emotion regulation by rendering pleasantness, providing emotional support, and shifting attention. Finally, we discussed the immediate effect of affective touch on anxiety and physiological stress, the benefits of affective touch as a passive intervention, and the implementation considerations to use affective touch in just-in-time systems.},
journal = {Proc. ACM Interact. Mob. Wearable Ubiquitous Technol.},
month = jan,
articleno = {200},
numpages = {23},
keywords = {affective touch, anxiety, behavioral health, haptics, health intervention, mental health, passive intervention, wearable}
}

@article{10.1145/3570344,
author = {Yin, Zhigang and Liyanage, Mohan and Ottun, Abdul-Rasheed and Paul, Souvik and Zuniga, Agustin and Nurmi, Petteri and Flores, Huber},
title = {HIPPO: Pervasive Hand-Grip Estimation from Everyday Interactions},
year = {2023},
issue_date = {December 2022},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {6},
number = {4},
url = {https://doi.org/10.1145/3570344},
doi = {10.1145/3570344},
abstract = {Hand-grip strength is widely used to estimate muscle strength and it serves as a general indicator of the overall health of a person, particularly in aging adults. Hand-grip strength is typically estimated using dynamometers or specialized force resistant pressure sensors embedded onto objects. Both of these solutions require the user to interact with a dedicated measurement device which unnecessarily restricts the contexts where estimates are acquired. We contribute HIPPO, a novel non-intrusive and opportunistic method for estimating hand-grip strength from everyday interactions with objects. HIPPO re-purposes light sensors available in wearables (e.g., rings or gloves) to capture changes in light reflectivity when people interact with objects. This allows HIPPO to non-intrusively piggyback everyday interactions for health information without affecting the user's everyday routines. We present two prototypes integrating HIPPO, an early smart glove proof-of-concept, and a further optimized solution that uses sensors integrated onto a ring. We validate HIPPO through extensive experiments and compare HIPPO against three baselines, including a clinical dynamometer. Our results show that HIPPO operates robustly across a wide range of everyday objects, and participants. The force strength estimates correlate with estimates produced by pressure-based devices, and can also determine the correct hand grip strength category with up to 86\% accuracy. Our findings also suggest that users prefer our approach to existing solutions as HIPPO blends the estimation with everyday interactions.},
journal = {Proc. ACM Interact. Mob. Wearable Ubiquitous Technol.},
month = jan,
articleno = {209},
numpages = {30},
keywords = {Hand grip strength, Internet of Things, Light reflectivity, Light scattering, Smart ring}
}

@article{10.1145/3569502,
author = {Watson, Amanda and Kendell, Claire and Lingamoorthy, Anush and Lee, Insup and Weimer, James},
title = {Lumos: An Open-Source Device for Wearable Spectroscopy Research},
year = {2023},
issue_date = {December 2022},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {6},
number = {4},
url = {https://doi.org/10.1145/3569502},
doi = {10.1145/3569502},
abstract = {Spectroscopy, the study of the interaction between electromagnetic radiation and matter, is a vital technique in many disciplines. This technique is limited to lab settings, and, as such, sensing is isolated and infrequent. Thus, it can only provide a brief snapshot of the monitored parameter. Wearable technology brings sensing and tracking technologies out into everyday life, creating longitudinal datasets that provide more insight into the monitored parameter. In this paper, we describe Lumos, an open-source device for wearable spectroscopy research. Lumos can facilitate on-body spectroscopy research in health monitoring, athletics, rehabilitation, and more. We developed an algorithm to determine the spectral response of a medium with a mean absolute error of 13nm. From this, researchers can determine the optimal spectrum and create customized sensors for their target application. We show the utility of Lumos in a pilot study, sensing of prediabetes, where we determine the relevant spectrum for glucose and create and evaluate a targeted tracking device.},
journal = {Proc. ACM Interact. Mob. Wearable Ubiquitous Technol.},
month = jan,
articleno = {187},
numpages = {24},
keywords = {health tracking, spectroscopy, wearable technology}
}

@article{10.1145/3569468,
author = {Liberis, Edgar and Lane, Nicholas D.},
title = {Differentiable Neural Network Pruning to Enable Smart Applications on Microcontrollers},
year = {2023},
issue_date = {December 2022},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {6},
number = {4},
url = {https://doi.org/10.1145/3569468},
doi = {10.1145/3569468},
abstract = {Wearable, embedded, and IoT devices are a centrepiece of many ubiquitous computing applications, such as fitness tracking, health monitoring, home security and voice assistants. By gathering user data through a variety of sensors and leveraging machine learning (ML), applications can adapt their behaviour: in other words, devices become "smart". Such devices are typically powered by microcontroller units (MCUs). As MCUs continue to improve, smart devices become capable of performing a non-trivial amount of sensing and data processing, including machine learning inference, which results in a greater degree of user data privacy and autonomy, compared to offloading the execution of ML models to another device.Advanced predictive capabilities across many tasks make neural networks an attractive ML model for ubiquitous computing applications; however, on-device inference on MCUs remains extremely challenging. Orders of magnitude less storage, memory and computational ability, compared to what is typically required to execute neural networks, impose strict structural constraints on the network architecture and call for specialist model compression methodology. In this work, we present a differentiable structured pruning method for convolutional neural networks, which integrates a model's MCU-specific resource usage and parameter importance feedback to obtain highly compressed yet accurate models. Compared to related network pruning work, compressed models are more accurate due to better use of MCU resource budget, and compared to MCU specialist work, compressed models are produced faster. The user only needs to specify the amount of available computational resources and the pruning algorithm will automatically compress the network during training to satisfy them.We evaluate our methodology using benchmark image and audio classification tasks and find that it (a) improves key resource usage of neural networks up to 80x; (b) has little to no overhead or even improves model training time; (c) produces compressed models with matching or improved resource usage up to 1.4x in less time compared to prior MCU-specific model compression methods.},
journal = {Proc. ACM Interact. Mob. Wearable Ubiquitous Technol.},
month = jan,
articleno = {171},
numpages = {19},
keywords = {microcontrollers, model compression, neural networks, on-device inference}
}

@article{10.1145/3569485,
author = {Xu, Xuhai and Liu, Xin and Zhang, Han and Wang, Weichen and Nepal, Subigya and Sefidgar, Yasaman and Seo, Woosuk and Kuehn, Kevin S. and Huckins, Jeremy F. and Morris, Margaret E. and Nurius, Paula S. and Riskin, Eve A. and Patel, Shwetak and Althoff, Tim and Campbell, Andrew and Dey, Anind K. and Mankoff, Jennifer},
title = {GLOBEM: Cross-Dataset Generalization of Longitudinal Human Behavior Modeling},
year = {2023},
issue_date = {December 2022},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {6},
number = {4},
url = {https://doi.org/10.1145/3569485},
doi = {10.1145/3569485},
abstract = {There is a growing body of research revealing that longitudinal passive sensing data from smartphones and wearable devices can capture daily behavior signals for human behavior modeling, such as depression detection. Most prior studies build and evaluate machine learning models using data collected from a single population. However, to ensure that a behavior model can work for a larger group of users, its generalizability needs to be verified on multiple datasets from different populations. We present the first work evaluating cross-dataset generalizability of longitudinal behavior models, using depression detection as an application. We collect multiple longitudinal passive mobile sensing datasets with over 500 users from two institutes over a two-year span, leading to four institute-year datasets. Using the datasets, we closely re-implement and evaluated nine prior depression detection algorithms. Our experiment reveals the lack of model generalizability of these methods. We also implement eight recently popular domain generalization algorithms from the machine learning community. Our results indicate that these methods also do not generalize well on our datasets, with barely any advantage over the naive baseline of guessing the majority. We then present two new algorithms with better generalizability. Our new algorithm, Reorder, significantly and consistently outperforms existing methods on most cross-dataset generalization setups. However, the overall advantage is incremental and still has great room for improvement. Our analysis reveals that the individual differences (both within and between populations) may play the most important role in the cross-dataset generalization challenge. Finally, we provide an open-source benchmark platform GLOBEM- short for Generalization of Longitudinal BEhavior Modeling - to consolidate all 19 algorithms. GLOBEM can support researchers in using, developing, and evaluating different longitudinal behavior modeling methods. We call for researchers' attention to model generalizability evaluation for future longitudinal human behavior modeling studies.},
journal = {Proc. ACM Interact. Mob. Wearable Ubiquitous Technol.},
month = jan,
articleno = {190},
numpages = {34},
keywords = {Behavior Modeling, Generalizability, Passive Sensing}
}

@article{10.1145/3569472,
author = {Sun, Xue and Xiong, Jie and Feng, Chao and Deng, Wenwen and Wei, Xudong and Fang, Dingyi and Chen, Xiaojiang},
title = {Earmonitor: In-ear Motion-resilient Acoustic Sensing Using Commodity Earphones},
year = {2023},
issue_date = {December 2022},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {6},
number = {4},
url = {https://doi.org/10.1145/3569472},
doi = {10.1145/3569472},
abstract = {Earphones are emerging as the most popular wearable devices and there has been a growing trend in bringing intelligence to earphones. Previous efforts include adding extra sensors (e.g., accelerometer and gyroscope) or peripheral hardware to make earphones smart. These methods are usually complex in design and also incur additional cost. In this paper, we present Earmonitor, a low-cost system that uses the in-ear earphones to achieve sensing purposes. The basic idea behind Earmonitor is that each person's ear canal varies in size and shape. We therefore can extract the unique features from the ear canal-reflected signals to depict the personalized differences in ear canal geometry. Furthermore, we discover that the signal variations are also affected by the fine-grained physiological activities. We can therefore further detect the subtle heartbeat from the ear canal reflections. Experiments show that Earmonitor can achieve up to 96.4\% Balanced Accuracy (BAC) and low False Acceptance Rate (FAR) for user identification on a large-scale data of 120 subjects. For heartbeat monitoring, without any training, we propose signal processing schemes to achieve high sensing accuracy even in the most challenging scenarios when the target is walking or running.},
journal = {Proc. ACM Interact. Mob. Wearable Ubiquitous Technol.},
month = jan,
articleno = {182},
numpages = {22},
keywords = {Acoustic sensing, Heartbeat sensing, User identification}
}

@article{10.1145/3569467,
author = {Zhou, Heng and Maekawa, Takuya},
title = {GPS-assisted Indoor Pedestrian Dead Reckoning},
year = {2023},
issue_date = {December 2022},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {6},
number = {4},
url = {https://doi.org/10.1145/3569467},
doi = {10.1145/3569467},
abstract = {Indoor pedestrian dead reckoning (PDR) using embedded inertial sensors in smartphones has been actively studied in the ubicomp community. However, PDR relying only on inertial sensors suffers from the accumulation of errors from the sensors. Researchers have employed various indoor landmarks detectable by smartphone sensors such as magnetic fingerprints caused by elevators and Bluetooth signals from beacons with known coordinates to compensate for the errors. This study proposes a new type of indoor landmark that does not require additional device installation, e.g., beacons, and training data collection in a target environment, e.g., magnetic fingerprints, unlike existing landmarks. This study proposes the use of GPS signals received by a smartphone to correct the accumulated errors of the PDR. While it is impossible to locate the smartphone indoors using GPS satellites, the smartphone can receive signals at a window-side area through windows from satellites aligned with the orientation of the window normal. Based on this idea, we design a machine-learning-based module for detecting the proximity of a user to a window and the orientation of the window, which enables us to roughly determine the absolute coordinates of the smartphone and to correct the accumulated errors by referring to positions of window-side areas found in the floor plan of the environment. A key technical contribution of this study is designing the module, such that it can be trained based on data from environments other than the target environment yet work in any environment by extracting GPS-related information independent of wall orientation. We evaluated the effectiveness of the proposed method using sensor data collected in real environments.},
journal = {Proc. ACM Interact. Mob. Wearable Ubiquitous Technol.},
month = jan,
articleno = {166},
numpages = {36},
keywords = {GPS satellite information, Indoor localization system, pedestrian dead reckoning}
}

@article{10.1145/3569460,
author = {Alharbi, Rawan and Shahi, Soroush and Cruz, Stefany and Li, Lingfeng and Sen, Sougata and Pedram, Mahdi and Romano, Christopher and Hester, Josiah and Katsaggelos, Aggelos K. and Alshurafa, Nabil},
title = {SmokeMon: Unobtrusive Extraction of Smoking Topography Using Wearable Energy-Efficient Thermal},
year = {2023},
issue_date = {December 2022},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {6},
number = {4},
url = {https://doi.org/10.1145/3569460},
doi = {10.1145/3569460},
abstract = {Smoking is the leading cause of preventable death worldwide. Cigarette smoke includes thousands of chemicals that are harmful and cause tobacco-related diseases. To date, the causality between human exposure to specific compounds and the harmful effects is unknown. A first step in closing the gap in knowledge has been measuring smoking topography, or how the smoker smokes the cigarette (puffs, puff volume, and duration). However, current gold-standard approaches to smoking topography involve expensive, bulky, and obtrusive sensor devices, creating unnatural smoking behavior and preventing their potential for real-time interventions in the wild. Although motion-based wearable sensors and their corresponding machine-learned models have shown promise in unobtrusively tracking smoking gestures, they are notorious for confounding smoking with other similar hand-to-mouth gestures such as eating and drinking. In this paper, we present SmokeMon, a chest-worn thermal-sensing wearable system that can capture spatial, temporal, and thermal information around the wearer and cigarette all day to unobtrusively and passively detect smoking events. We also developed a deep learning--based framework to extract puffs and smoking topography. We evaluate SmokeMon in both controlled and free-living experiments with a total of 19 participants, more than 110 hours of data, and 115 smoking sessions achieving an F1-score of 0.9 for puff detection in the laboratory and 0.8 in the wild. By providing SmokeMon as an open platform, we provide measurement of smoking topography in free-living settings to enable testing of smoking topography in the real world, with potential to facilitate timely smoking cessation interventions.},
journal = {Proc. ACM Interact. Mob. Wearable Ubiquitous Technol.},
month = jan,
articleno = {155},
numpages = {25},
keywords = {HAR, Smoking, Thermal, Wearable}
}

@article{10.1145/3569489,
author = {Zakaria, Camellia and Yilmaz, Gizem and Mammen, Priyanka Mary and Chee, Michael and Shenoy, Prashant and Balan, Rajesh},
title = {SleepMore: Inferring Sleep Duration at Scale via Multi-Device WiFi Sensing},
year = {2023},
issue_date = {December 2022},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {6},
number = {4},
url = {https://doi.org/10.1145/3569489},
doi = {10.1145/3569489},
abstract = {The availability of commercial wearable trackers equipped with features to monitor sleep duration and quality has enabled more useful sleep health monitoring applications and analyses. However, much research has reported the challenge of long-term user retention in sleep monitoring through these modalities. Since modern Internet users own multiple mobile devices, our work explores the possibility of employing ubiquitous mobile devices and passive WiFi sensing techniques to predict sleep duration as the fundamental measure for complementing long-term sleep monitoring initiatives. In this paper, we propose SleepMore, an accurate and easy-to-deploy sleep-tracking approach based on machine learning over the user's WiFi network activity. It first employs a semi-personalized random forest model with an infinitesimal jackknife variance estimation method to classify a user's network activity behavior into sleep and awake states per minute granularity. Through a moving average technique, the system uses these state sequences to estimate the user's nocturnal sleep period and its uncertainty rate. Uncertainty quantification enables SleepMore to overcome the impact of noisy WiFi data that can yield large prediction errors. We validate SleepMore using data from a month-long user study involving 46 college students and draw comparisons with the Oura Ring wearable. Beyond the college campus, we evaluate SleepMore on non-student users of different housing profiles. Our results demonstrate that SleepMore produces statistically indistinguishable sleep statistics from the Oura ring baseline for predictions made within a 5\% uncertainty rate. These errors range between 15-28 minutes for determining sleep time and 7-29 minutes for determining wake time, proving statistically significant improvements over prior work. Our in-depth analysis explains the sources of errors.},
journal = {Proc. ACM Interact. Mob. Wearable Ubiquitous Technol.},
month = jan,
articleno = {193},
numpages = {32},
keywords = {WiFi, mobile health, sleep}
}

@article{10.1145/3569475,
author = {Bentvelzen, Marit and Niess, Jasmin and Wo\'{z}niak, Pawe\l{} W.},
title = {Designing Reflective Derived Metrics for Fitness Trackers},
year = {2023},
issue_date = {December 2022},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {6},
number = {4},
url = {https://doi.org/10.1145/3569475},
doi = {10.1145/3569475},
abstract = {Personal tracking devices are equipped with more and more sensors and offer an ever-increasing level of accuracy. Yet, this comes at the cost of increased complexity. To deal with that problem, fitness trackers use derived metrics---scores calculated based on sensor data, e.g. a stress score. This means that part of the agency in interpreting health data is transferred from the user to the tracker. In this paper, we investigate the consequences of that transition and study how derived metrics can be designed to offer an optimal personal informatics experience. We conducted an online survey and a series of interviews which examined a health score (a hypothetical derived metric) at three levels of abstraction. We found that the medium abstraction level led to the highest level of reflection. Further, we determined that presenting the metric without contextual information led to decreased transparency and meaning. Our work contributes guidelines for designing effective derived metrics.},
journal = {Proc. ACM Interact. Mob. Wearable Ubiquitous Technol.},
month = jan,
articleno = {158},
numpages = {19},
keywords = {derived metrics, fitness trackers, metrics, personal informatics, reflection}
}

@article{10.1145/3569496,
author = {Yang, Yanni and Xu, Huafeng and Chen, Qianyi and Cao, Jiannong and Wang, Yanwen},
title = {Multi-Vib: Precise Multi-point Vibration Monitoring Using mmWave Radar},
year = {2023},
issue_date = {December 2022},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {6},
number = {4},
url = {https://doi.org/10.1145/3569496},
doi = {10.1145/3569496},
abstract = {Vibration measurement is vital for fault diagnosis of structures (e.g., machines and civil structures). Different structure components undergo distinct vibration patterns, which jointly determine the structure's health condition, thus demanding simultaneous multi-point vibration monitoring. Existing solutions deploy multiple accelerometers along with their power supplies or laser vibrometers on the monitored object to measure multi-point vibration, which is inconvenient and costly. Cameras provide a less expensive solution while heavily relying on good lighting conditions. To overcome these limitations, we propose a cost-effective and passive system, called Multi-Vib, for precise multi-point vibration monitoring. Multi-Vib is implemented using a single mmWave radar to remotely and separately sense the vibration displacement of multiple points via signal reflection. However, simultaneously detecting and monitoring multiple points on a single object is a daunting task. This is because most radar signals are scattered away from vibration points due to their tilted locations and shapes by nature, causing an extremely weak reflected signal to the radar. To solve this issue, we dedicatedly design a physical marker placed on the target point, which can force the direction of the reflected signal towards the radar and significantly increase the reflected signal strength. Another practical issue is that the reflected signal from each point endures interferences and noises from the surroundings. Thus, we develop a series of effective signal processing methods to denoise the signal for accurate vibration frequency and displacement estimation. Extensive experimental results show that the average errors in multi-point vibration frequency and displacement estimation are around 0.16Hz and 14μm, respectively.},
journal = {Proc. ACM Interact. Mob. Wearable Ubiquitous Technol.},
month = jan,
articleno = {192},
numpages = {26},
keywords = {millimeter wave, vibration monitoring, wireless sensing}
}

@article{10.1145/3569476,
author = {Li, Huining and Chen, Huan and Xu, Chenhan and Li, Zhengxiong and Zhang, Hanbin and Qian, Xiaoye and Li, Dongmei and Huang, Ming-chun and Xu, Wenyao},
title = {NeuralGait: Assessing Brain Health Using Your Smartphone},
year = {2023},
issue_date = {December 2022},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {6},
number = {4},
url = {https://doi.org/10.1145/3569476},
doi = {10.1145/3569476},
abstract = {Brain health attracts more recent attention as the population ages. Smartphone-based gait sensing and analysis can help identify the risks of brain diseases in daily life for prevention. Existing gait analysis approaches mainly hand-craft temporal gait features or developing CNN-based feature extractors, but they are either prone to lose some inconspicuous pathological information or are only dedicated to a single brain disease screening. We discover that the relationship between gait segments can be used as a principle and generic indicator to quantify multiple pathological patterns. In this paper, we propose NeuralGait, a pervasive smartphone-cloud system that passively captures and analyzes principle gait segments relationship for brain health assessment. On the smartphone end, inertial gait data are collected while putting the smartphone in the pants pocket. We then craft local temporal-frequent gait domain features and develop a self-attention-based gait segment relationship encoder. Afterward, the domain features and relation features are fed to a scalable RiskNet in the cloud for brain health assessment. We also design a pathological hot update protocol to efficiently add new brain diseases in the RiskNet. NeuralGait is practical as it provides brain health assessment with no burden in daily life. In the experiment, we recruit 988 healthy people and 417 patients with a single or combination of PD, TBI, and stroke, and evaluate the brain health assessment using a set of specifically designed metrics including global accuracy, exact accuracy, sensitivity, and false alarm rate. We also demonstrate the generalization (e.g., analysis of feature effectiveness and model efficiency) and inclusiveness of NeuralGait.},
journal = {Proc. ACM Interact. Mob. Wearable Ubiquitous Technol.},
month = jan,
articleno = {169},
numpages = {28},
keywords = {Multi-label brain diseases, gait analysis, smartphone}
}

@article{10.1145/3569494,
author = {Zhang, Hualei and Wang, Zhu and Sun, Zhuo and Song, Wenchao and Ren, Zhihui and Yu, Zhiwen and Guo, Bin},
title = {Understanding the Mechanism of Through-Wall Wireless Sensing: A Model-based Perspective},
year = {2023},
issue_date = {December 2022},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {6},
number = {4},
url = {https://doi.org/10.1145/3569494},
doi = {10.1145/3569494},
abstract = {During the last few years, there is a growing interest on the usage of Wi-Fi signals for human activity detection. A large number of Wi-Fi based sensing systems have been developed, including respiration detection, gesture classification, identity recognition, etc. However, the usability and robustness of such systems are still limited, due to the complexity of practical environments. Various pioneering approaches have been proposed to solve this problem, among which the model-based approach is attracting more and more attention, due to the advantage that it does not require a huge dataset for model training. Existing models are usually developed for Line-of-Sight (LoS) scenarios, and can not be applied to facilitating the design of wireless sensing systems in Non-Line-of-Sight (NLoS) scenarios (e.g., through-wall sensing). To fill this gap, we propose a through-wall wireless sensing model, aiming to characterize the propagation laws and sensing mechanisms of Wi-Fi signals in through-wall scenarios. Specifically, based on the insight that Wi-Fi signals will be refracted while there is a wall between the transceivers, we develop a refraction-aware Fresnel model, and prove theoretically that the original Fresnel model can be seen as a special case of the proposed model. We find that the presence of a wall will change the distribution of Fresnel zones, which we called the "squeeze effect" of Fresnel zones. Moreover, our theoretical analysis indicates that the "squeeze effect" can help improve the sensing capability (i.e., spatial resolution) of Wi-Fi signals. To validate the proposed model, we implement a through-wall respiration sensing system with a pair of transceivers. Extensive experiments in typical through-wall environments show that the respiration detection error is lower than 0.5 bpm, while the subject's vertical distance to the connection line of the transceivers is less than 200 cm. To the best of our knowledge, this is the first theoretical model that reveals the Wi-Fi based wireless sensing mechanism in through-wall scenarios.},
journal = {Proc. ACM Interact. Mob. Wearable Ubiquitous Technol.},
month = jan,
articleno = {195},
numpages = {28},
keywords = {Fresnel Zone, Respiration Detection, Through-wall Sensing, Wi-Fi CSI}
}

@inproceedings{10.1145/3558884.3558887,
author = {Negrete Ram\'{\i}rez, Jos\'{e} Manuel and Cardinale, Yudith},
title = {Activities of Daily Living Detection on Healthcare: A Categorization},
year = {2023},
isbn = {9781450396240},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3558884.3558887},
doi = {10.1145/3558884.3558887},
abstract = {The incremental advancement of sensor technology has positively impacted the field of activities of daily living (ADL) recognition and monitoring in Ambient Assisted Living (AAL) environments. People in AAL environments interact by means of electronic devices (e.g., sensors, actuators, mobile phones, tablets, wearable technologies) to accomplish their ADL, which can be analysed to identify such as ADL and monitor the behaviour of inhabitants in AAL. In this paper, we present the trends on this area in the context of Pervasive Healthcare. To do so, we propose a categorization of ADL, along with the monitoring approaches based on sensing and context-awareness technologies. Moreover, we present an overview of evaluation models on the extent of performance of ADL.},
booktitle = {Proceedings of the 7th International Workshop on Sensor-Based Activity Recognition and Artificial Intelligence},
articleno = {6},
numpages = {10},
keywords = {Pervasive Health Systems and Services, Pervasive Computing, Literature review, Feature-oriented Programming, Dependency evaluation models, Activities of daily living},
location = {Rostock, Germany},
series = {iWOAR '22}
}

@article{10.1145/3510856,
author = {Shao, Xuan and Shen, Ying and Zhang, Lin and Zhao, Shengjie and Zhu, Dandan and Zhou, Yicong},
title = {SLAM for Indoor Parking: A Comprehensive Benchmark Dataset and a Tightly Coupled Semantic Framework},
year = {2023},
issue_date = {January 2023},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {19},
number = {1},
issn = {1551-6857},
url = {https://doi.org/10.1145/3510856},
doi = {10.1145/3510856},
abstract = {For the task of autonomous indoor parking, various Visual-Inertial Simultaneous Localization And Mapping (SLAM) systems are expected to achieve comparable results with the benefit of complementary effects of visual cameras and the Inertial Measurement Units. To compare these competing SLAM systems, it is necessary to have publicly available datasets, offering an objective way to demonstrate the pros/cons of each SLAM system. However, the availability of such high-quality datasets is surprisingly limited due to the profound challenge of the groundtruth trajectory acquisition in the Global Positioning Satellite denied indoor parking environments. In this article, we establish BeVIS, a large-scale Benchmark dataset with Visual (front-view), Inertial and Surround-view sensors for evaluating the performance of SLAM systems developed for autonomous indoor parking, which is the first of its kind where both the raw data and the groundtruth trajectories are available. In BeVIS, the groundtruth trajectories are obtained by tracking artificial landmarks scattered in the indoor parking environments, whose coordinates are recorded in a surveying manner with a high-precision Electronic Total Station. Moreover, the groundtruth trajectories are comprehensively evaluated in terms of two respects, the reprojection error and the pose volatility, respectively. Apart from BeVIS, we propose a novel tightly coupled semantic SLAM framework, namely VISSLAM-2, leveraging Visual (front-view), Inertial, and Surround-view sensor modalities, specially for the task of autonomous indoor parking. It is the first work attempting to provide a general form to model various semantic objects on the ground. Experiments on BeVIS demonstrate the effectiveness of the proposed VISSLAM-2. Our benchmark dataset BeVIS is publicly available at .},
journal = {ACM Trans. Multimedia Comput. Commun. Appl.},
month = jan,
articleno = {1},
numpages = {23},
keywords = {semantic SLAM, Electronic Total Station, groundtruth trajectory acquisition, benchmark dataset, Autonomous indoor parking}
}

@inproceedings{10.1145/3558884.3558893,
author = {Pandurangan, Shalini and Papandrea, Michela and Gelsomini, Mirko},
title = {Fine-Grained Human Activity Recognition - A new paradigm},
year = {2023},
isbn = {9781450396240},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3558884.3558893},
doi = {10.1145/3558884.3558893},
abstract = {Nowadays, fine-grained Human Activity Recognition (HAR) has become extremely interesting among researchers due to its applications in fields such as healthcare, security, sports, and smart environments. In this paper, we provide a brief overview of the State of the Art approaches in fine-grained human activity recognition. We also discuss the characteristics, complexities, and scarcity of inertial datasets related to fine-grained and coarse-grained activities. To mitigate this scarcity, we collect our inertial dataset, consisting of 17 participants performing 4 fine-grained tasks while interacting with an Inertial Measurement Unit (IMU) sensor embedded in a solid object. Next, we test the most commonly used machine learning classifiers (e.g., kNN, XGboost) on the collected dataset and present the results. Finally, we demonstrate the necessity of a new approach to deal with the recognition of fine-grained activities, and we state our future research directions in this context.},
booktitle = {Proceedings of the 7th International Workshop on Sensor-Based Activity Recognition and Artificial Intelligence},
articleno = {2},
numpages = {8},
keywords = {Machine learning, Human Object Interaction., Fine-grained HAR},
location = {Rostock, Germany},
series = {iWOAR '22}
}

@inproceedings{10.1145/3567445.3571112,
author = {Tachibana, Koki and Matsuda, Yuki and Isobe, Kaito and Mayumi, Daiki and Kikuchi, Takamasa and Suwa, Hirohiko and Yasumoto, Keiichi and Murao, Kazuya},
title = {Tongaraas: Tongs for Recognizing Littering Garbage with Active Acoustic Sensing},
year = {2023},
isbn = {9781450396653},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3567445.3571112},
doi = {10.1145/3567445.3571112},
abstract = {Littering has developed into a serious environmental problem. However, the actual situation of litter and the results of litter pickup activities are not organized as information. Therefore, the objective of this research is to grasp the distribution of the type and location of litter comprehensively. To achieve the objective of this research, we have proposed a method for recognizing litter using an acoustic sensor on a smartwatch worn on the wrist and a method for recognizing litter using a small camera mounted on tongs. However, in these studies, there were limitations in the range of litter type estimation, lack of recognition accuracy, and privacy issues. To solve the above problem, we propose a litter type recognition system, named Tongaraas, that combines active acoustic sensing with tongs. In the evaluation experiment, we built the litter type recognition model for six categories of litter. The evaluation results showed the models, which were trained with dataset collected by single person and three people, perform at F-value of 0.978 (SVM) and 0.849 (LightGBM), respectively. It suggests it is possible to estimate with common litter type recognition model, although there is a certain level of negative effects due to the individual difference.},
booktitle = {Proceedings of the 12th International Conference on the Internet of Things},
pages = {224–230},
numpages = {7},
keywords = {Smart city, Littering, Active acoustic sensing.},
location = {Delft, Netherlands},
series = {IoT '22}
}

@inproceedings{10.1145/3567445.3571108,
author = {Matsuda, Yuki},
title = {IoPT: A Concept of Internet of Perception-aware Things},
year = {2023},
isbn = {9781450396653},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3567445.3571108},
doi = {10.1145/3567445.3571108},
abstract = {The Internet of Things (IoT) is undergoing remarkable technological innovation, it is expected uncountable number of IoT devices will be installed everywhere and enrich our daily life in near future. There is a technical challenge that is the physically accurate data does not always match the “experience” of people, because the “perception” of people will be easily biased by various stimulations from surrounding environments. This paper presents a concept of Internet of Perception-aware Things (IoPT), which aims to fill the gap in perception between IoT and human. Through the case study targeting subjective crowdedness, we have confirmed perception data have huge deviations though there are correlations between sensor data and perception data, and perception will be biased due to the environmental conditions.},
booktitle = {Proceedings of the 12th International Conference on the Internet of Things},
pages = {201–204},
numpages = {4},
keywords = {Perception, Internet of Things, Human-in-the-loop System.},
location = {Delft, Netherlands},
series = {IoT '22}
}

@inproceedings{10.1145/3558884.3558888,
author = {Joch, Julia and Kirsten, Kristina and Arnrich, Bert},
title = {Hand Gesture Recognition in Daily Life as an Additional Tool for Unobtrusive Data Labeling in Medical Studies},
year = {2023},
isbn = {9781450396240},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3558884.3558888},
doi = {10.1145/3558884.3558888},
abstract = {For many use cases, such as supervised machine learning, labeled data is needed. However, to collect information for labels in real-life contexts, scientists are confronted with the challenge of gathering labeled data over an extended period. Labeling this data can become problematic, as constant supervision, similar to a laboratory setting, is neither feasible nor desired. Therefore, participants of such studies have to label their data themselves via appropriate apps on a smartphone. Nevertheless, this process can become very obtrusive in daily life and might even influence the results, especially studies regarding emotions. For example, in studies where participants need to indicate their stress levels frequently, labels get missed in situations where it would be inappropriate to take the phone. Consequently, missing these labels presents a significant problem. This paper aims to provide an unobtrusive solution to labeling data in real-world studies. We recorded a dataset consisting of five gestures and data from daily life. Thereby, we provide a set of predefined gestures that can be distinguished from other everyday life activities by using accelerometer and gyroscope sensors of wearable devices on the wrist. The use of predefined hand gestures for labeling data can therefore serve as an additional tool for the labeling process. Two machine learning approaches were compared and achieved promising results with Matthews Correlation Coefficients of up to 0.789 for a Random Forest and up to 0.835 for a Convolutional Neural Network.},
booktitle = {Proceedings of the 7th International Workshop on Sensor-Based Activity Recognition and Artificial Intelligence},
articleno = {5},
numpages = {7},
keywords = {machine learning, hand gesture recognition, data labeling},
location = {Rostock, Germany},
series = {iWOAR '22}
}

@article{10.1145/3578363,
author = {Bhardwaj, Akashdeep and Kaushik, Keshav and Alshehri, Mohammed and Mohamed, Ahmed Abo-Bakr and Keshta, Ismail},
title = {ISF: Security Analysis and Assessment of Smart Home IoT-based Firmware},
year = {2023},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
issn = {1550-4859},
url = {https://doi.org/10.1145/3578363},
doi = {10.1145/3578363},
abstract = {The applications and services offered by the Internet of Things (IoT) have grown significantly during the past few years. Device makers and corporate suppliers have taken notice of this, which has led to a sudden inflow of new-age firms. Confidential data and information are involved as IoT device use rises. IoT device security has emerged as a major issue and is becoming more and more significant. Appropriate security measures are needed to prevent dangers and hazards associated with the adoption of smart technology in smart cities and houses that run IoT devices, according to security evaluations. In order to safeguard the smart home environment, our research focuses on IoT device firmware. The security methodology presented in this research may be used to analyze and investigate IoT firmware, revealing sensitive data and hardcoded user IDs and passwords that can be used in future attacks and breach of IoT devices. The authors put out an idea for how real-time datasets produced by IoT search engines may be analyzed using keywords according to different device kinds, locations, and manufacturers. The results showed that it took device owners 11–13 months to upgrade the firmware. Only HP and Cisco routinely provided firmware updates to protect IoT devices among IoT device makers.},
note = {Just Accepted},
journal = {ACM Trans. Sen. Netw.},
month = jan,
keywords = {Hypothesis, Attack Vector, Hardcoded, Entropy, Firmware, Cybersecurity, Internet of Things}
}

