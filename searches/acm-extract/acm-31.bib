@inproceedings{10.1145/3581791.3596848,
author = {Zhang, Tianfang and Shi, Cong and Walker, Payton and Ye, Zhengkun and Wang, Yan and Saxena, Nitesh and Chen, Yingying},
title = {Passive Vital Sign Monitoring via Facial Vibrations Leveraging AR/VR Headsets},
year = {2023},
isbn = {9798400701108},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3581791.3596848},
doi = {10.1145/3581791.3596848},
abstract = {Vital signs (e.g., breathing and heart rates) and personal identities are essential information for personalized medicine and healthcare. The popularity of augmented reality/virtual reality (AR/VR) provides an excellent opportunity for enabling long-term health monitoring in a broad range of scenarios, including virtual entertainment, education, and telemedicine. However, commercial-off-the-shelf AR/VR devices do not have dedicated biosensors for providing vital signs and personal identities. In this work, we propose a novel framework that can generate fine-grained vital sign signals and other personalized health information of an AR/VR user through passive sensing on AR/VR devices. In particular, we find that the user's minute facial vibrations induced by breathing and heart beating can impact the readily available motion sensors on AR/VR headsets, which encode rich vital sign patterns and unique biometrics. The proposed framework further estimates the breathing and heartbeat rates, detects the gender and identity, and derives the body fat percentage of the user. To mitigate the impacts of body movement, we design an adaptive filtering scheme to cancel the spontaneous and non-spontaneous motion artifacts. We also develop unique facial vibration features and deep learning techniques to facilitate vital sign signal reconstruction and user identification. Extensive experiments demonstrate that our framework can achieve a low error of vital sign signal reconstruction and rate measurement, along with 95.51\% and 93.33\% accuracy on identity and gender recognition.},
booktitle = {Proceedings of the 21st Annual International Conference on Mobile Systems, Applications and Services},
pages = {96‚Äì109},
numpages = {14},
keywords = {health monitoring, facial vibrations, AR/VR headsets},
location = {Helsinki, Finland},
series = {MobiSys '23}
}

@inproceedings{10.1145/3597061.3597260,
author = {Kumari, Shashee and Bhattacharya, Sakyajit and Chatterjee, Arnab and Ghose, Avik},
title = {Imputation of Human Mobility Data for Comprehensive Risk Models},
year = {2023},
isbn = {9798400702112},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3597061.3597260},
doi = {10.1145/3597061.3597260},
abstract = {Sensor-equipped wearable devices are becoming increasingly popular in the healthcare industry, with some equipped with GPS and Proximity sensors as well. Raw (GPS) trajectories obtained through human-centric systems like body worn senors, and enriched with semantic annotations generate huge actionable insights for downstream domain specific applications like epidemic risk modeling. However, trajectory data suffer from missing data problem owing to various technical as well as behavioral factors. Our paper shows that, for a semantic trajectory dataset and using coarse grain semantic location for both prediction and imputation purposes, a simple ensemble classifier-based model can outperform the existing deep models where trajectory imputation is almost real-time delay.},
booktitle = {Proceedings of the 8th Workshop on Body-Centric Computing Systems},
pages = {19‚Äì24},
numpages = {6},
keywords = {wearable-devices, semantic trajectory, ensemble-classifier, imputation},
location = {Helsinki, Finland},
series = {BodySys '23}
}

@inproceedings{10.1145/3597061.3597261,
author = {Sugimoto, Yu and Rizk, Hamada and Uchiyama, Akira and Yamaguchi, Hirozumi},
title = {Towards Environment-Independent Activity Recognition Using Wi-Fi CSI with an Encoder-Decoder Network},
year = {2023},
isbn = {9798400702112},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3597061.3597261},
doi = {10.1145/3597061.3597261},
abstract = {Human Activity Recognition (HAR) has attracted considerable attention in recent years due to its potential applications in healthcare, smart homes, and security. Wi-Fi Channel State Information (CSI) is a promising sensor modality for HAR, providing a device-free and low-cost solution. However, building environment-independent models for HAR using Wi-Fi CSI remains a significant challenge. In this paper, we present a deep learning-based activity recognition system that exploits CSI measurements obtained from one or more environments to deliver consistent and accurate performance even in unseen environments. Our system employs a multi-task learning approach that is based on an encoder-decoder network architecture. This enables the encoder part of this architecture to mitigate the environment-dependent factors and extract a rich and environment-invariant representation. To evaluate the proposed system, we collected CSI samples for six activities pursued by three participants in four distinct environments. The results demonstrate the efficacy of the proposed system in achieving environment-independent HAR with an average accuracy of 80\%. Additionally, the results validate the superiority of our method over environment-specific models by a minimum margin of 6\% in cases of limited data.},
booktitle = {Proceedings of the 8th Workshop on Body-Centric Computing Systems},
pages = {13‚Äì18},
numpages = {6},
keywords = {Wi-Fi CSI, human activity recognition, environment-independent feature extraction, deep learning},
location = {Helsinki, Finland},
series = {BodySys '23}
}

@inproceedings{10.1145/3581791.3596838,
author = {Zhang, Xiao and Klevering, Griffin and Wang, Juexing and Xiao, Li and Li, Tianxing},
title = {RoFin: 3D Hand Pose Reconstructing via 2D Rolling Fingertips},
year = {2023},
isbn = {9798400701108},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3581791.3596838},
doi = {10.1145/3581791.3596838},
abstract = {Smart homes, medical devices, and education systems, among other emerging cyber-physical systems, hold immense promise for sensing-based user interfaces, especially for using fingers and hand gestures as system input. However, vision approaches compatible with time-consuming image processing adopt low 60 Hz location sampling rate (frame rate) for real-time hand gesture recognition. Furthermore, they are not suitable for low-light environment and long detection range. In this paper, we propose RoFin, which first exploits 6 temporal-spatial 2D rolling fingertips for real-time 3D reconstructing of 20-joint hand pose. RoFin designs active optical labeling for finger identification and enhances inside-frame 3D location tracking via high rolling shutter rate (5--8 KHz). These features enable great potentials for enhanced multi-user HCI, virtual writing for Parkinson suffers, etc. We implement RoFin prototypes with wearable gloves attached with low-power single-colored LED nodes and commercial cameras. The experiment results show that (1) In flexible sensing distances up to 2.5 m, RoFin achieves an average labeling parsing accuracy of 85\%. (2) In comparison to vision-based techniques, RoFin improves the tracking grain with 4\texttimes{} more sampled points each frame. (3) RoFin reconstructs a hand pose in real time with 16 mm mean deviation error compared with Leap Motion under flexible distance.},
booktitle = {Proceedings of the 21st Annual International Conference on Mobile Systems, Applications and Services},
pages = {330‚Äì342},
numpages = {13},
keywords = {rolling shutter, sensing, hand pose reconstructing, deep learning, wearable device, optical wireless communication},
location = {Helsinki, Finland},
series = {MobiSys '23}
}

@inproceedings{10.1145/3579142.3594294,
author = {Deshpande, Shailesh Shankar and Kunde, Shruti and Singh, Ravi and Banolia, Chaman and Singhal, Rekha and P., Balamurlidhar},
title = {DAFTA: Distributed Architecture for Fusion-Transformer training Acceleration},
year = {2023},
isbn = {9798400700934},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3579142.3594294},
doi = {10.1145/3579142.3594294},
abstract = {Multi-modal data fusion transformer is a deep learning model that integrates information from multiple modalities, such as text, image, audio, etc., to improve performance in various tasks, especially in the remote sensing domain. Recent efforts leverage hyperspectral imaging (HSI) and LiDAR sensors and their complementary information about the target. Remote sensing image classification is inherently a transductive learning problem, requiring repeated model training (e.g., environment monitoring applications where changes occur on a daily or weekly basis). Hyperspectral data is typically high dimensional and massive, and model training can take an impractically long time (several days to weeks). By reducing training time, it becomes possible to process larger amounts of data and develop more efficient and accurate models. In this paper, we introduce a novel distributed training architecture, DAFTA, which addresses the challenges associated with the processing of large multi-modal remote sensing data. DAFTA is enabled to handle any combination of remote sensing modalities. Additionally, we leverage the similarity of the feature space to optimize the training process and achieve the training with a reduced data set which is equivalent to a complete data set. The proposed approach provides a systematic and efficient method for managing large remote sensing data and enables accurate and timely insights for various applications such as agriculture and infrastructure development. We conduct experiments on two real-world data sets of remotely-sensed images. Our results validate the efficacy of the proposed distributed training approach by achieving a speed-up in the range of 5x without compromising the accuracy, thus making it more practical for real-world applications.},
booktitle = {Proceedings of the International Workshop on Big Data in Emergent Distributed Environments},
articleno = {6},
numpages = {9},
keywords = {remote sensing, multi-modal, fusion transformers, distributed training},
location = {Seattle, WA, USA},
series = {BiDEDE '23}
}

@inproceedings{10.1145/3579371.3589066,
author = {Hou, Xiaofeng and Liu, Jiacheng and Tang, Xuehan and Li, Chao and Chen, Jia and Liang, Luhong and Cheng, Kwang-Ting and Guo, Minyi},
title = {Architecting Efficient Multi-modal AIoT Systems},
year = {2023},
isbn = {9798400700958},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3579371.3589066},
doi = {10.1145/3579371.3589066},
abstract = {Multi-modal computing (M2C) has recently exhibited impressive accuracy improvements in numerous autonomous artificial intelligence of things (AIoT) systems. However, this accuracy gain is often tethered to an incredible increase in energy consumption. Particularly, various highly-developed modality sensors devour most of the energy budget, which would make the deployment of M2C for real-world AIoT applications a difficult challenge.To address the above issue, we propose AMG, an innovative HW/SW co-design solution tailored to multi-modal AIoT systems. The key behind AMG is modality gating (throttling) that allows for adaptively sensing and computing modalities for different tasks. This is non-trivial since we must balance situational awareness, energy conservation, and execution latency. AMG achieves our goal with two first-of-its-kind designs. 1) It introduces a novel decoupled modality sensor architecture to support partial throttling of modality sensors. Doing so allows one to greatly save AIoT power but maintains sensor data flow. 2) AMG also features a smart power management strategy based on the new architecture, allowing the device to initialize and tune itself with the optimal configuration. It can predict whether a reasonable degree of accuracy will be satisfied during runtime, and react proactively to remediate the gating process. Extensive evaluation based on our prototype system confirms that AMG improves the AIoT lifespan by 74.5\% to 133.7\% with the same energy budget while meeting the performance requirements.},
booktitle = {Proceedings of the 50th Annual International Symposium on Computer Architecture},
articleno = {31},
numpages = {13},
keywords = {edge artificial intelligence, autonomous embedded systems, multi-modal computing, modality gating, energy efficiency},
location = {Orlando, FL, USA},
series = {ISCA '23}
}

@inproceedings{10.1145/3579371.3589061,
author = {Bleier, Nathaniel and Wezelis, Abigail and Varshney, Lav and Kumar, Rakesh},
title = {Programmable Olfactory Computing},
year = {2023},
isbn = {9798400700958},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3579371.3589061},
doi = {10.1145/3579371.3589061},
abstract = {While smell is arguably the most visceral of senses, olfactory computing has been barely explored in the mainstream. We argue that this is a good time to explore olfactory computing since a) a large number of driver applications are emerging, b) odor sensors are now dramatically better, and c) non-traditional form factors such as sensor, wearable, and xR devices that would be required to support olfactory computing are already getting widespread acceptance. Through a comprehensive review of literature, we identify the key algorithms needed to support a wide variety of olfactory computing tasks. We profiled these algorithms on existing hardware and identified several characteristics, including the preponderance of fixed-point computation, and linear operations, and real arithmetic; a variety of data memory requirements; and opportunities for data-level parallelism. We propose Ahromaa, a heterogeneous architecture for olfactory computing targeting extremely power and energy constrained olfactory computing workloads and evaluate it against baseline architectures of an MCU, a state-of-art CGRA, and an MCU with packed SIMD. Across our algorithms, Ahromaa's operating modes outperform the baseline architectures by 1.36, 1.22, and 1.1\texttimes{} in energy efficiency when operating at MEOP. We also show how careful design of data memory organization can lead to significant energy savings in olfactory computing, due to the limited amount of data memory many olfactory computing kernels require. These improvements to the data memory organization lead to additional 4.21, 4.37, and 2.85\texttimes{} improvements in energy efficiency on average.},
booktitle = {Proceedings of the 50th Annual International Symposium on Computer Architecture},
articleno = {26},
numpages = {14},
location = {Orlando, FL, USA},
series = {ISCA '23}
}

@inproceedings{10.1145/3588444.3591002,
author = {Yu, Ping and Wang, Yi A and Li, Ming and Du, Jianxin and Diaz, Raul},
title = {RMTS: A Real-time Media Transport Stack Based on Commercial Off-the-shelf Hardware},
year = {2023},
isbn = {9798400701603},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3588444.3591002},
doi = {10.1145/3588444.3591002},
abstract = {The broadcast production industry is undergoing a transformation from Serial Digital Interface (SDI) [18] to Internet Protocol (IP) [1] networks for media transport. Specialized equipment and FPGA implementations for IP based raw media transport are currently dominant due to strict low-latency and reliability requirements. These custom hardware solutions inevitably cause production environment operational complexity and scalability challenges. To enable more flexible and modular media production environments, this paper proposes RMTS, a software stack for real-time media transport based on commercial off-the-shelf (COTS) hardware to improve broadcast efficiency and scalability. RMTS provides end-to-end media transport capability compatible with the Society of Motion Picture and Television Engineers (SMPTE) [22] ST 2110 standard [13]. RMTS offers a time-sensitive scheduling algorithm that implements two timing related models by leveraging rate limiting and time synchronization functionality in Network Interface Cards (NICs): (1) an accurate traffic shaping model, and (2) an on-time delivery model, both compatible with ST 2110-21 "Professional Media Over Managed IP Networks: Traffic Shaping and Delivery Timing for Video" [16]. The high accuracy of the traffic shaping model has been validated through third-party ST 2110 testing tools. As a result, RMTS enables standards-based, realtime media transport on COTS systems for high bandwidth, low-latency media applications.},
booktitle = {Proceedings of the 2nd Mile-High Video Conference},
pages = {39‚Äì45},
numpages = {7},
keywords = {SMPTE ST 2110, ultra-high definition video, UHD, rate limiting},
location = {Denver, CO, USA},
series = {MHV '23}
}

@inproceedings{10.1145/3575813.3595207,
author = {Bockrath, Steffen and Pruckner, Marco},
title = {Generalized State of Health Estimation Approach based on Neural Networks for Various Lithium-Ion Battery Chemistries},
year = {2023},
isbn = {9798400700323},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3575813.3595207},
doi = {10.1145/3575813.3595207},
abstract = {The aging estimation of lithium-ion batteries is a central mission for a safe and efficient handling of lithium-ion batteries over the whole battery lifetime. However, especially the absence of precise diagnostic measurements within real-world applications yields the aging estimation a complex challenge. Moreover, the non-linear aging of lithium-ion batteries is strongly dependent on various operating and environmental conditions and the specific battery cell chemistry. This paper presents a generalized state of health estimation approach based on a neural network that can be used for different lithium-ion battery chemistries. The presented algorithm is able to estimate the aging of lithium-ion batteries by using information obtained from raw sensor data without executing further preprocessing or feature engineering steps. It is firstly shown that the developed temporal convolutional network accurately estimates the state of health for three different lithium-ion battery chemistries by only using high-level parameters from partial charging profiles. In addition, the obtained high-level parameters can provide relevant information needed for a battery passport. The final neural network is trained using transfer learning approaches to model the state of health development of a Lithium-Nickel-Cobalt-Aluminum-Oxide (NCA), a Lithium-Nickel-Cobalt-Manganese-Oxide (NCM) and, an NCM-NCA battery cell. The overall mean absolute percentage error of the generalized state of health estimation is 1.43\%.},
booktitle = {Proceedings of the 14th ACM International Conference on Future Energy Systems},
pages = {314‚Äì323},
numpages = {10},
keywords = {Deep learning, Generalized state of health estimation, Lithium-ion battery, Neural network},
location = {Orlando, FL, USA},
series = {e-Energy '23}
}

@article{10.1145/3596243,
author = {Panagiotidou, Georgia and Costanza, Enrico and Fell, Michael J. and Samanani, Farhan and Knox, Hannah},
title = {Supporting Solar Energy Coordination among Communities},
year = {2023},
issue_date = {June 2023},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {7},
number = {2},
url = {https://doi.org/10.1145/3596243},
doi = {10.1145/3596243},
abstract = {The transition to renewable energy is likely to require the creation of growing numbers of energy communities: collectives organized around shared, local renewable resources. Unlike individual households however, the requirements for such communities to share a resource and demand-shift their consumption are still unexplored. By deploying a custom sensor energy monitoring kit and data physicalization workshops with 17 households, we examine the factors that impact their coordination around the shared resource. We found that collective demand-shifting has an extended set of considerations including trade-offs related to privacy, flexibility and social cohesion which are core for navigating already delicate neighborly relations. We use these factors to propose design considerations for a digital system that can act as a mediator among households. Such a system should enable multiple levels of immediacy to account for people's routines, should have adjustable levels of privacy to balance policing and fairness and should be able to offload some of the mundane decision-making. This study moves beyond individual energy consumption behavior to help identify energy as a collective issue that demands collective action. Accordingly, our findings contribute to the development of a next generation of Ubicomp technologies that can support collective action for environmental sustainability.},
journal = {Proc. ACM Interact. Mob. Wearable Ubiquitous Technol.},
month = jun,
articleno = {71},
numpages = {23},
keywords = {coordination, data physicalization, demand-shifting, energy communities, sensors, visualization}
}

@article{10.1145/3596264,
author = {Miao, Yuchen and Gu, Chaojie and Yan, Zhenyu and Chau, Sze Yiu and Tan, Rui and Lin, Qi and Hu, Wen and He, Shibo and Chen, Jiming},
title = {TouchKey: Touch to Generate Symmetric Keys by Skin Electric Potentials Induced by Powerline Radiation},
year = {2023},
issue_date = {June 2023},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {7},
number = {2},
url = {https://doi.org/10.1145/3596264},
doi = {10.1145/3596264},
abstract = {Secure device pairing is important to wearables. Existing solutions either degrade usability due to the need of specific actions like shaking, or they lack universality due to the need of dedicated hardware like electrocardiogram sensors. This paper proposes TouchKey, a symmetric key generation scheme that exploits the skin electric potential (SEP) induced by powerline electromagnetic radiation. The SEP is ubiquitously accessible indoors with analog-to-digital converters widely available on Internet of Things devices. Our measurements show that the SEP has high randomness and the SEPs measured at two close locations on the same human body are similar. Extensive experiments show that TouchKey achieves a high key generation rate of 345 bit/s and an average success rate of 99.29\%. Under a range of adversary models including active and passive attacks, TouchKey shows a low false acceptance rate of 0.86\%, which outperforms existing solutions. Besides, the overall execution time and energy usage are 0.44 s and 2.716 mJ, which make it suitable for resource-constrained devices.},
journal = {Proc. ACM Interact. Mob. Wearable Ubiquitous Technol.},
month = jun,
articleno = {70},
numpages = {21},
keywords = {Key generation, induced body electric potential, wearables}
}

@article{10.1145/3596252,
author = {Kalupahana, Ayanga Imesha Kumari and Balaji, Ananta Narayanan and Xiao, Xiaokui and Peh, Li-Shiuan},
title = {SeRaNDiP: Leveraging Inherent Sensor Random Noise for Differential Privacy Preservation in Wearable Community Sensing Applications},
year = {2023},
issue_date = {June 2023},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {7},
number = {2},
url = {https://doi.org/10.1145/3596252},
doi = {10.1145/3596252},
abstract = {Personal data collected from today's wearable sensors contain a rich amount of information that can reveal a user's identity. Differential privacy (DP) is a well-known technique for protecting the privacy of the sensor data being sent to community sensing applications while preserving its statistical properties. However, differential privacy algorithms are computationally expensive, requiring user-level random noise generation which incurs high overheads on wearables with constrained hardware resources. In this paper, we propose SeRaNDiP -- which utilizes the inherent random noise existing in wearable sensors for distributed differential privacy. We show how various hardware configuration parameters available in wearable sensors can enable different amounts of inherent sensor noise and ensure distributed differential privacy guarantee for various community sensing applications with varying sizes of populations. Our evaluations of SeRaNDiP on five wearable sensors that are widely used in today's commercial wearables -- MPU-9250 accelerometer, ADXL345 accelerometer, BMP 388 barometer, MLP 3115A2 barometer, and MLX90632 body temperature sensor show a 1.4X-1.8X computation/communication speedup and 1.2X-1.5X energy savings against state-of-the-art DP implementation. To the best of our knowledge, SeRaNDiP is the first framework to leverage the inherent random sensor noise for differential privacy preservation in community sensing without any hardware modification.},
journal = {Proc. ACM Interact. Mob. Wearable Ubiquitous Technol.},
month = jun,
articleno = {61},
numpages = {38},
keywords = {Differential Privacy, Inherent Sensor Noise, Low Power, Sensors}
}

@article{10.1145/3596268,
author = {Meier, Manuel and Holz, Christian},
title = {BMAR: Barometric and Motion-based Alignment and Refinement for Offline Signal Synchronization across Devices},
year = {2023},
issue_date = {June 2023},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {7},
number = {2},
url = {https://doi.org/10.1145/3596268},
doi = {10.1145/3596268},
abstract = {A requirement of cross-modal signal processing is accurate signal alignment. Though simple on a single device, accurate signal synchronization becomes challenging as soon as multiple devices are involved, such as during activity monitoring, health tracking, or motion capture---particularly outside controlled scenarios where data collection must be standalone, low-power, and support long runtimes. In this paper, we present BMAR, a novel synchronization method that operates purely based on recorded signals and is thus suitable for offline processing. BMAR needs no wireless communication between devices during runtime and does not require any specific user input, action, or behavior. BMAR operates on the data from devices worn by the same person that record barometric pressure and acceleration---inexpensive, low-power, and thus commonly included sensors in today's wearable devices. In its first stage, BMAR verifies that two recordings were acquired simultaneously and pre-aligns all data traces. In a second stage, BMAR refines the alignment using acceleration measurements while accounting for clock skew between devices. In our evaluation, three to five body-worn devices recorded signals from the wearer for up to ten hours during a series of activities. BMAR synchronized all signal recordings with a median error of 33.4 ms and reliably rejected non-overlapping signal traces. The worst-case activity was sleeping, where BMAR's second stage could not exploit motion for refinement and, thus, aligned traces with a median error of 3.06 s.},
journal = {Proc. ACM Interact. Mob. Wearable Ubiquitous Technol.},
month = jun,
articleno = {69},
numpages = {21},
keywords = {Synchronization, data analysis, embedded systems, monitoring, signal processing, wearable devices}
}

@article{10.1145/3596270,
author = {Liu, Jinyi and Li, Wenwei and Gu, Tao and Gao, Ruiyang and Chen, Bin and Zhang, Fusang and Wu, Dan and Zhang, Daqing},
title = {Towards a Dynamic Fresnel Zone Model to WiFi-based Human Activity Recognition},
year = {2023},
issue_date = {June 2023},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {7},
number = {2},
url = {https://doi.org/10.1145/3596270},
doi = {10.1145/3596270},
abstract = {The passive WiFi sensing research has largely centered on activity sensing using fixed-location WiFi transceivers, leading to the development of several theoretical models that aim to map received WiFi signals to human activity. Of these models, the Fresnel zone model has shown to be particularly noteworthy. However, the growing popularity of mobile WiFi receivers has not been matched by corresponding research on mobile receiver-based theoretical models. This paper fills this gap by presenting the first theoretical model to quantify the impact of moving a moving receiver for WiFi sensing. We propose a novel dynamic Fresnel zone model in the free space of an indoor environment, which takes the form of a cluster of concentric hyperbolas centered on the transmitter and reflection subject. We examine three properties of this model, i.e., relating the variation in RF signals received by the receiver to the position and orientation of the human, the movement of the receiver, and the presence of other objects in the environment. To validate this model, we develop a prototype system and conduct extensive experiments. The results are consistent with our theoretical analysis, and the system is able to detect the direction of the transmitter with an accuracy of 10¬∞ or better, measure the receiver's relative motion displacement within 1 cm a millimeter-level accuracy, and classify five receiver-side activities with an accuracy of 98\%. Our work moves a significant step forward in WiFi sensing and may potentially open up new avenues for future research.},
journal = {Proc. ACM Interact. Mob. Wearable Ubiquitous Technol.},
month = jun,
articleno = {65},
numpages = {24},
keywords = {Channel state information, Dynamic Fresnel Zone Model, Mobile Receiver, Wireless sensing}
}

@article{10.1145/3596246,
author = {Yu, Han and Sano, Akane},
title = {Semi-Supervised Learning for Wearable-based Momentary Stress Detection in the Wild},
year = {2023},
issue_date = {June 2023},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {7},
number = {2},
url = {https://doi.org/10.1145/3596246},
doi = {10.1145/3596246},
abstract = {Physiological and behavioral data collected from wearable or mobile sensors have been used to estimate self-reported stress levels. Since stress annotation usually relies on self-reports during the study, a limited amount of labeled data can be an obstacle to developing accurate and generalized stress-predicting models. On the other hand, the sensors can continuously capture signals without annotations. This work investigates leveraging unlabeled wearable sensor data for stress detection in the wild. We propose a two-stage semi-supervised learning framework that leverages wearable sensor data to help with stress detection. The proposed structure consists of an auto-encoder pre-training method for learning information from unlabeled data and the consistency regularization approach to enhance the robustness of the model. Besides, we propose a novel active sampling method for selecting unlabeled samples to avoid introducing redundant information to the model. We validate these methods using two datasets with physiological signals and stress labels collected in the wild, as well as four human activity recognition (HAR) datasets to evaluate the generality of the proposed method. Our approach demonstrated competitive results for stress detection, improving stress classification performance by approximately 7\% to 10\% on the stress detection datasets compared to the baseline supervised learning models. Furthermore, the ablation study we conducted for the HAR tasks supported the effectiveness of our methods. Our approach showed comparable performance to state-of-the-art semi-supervised learning methods for both stress detection and HAR tasks.},
journal = {Proc. ACM Interact. Mob. Wearable Ubiquitous Technol.},
month = jun,
articleno = {80},
numpages = {23},
keywords = {Semi-Supervised Learning, Stress Detection, Time-Series Learning, Wearable Data}
}

@article{10.1145/3596256,
author = {Gong, Taesik and Kim, Yewon and Orzikulova, Adiba and Liu, Yunxin and Hwang, Sung Ju and Shin, Jinwoo and Lee, Sung-Ju},
title = {DAPPER: Label-Free Performance Estimation after Personalization for Heterogeneous Mobile Sensing},
year = {2023},
issue_date = {June 2023},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {7},
number = {2},
url = {https://doi.org/10.1145/3596256},
doi = {10.1145/3596256},
abstract = {Many applications utilize sensors in mobile devices and machine learning to provide novel services. However, various factors such as different users, devices, and environments impact the performance of such applications, thus making the domain shift (i.e., distributional shift between the training domain and the target domain) a critical issue in mobile sensing. Despite attempts in domain adaptation to solve this challenging problem, their performance is unreliable due to the complex interplay among diverse factors. In principle, the performance uncertainty can be identified and redeemed by performance validation with ground-truth labels. However, it is infeasible for every user to collect high-quality, sufficient labeled data. To address the issue, we present DAPPER (Domain AdaPtation Performance EstimatoR) that estimates the adaptation performance in a target domain with only unlabeled target data. Our key idea is to approximate the model performance based on the mutual information between the model inputs and corresponding outputs. Our evaluation with four real-world sensing datasets compared against six baselines shows that on average, DAPPER outperforms the state-of-the-art baseline by 39.8\% in estimation accuracy. Moreover, our on-device experiment shows that DAPPER achieves up to 396x less computation overhead compared with the baselines.},
journal = {Proc. ACM Interact. Mob. Wearable Ubiquitous Technol.},
month = jun,
articleno = {55},
numpages = {27},
keywords = {Deep learning, Domain adaptation, Mobile sensing, Performance estimation}
}

@article{10.1145/3596234,
author = {Shao, Shuai and Guan, Yu and Zhai, Bing and Missier, Paolo and Pl\"{o}tz, Thomas},
title = {ConvBoost: Boosting ConvNets for Sensor-based Activity Recognition},
year = {2023},
issue_date = {June 2023},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {7},
number = {2},
url = {https://doi.org/10.1145/3596234},
doi = {10.1145/3596234},
abstract = {Human activity recognition (HAR) is one of the core research themes in ubiquitous and wearable computing. With the shift to deep learning (DL) based analysis approaches, it has become possible to extract high-level features and perform classification in an end-to-end manner. Despite their promising overall capabilities, DL-based HAR may suffer from overfitting due to the notoriously small, often inadequate, amounts of labeled sample data that are available for typical HAR applications. In response to such challenges, we propose ConvBoost -- a novel, three-layer, structured model architecture and boosting framework for convolutional network based HAR. Our framework generates additional training data from three different perspectives for improved HAR, aiming to alleviate the shortness of labeled training data in the field. Specifically, with the introduction of three conceptual layers--Sampling Layer, Data Augmentation Layer, and Resilient Layer--we develop three "boosters"--R-Frame, Mix-up, and C-Drop--to enrich the per-epoch training data by dense-sampling, synthesizing, and simulating, respectively. These new conceptual layers and boosters, that are universally applicable for any kind of convolutional network, have been designed based on the characteristics of the sensor data and the concept of frame-wise HAR. In our experimental evaluation on three standard benchmarks (Opportunity, PAMAP2, GOTOV) we demonstrate the effectiveness of our ConvBoost framework for HAR applications based on variants of convolutional networks: vanilla CNN, ConvLSTM, and Attention Models. We achieved substantial performance gains for all of them, which suggests that the proposed approach is generic and can serve as a practical solution for boosting the performance of existing ConvNet-based HAR models. This is an open-source project, and the code can be found at https://github.com/sshao2013/ConvBoost},
journal = {Proc. ACM Interact. Mob. Wearable Ubiquitous Technol.},
month = jun,
articleno = {75},
numpages = {21},
keywords = {Data Augmentation, Deep Learning, Ensemble, Human Activity Recognition, Sensors}
}

@inproceedings{10.1145/3587819.3592553,
author = {Wu, Yi-Hung and Chiang, Hsin-Che and Shirmohammadi, Shervin and Hsu, Cheng-Hsin},
title = {A Dataset of Food Intake Activities Using Sensors with Heterogeneous Privacy Sensitivity Levels},
year = {2023},
isbn = {9798400701481},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3587819.3592553},
doi = {10.1145/3587819.3592553},
abstract = {Human activity recognition, which involves recognizing human activities from sensor data, has drawn a lot of interest from researchers and practitioners as a result of the advent of smart homes, smart cities, and smart systems. Existing studies on activity recognition mostly concentrate on coarse-grained activities like walking and jumping, while fine-grained activities like eating and drinking are understudied because it is more difficult to recognize fine-grained activities than coarse-grained ones. As such, food intake activity recognition in particular is under investigation in the literature despite its importance for human health and well-being, including telehealth and diet management. In order to determine sensors' practical recognition accuracy, preferably with the least amount of privacy intrusion, a dataset of food intake activities utilizing sensors with varying degrees of privacy sensitivity is required. In this study, we collected such a dataset by collecting fine-grained food intake activities using sensors of heterogeneous privacy sensitivity levels, namely a mmWave radar, an RGB camera, and a depth camera. Solutions to recognize food intake activities can be developed using this dataset, which may provide a more comprehensive picture of the accuracy and privacy trade-offs involved with heterogeneous sensors.},
booktitle = {Proceedings of the 14th ACM Multimedia Systems Conference},
pages = {416‚Äì422},
numpages = {7},
keywords = {dataset, activity recognition, food intake, eating, drinking, classification, privacy, mmWave radar, point cloud, RGBD camera, RGBD video},
location = {Vancouver, BC, Canada},
series = {MMSys '23}
}

@inproceedings{10.1145/3586185.3586192,
author = {Wu, Feiyang and Zou, Danping},
title = {Learning Visual Navigation System in Simulation for Autonomous Ground Vehicles in Real World},
year = {2023},
isbn = {9781450399517},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3586185.3586192},
doi = {10.1145/3586185.3586192},
abstract = {Navigation for autonomous ground vehicles (AGV) should be accurate and quick. Traditional navigation systems, consisting of perception, planning, and control, are unable to use noisy visual images efficiently on a power-limited computation unit. These systems also require lots of parameter-tuning work when deployed on a new robot. By contrast, end-to-end approaches, that directly map sensor information and robot state to planned trajectories, have the potential to navigate autonomous ground vehicles on edge computation devices and possess far fewer manually-tuned parameters. However, collecting data on real robots and labeling the data for training is time-consuming and costly. Therefore, many approaches turn to automatic data labeling and collection in the simulation environment. Motivated by a learning-based navigation system for drones, we present a sim-to-real learning-based navigation pipeline for AGVs where the model is solely trained in simulation environments (Gazebo and UE4) and directly deployed to a real AGV. Results show that after training, the system achieves a high success rate in both simulation and real-world cases, indicating the great potential of this learning pipeline.},
booktitle = {Proceedings of the 2023 4th International Conference on Artificial Intelligence in Electronics Engineering},
pages = {16‚Äì23},
numpages = {8},
keywords = {autonomous navigation, imitation learning, neural networks, sim-to-real transfer},
location = {Haikou, China},
series = {AIEE '23}
}

@inproceedings{10.1145/3555776.3578836,
author = {Kumar, Sanjay and Abhishek, Kumar and Jhaveri, Rutvij and Alabdulatif, Abdulatif and Gaur, Rajkumar},
title = {An Efficient Dual Encryption of IoMT data Using Lightweight Security Scheme for Cloud Based IoT Environment},
year = {2023},
isbn = {9781450395175},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3555776.3578836},
doi = {10.1145/3555776.3578836},
abstract = {As Internet of Things (IoT) technology develops, medical equipment, wearables, sensors, and users can be linked together to create an ecosystem known as the Internet of Medical Things (IoMT). IoMT enhances the effectiveness, precision, and affordability of the current healthcare system. It is difficult to guarantee data security and privacy of data in the IoMT ecosystem due to the fact that it incorporates several businesses, heterogeneous networks, and a lot of private information. IoT devices' processing and power requirements make it difficult to ensure their security. In order to secure their data and connections, many IoT systems use asymmetric cryptography and Elliptic Curve Cryptography (ECC). Implementing and deploying these security and privacy solutions for the IoT environment, however, continues to be a substantial problem due to the hardware restrictions of IoT objects. In this paper, we have presented a more effective lightweight cryptographic system based on Elliptic Curve and Dual Cryptography (ECDC) to strengthen ECC and secure communication between IoMT devices. It protects against all kinds of security problems, like authentication, privacy, and integrity, and stops common cyberattacks.},
booktitle = {Proceedings of the 38th ACM/SIGAPP Symposium on Applied Computing},
pages = {1782‚Äì1788},
numpages = {7},
keywords = {IoMT, security, healthcare, ECC},
location = {Tallinn, Estonia},
series = {SAC '23}
}

@inproceedings{10.1145/3575757.3593652,
author = {Peeck, Jonas and Ernst, Rolf},
title = {Enabling multi-link data transmission for collaborative sensing in open road scenarios},
year = {2023},
isbn = {9781450399838},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3575757.3593652},
doi = {10.1145/3575757.3593652},
abstract = {Fully autonomous driving applications rely on a complete knowledge of their operational environment to ensure safety while maintaining efficient driving. However, in scenarios with close visual restrictions, such as urban traffic, the lack of sensor data leads to a safety-related degradation of the autonomous service. Collaborative sensing, describing the timely wireless transmission of additional large external sensor data, can fill this information gap. However, real-time protocols for error-protected transmission of sensor data that also consider load dynamics as well as link prioritization are not available. To make the channel usable for such collaborative sensing requirements, even in challenging load scenarios, we introduce an adaptive minimum distance shaping mechanism of fragments that exploits the round-trip time information from the protocol‚Äôs error protection mechanism. We place that mechanism in the context of the IEEE&nbsp;802.11p WLAN-based V2X software stack and evaluate them with an OMNeT++ simulation. The results show that link robustness is achieved under varying load conditions while channel access and load injection follow the expected prioritization.},
booktitle = {Proceedings of the 31st International Conference on Real-Time Networks and Systems},
pages = {76‚Äì86},
numpages = {11},
keywords = {V2X, collaborative sensing, middleware, real-time, wireless},
location = {Dortmund, Germany},
series = {RTNS '23}
}

@article{10.1145/3591240,
author = {Park, Jihyeok and Youn, Dongjun and Lee, Kanguk and Ryu, Sukyoung},
title = {Feature-Sensitive Coverage for Conformance Testing of Programming Language Implementations},
year = {2023},
issue_date = {June 2023},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {7},
number = {PLDI},
url = {https://doi.org/10.1145/3591240},
doi = {10.1145/3591240},
abstract = {The conformance testing of programming language implementations is crucial to support correct and consistent execution environments. Because manually maintaining conformance tests for real-world programming languages is cumbersome and labor-intensive, researchers have presented various ways to make conformance tests effective and efficient. One such approach is to use graph coverage, one of the most widely-used coverage criteria, to generate tests that reach different parts of a mechanized language specification. Since mechanized specifications use functions or inductive definitions to describe the semantics of language features, traditional graph coverage criteria for software work as they are. However, they may not produce high-quality conformance tests because language implementations often have specialized execution paths for different features, even when their semantics descriptions use the same functions. Traditional graph coverage may not distinguish test requirements of such language features, which degrades the quality of conformance testing. Similarly, it may not distinguish test requirements of different parts of the same language feature when their semantics descriptions use the same functions.    We present feature-sensitive (FS) coverage as a novel coverage criterion to generate high-quality conformance tests for language implementations. It is a general extension of graph coverage, refining conventional test requirements using the innermost enclosing language features. We also introduce feature-call-path-sensitive (FCPS) coverage, a variant of FS coverage, and extend both coverage criteria using the ùëò-limiting approach. To evaluate the effectiveness of the new coverage criteria for language implementations, we apply them to a mechanized specification of JavaScript. We extend JEST, the state-of-the-art JavaScript conformance test synthesizer using coverage-guided mutational fuzzing, with various FS and FCPS coverage criteria. For the latest JavaScript language specification (ES13, 2022), our tool automatically synthesizes 237,981 conformance tests in 50 hours with five coverage criteria. We evaluated the conformance of eight mainstream JavaScript implementations (four engines and four transpilers) with the synthesized conformance tests and discovered bugs in all of them. The tool detected 143 distinct conformance bugs (42 in engines and 101 in transpilers), 85 of which were confirmed by the developers and 83 of which were newly discovered bugs.},
journal = {Proc. ACM Program. Lang.},
month = jun,
articleno = {126},
numpages = {23},
keywords = {conformance test synthesis, coverage-guided fuzzing, feature-sensitive coverage, mechanized specification}
}

@inproceedings{10.1145/3589250.3596146,
author = {Miltenberger, Marc and Arzt, Steven},
title = {Extensible and Scalable Architecture for Hybrid Analysis},
year = {2023},
isbn = {9798400701702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3589250.3596146},
doi = {10.1145/3589250.3596146},
abstract = {The prevalence of Android apps and their widespread use in daily life has made them a prime subject of study in program analysis. Apps for e-mail, navigation, mobile banking, eGovernment, healthcare, etc. each have their respective requirements on stability, effciency, and security, which can be checked using static and dynamic analysis.   While developers and researchers can pick from a variety of scalable and integrated frameworks for static analysis, designing a dynamic analysis still requires significant engineering and design effort that contributes little to the analysis task at hand. Existing scholarly work on dynamic analysis has instead focused on individual challenges such as effcient data flow tracking, or code coverage in UI exploration. Combining dynamic analysis configuration and results with artifacts from static analysis is usually dealt with on an individual basis that does not generalize in the sense of a re-usable framework.   In this paper, we present a reference architecture and implementation for an integrated, scalable, and extensible hybrid analysis that offers a wide range of dynamic analysis capabilities. We hope that researchers can build upon our work for increased effciency in hybrid analysis.},
booktitle = {Proceedings of the 12th ACM SIGPLAN International Workshop on the State Of the Art in Program Analysis},
pages = {34‚Äì39},
numpages = {6},
keywords = {analysis, android, architecture, dynamic, static},
location = {Orlando, FL, USA},
series = {SOAP 2023}
}

@inproceedings{10.1145/3583781.3590276,
author = {Liao, Yunkun and Wu, Jingya and Lu, Wenyan and Li, Xiaowei and Yan, Guihai},
title = {Optimize the TX Architecture of RDMA NIC for Performance Isolation in the Cloud Environment},
year = {2023},
isbn = {9798400701252},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3583781.3590276},
doi = {10.1145/3583781.3590276},
abstract = {Remote Direct Memory Access (RDMA) is a promising technology for achieving low latency and high bandwidth access to remote memory. However, performance interference exists when multiple tenants share an RDMA Network Interface Card (RNIC) in the cloud environment. Although some initial studies have investigated the root cause and possible solutions to RDMA performance interference, there is no research to analyze and solve the performance interference from the RNIC architecture. Compared with the existing software approach, optimizing RNIC architecture can introduce less performance and CPU overhead. This paper addresses performance isolation by modeling, analyzing, and optimizing the transmit-side (TX) RNIC architecture. First, we introduce a baseline TX RNIC architecture to explain the existing performance interference. Then, we propose separate caching and slicing execution to avoid the bandwidth-sensitive tenants affecting latency-sensitive tenants. Later, we add isolated backpressure and adaptive Weighted Round-robin scheduling to ensure the bandwidth-sensitive tenants share the bandwidth equally. Our experiments show that these optimizations achieve near-optimal performance isolation.},
booktitle = {Proceedings of the Great Lakes Symposium on VLSI 2023},
pages = {29‚Äì35},
numpages = {7},
keywords = {architecture design, network interface card (nic), performance isolation, remote direct memory access (rdma)},
location = {Knoxville, TN, USA},
series = {GLSVLSI '23}
}

@inproceedings{10.1145/3583781.3590255,
author = {Alruwaill, Musharraf N. and Mohanty, Saraju P. and Kougianos, Elias},
title = {hChain: Blockchain Based Healthcare Data Sharing with Enhanced Security and Privacy Location-Based-Authentication},
year = {2023},
isbn = {9798400701252},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3583781.3590255},
doi = {10.1145/3583781.3590255},
abstract = {In smart healthcare, blockchain technology addresses existing concerns with security, privacy, and electronic healthcare records. In addition, utilizing edge devices with IoMT devices is very advantageous for addressing security, computing, and storage challenges. Symmetric and asymmetric keys are used to conceal sensitive information from unauthorized parties. Moreover, the hash function SHA256 helps for data alteration detection. The proposed system uses a blockchain-based smart healthcare system using IoMT devices for continuous patient monitoring. The edge device is used to hash and encrypt data and provide additional computational capability. A symmetric key maintains data privacy in the blockchain, allowing patients to safely share data through smart contracts while preventing unauthorized physicians from seeing it. A verification node and blockchain sign and validate patient data in the healthcare provider system using an asymmetric key. Location-based authentication is addressed to ensure the authenticity and data source.},
booktitle = {Proceedings of the Great Lakes Symposium on VLSI 2023},
pages = {97‚Äì102},
numpages = {6},
keywords = {blockchain, data integrity, data privacy, data security, data sharing, electronic health record (ehr), healthcare cyber-physical system (h-cps), internet-of-medical-things (iomt), smart healthcare},
location = {Knoxville, TN, USA},
series = {GLSVLSI '23}
}

@inproceedings{10.1145/3590837.3590906,
author = {Ugale, Archana Ramrao and Potgantwar, Amol Dnyaneshwar},
title = {An Analytical Approach on Artificial Intelligence Based Models for Anomaly Detection in Sensor Networks},
year = {2023},
isbn = {9781450399937},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3590837.3590906},
doi = {10.1145/3590837.3590906},
abstract = {Wireless sensor networks, also known as WSNs, have quickly transformed into one of the main important areas of research, significantly influencing the development of new technologies. Many resource-constrained sensor nodes function independently to collaborate and maintain wireless networks. Through these networks, essential source information is gathered and transferred to the end users or decision-makers. WSNs have been implemented in different critical applications, such as remote patient health monitoring systems, home automation systems, sales tracking systems, enemy target monitoring and tracking systems, and fire detection system implementations, where the trustworthiness of WSNs becomes very important. These kinds of applications desire to have both comprehensive and accurate data. WSNs may be prone to anomalies as a result of low-cost hardware and software that is unstable, as well as an adverse operating environment that may disrupt the network's communication. It is necessary to identify these anomalies because they can bring about malfunctions in the network and, as a result, impair the quality of the data that has been gathered. In this research, we investigate the anomalies present in WSN, discuss the desirable attributes of anomaly detection approaches, and examine the different anomaly detection strategies that can be applied to wireless sensor networks.},
booktitle = {Proceedings of the 4th International Conference on Information Management \&amp; Machine Intelligence},
articleno = {69},
numpages = {6},
keywords = {Cloud Service Providers, Cloud Services, Cost Analysis, Resource Scheduling},
location = {Jaipur, India},
series = {ICIMMI '22}
}

@inproceedings{10.1145/3590837.3590904,
author = {E V, Sandeepkumar and Jayavel, Kayalvizhi},
title = {Effective and light weight security system for highly confidential cloud data such as PHR},
year = {2023},
isbn = {9781450399937},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3590837.3590904},
doi = {10.1145/3590837.3590904},
abstract = {The server in a cloud storage system can hold a very large amount of Personal health records (PHR) data or information. The cloud platform's storage servers provide archival services for a lengthy time frame. The third party basically functions as an administrator for the efficiency of cloud storage. This is why we're starting up our cloud storage service. One of the biggest difficulties with the cloud is that it is vulnerable to hacking. Ordinary methods of encryption are used to safeguard the information from prying eyes. All of the secret messages' code words are kept in a system of varying symbols. Deletion coding is carried out in a manner analogous to that which is used to calculate the unequal code word cyphers required for a communication in a distributed setting. When the message symbols are stored in different servers in a dispersed environment, the cryptographic term signs are also calculated independently and stored. For this reason, we introduce and include a threshold proxy re-encryption scheme. Fully Homomorphic Encryption is a promising approach to securing sensitive PHR data by limiting who can view it. When sending encrypted PHR data, the proxy re-encryption mechanism re-encrypts the PHR data again before sending it on to the recipient or storage server. Allocation is completed when secure access control has maximised performance. In light of this, we expect to see the Schmidt-Samoa Public Key Encryption (SSPKE) method developed on the Enhanced v Boosting Algorithm (EBA) by PHR data Hiding Architecture. Additionally, in this initiative, we employ a procedure of multi-party protocol admission control to operate and access the user's PHR data without jeopardising the sensitive cloud PHR data privacy. The results of the experiments show the beneficial effect when various metrics, such as total processing time, server response time, and PHR data decomposition rate, are taken into account for the application of PHR.},
booktitle = {Proceedings of the 4th International Conference on Information Management \&amp; Machine Intelligence},
articleno = {67},
numpages = {7},
keywords = {EBA, PHR, Re-encryption,Security, SSPKE},
location = {Jaipur, India},
series = {ICIMMI '22}
}

@inproceedings{10.1145/3590837.3590943,
author = {Rajpoot, Navneet Kumar and Singh, Prabhdeep and Pant, Bhaskar},
title = {Nature-Inspired Load Balancing Approach in Cloud Computing Environment for Smart Healthcare},
year = {2023},
isbn = {9781450399937},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3590837.3590943},
doi = {10.1145/3590837.3590943},
abstract = {The development of a fast-response, a smart healthcare system that makes use of fog computing and the internet of things is of paramount importance at present time. Managing the ever-increasing load on fog nodes can be especially challenging in dynamic and diverse fog networks due to the high potential for overhead. As the number and variety of IoT-based devices grow, so ensure their processing requirements, and this is where fog computing comes in. The use of sensor-based technologies helps intelligent medical services operate, as well as the system's ability to automatically gather and process data can help to accelerate the entire platform's performance. The research formulated here introduces a novel framework for smart health care, in which a set of procedures are carried out with the primary goal of decreasing delay and performance issues. The Ant Colony Optimization Technique is a nature-inspired technique utilized to improve system efficiency by balancing loads, decreasing response times, and minimizing delay. In this research, we have proposed an approach for fog-assisted smart healthcare systems that is superior to the state-of-the-art in all of these important metrics: latency, response time, overall system accuracy, and system stability.},
booktitle = {Proceedings of the 4th International Conference on Information Management \&amp; Machine Intelligence},
articleno = {106},
numpages = {6},
keywords = {Cloud Computing, Fog computing, IoT, Load balancing, Smart health care},
location = {Jaipur, India},
series = {ICIMMI '22}
}

@inproceedings{10.1145/3593743.3593753,
author = {Slingerland, Geertje and Overdiek, Anja},
title = {Beyond human sensors: More-than-human Citizen Sensing in biodiversity Urban Living Labs},
year = {2023},
isbn = {9798400707582},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3593743.3593753},
doi = {10.1145/3593743.3593753},
abstract = {Recent interest in biodiversity to combat climate crises led governments to use data platforms and sensing tools to monitor, conserve and increase city biodiversity. Given that most of these tools are designed for expert users and most city space is privately owned, there is a growing need for urban living labs (ULLs) approaches that combine community co-design with HCI for biodiversity. This paper develops and explores the BULL (Biodiversity Urban Living Lab) approach, building on the existing City Commons HCI framework, using research-through-design and action research methods. A BULL approach should not only engage citizens but also lead to opportunities for individual and collective action towards biodiversity as perceived common. Next to this, ecological and technological entities as non-human actors need to be involved in community-based co-creation in BULLs. The BULL approach provides a process and specific tools for multi-stakeholder groups, including more-than-human ones, to experiment with opportunities for more biodiversity in a local community, resulting in individual and collective action.},
booktitle = {Proceedings of the 11th International Conference on Communities and Technologies},
pages = {27‚Äì38},
numpages = {12},
keywords = {Biodiversity, Citizen Sensing, More-than-human, Smart City, Urban Living Lab},
location = {Lahti, Finland},
series = {C&amp;T '23}
}

@inproceedings{10.1145/3590003.3590057,
author = {Peng, Qingsong},
title = {Health monitoring system for elderly people based on Raspberry Pi},
year = {2023},
isbn = {9781450399449},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3590003.3590057},
doi = {10.1145/3590003.3590057},
abstract = {We present a comprehensive overview of the application of Raspberry Pi in the field of health monitoring for elderly people with disabilities. Firstly we discuss the advantages of using artificial intelligence technology for health monitoring of elderly people, and the significance of using information technology devices to achieve health monitoring for the elderly, while keeping the cost of the devices low. And then we examine the development of Raspberry Pi and its advantages for health monitoring of elderly people with disabilities, such as its low cost, portability, and ease of use. After that we outline the methods of collecting data for health monitoring of elderly people, such as using sensors to measure heart rate, oxygen levels, and blood pressure, and integrating these sensors into a single device. We also discuss the implementation of a Raspberry Pi-based health monitoring system for elderly people, and the ways in which health data can be utilized to optimize the performance of the system. The work provides useful insights for those who are interested in using Raspberry Pi for health monitoring applications for elderly people with disabilities.},
booktitle = {Proceedings of the 2023 2nd Asia Conference on Algorithms, Computing and Machine Learning},
pages = {305‚Äì308},
numpages = {4},
keywords = {CCS CONCEPTS},
location = {Shanghai, China},
series = {CACML '23}
}

@inproceedings{10.1145/3590003.3590101,
author = {Shen, Jiamin and Xu, Li and Wan, Xu and Chai, Jixuan and Fan, Chunlong},
title = {Research on Constant Perturbation Strategy for Deep Reinforcement Learning},
year = {2023},
isbn = {9781450399449},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3590003.3590101},
doi = {10.1145/3590003.3590101},
abstract = {The development of attack algorithms for deep reinforcement learning is an important part of its security research. In this paper, we propose a deep reinforcement constant perturbation strategy approach for deep reinforcement learning with long-range time-series dependence from the perspective of the sequence of interaction between an agent and its environment.The algorithm is based on a small amount of historical interaction information, and a constant perturbation is designed to disrupt the long-range temporal association of the deep reinforcement learning algorithm based on sensitive region selection to achieve the attack effect.The experimental results show that the constant perturbation based on time series has a good effect, i.e. inducing agents to make frequent wrong decisions and get minimal reward. At the same time, this algorithm still has an attacking effect on the defensively trained agents, and it effectively reduces the number of computations adversarial perturbations.},
booktitle = {Proceedings of the 2023 2nd Asia Conference on Algorithms, Computing and Machine Learning},
pages = {526‚Äì533},
numpages = {8},
keywords = {Deep reinforcement learning, constant perturbation strategies, robustness of models, time series dependence.},
location = {Shanghai, China},
series = {CACML '23}
}

@inproceedings{10.1145/3590003.3590100,
author = {Huang, Xinmei and Zhang, Sheng},
title = {Human Activity Recognition based on Transformer in Smart Home},
year = {2023},
isbn = {9781450399449},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3590003.3590100},
doi = {10.1145/3590003.3590100},
abstract = {With the advancement of artificial intelligence, smart home has attracted much attention from scholars. Human Activity Recognition (HAR) is a crucial foundation for various applications in smart home. In this paper, to improve the accuracy of HAR and promote the development of applications and services in smart home, we propose a Transformer-based approach that integrates multiple sensor sequence inputs for HAR. We integrate sequence features, collect contextual information, and employ Transformer to recognize various activities for the CASAS Aruba dataset that uses environmental sensors. The validation results on real-world dataset demonstrate its effectiveness compared to traditional machine learning and deep learning methods.},
booktitle = {Proceedings of the 2023 2nd Asia Conference on Algorithms, Computing and Machine Learning},
pages = {520‚Äì525},
numpages = {6},
keywords = {Human activity recognition, Smart home, Transformer},
location = {Shanghai, China},
series = {CACML '23}
}

@inproceedings{10.1145/3590003.3590046,
author = {Geng, Kuan and Ata, Jahangir Moshayedi and Chen, Jing and Hu, Jiandong and Zhang, Hao},
title = {ENOSE Performance in Transient Time and Steady State Area of Gas Sensor Response for Ammonia Gas: Comparison and Study},
year = {2023},
isbn = {9781450399449},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3590003.3590046},
doi = {10.1145/3590003.3590046},
abstract = {This paper proposed an electronic nose system that utilized a SnO2 semiconductor sensor array to detect volatile ammonia gas in farmland. All sensors were controlled by the Arduino development board. The system could collect data during both the steady-state and transient phases of sensor operation. The collected data was analyzed using PCA (principal component analysis) and MLP (Multi-layer perceptron) neural networks. The experiment was divided into two parts: The first part analyzed four concentrations of ammonia (100ppm, 200ppm, 400ppm, and Air) using PCA and MLP, which successfully distinguished the concentrations with an identification rate of over 95\%. In the second part, four gases (air mixed with ammonia, pure ammonia gas, air mixed with ethanol, and pure ethanol) were analyzed using PCA and MLP, with the electronic nose system successfully distinguishing between the four types of gases. The system could read and process data during the transient phase of the sensor, and the constructed sensor array electronic nose system and acquisition method has significant potential for ammonia detection in agricultural environments.},
booktitle = {Proceedings of the 2023 2nd Asia Conference on Algorithms, Computing and Machine Learning},
pages = {247‚Äì252},
numpages = {6},
keywords = {Electronic nose, MLP, Neural network, PCA, Volatile ammonia},
location = {Shanghai, China},
series = {CACML '23}
}

@inproceedings{10.1145/3581807.3581872,
author = {Jie, Rongxin and Yang, Banghua and Wang, Zhaokun and Ma, Jun and Xia, Xinxing and Gao, Shouwei},
title = {Brain control jigsaw puzzle system based on hybrid brain computer interface of motor imagery and steady-state visual evoked potential},
year = {2023},
isbn = {9781450397056},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3581807.3581872},
doi = {10.1145/3581807.3581872},
abstract = {With the development of information decoding technology, the field of Brain-computer interface (BCI) has developed rapidly in recent years. Among them, Motor Imagery Brain-computer Interface (MI-BCI) and Steady state visual evoked potential Brain-computer Interface (SSVEP-BCI) have been effectively applied in some brain-controlled rehabilitation training systems to assist stroke patients in their normal life. In this paper, a brain-controlled jigsaw puzzle system based on Motor Imagery and Steady state visual evoked potential (MI-SSVEP) hybrid brain-machine is constructed. In this system, the left-right moving jigsaw puzzle uses the MI-BCI paradigm and the up-down moving jigsaw puzzle uses the SSVEP-BCI paradigm. To reduce the difficulty for patients, the system will set the moving route of the puzzle in advance. When the puzzle piece needs to move left or right, the system will remind the patient through voice and words that the patient needs to Imagine clenching his fist with his left or right hand at this time. When the puzzle piece needs to move up and down, the system will remind the patient to gaze at the upward or downward flashing arrow. If the patient makes an incorrect recognition, the system will re-open the recognition at the current position until it is correct. Compared with the ordinary rehabilitation training system, this system adds the elements of the jigsaw puzzle, so that patients can complete the training in the process of enjoying the game. The success of the jigsaw puzzle will also increase the sense of achievement for patients, and play the effect of rehabilitation training while maintaining the healthy state of mind of patients. The average recognition time of MI is 2.5s, and the accuracy is 65\%. The average recognition time of SSVEP is 1.5s, and the accuracy is 95\%. The system operates stably, each subject was able to complete the puzzle task quickly. The experimental results demonstrate the feasibility and potential of this hybrid brain-machine system and provide a new idea for the rehabilitation training of stroke patients.},
booktitle = {Proceedings of the 2022 11th International Conference on Computing and Pattern Recognition},
pages = {447‚Äì451},
numpages = {5},
keywords = {Brain control puzzle system, Hybrid brain-computer interface, MI-BCI, SSVEP-BCI},
location = {Beijing, China},
series = {ICCPR '22}
}

@inproceedings{10.1145/3581807.3581821,
author = {Liu, Lingzhi and Qiang, Baohua and Wang, Yuanchun and Yang, Xianyi and Tian, Jubo and Zhang, Shihao},
title = {Object Detection Algorithm Based on Coordinate Attention and Context Feature Enhancement},
year = {2023},
isbn = {9781450397056},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3581807.3581821},
doi = {10.1145/3581807.3581821},
abstract = {In recent years, object detection has been widely used in various fields such as face detection, remote sensing image detection and pedestrian detection. Due to the complex environment in the actual scene, we need to fully obtain the feature information in the image to improve the accuracy of object detection. This paper proposes an object detection algorithm based on coordinate attention and contextual feature enhancement. We design a multi-scale attention feature pyramid network, which first uses multi-branch atrous convolution to capture multi-scale context information, and then fuses the coordinate attention mechanism to embed location information into channel attention, and finally uses a bidirectional feature pyramid structure to effectively fuse high-level features and low-level features. We also adopt the GIoU loss function to further improve the accuracy of object detection. The experimental results show that the proposed method has certain advantages compared with other detection algorithms in the PASCAL VOC datasets.},
booktitle = {Proceedings of the 2022 11th International Conference on Computing and Pattern Recognition},
pages = {95‚Äì101},
numpages = {7},
keywords = {Atrous convolution, Coordinate attention, Feature pyramid network, Object detection},
location = {Beijing, China},
series = {ICCPR '22}
}

@article{10.1145/3558519,
author = {Adil, Muhammad and Ali, Jehad and Jadoon, Muhammad Mohsin and Alotaibi, Sattam Rabia and Kumar, Neeraj and Farouk, Ahmed and Song, Houbing},
title = {COVID-19: Secure Healthcare Internet of Things Networks, Current Trends and Challenges with Future Research Directions},
year = {2023},
issue_date = {August 2023},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {19},
number = {3},
issn = {1550-4859},
url = {https://doi.org/10.1145/3558519},
doi = {10.1145/3558519},
abstract = {The number of affirmed COVID-19 cases showed an enormous increase in the recent past throughout the globe. Keeping in view the catastrophic destruction of this devastating virus, there is a must-need situation to maximize the use of existing healthcare technologies such as the healthcare Internet of Things (H-IoT). In healthcare, patient wearable devices are widely recognized as a dormant technology with enormous capabilities to assess and combat various diseases, e.g., cough, seizure, temperature, heartbeat, and so on. As we know, in the H-IoT, patient-wearable devices are dispersed in an infrastructure-free environment that exposes them to several private and public coercion while accumulating and transmitting high sensitive data over the wireless communication channel. Therefore, security is the main concern of these applications, and thus, the primary focus of this article to outline the limitations and challenges in the present literature from 2019 to 2021, to identify the requirements of H-IoT applications used in the context of COVID-19. Following this, we will move one step ahead to explore the current security techniques adopted in these applications. Consequently, we will identify the network architectural, cryptographic, protocols, and operational security challenges during our study to recommend viable research directions and opportunities, which could be helpful and capable to minimize the network architecture, deployment, and maintenance cost with more productive outcomes.},
journal = {ACM Trans. Sen. Netw.},
month = may,
articleno = {54},
numpages = {25},
keywords = {Data privacy, authentication of patient wearable devices, healthcare IoT applications, COVID-19 and healthcare IoT applications}
}

@article{10.1145/3584986,
author = {Lin, Qi and Peng, Shuhua and Wu, Yuezhong and Liu, Jun and Jia, Hong and Hu, Wen and Hassan, Mahbub and Seneviratne, Aruna and Wang, Chun H.},
title = {Subject-adaptive Loose-fitting Smart Garment Platform for Human Activity Recognition},
year = {2023},
issue_date = {November 2023},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {19},
number = {4},
issn = {1550-4859},
url = {https://doi.org/10.1145/3584986},
doi = {10.1145/3584986},
abstract = {The ability to recognize and detect changes in human posture is important in a wide range of applications such as health care and human‚Äìcomputer interaction. Achieving this goal using loose-fit garments instrumented with sensors is particularly challenging, due to the complex interaction between garments and human body. Herein we present a method to detect and recognize human posture with casual loose-fitting smart garments integrated with highly sensitive, stretchable, optical transparent, and low-cost strain sensors. By attaching these sensors to an off-the-shelf casual jacket, we developed a smart loose-fitting sensing garment that enables posture recognition using a deep learning model, domain-adaptive Convolutional Neural Networks‚ÄìLong Short-Term Memory (CNN-LSTM). This deep learning model overcame the noise and variation due to the complex interaction between loose-fitting garments and human body. Considering that users‚Äô labeled data are usually not available in the training stage, an additional domain discriminator path on the conventional CNN-LSTM model has been introduced to further improve the adaptability. To evaluate the potential of this loose-fitting smart garment, three case studies were conducted under realistic conditions: recognitions of human activities, stationary postures with random hand movements and slouch. Our results demonstrate the potential of the proposed smart garment system for practical applications.},
journal = {ACM Trans. Sen. Netw.},
month = may,
articleno = {84},
numpages = {23},
keywords = {Strain sensor, smart garment, CNN-LSTM, domain adaptation}
}

@inproceedings{10.1145/3576842.3582382,
author = {Zhou, Hao and Lu, Taiting and Liu, Yilin and Zhang, Shijia and Liu, Runze and Gowda, Mahanth},
title = {One Ring to Rule Them All: An Open Source Smartring Platform for Finger Motion Analytics and Healthcare Applications},
year = {2023},
isbn = {9798400700378},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3576842.3582382},
doi = {10.1145/3576842.3582382},
abstract = {This paper presents OmniRing, an open-source smartring platform with IMU and PPG sensors for activity tracking and health analytics applications. Smartring platforms are on the rise because of comfortable wearing, with the market size expected to reach $92 million soon. Nevertheless, most existing platforms are either commercial and proprietary without details of software/hardware or use suboptimal PCB design resulting in bulky form factors, inconvenient for wearing in daily life. Towards bridging the gap, OmniRing presents an extensible design of a smartring with a miniature form factor, longer battery life, wireless communication, and water resistance so that users can wear it all the time. Towards this end, OmniRing exploits opportunities in SoC, and carefully integrates the sensing units with a microcontroller and BLE modules. The electronic components are integrated on both sides of a flexible PCB that is bent in the shape of a ring and enclosed in a flexible and waterproof case for smooth skin contact. The overall cost is under $25, with weight of 2.5g, and up to a week of battery life. Extensive usability surveys validate the comfort levels. To validate the sensing capabilities, we enable an application in 3D finger motion tracking. By extracting synthetic training data from public videos coupled with data augmentation to minimize the overhead of training data generation for a new platform, OmniRing designs a transformer-based model that exploits correlations across fingers and time to track 3D finger motion with an accuracy of 6.57mm. We also validate the use of PPG data from OmniRing for heart rate monitoring. We believe the platform can enable exciting applications in fitness tracking, metaverse, sports, and healthcare.},
booktitle = {Proceedings of the 8th ACM/IEEE Conference on Internet of Things Design and Implementation},
pages = {27‚Äì38},
numpages = {12},
location = {San Antonio, TX, USA},
series = {IoTDI '23}
}

@inproceedings{10.1145/3576842.3582385,
author = {Ghosh, Anurag and Iyengar, Srinivasan and Lee, Stephen and Rathore, Anuj and Padmanabhan, Venkata N},
title = {REACT: Streaming Video Analytics On The Edge With Asynchronous Cloud Support},
year = {2023},
isbn = {9798400700378},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3576842.3582385},
doi = {10.1145/3576842.3582385},
abstract = {Emerging Internet of Things (IoT) and mobile computing applications are expected to support latency-sensitive deep neural network (DNN) workloads. To realize this vision, the Internet is evolving towards an edge-computing architecture, where computing infrastructure is located closer to the end device to help achieve low latency. However, edge computing may have limited resources compared to cloud environments and thus, cannot run large DNN models that often have high accuracy. In this work, we develop REACT, a framework that leverages cloud resources to execute large DNN models with higher accuracy to improve the accuracy of models running on edge devices. To do so, we propose a novel edge-cloud fusion algorithm that fuses edge and cloud predictions, achieving low latency and high accuracy. We extensively evaluate our approach and show that our approach can significantly improve the accuracy compared to baseline approaches. We focus specifically on object detection in videos (applicable in many video analytics scenarios) and show that the fused edge-cloud predictions can outperform the accuracy of edge-only and cloud-only scenarios by as much as 50\%. REACT shows that for Edge AI, the choice between offloading and on-device inference is not binary ‚Äî redundant execution at cloud and edge locations complement each other when carefully employed.},
booktitle = {Proceedings of the 8th ACM/IEEE Conference on Internet of Things Design and Implementation},
pages = {222‚Äì235},
numpages = {14},
location = {San Antonio, TX, USA},
series = {IoTDI '23}
}

@inproceedings{10.1145/3576842.3582368,
author = {Liu, Li and Cao, Zhichao and Li, Tianxing},
title = {FaceTouch: Practical Face Touch Detection with a Multimodal Wearable System for Epidemiological Surveillance},
year = {2023},
isbn = {9798400700378},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3576842.3582368},
doi = {10.1145/3576842.3582368},
abstract = {In this paper, we propose FaceTouch, a low-power and versatile method that enables accurate face touch detection with a multimodal wearable system. FaceTouch consists of two sensing components, an inertial sensor on the wrist and a novel vibration sensor on the finger. We leverage the wrist inertial sensor to detect the face-touch gesture that the hand moves towards the face area. To achieve this goal in a computation-efficient manner, we develop a cascading classification model including three classifiers to filter out irrelevant gestures to significantly extend the battery life while keeping a high recall. Once a face-touch gesture is triggered, we activate the vibration sensor to detect touch events. We implement FaceTouch using commercial off-the-shelf hardware components and evaluate its performance with various user activities and false-positive behaviors. FaceTouch achieves 93.5\% F-1 score of face touch detection. The entire system only consumes 60.89 Œº W power on average in normal daily usage and 209.15 Œº W in extremely heavy usage, which is several magnitudes lower than the state-of-the-art systems, and FaceTouch can continuously detect face-touch events for 79 ‚Äì 273 days using a small 400 mWh battery depending on usage.},
booktitle = {Proceedings of the 8th ACM/IEEE Conference on Internet of Things Design and Implementation},
pages = {13‚Äì26},
numpages = {14},
location = {San Antonio, TX, USA},
series = {IoTDI '23}
}

@inproceedings{10.1145/3576914.3588016,
author = {Ledgerwood, Scott and Lewis, Jack and Karhoff, Jeffrey and Zhu, Qi and Whitlock, Matthew and Chelen, Julia},
title = {The Technical Development of an Extended Reality Research Testbed for Public Safety},
year = {2023},
isbn = {9798400700491},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3576914.3588016},
doi = {10.1145/3576914.3588016},
abstract = {The study of public safety technology, interventions, and training involves variable and hazardous conditions, which complicate observation and measurement. Informative evaluation approaches require reasonable representation of these conditions. Nonetheless, representing these conditions is resource intensive and difficult to replicate. For these reasons, public safety research may be limited by low-fidelity approaches that differ from the intended real-world application and by the inaccessibility of more realistic training. Extended Reality (XR) environments offer highly immersive and repeatable training for first responders, as well as controlled methods for technical research. In this paper, we discuss the development of the National Institute of Standards and Technology (NIST) Public Safety Immersive Test Center (PSITC): a testbed for multi-sensory extended reality-based research for public safety scenarios. We describe how the PSITC supports realistic training for public safety with an overview of the center‚Äôs design, development, and technical implementation. We discuss methods to address the challenges of building such a testbed for XR-based research, including integration of nascent technologies from various vendors, extensive use of sensor and imaging technologies, and intergovernmental cooperation between the First Responder Network Authority and the NIST Public Safety Communications Research Division. This paper introduces a model for the development of immersive centers built to evaluate prototypes for public safety operations, improve training for emergency response, and support public safety technology research.},
booktitle = {Proceedings of Cyber-Physical Systems and Internet of Things Week 2023},
pages = {292‚Äì296},
numpages = {5},
keywords = {Emergency Response, Haptics, Human-Centered Computing, Mixed / Extended / Augmented Reality, Optics, Public Safety, Training, User Experience, Virtual Reality},
location = {San Antonio, TX, USA},
series = {CPS-IoT Week '23}
}

@inproceedings{10.1145/3576914.3589559,
author = {Li, Yin and Nandakumar, Rajalakshmi},
title = {A Cognitive Scaling Mixer for Concurrent Ultrasound Sensing and Music Playback in Smart Devices},
year = {2023},
isbn = {9798400700491},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3576914.3589559},
doi = {10.1145/3576914.3589559},
abstract = {Recent advances in the field of acoustic sensing have enabled various applications in different domains including mobile health (biosignals monitoring), human-computer interaction (gesture recognition), and imaging. These acoustic sensing systems typically leverage the existing speakers and microphones in COTS smart devices by transforming them into a SONAR system that can detect minute motions in the environment. Although this is beneficial, the sensing systems might negatively affect the traditional utilities of these sensors, which is to play/record music and voice. For example, transmitting ultrasonic sound signals concurrently with music on a smart speaker can lead to overload in the speaker‚Äôs mixer, resulting in a degraded quality of both music and sensing. In this paper, we address this problem by cognitively adapting the sensing systems, so that they can work in concurrence with the music playback without any degradation in the music quality that can be interpreted by the users and also achieving optimal sensing accuracy. We enable this by formalizing it as an optimization problem that maximizes the transmitted sensing signal magnitude and minimizes the distortion conditioned on the concurrent music play. Specifically, we design a deep learning model that takes a high-frequency sine wave sensing signal and generates an adapted sensing signal that ensures both the accuracy of sensing and the quality of music play simultaneously. We conduct a small pilot study to validate our approach in a downstream task of respiration monitoring. The results show that the adapted signal achieves similar accuracy in respiration signal detection with scenarios with no concurrent music.},
booktitle = {Proceedings of Cyber-Physical Systems and Internet of Things Week 2023},
pages = {260‚Äì265},
numpages = {6},
keywords = {acoustic sensing},
location = {San Antonio, TX, USA},
series = {CPS-IoT Week '23}
}

@inproceedings{10.1145/3576842.3582364,
author = {Rathnayake, Darshana and Radhakrishnan, Meeralakshmi and Hwang, Inseok and Misra, Archan},
title = {LILOC: Enabling Precise 3D Localization in Dynamic Indoor Environments using LiDARs},
year = {2023},
isbn = {9798400700378},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3576842.3582364},
doi = {10.1145/3576842.3582364},
abstract = {We present LiLoc, a system for precise 3D localization and tracking of mobile IoT devices (e.g., robots) in indoor environments using multi-perspective LiDAR sensing. The key differentiators in our work are: (a) First, unlike traditional localization approaches, our approach is robust to dynamically changing environmental conditions (e.g., varying crowd levels, object placement/layout changes); (b) Second, unlike prior work on visual and 3D SLAM, LiLoc is not dependent on a pre-built static map of the environment and instead works by utilizing dynamically updated point clouds captured from both infrastructural-mounted LiDARs and LiDARs equipped on individual mobile IoT devices. To achieve fine-grained, near real-time location tracking, it employs complex 3D ‚Äòglobal‚Äô registration among the two point clouds only intermittently to obtain robust spot location estimates and further augments it with repeated simpler ‚Äòlocal‚Äô registrations to update the trajectory of IoT device continuously. We demonstrate that LiLoc can (a) support accurate location tracking with location and pose estimation error being &lt;=7.4cm and &lt;=3.2¬∞ respectively for 84\% of the time and the median error increasing only marginally (8\%), for correctly estimated trajectories, when the ambient environment is dynamic, (b) achieve a 36\% reduction in median location estimation error compared to an approach that uses only quasi-static global point cloud, and (c) obtain spot location estimates with a latency of only 973 msecs.},
booktitle = {Proceedings of the 8th ACM/IEEE Conference on Internet of Things Design and Implementation},
pages = {158‚Äì171},
numpages = {14},
keywords = {3D Localization, Dynamic Indoor Environments, LiDAR, Pose Estimation, Trajectory Tracking},
location = {San Antonio, TX, USA},
series = {IoTDI '23}
}

@inproceedings{10.1145/3583120.3586969,
author = {Yang, Kang and Chen, Yuning and Su, Tingruixiang and Du, Wan},
title = {Link Quality Modeling for LoRa Networks in Orchards},
year = {2023},
isbn = {9798400701184},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3583120.3586969},
doi = {10.1145/3583120.3586969},
abstract = {LoRa networks have been deployed in many orchards for environmental monitoring and crop management. An accurate propagation model is essential for efficiently deploying a LoRa network in orchards, e.g., determining gateway coverage and sensor placement. Although some propagation models have been studied for LoRa networks, they are not suitable for orchard environments, because they do not consider the shadowing effect on wireless propagation caused by the ground and tree canopies. This paper presents FLog, a propagation model for LoRa signals in orchard environments. FLog leverages a unique feature of orchards, i.e., all trees have similar shapes and are planted regularly in space. We develop a 3D model of the orchards. Once we have the location of a sensor and a gateway, we know the mediums that the wireless signal traverse. Based on this knowledge, we generate the First Fresnel Zone (FFZ) between the sender and the receiver. The intrinsic path loss exponents (PLE) of all mediums can be combined into a classic Log-Normal Shadowing model in the FFZ. Extensive experiments in almond orchards show that FLog reduces the link quality estimation error by 42.7\% and improves gateway coverage estimation accuracy by 70.3\%, compared with a widely-used propagation model.},
booktitle = {Proceedings of the 22nd International Conference on Information Processing in Sensor Networks},
pages = {27‚Äì39},
numpages = {13},
keywords = {First Fresnel Zone, Link quality, LoRa, Low-Power Wide-Area Networks, Signal propagation model},
location = {San Antonio, TX, USA},
series = {IPSN '23}
}

@inproceedings{10.1145/3583120.3586957,
author = {Perez-Ramirez, Daniel F. and P\'{e}rez-Penichet, Carlos and Tsiftes, Nicolas and Voigt, Thiemo and Kosti\'{c}, Dejan and Boman, Magnus},
title = {DeepGANTT: A Scalable Deep Learning Scheduler for Backscatter Networks},
year = {2023},
isbn = {9798400701184},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3583120.3586957},
doi = {10.1145/3583120.3586957},
abstract = {Novel backscatter communication techniques enable battery-free sensor tags to interoperate with unmodified standard IoT devices, extending a sensor network‚Äôs capabilities in a scalable manner. Without requiring additional dedicated infrastructure, the battery-free tags harvest energy from the environment, while the IoT devices provide them with the unmodulated carrier they need to communicate. A schedule coordinates the provision of carriers for the communications of battery-free devices with IoT nodes. Optimal carrier scheduling is an NP-hard problem that limits the scalability of network deployments. Thus, existing solutions waste energy and other valuable resources by scheduling the carriers suboptimally. We present DeepGANTT, a deep learning scheduler that leverages graph neural networks to efficiently provide near-optimal carrier scheduling. We train our scheduler with optimal schedules of relatively small networks obtained from a constraint optimization solver, achieving a performance within 3\% of the optimum. Without the need to retrain, our scheduler generalizes to networks 6 \texttimes{} larger in the number of nodes and 10 \texttimes{} larger in the number of tags than those used for training. DeepGANTT breaks the scalability limitations of the optimal scheduler and reduces carrier utilization by up to compared to the state-of-the-art heuristic. As a consequence, our scheduler efficiently reduces energy and spectrum utilization in backscatter networks.},
booktitle = {Proceedings of the 22nd International Conference on Information Processing in Sensor Networks},
pages = {163‚Äì176},
numpages = {14},
keywords = {combinatorial optimization, machine learning, scheduling, wireless backscatter communications},
location = {San Antonio, TX, USA},
series = {IPSN '23}
}

@inproceedings{10.1145/3576842.3582387,
author = {Zainab, Tayyaba and Karstens, Jens and Landsiedel, Olaf},
title = {LightEQ: On-Device Earthquake Detection with Embedded Machine Learning},
year = {2023},
isbn = {9798400700378},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3576842.3582387},
doi = {10.1145/3576842.3582387},
abstract = {The detection of earthquakes in seismological time series is central to observational seismology. Generally, seismic sensors passively record data and transmit it to the cloud or edge for integration, storage, and processing. However, transmitting raw data through the network is not an option for sensors deployed in harsh environments like underwater, underground, or in rural areas with limited connectivity. This paper introduces an efficient data processing pipeline and a set of lightweight deep-learning models for seismic event detection deployable on tiny devices such as microcontrollers. We conduct an extensive hyperparameter search and devise three lightweight models. We evaluate our models using the Stanford Earthquake Dataset and compare them with a basic STA/LTA detection algorithm and the state-of-the-art machine learning models, i.e., CRED, EQtransformer, and LCANet. For example, our smallest model consumes 193 kB of RAM and has an F1 score of 0.99 with just 29k parameters. Compared to CRED, which has an F1 score of 0.98 and 293k parameters, we reduce the number of parameters by a factor of 10. Deployed on Cortex M4 microcontrollers, the smallest version of LightEQ-NN has an inference time of 932 ms for 1 minute of raw data, an energy consumption of 5.86 mJ, and a flash requirement of 593 kB. Our results show that resource-efficient, on-device machine learning for seismological time series data is feasible and enables new approaches to seismic monitoring and early warning applications.},
booktitle = {Proceedings of the 8th ACM/IEEE Conference on Internet of Things Design and Implementation},
pages = {130‚Äì143},
numpages = {14},
keywords = {Deep Neural Networks, Earthquake detection, Edge AI, Internet of Things, Low-Power, On-device, Seismological data analysis},
location = {San Antonio, TX, USA},
series = {IoTDI '23}
}

@inproceedings{10.1145/3583120.3586959,
author = {Feng, Justin and Jacques, Timothy and Abari, Omid and Sehatbakhsh, Nader},
title = {Everything has its Bad Side and Good Side: Turning Processors to Low Overhead Radios Using Side-Channels},
year = {2023},
isbn = {9798400701184},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3583120.3586959},
doi = {10.1145/3583120.3586959},
abstract = {Side-channels have traditionally been exploited as a means of uncovering sensitive information such as cryptographic keys from a computing device. In particular, past work has shown that electromagnetic (EM) radiation from a device‚Äôs processor and memory during the execution of code and data can be used by attackers to extract private information. In contrast, instead of considering side-channels and electromagnetic radiation as vulnerabilities, we see them as opportunities for wireless communication on resource-limited IoT devices. We present SideComm, a side-channel-based communication system that leverages processors‚Äô EM side-channels to enable resource-limited IoT devices to wirelessly send their data without having any radios. The main advantage of this approach is completely eliminating the need for a conventional radio and antenna, which offers energy savings, simplicity, and flexibility for IoT devices. Our evaluation demonstrates SideComm‚Äôs ability to achieve a communication range of more than 10m (enabling ‚â• 3 dB SNR at 15m) and to work in non-line-of-sight scenarios, such as around corners and through walls. We believe SideComm can enable increased connectivity for many resource-constrained IoT devices in smart environments.},
booktitle = {Proceedings of the 22nd International Conference on Information Processing in Sensor Networks},
pages = {288‚Äì301},
numpages = {14},
keywords = {Physical side-channels, embedded systems, low overhead communication},
location = {San Antonio, TX, USA},
series = {IPSN '23}
}

@inproceedings{10.1145/3576914.3588338,
author = {Morales-Badajoz, Anthony Manuel and Elieh, Neville and Diederich, April and Sadler, Elliot and Glover, Jasmine and Nizampatnam, Manoj and Israel, Troy and Wang, Andrew and Zhang, Larry and Besnilian, Annette and George, Andreas and Miller, Julie and Jiang, Xunfei and Li, Bingbing},
title = {Astro Cultivators: Autonomous Growth System for Space Farming based on Machine Vision and Multi-Sensor Fusion},
year = {2023},
isbn = {9798400700491},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3576914.3588338},
doi = {10.1145/3576914.3588338},
abstract = {The autonomous space farming system could be used to grow self-pollinating crops in space exploration missions that require no human intervention. Our goal is to utilize hyper spectral imaging and traditional imaging to allow for machine learning models to be used and retrained for not only our crops, but others as well. Temperature, humidity, and pressure sensors coupled with a robotic arm will care and tend to the crops at every stage of development. This system can decrease crew members‚Äô input needed to operate the plant growth systems in deep space by providing autonomous monitoring, real-time data reporting, ambient environment management, automatic harvesting, and cleaning. Crops with high nutrient content, high acceptability ratings, dwarf growth habits, and short harvest cycles (Sugar Ann Snap Peas and Red Robin Tomato) will initially be grown in this modular system which has the potential to be scale up or down, depending on the mission. A variety of ‚Äúpick and eat‚Äù crops can be grown to provide palatable, safe, nutritious foods that are familiar foods for crews to consume. To reduce resupply from Earth, the seeds from these crops have the potential to be saved and used to grow continuous generations of crops.},
booktitle = {Proceedings of Cyber-Physical Systems and Internet of Things Week 2023},
pages = {385‚Äì390},
numpages = {6},
keywords = {Image Classification, Machine Vision, Multi-Sensor Fusion, Object Detection, Robotic Harvesting},
location = {San Antonio, TX, USA},
series = {CPS-IoT Week '23}
}

@inproceedings{10.1145/3552326.3567483,
author = {Park, Heejin and Lin, Felix Xiaozhu},
title = {Safe and Practical GPU Computation in TrustZone},
year = {2023},
isbn = {9781450394871},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3552326.3567483},
doi = {10.1145/3552326.3567483},
abstract = {For mobile devices, it is compelling to run sensitive GPU computation within a TrustZone trusted execution environment (TEE). To minimize GPU software deployed in TEE, the replay approach is promising: record CPU/GPU interactions on a full GPU stack outside the TEE; replay the interactions inside the TEE without the GPU stack. A key dilemma is that the recording process must both (1) occur in a safe environment and (2) access the exact GPU models to be used for replay. To this end, we present a novel recording architecture called GR-T: a mobile device possessing the GPU hardware collaborates with a GPU-less cloud service which runs the GPU software; the two parties exercise the GPU hardware/software jointly for recording. To overcome the resultant network delays, GR-T contributes optimizations: register access deferral, speculation, and meta-only synchronization. These techniques reduce the recording delay by 20x, from hundreds of seconds to tens of seconds. Replay-based GPU computation incurs 25\% lower delays compared to native execution outside TEE. The code is available at https://github.com/bakhi/GPUReplay.},
booktitle = {Proceedings of the Eighteenth European Conference on Computer Systems},
pages = {505‚Äì520},
numpages = {16},
keywords = {secure GPU computation, record and replay, dry run, GPU stack, TrustZone, TEE},
location = {Rome, Italy},
series = {EuroSys '23}
}

@inproceedings{10.1145/3577148.3577156,
author = {Auccahuasi, Wilver and Meza, Sandra and Rojas, Karin and Linares, Oscar and Inciso-Rojas, Miryam and Auccahuasi, Aly and Flores, Edward and Felix, Edwin and Aybar, Justiniano and Pando-Ezcurra, Tamara},
title = {Methodology for Interoperability between Health Information Systems, for Information Management and Decision-Making},
year = {2023},
isbn = {9781450397124},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3577148.3577156},
doi = {10.1145/3577148.3577156},
abstract = {ICTS are revolutionizing not only the way of communication and interrelation between people, but also between information systems, in such a way that they allow the exchange of information between computer systems, a method will be developed to take advantage of the functionalities of the information systems dedicated to the health area, where information related to the health area can be shared, to improve the procedures related to decision making, which are vital in emergency situations, as in the case of an emergency care where it is required to know if the patient has some type of insurance or if he/she is allergic to certain medications, this information is important if an online consultation is made with the information systems. In this sense the information systems that work in the Health System, communicates with the information system of the insurance companies, to request the data of the insurance policy, as well as the hospital systems can communicate with the service providers to request medical supplies, among other applications, thanks to the interoperability, based on the XML communication standard that in its essence is the basis of the HL7 protocol, the results of the proposed methodology allow the interaction between systems, if as a development and application guide where you can create and read these messages based on XML, which can be applicable and scalable.},
booktitle = {Proceedings of the 2022 5th International Conference on Sensors, Signal and Image Processing},
pages = {43‚Äì46},
numpages = {4},
keywords = {Interoperability, Medical data, Message, Systems, XML},
location = {Nanjing, China},
series = {SSIP '22}
}

